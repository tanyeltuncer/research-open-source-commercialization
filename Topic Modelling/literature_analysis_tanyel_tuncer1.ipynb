{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "026ac02c",
   "metadata": {},
   "source": [
    "## Literature analysis with non-negative matrix factorization topic model \n",
    "\n",
    "Project: Scientific Anaylsis <br>\n",
    "Documentation: Master Thesis <br>\n",
    "Author: Tanyel Tunçer <br>\n",
    "<br>\n",
    "\n",
    "\n",
    "### Data Preparation \n",
    "\n",
    "Step 1: Define a search string <br>\n",
    "Step 2: Query scientific data based on the defined search string  <br>\n",
    "Step 3: Export results <br>\n",
    "Step 4: Import data from local to model\n",
    "<br>\n",
    "\n",
    "### Analysis Instructions\n",
    "\n",
    "Step 1: Import data <br>\n",
    "Step 2: Pre-process imported data <br>\n",
    "Step 3: Exploratory data analysis <br>\n",
    "Step 4: Define model parameter <br>\n",
    "Step 5: Calculate topic coherence Cv <br>\n",
    "Step 7: Execute non-negative matrix factorization algoritmn\n",
    "<br>\n",
    "\n",
    "### Technical Preparation for model execution \n",
    "\n",
    "Install following version before importing libaries <br>\n",
    "Note: All results from the thesis are identified based on the listed libary versions, other version can result in different result <br> <br>\n",
    "pandas: 1.2.4  <br>\n",
    "numpy: 1.19.2 <br>\n",
    "nltk: 3.7 <br>\n",
    "plotly: 5.8.0 <br>\n",
    "sklearn 1.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6057e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.get_option(\"display.max_rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0ec32a",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1176834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# get current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "#get files in directory\n",
    "files = os.listdir(cwd) \n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24a1ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change data path. Data will be automatically imported from the given data path. \n",
    "text = pd.read_csv(\"C:/Users/tanye/Desktop/Literature Review/Literature 1/scopus.csv\", sep = \",\")\n",
    "\n",
    "#text = pd.read_csv(document_dir, delimiter = \",\")\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25329cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd86c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a218fa35",
   "metadata": {},
   "source": [
    "## 2. Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1951fb35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "text[\"Cited by\"] = text[\"Cited by\"].fillna(0)\n",
    "\n",
    "text.drop(text[text[\"Abstract\"]==\"[No abstract available]\"].index, inplace=True)\n",
    "#text = text[text[\"Cited by\"] >= 150]\n",
    "\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa1df9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = text.copy()\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    text = [x for x in tokens if x not in nltk.corpus.stopwords.words(\"english\")]\n",
    "    return text\n",
    "\n",
    "def remove_punctuation(tokens):\n",
    "    import string\n",
    "    text = \" \".join([x for x in tokens if x not in string.punctuation])\n",
    "    text = \" \".join([x for x in tokens if x not in string.digits])\n",
    "    return text\n",
    "\n",
    "def remove_words(tokens):\n",
    "    words = [\"δ18o\", \"paper\"]\n",
    "    text = [x for x in tokens if x not in words]\n",
    "    text = [x for x in text if len(x) >= 3]\n",
    "    #text = [x for x in text if x != \",\"]\n",
    "    return text\n",
    "\n",
    "    \n",
    "def get_pos_tag(pos_tag):\n",
    "    if pos_tag in [\"JJ\", \"JJR\", \"JJS\"]:\n",
    "        return wordnet.ADJ\n",
    "    elif pos_tag in [\"RB\", \"RBR\", \"RBS\"]:\n",
    "        return wordnet.ADV\n",
    "    elif pos_tag in [\"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"]:\n",
    "        return wordnet.VERB\n",
    "    else: \n",
    "        return wordnet.NOUN\n",
    "\n",
    "def lemmatize_words(tokens):\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    words = \" \".join([WordNetLemmatizer().lemmatize(i) for i in tokens])\n",
    "    return words\n",
    "\n",
    "def extract_noun (tokens):\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    tags = [\"NN\", \"NNS\", \"NNP\", \"NNPS\"]\n",
    "    words = [i[0] for i in pos_tags if i[1] in tags]\n",
    "    return words\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdc2f4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus[\"Abstract\"] = corpus[\"Abstract\"].map(lambda x: x.lower())\n",
    "corpus[\"Abstract\"] = corpus[\"Abstract\"].map(lambda x: RegexpTokenizer(r\"\\w+\").tokenize(x))\n",
    "corpus[\"Abstract\"] = corpus[\"Abstract\"].apply(lambda x: remove_words(x))\n",
    "corpus[\"Abstract\"] = corpus[\"Abstract\"].map(lambda x: remove_stopwords(x))\n",
    "corpus[\"Abstract\"] = corpus[\"Abstract\"].apply(lambda x: extract_noun(x))\n",
    "corpus[\"Abstract\"] = corpus[\"Abstract\"].apply(lambda x: lemmatize_words(x))\n",
    "print(\"Data pre-processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af235aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original data: \" + text[\"Abstract\"][0])\n",
    "print(\"\")\n",
    "print(\"Pre-processed data: \" + corpus[\"Abstract\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21035263",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafed4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors1 = [\"#023373\"]\n",
    "colors2 = [\"#023373\", \"#979797\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8006c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line(df, x, y, z):\n",
    "    \"\"\"\n",
    "    Plot line chart.\n",
    "    \n",
    "    df = dataframe \n",
    "    x = categorical variable\n",
    "    y = numerical variable \n",
    "    z = color_code\n",
    "    \n",
    "    \"\"\"\n",
    "    fig = px.line(\n",
    "        data_frame = df,\n",
    "        x = x, \n",
    "        y = y,\n",
    "        color = z,\n",
    "        color_discrete_sequence= colors2,\n",
    "        template=\"simple_white\",\n",
    "        width=1000,        \n",
    "        height=400,\n",
    "        log_x = False\n",
    "    )\n",
    "        \n",
    "    return fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e810164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_chart(df, x, y):\n",
    "    \"\"\"\n",
    "    Plot bar chart.\n",
    "    \n",
    "    df = dataframe\n",
    "    x = categorical variable\n",
    "    y = numerical variable \n",
    "    \n",
    "    \"\"\"\n",
    "    fig = px.bar(\n",
    "        data_frame = df,\n",
    "        x = x,\n",
    "        y = y,\n",
    "        color_discrete_sequence=[\"#03658C\"],\n",
    "        template=\"simple_white\",\n",
    "        orientation = \"v\",\n",
    "        text = y,\n",
    "        facet_col = \"Period\",\n",
    "        facet_col_wrap=2,\n",
    "        facet_row_spacing = 0.15,        \n",
    "        width=1000,        \n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(font=dict(family=\"Times New Roman\",size=12),\n",
    "                      xaxis={\"categoryorder\":\"category ascending\"}\n",
    "                     )\n",
    "    \n",
    "    fig.for_each_annotation(lambda x: x.update(text = x.text.replace(\"Period=\", \"\")))\n",
    "    fig.update_yaxes(title_text = \"\", visible = False)\n",
    "    fig.update_xaxes(title_text = \"Topic\")\n",
    "    \n",
    "    \n",
    "    return fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c409c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def barh_chart(df, x, y, title):\n",
    "    \"\"\"\n",
    "    Plot bar chart.\n",
    "    \n",
    "    df = dataframe\n",
    "    x = categorical variable\n",
    "    y = numerical variable \n",
    "    \n",
    "    \"\"\"\n",
    "    fig = px.bar(\n",
    "        data_frame = df,\n",
    "        x = x,\n",
    "        y = y,\n",
    "        color_discrete_sequence=[\"#03658C\"],\n",
    "        template=\"simple_white\",\n",
    "        orientation = \"h\",\n",
    "        text = x,\n",
    "        width=1000,        \n",
    "        height=800\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(font=dict(family=\"Times New Roman\",size=12),\n",
    "                      yaxis={'categoryorder':'max ascending'},\n",
    "                      title={\n",
    "                          'text': title,\n",
    "                          'y':0.98,\n",
    "                          'x':0.5,\n",
    "                          'xanchor': 'center',\n",
    "                          'yanchor': 'top'}\n",
    "                     )\n",
    "    \n",
    "    fig.update_yaxes(title_text = \"\")\n",
    "    fig.update_xaxes(title_text = \"\", visible = False)\n",
    "    \n",
    "    \n",
    "    return fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a08afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram(df, x, n_bins, title): \n",
    "    \"\"\"\n",
    "    Plot histogram.\n",
    "    \n",
    "    df = dataframe\n",
    "    x = categorical variable\n",
    "    n_bins = bin size \n",
    "    \n",
    "    \"\"\"\n",
    "    fig = px.histogram(\n",
    "        data_frame=df,\n",
    "        x = x,\n",
    "        marginal= \"box\",\n",
    "        color_discrete_sequence=[\"#03658C\"],\n",
    "        nbins=n_bins,\n",
    "        template=\"simple_white\",\n",
    "        width=1000,        \n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        font_family=\"Times New Roman\", \n",
    "        title={\n",
    "            'text': title,\n",
    "            'y':0.95,\n",
    "            'x':0.5,\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top'}\n",
    "    )\n",
    "\n",
    "    \n",
    "    return fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2026840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(df):\n",
    "    \"\"\"\n",
    "    Plot scatter plot.\n",
    "    \n",
    "    df = dataframe with x and y coordinates \n",
    "    \n",
    "    \"\"\"\n",
    "    fig = px.scatter(\n",
    "        data_frame = df,\n",
    "        #color = topics,\n",
    "        opacity = 0.5,\n",
    "        title = None,\n",
    "        color_discrete_sequence=[\"#023373\", \"#03588C\", \"#03658C\", \"#6CBAD9\", \"#F2F2F2\" ],\n",
    "        template=\"simple_white\",\n",
    "        orientation = \"h\",\n",
    "        width=1000,        \n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        font_family=\"Times New Roman\" \n",
    "    )\n",
    "    \n",
    "    return fig.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01f7a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def area(df, x, y, z):  \n",
    "    \"\"\"\n",
    "    Plot area chart.\n",
    "    \n",
    "    df = dataframe \n",
    "    x = categorical variable\n",
    "    y = numerical variable \n",
    "    z = topics\n",
    "    \n",
    "    \"\"\"\n",
    "    fig = px.area(\n",
    "        data_frame = df,\n",
    "        x = x,\n",
    "        y = y,\n",
    "        template = \"simple_white\",\n",
    "        color_discrete_sequence = colors1,\n",
    "        facet_col = z,\n",
    "        facet_col_wrap=2,\n",
    "        facet_row_spacing = 0.1,\n",
    "        height = 1000,\n",
    "        width = 1000\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        font_family=\"Times New Roman\",\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.for_each_annotation(lambda x: x.update(text = x.text.replace(\"variable=\", \"\")))\n",
    "    \n",
    "    fig.update_xaxes(title_text = \"\")\n",
    "    fig.update_yaxes(title_text = \"\")\n",
    "    \n",
    "    return fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f88e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_words(model, feature_names, n_top_words):\n",
    "    \n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_features_ind = topic.argsort()[: -n_top_words - 1 : -1]\n",
    "        top_features = [feature_names[i] for i in top_features_ind]\n",
    "        weights = topic[top_features_ind]\n",
    "\n",
    "        fig = px.bar(\n",
    "            x = weights,\n",
    "            y = top_features,\n",
    "            text =np.round(weights, 2),\n",
    "            orientation = \"h\",\n",
    "            color_discrete_sequence=[\"#03658C\"],\n",
    "            template = \"simple_white\", \n",
    "            #title=\"Long-Form Input\",\n",
    "            title = \"Topic \" + str(topic_idx),\n",
    "            height = 400,\n",
    "            width = 400\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        fig.update_layout(\n",
    "            font_family=\"Times New Roman\",\n",
    "            showlegend=False,\n",
    "            yaxis={'categoryorder':'max ascending'},\n",
    "            title={\n",
    "                'y':0.9,\n",
    "                'x':0.5,\n",
    "                'xanchor': 'center',\n",
    "                'yanchor': 'top'}\n",
    "        )\n",
    "        \n",
    "        fig.for_each_annotation(lambda x: x.update(text = x.text.replace(\"topic=\", \" \")))\n",
    "        fig.update_yaxes(title_text = \"\")\n",
    "        fig.update_xaxes(title_text = \"\", visible = False)\n",
    "        \n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5675b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig_2d(df, x, y, document, color, topic_order):\n",
    "    fig = px.scatter(\n",
    "        df, \n",
    "        x=x, \n",
    "        y=y,\n",
    "        color = color, labels={\"topic\": \"Themen\"},\n",
    "        hover_name = document,\n",
    "        opacity = 0.85,\n",
    "        template=\"simple_white\",\n",
    "        width=800,        \n",
    "        height=500,\n",
    "        color_discrete_sequence=[\"red\", \"green\", \"blue\", \"orange\", \"goldenrod\", \"magenta\"],\n",
    "        category_orders= topic_order\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(showlegend=True)\n",
    "\n",
    "\n",
    "    fig.update_xaxes(visible = False)\n",
    "    fig.update_yaxes(visible = False)\n",
    "\n",
    "    return fig.show()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e598113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig_3d(df, x, y, z, color):\n",
    "    fig = px.scatter_3d(\n",
    "        df, \n",
    "        x=x, \n",
    "        y=y,\n",
    "        z=z,\n",
    "        color = color,\n",
    "        #hover_name = \"Topic\",\n",
    "        opacity = 0.85,\n",
    "        template=\"simple_white\",\n",
    "        width=1000,        \n",
    "        height=800,\n",
    "        color_continuous_scale = colors2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(showlegend=False)\n",
    "\n",
    "\n",
    "    fig.update_xaxes(visible = False)\n",
    "    fig.update_yaxes(visible = False)\n",
    "\n",
    "    return fig.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06ead78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tm_dist_period(df):\n",
    "    df = df.copy()\n",
    "    df = df.groupby([\"Year\", \"Topic\"]).size()\n",
    "    df = pd.DataFrame(df).reset_index().rename(columns={0:\"Count\"})\n",
    "\n",
    "    df[\"Year\"] = df[\"Year\"].astype(int).astype(str)\n",
    "    df[\"Topic\"] = df[\"Topic\"].astype(str)\n",
    "\n",
    "    conditions = [\n",
    "        (df[\"Year\"] <= \"1997\"),\n",
    "        (df[\"Year\"] >= \"1998\") & (df[\"Year\"] <= \"2005\"),\n",
    "        (df[\"Year\"] >= \"2006\") & (df[\"Year\"] <= \"2013\"),\n",
    "        (df[\"Year\"] >= \"2014\")\n",
    "    ]\n",
    "\n",
    "    titles = [\"a) betweeen 1977 and 1997\",\n",
    "              \"b) betweeen 1998 and 2005\", \n",
    "              \"c) betweeen 2006 and 2013\",\n",
    "              \"d) betweeen 2014 and 2020\"]\n",
    "\n",
    "    df[\"Period\"] = np.select(conditions, titles)\n",
    "    df = df.groupby(by = [\"Period\", \"Topic\"]).agg(Count = (\"Count\", np.sum)).reset_index()\n",
    "    \n",
    "    fig = bar_chart(df, df[\"Topic\"].astype(\"int64\"), df[\"Count\"])\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f1f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_distribution(df):\n",
    "    topic_count = pd.DataFrame()\n",
    "\n",
    "    topic_count[\"Topic\"] = df.Topic\n",
    "    topic_count = topic_count.groupby(\"Topic\").agg(\n",
    "        Total_Documents = (\"Topic\", np.size),\n",
    "        Proportion = (\"Topic\", np.size))\n",
    "\n",
    "    topic_count[\"Proportion\"] = topic_count[\"Proportion\"].apply(lambda x: round((x * 100) / len(corpus), 2))\n",
    "\n",
    "    return topic_count.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d142247",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(text, \"Cited by\", 150, \"Histogramm der Anzahl der Zitationen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a307406",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_journals = (text.groupby(by = [\"Source title\"]).size().reset_index(name=\"Totel Documents\"))\n",
    "top_journals = top_journals.sort_values(\"Totel Documents\", ascending=False)\n",
    "\n",
    "top_journals = top_journals[:15]\n",
    "barh_chart(top_journals, y = \"Source title\", x = \"Totel Documents\", title = \"Top 15 Journals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a93ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(text, \"Year\", (len(text[\"Year\"].unique())), \"Histogram of the publication years\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08055ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[\"word_count\"] = corpus[\"Abstract\"].apply(lambda x: len(str(x).split()))\n",
    "histogram(corpus, \"word_count\", 30, \"Histogram of the number of words in an abstract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e955bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = pd.Series(' '.join(corpus[\"Abstract\"]).split()).value_counts()[:30]\n",
    "top_words = pd.DataFrame(top_words, columns = [\"count\"])\n",
    "\n",
    "barh_chart(top_words, \"count\", top_words.index, \"Top 30 words in the corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c07450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_gram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(2, 3)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    \n",
    "    sum_words = bag_of_words.sum(axis=0).round(2)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n",
    "top_words = get_top_n_gram(corpus[\"Abstract\"], 30)\n",
    "df3 = pd.DataFrame(top_words, columns = [\"n_gram\", \"count\"])\n",
    "\n",
    "barh_chart(df3, \"count\", \"n_gram\", \"Top 30 words in the corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3647d1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_popularity(model, df):\n",
    "    topic_distribution = df.iloc[:, 5:]\n",
    "    topic_distribution[\"Year\"] = df.Year\n",
    "    \n",
    "    ytime = np.unique(df['Year'])\n",
    "    \n",
    "    topic_distributions_by_year = np.zeros([len(ytime), model.n_components])\n",
    "\n",
    "    topic_distribution_by_year = topic_distribution.groupby(by = \"Year\").sum()\n",
    "    topic_distribution_by_year = topic_distribution_by_year / np.sum(topic_distribution_by_year)\n",
    "    topic_distribution_by_year = topic_distribution_by_year.reset_index().melt(id_vars = \"Year\")\n",
    "    \n",
    "    return topic_distribution_by_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69707096",
   "metadata": {},
   "source": [
    "## 4. Model parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca61a30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = None\n",
    "n_top_words = 10\n",
    "\n",
    "k_min = 3\n",
    "k_max = 30 + 1\n",
    "k_step = 1\n",
    "\n",
    "max_df = 0.95\n",
    "min_df = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830da127",
   "metadata": {},
   "source": [
    "## 5. Calculate Topic Coherence Cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4bd5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gensim_data(corpus):\n",
    "    from gensim.models.coherencemodel import CoherenceModel\n",
    "    from gensim.corpora.dictionary import Dictionary\n",
    "   \n",
    "    gensim_data = [i.split( ) for i in corpus]\n",
    "    gensim_dict = Dictionary(gensim_data)\n",
    "\n",
    "    gensim_dict.filter_extremes(no_below=3, no_above=0.95, keep_n=5000)\n",
    "\n",
    "    gensim_corpus = [gensim_dict.doc2bow(text) for text in gensim_data]\n",
    "   \n",
    "    return gensim_data, gensim_dict, gensim_corpus\n",
    "gensim_data, gensim_dict, gensim_corpus = gensim_data(corpus[\"Abstract\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4062082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.nmf import Nmf\n",
    "from operator import itemgetter\n",
    "\n",
    "coherence = []\n",
    "n_topic = list(np.arange(k_min, k_max, k_step))\n",
    "for i in n_topic:\n",
    "    gensim_nmfModel = Nmf(\n",
    "        corpus=gensim_corpus,\n",
    "        num_topics=i,\n",
    "        id2word=gensim_dict,\n",
    "        chunksize=2000,\n",
    "        passes=5,\n",
    "        kappa=.1,\n",
    "        minimum_probability=0.01,\n",
    "        w_max_iter=300,\n",
    "        w_stop_condition=0.0001,\n",
    "        h_max_iter=100,\n",
    "        h_stop_condition=0.001,\n",
    "        eval_every=10,\n",
    "        normalize=True,\n",
    "        random_state=1\n",
    "    )\n",
    "  \n",
    "    cm = CoherenceModel(\n",
    "        model=gensim_nmfModel,\n",
    "        texts=gensim_data,\n",
    "        dictionary=gensim_dict,\n",
    "        coherence= \"c_v\"\n",
    "    )\n",
    "  \n",
    "    coherence.append((cm.get_coherence(), i, \"NMF\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e8ec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_coherence_values = pd.DataFrame(coherence, columns = [\"Coherence value Cv\", \"Number of subjects\", \"Algorithm\"])\n",
    "plot_coherence = line(nmf_coherence_values, \"Number of subjects\", \"Coherence value Cv\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b028fdb6",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Non-negative Matrix Factorization Topic Modell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6b6e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df = max_df, \n",
    "                                   min_df = min_df,\n",
    "                                   max_features = n_features, \n",
    "                                   ngram_range = (1,2)\n",
    "                                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d209938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_dtm = tfidf_vectorizer.fit_transform(corpus[\"Abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1eb84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_tm = NMF(n_components = 5, \n",
    "             random_state=1,\n",
    "             alpha=.1,\n",
    "             solver = \"mu\",\n",
    "             max_iter = 1000,\n",
    "             beta_loss=\"frobenius\",\n",
    "             l1_ratio=.5\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35631ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_tm = nmf_tm.fit(tfidf_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca461ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = tfidf_vectorizer.transform(corpus[\"Abstract\"])\n",
    "W = nmf_tm.components_\n",
    "H = nmf_tm.fit_transform(V) \n",
    "\n",
    "\n",
    "print(\"Non-negative Matrix Factorization Modell\")\n",
    "print('V = {} x {}'.format(V.shape[0], V.shape[1]))\n",
    "print('W = {} x {}'.format(W.shape[0], W.shape[1]))\n",
    "print('H = {} x {}'.format(H.shape[0], H.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a42e308",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_df = pd.DataFrame(\n",
    "    {\"Topic\" : np.argmax(H, axis = 1), \n",
    "     \"Terms\" : corpus[\"Abstract\"], \n",
    "     \"Keywords\" : corpus[\"Author Keywords\"], \n",
    "     \"Title\" : corpus[\"Titles\"], \n",
    "     \"DOI\" : corpus[\"DOI\"], \n",
    "     \"Year\" : corpus[\"Year\"],\n",
    "     \"Journal\" : corpus[\"Source title\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f84f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_df = nmf_df.reset_index()\n",
    "\n",
    "topic_names = [\"Topic \" + str(i) for i in range(nmf_tm.n_components)]\n",
    "\n",
    "df_document_topic = pd.DataFrame(np.round(H, 2), columns = topic_names)\n",
    "\n",
    "nmf_df = nmf_df.join(df_document_topic)\n",
    "nmf_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71ccbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_distribution(nmf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e4ee78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "plot_top_words(nmf_tm, feature_names, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127ca97a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "area(topic_popularity(nmf_tm, nmf_df), \"Year\", \"value\", \"variable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63dfb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_dist_period(nmf_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b9a960",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_df.to_excel(\"C:/Users/tanye/Desktop/Literature Review/Literature 1/research-dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b07a2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
