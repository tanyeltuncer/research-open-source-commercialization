"Authors","Author full names","Author(s) ID","Titles","Year","Source title","DOI","Cited by","Link","Abstract","Author Keywords","Document Type","Source"
"Karthik Pai B.H.; Pai V.; Devidas; Deeksh S.N.; Rao R.","Karthik Pai, B.H. (57214719472); Pai, Vasudeva (57202778194); Devidas (57210970005); Deeksh, S.N. (57211600136); Rao, Rahul (57211606723)","57214719472; 57202778194; 57210970005; 57211600136; 57211606723","A prologue of git and SVN","2019","International Journal of Engineering and Advanced Technology","10.35940/ijeat.A9451.109119","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074576507&doi=10.35940%2fijeat.A9451.109119&partnerID=40&md5=1f990c9c70ceacc9fb34efa20ba4de39","Version Control Software or Revision Control Software are the most important things in the world of software development. In this paper, we have described two version control tools: Git and Apache Subversion. Git comes as free and open source code management and version control system which is disseminated with the GNU general public license. Apache Subversion abbreviated as SVN is one amongst a software versioning and revision control systems given as open source under Apache License. Git design, its functionality, and usage of Git and SVN are discussed in this paper. The goal of this research paper is to accentuate on GIT and SVN tools, evaluate and compare five version control tools to ascertain their usage and efficacy. © BEIESP.","Control tools; Git; SVN; Version Control","Article","Scopus"
"Subhani S.","Subhani, Sohail (57469826700)","57469826700","Is Open Source Software the Future of Software Development?","2020","International Journal of Business","10.30845/ijbht.v10n1p2","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125383930&doi=10.30845%2fijbht.v10n1p2&partnerID=40&md5=c9739bc87df584ee7635f0a51e6ea58e","Just a few years ago, it would have been difficult to envision that open source software applications could seriously threaten closed source or proprietary software industry. But as we look at the existing software development landscape, it becomes vividly clear that the open source software movement is gathering momentum and poses a serious challenge to the proprietary software industry. The infrastructure of the internet, such as mail servers, web servers, and FTP servers is largely based on open source applications. Apache servers, representing sixty percent of the web servers on the internet, is currently the number one web server; Send mail controls forty percent of the e-mail servers. My SQL's market share is growing faster than Microsoft's SQL server and Access databases. Even large technology companies such as IBM, Intel, and Sun have started to support open source development with the expectation of enhancing their hardware sales. In view of the evidence, it is hard to refute the fact that the open source philosophy will dominate the software development environment of the future. In order to assess the viability of the open source software development, this paper examines factors contributing to the growth of the open source movement and also looks at the adequacy of the open source business model. © 2020. All Rights Reserved.","Open Source Software; Proprietary Software; Software Development","Article","Scopus"
"Comino S.; Manenti F.M.; Parisi M.L.","Comino, Stefano (8578610100); Manenti, Fabio M. (35997145900); Parisi, Maria Laura (22981096300)","8578610100; 35997145900; 22981096300","From planning to mature: On the success of open source projects","2007","Research Policy","10.1016/j.respol.2007.08.003","75","https://www.scopus.com/inward/record.uri?eid=2-s2.0-36048986346&doi=10.1016%2fj.respol.2007.08.003&partnerID=40&md5=6d32600f352038497ca2707381b865e6","Open source is an example of user-centric innovation initiated by an individual or group of users to satisfy their specific needs; the more a software evolves towards a stable release able to address the requirements of its developers, the more successful the project. In this paper we use a large data-set obtained from SourceForge.net to estimate the relationship between a series of different characteristics of OS projects and the probability of evolution of the source code from a preliminary release to a mature version. We show that while projects distributed under highly restrictive licensing terms (GPL) have a significantly smaller probability of reaching a stable release, applications towards sophisticated users have a larger probability of evolving in the development status. Interestingly, we find that the size of the ""community of developers"" increases the chances of progress but this effect decreases as the community gets larger, a signal of possible coordination problems. © 2007 Elsevier B.V. All rights reserved.","Development status; Intended audience; License; Open source software; Software market","Article","Scopus"
"Amrollahi A.; Khansari M.; Manian A.","Amrollahi, Alireza (56258799900); Khansari, Mohammad (36613129200); Manian, Amir (35113563700)","56258799900; 36613129200; 35113563700","Success of Open Source in Developing Countries: The Case of Iran","2014","International Journal of Open Source Software and Processes","10.4018/ijossp.2014010103","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996569854&doi=10.4018%2fijossp.2014010103&partnerID=40&md5=722192dbd7975c3c40d84f5bf535e4aa","Open Source approach has been recognized as one of the best methods for software development in developing countries. Previous research however underemphasized different aspects of Open Source Software (OSS) success in context of developing countries compared to western context. In this research the authors use exploratory mixed methodology to study measures of and factors affecting OSS success with emphasize on the social and cultural context of Iran. In the qualitative section of the research 13 interviews with experts of the field have been conducted and the result is reflected in the research model. In the quantitative section, five research hypotheses have been evaluated by using data of 109 Iranian projects from sourceforge.net repository. The results indicate that the license type and use of project management tools may affect the success of OSS. The authors finally conclude that OSS research especially in the field of OSS success may lead to different findings in different contexts. © 2014, IGI Global. All rights reserved.","Developing Countries; Mixed Method; Open Source; Open Source License; Open Source Project Management Tools; Open Source Success","Article","Scopus"
"Wasserman A.I.","Wasserman, Anthony I. (7102134728)","7102134728","Community and commercial strategies in open source software / gemeinschafts- und kommerzielle strategien in der open-source-softwarewelt","2013","IT - Information Technology","10.1515/itit.2013.1003","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062509689&doi=10.1515%2fitit.2013.1003&partnerID=40&md5=44e0cf8fb2a8ce5b9e53670e18837b50","Summary: This paper describes the recent evolution of business strategies used by companies offering products and services based on free and open source software (FOSS). The primary focus is on companies that develop and release products under an open source license. The paper compares their practices with traditional proprietary software companies and with community-based open source projects, and identifies growing overlaps between the different kinds of software companies. Finally, the paper describes the likely impact of recent technology developments in mobile and cloud computing on open source software and related business.  © 2013 Oldenbourg Wissenschaftsverlag GmbH, Rosenheimer Str. 145, 81671 München.","Acm css; Collaboration in software development; Floss; Foss; Open source model; Open source software; Software and its engineering; Software business; Software creation and management","Article","Scopus"
"Cao Y.; Wang Y.; Zheng X.; Li F.; Bo X.","Cao, Yang (55580536000); Wang, Yuanyuan (56741587700); Zheng, Xiaofei (7404091418); Li, Fei (56874986800); Bo, Xiaochen (7005391024)","55580536000; 56741587700; 7404091418; 56874986800; 7005391024","RevEcoR: An R package for the reverse ecology analysis of microbiomes","2016","BMC Bioinformatics","10.1186/s12859-016-1088-4","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984653407&doi=10.1186%2fs12859-016-1088-4&partnerID=40&md5=6edac424aeb4f6fd297f84fec3bcfa5e","Background: All species live in complex ecosystems. The structure and complexity of a microbial community reflects not only diversity and function, but also the environment in which it occurs. However, traditional ecological methods can only be applied on a small scale and for relatively well-understood biological systems. Recently, a graph-theory-based algorithm called the reverse ecology approach has been developed that can analyze the metabolic networks of all the species in a microbial community, and predict the metabolic interface between species and their environment. Results: Here, we present RevEcoR, an R package and a Shiny Web application that implements the reverse ecology algorithm for determining microbe-microbe interactions in microbial communities. This software allows users to obtain large-scale ecological insights into species' ecology directly from high-throughput metagenomic data. The software has great potential for facilitating the study of microbiomes. Conclusions: RevEcoR is open source software for the study of microbial community ecology. The RevEcoR R package is freely available under the GNU General Public License v. 2.0 at http://cran.r-project.org/web/packages/RevEcoR/with the vignette and typical usage examples, and the interactive Shiny web application is available at http://yiluheihei.shinyapps.io/shiny-RevEcoR, or can be installed locally with the source code accessed from https://github.com/yiluheihei/shiny-RevEcoR. © 2016 Cao et al.","Metabolic network; Microbiome; Reverse ecology","Article","Scopus"
"Mooij J.M.","Mooij, Joris M. (9943022800)","9943022800","Libdai: A free and open source C++ library for discrete approximate inference in graphical models","2010","Journal of Machine Learning Research","","176","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956951736&partnerID=40&md5=e08d6711cdd846c5fd2d3d9d1680e82a","This paper describes the software package libDAI, a free & open source C++ library that provides implementations of various exact and approximate inference methods for graphical models with discrete-valued variables. libDAI supports directed graphical models (Bayesian networks) as well as undirected ones (Markov random fields and factor graphs). It offers various approximations of the partition sum, marginal probability distributions and maximum probability states. Parameter learning is also supported. A feature comparison with other open source software packages for approximate inference is given. libDAI is licensed under the GPL v2+ license and is available at http://www.libdai.org. © 2010.","Approximate inference; Bayesian networks; Factor graphs; Markov random fields; Open source software; Probabilistic graphical models","Article","Scopus"
"Butler S.; Gamalielsson J.; Lundell B.; Brax C.; Sjoberg J.; Mattsson A.; Gustavsson T.; Feist J.; Lonroth E.","Butler, Simon (57203032212); Gamalielsson, Jonas (6506812796); Lundell, Bjorn (7004530817); Brax, Christoffer (25654534300); Sjoberg, Johan (57202891658); Mattsson, Anders (36899074500); Gustavsson, Tomas (57208024075); Feist, Jonas (55508021700); Lonroth, Erik (57194282770)","57203032212; 6506812796; 7004530817; 25654534300; 57202891658; 36899074500; 57208024075; 55508021700; 57194282770","On Company Contributions to Community Open Source Software Projects","2021","IEEE Transactions on Software Engineering","10.1109/TSE.2019.2919305","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068577239&doi=10.1109%2fTSE.2019.2919305&partnerID=40&md5=57e3a15df8bf3b2edd74e410ce356cdd","The majority of contributions to community open source software (OSS) projects are made by practitioners acting on behalf of companies and other organisations. Previous research has addressed the motivations of both individuals and companies to engage with OSS projects. However, limited research has been undertaken that examines and explains the practical mechanisms or work practices used by companies and their developers to pursue their commercial and technical objectives when engaging with OSS projects. This research investigates the variety of work practices used in public communication channels by company contributors to engage with and contribute to eight community OSS projects. Through interviews with contributors to the eight projects we draw on their experiences and insights to explore the motivations to use particular methods of contribution. We find that companies utilise work practices for contributing to community projects which are congruent with the circumstances and their capabilities that support their short- and long-term needs. We also find that companies contribute to community OSS projects in ways that may not always be apparent from public sources, such as employing core project developers, making donations, and joining project steering committees in order to advance strategic interests. The factors influencing contributor work practices can be complex and are often dynamic arising from considerations such as company and project structure, as well as technical concerns and commercial strategies. The business context in which software created by the OSS project is deployed is also found to influence contributor work practices.  © 1976-2012 IEEE.","company contribution; Open source software; work practices","Article","Scopus"
"Kapitsaki G.M.; Tselikas N.D.; Foukarakis I.E.","Kapitsaki, Georgia M. (24801845800); Tselikas, Nikolaos D. (6506637365); Foukarakis, Ioannis E. (6506714187)","24801845800; 6506637365; 6506714187","An insight into license tools for open source software systems","2015","Journal of Systems and Software","10.1016/j.jss.2014.12.050","27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923206097&doi=10.1016%2fj.jss.2014.12.050&partnerID=40&md5=c830da504c4358ecb8df3ae0102d1957","Free/Libre/Open Source Software (FLOSS) has gained a lot of attention lately allowing organizations to incorporate third party source code into their implementations. When open source software libraries are used, software resources may be linked directly or indirectly with multiple open source licenses giving rise to potential license incompatibilities. Adequate support in license use is vital in order to avoid such violations and address how diverse licenses should be handled. In the current work we investigate software licensing giving a critical and comparative overview of existing assistive approaches and tools. These approaches are centered on three main categories: license information identification from source code and binaries, software metadata stored in code repositories, and license modeling and associated reasoning actions. We also give a formalization of the license compatibility problem and demonstrate the role of existing approaches in license use decisions. © 2014 Elsevier Inc. All rights reserved.","Free/Libre/Open Source Software; License compatibility; License identification","Article","Scopus"
"Dubbeldam D.; Calero S.; Ellis D.E.; Snurr R.Q.","Dubbeldam, David (6701729641); Calero, Sofía (7003615005); Ellis, Donald E. (8736923900); Snurr, Randall Q. (7004265176)","6701729641; 7003615005; 8736923900; 7004265176","RASPA: Molecular simulation software for adsorption and diffusion in flexible nanoporous materials","2016","Molecular Simulation","10.1080/08927022.2015.1010082","947","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942988620&doi=10.1080%2f08927022.2015.1010082&partnerID=40&md5=b2214b28d25d4ea67d6fa533a929d675","A new software package, RASPA, for simulating adsorption and diffusion of molecules in flexible nanoporous materials is presented. The code implements the latest state-of-the-art algorithms for molecular dynamics and Monte Carlo (MC) in various ensembles including symplectic/measure-preserving integrators, Ewald summation, configurational-bias MC, continuous fractional component MC, reactive MC and Baker's minimisation. We show example applications of RASPA in computing coexistence properties, adsorption isotherms for single and multiple components, self- and collective diffusivities, reaction systems and visualisation. The software is released under the GNU General Public License. © 2015 The Author(s). Published by Taylor & Francis.","adsorption; diffusion; molecular dynamics; molecular simulation; Monte Carlo; software","Article","Scopus"
"Molina T.; Ortega J.; Muñoz J.","Molina, Tulio (57213590500); Ortega, Juan (57213939946); Muñoz, Juan (35368813300)","57213590500; 57213939946; 35368813300","HELMpy, Open Source Package of Power Flow Solvers, Including the Holomorphic Embedding Load Flow Method (HELM), Developed on Python 3","2021","Journal of Open Research Software","10.5334/jors.310","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117961167&doi=10.5334%2fjors.310&partnerID=40&md5=7715321afae22cc6bc62e2dc68e71c15","HELMpy is an open source software for power flow solution developed on Python 3. Specifically, two algorithms for power flow solution are implemented in this software: a Holomorphic Embedding Load-flow Method (HELM), and a Newton-Raphson (NR) based power flow method, using either a classical single slack bus model or a distributed slack bus model. HELMpy is aimed at supporting academic research, emphasizing on the development of open source software related to the HELM. To ease the comprehension and modification of HELMpy’s code, it is properly commented and structured as a group of Python modules. These modules are composed of sets of functions used for solving the power flow problem according to the previously mentioned algorithms. HELMpy is distributed under the GNU Affero General Public License v3.0 or later and it is available on GitHub. (https://github.com/HELMpy/HELMpy) © 2021. The Author(s). This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International License (CC-BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. See http://creativecommons.org/licenses/by/4.0/.","Distributed slack bus; HELM; Newton Raphson method; Power flow","Article","Scopus"
"Medappa P.K.; Srivastava S.C.","Medappa, Poonacha K. (57194237464); Srivastava, Shirish C. (22938941000)","57194237464; 22938941000","Ideological shifts in open source orchestration: examining the influence of licence choice and organisational participation on open source project outcomes","2020","European Journal of Information Systems","10.1080/0960085X.2020.1756003","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087124045&doi=10.1080%2f0960085X.2020.1756003&partnerID=40&md5=f254a03e6172232537999986893dce76","Though volunteer-driven Free (Libre) and Open Source Software (FLOSS) development were founded on the ideological beliefs of “openness” and “absence of any commercial appropriation”, in recent years, FLOSS movement has witnessed two ideological shifts. First, the emergence of “permissive FLOSS licences” that allow commercial appropriation of the collaboratively developed code, and second, “organisational ownership” of FLOSS projects. Because ideological beliefs shape the motivational needs of the volunteer contributors, and motivational needs influence the dominant work structures, it is expected that ideological shifts could influence the mechanisms through which work is orchestrated in FLOSS projects. Motivated by the need to understand the impact of these ideological shifts, we theorise the mechanisms through which the two ideological shifts alter the influence of FLOSS work structures on project outcomes of popularity and survival. Adopting an instrument variable approach, our analysis of projects hosted on GitHub confirms the significance of both the ideological shifts with some interesting contextual differences across the two project outcomes. Specifically, we find that the ideological shift pertaining to licence type has a significant influence on both the examined project outcomes, whereas organisational ownership has a significant influence only on the popularity of FLOSS projects. © Operational Research Society 2020.","ideologies; instrument variable; licence; Likoebe Maruping and Sabine Matook; Open source software; structures of work; superposition","Article","Scopus"
"Baumann J.M.; Dilsavor R.; Stubbles J.; Mossing J.","Baumann, James M. (7101865746); Dilsavor, Ronald (6603229284); Stubbles, James (7003589668); Mossing, John (6602723774)","7101865746; 6603229284; 7003589668; 6602723774","Open source tools for ATR development and performance evaluation","2002","Proceedings of SPIE-The International Society for Optical Engineering","10.1117/12.477019","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036033157&doi=10.1117%2f12.477019&partnerID=40&md5=93278d9c80220883dbd7cec8f08a60a8","Early in almost every engineering project, a decision must be made about tools; should I buy off-the-shelf tools or should I develop my own. Either choice can involve significant cost and risk. Off-the-shelf tools may be readily available, but they can be expensive to purchase and to maintain licenses, and may not be flexible enough to satisfy all project requirements. On the other hand, developing new tools permits great flexibility, but it can be time-(and budget-) consuming, and the end product still may not work as intended. Open source software has the advantages of both approaches without many of the pitfalls. This paper examines the concept of open source software, including its history, unique culture, and informal yet closely followed conventions. These characteristics influence the quality and quantity of software available, and ultimately its suitability for serious ATR development work. We give an example where Python, an open source scripting language, and OpenEV, a viewing and analysis tool for geospatial data, have been incorporated into ATR performance evaluation projects. While this case highlights the successful use of open source tools, we also offer important insight into risks associated with this approach. © 2002 SPIE · 0277-786X/02/$15.00.","Image viewer; Open source; OpenEV; Software","Article","Scopus"
"Legenvre H.; Kauttu P.; Bos M.; Khawand R.","Legenvre, Hervé (57190956746); Kauttu, Pietari (57218142555); Bos, Martin (57196051253); Khawand, Roger (57218142878)","57190956746; 57218142555; 57196051253; 57218142878","Is Open Hardware Worthwhile? Learning from Thales’ Experience with RISC-V","2020","Research Technology Management","10.1080/08956308.2020.1762445","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088008940&doi=10.1080%2f08956308.2020.1762445&partnerID=40&md5=8595b16bd8bddfd39b112f33c36a5519","Overview: In this article we frame the concept of a hardware-rich open source ecosystem (H-ROSE) that generates software and hardware components. In an H-ROSE, the designs of some components are accessible under open source licenses, while other component designs remain proprietary. We describe seven adoption factors used by the multinational French firm Thales to assess the efficacy of RISC-V to design processors. Other companies can use these adoption factors to explore whether an open hardware initiative supported by an H-ROSE is worthwhile. © 2020, Copyright © 2020, Innovation Research Interchange.","Adoption factors; Ecosystems; H-ROSE; Open source; RISC-V","Article","Scopus"
"Belenzon S.; Schankerman M.","Belenzon, Sharon (26634880300); Schankerman, Mark (6603557603)","26634880300; 6603557603","Motivation and sorting of human capital in open innovation","2015","Strategic Management Journal","10.1002/smj.2284","48","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928588287&doi=10.1002%2fsmj.2284&partnerID=40&md5=57ecd6e50bb3d1c23d7adeb50d451a9f","This paper studies how business models can be designed to tap effectively into open innovation labor markets with heterogeneously motivated workers. Using data on open source software, we show that motivations are diverse, and demonstrate how managers can strategically influence the flow of code contributions and their impact on project performance. Unlike previous literature using survey data, we exploit the observed pattern of project membership and code contributions - the ""revealed preference"" of developers - to infer the motivations driving their decision to contribute. Developers strongly sort along key dimensions of the business model chosen by project managers, especially the degree of openness of the project license. The results indicate an important role for intrinsic motivation, reputation, and labor market signaling, and a more limited role for reciprocity. Copyright © 2014 John Wiley & Sons, Ltd.","intellectual property rights; motivations; open innovation; open source; sorting; strategic human capital","Article","Scopus"
"Yao E.; Buels R.; Stein L.; Sen T.Z.; Holmes I.","Yao, Eric (57188820177); Buels, Robert (8949007700); Stein, Lincoln (7202575097); Sen, Taner Z. (7006797407); Holmes, Ian (57197575337)","57188820177; 8949007700; 7202575097; 7006797407; 57197575337","JBrowse Connect: A server API to connect JBrowse instances and users","2020","PLoS Computational Biology","10.1371/journal.pcbi.1007261","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090796337&doi=10.1371%2fjournal.pcbi.1007261&partnerID=40&md5=a5500220109eb815266b99f8236c782d","We describe JBrowse Connect, an optional expansion to the JBrowse genome browser, targeted at developers. JBrowse Connect allows live messaging, notifications for new annotation tracks, heavy-duty analyses initiated by the user from within the browser, and other dynamic features. We present example applications of JBrowse Connect that allow users 1) to specify and execute BLAST searches by either running on the same host as the webserver, with a self-contained BLAST module leveraging NCBI Blast+ commands, or via a managed Galaxy instance that can optionally run on a different host, and 2) to run the primer design service Primer3. JBrowse Connect allows users to track job progress and view results in the context of the browser. The software is available under a choice of open source licenses including LGPL and the Artistic License. This is an open access article, free of all copyright, and may be freely reproduced, distributed, transmitted, modified, built upon, or otherwise used by anyone for any lawful purpose. The work is made available under the Creative Commons CC0 public domain dedication.","","Article","Scopus"
"Nagy D.; Yassin A.M.; Bhattacherjee A.","Nagy, Del (35727231100); Yassin, Areej M. (35727406800); Bhattacherjee, Anol (7006737091)","35727231100; 35727406800; 7006737091","Organizational adoption of open source software: Barriers and remedies","2010","Communications of the ACM","10.1145/1666420.1666457","70","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77649243015&doi=10.1145%2f1666420.1666457&partnerID=40&md5=9d295b91f5f39b27e392318b7be76a79","Introduction Perhaps the business case for adopting open source software is an easy sell. After all, the software is free, and can be simply downloaded from the Internet and installed or customized as needed. Organizations interested in reducing the licensing fees of proprietary software, while also avoiding the penalties and legal liabilities associated with their illegal use, can definitely consider open source software a plausible alternative. However, less obvious than the cost savings but equally important are the barriers (""hidden costs"") of adopting open source software. Open source software has created considerable excitement in the business world over the last decade. These applications, designed by groups of volunteer software developers, have the potential to break the current dominance of proprietary software and restrictive licenses for many business applications, reduce software development time and improve software quality, and most importantly, bring much needed software applications within the reach of individuals and small businesses, who cannot otherwise afford such software. Further, unlike proprietary software, open source software applications make their source code available for free, which can be customized to fit the unique needs of specific organizations. Many organizations have caught on to open source software and realized significant cost savings in technology expenditure as a result. For instance, Cendant Travel Distribution Services replaced a $100 million mainframe system with a $2.5 million system running on 144 Linux servers. Amazon.com cut its technology expenditure from $71 million to $54 million by switching to open source applications. Sabre Holdings saved tens of millions of dollars by adopting MySQL, an open source database product. Though the basic open source software is free, the prospect of paid ancillary products and services such as hardware and consulting has motivated many erstwhile proprietary technology vendors such as Hewlett-Packard, IBM, and Sun Microsystems to embrace open source software and offer value-added services based on such software. Table 1 shows an estimated range of the current global market share of several of today's open source software applications. This table shows that though the open source market is large and growing for some application domains such as Web server (such as Apache), server operating systems (such as Linux Server), database server (such as MySQL), electronic mail client (such as Sendmail), and Internet browser (such as Firefox), it is lagging behind its proprietary counterparts in other domains such as client operating systems (such as Linux Workstation), office productivity software (such as OpenOffice), and enterprise resource planning (ERP) systems. This pattern suggests that there may be significant barriers to open source software adoption among some sectors of the user populations. It is widely believed that proprietary software vendors often use fear, uncertainty and doubt to undermine and cut the market potential of their open source competitors. The objective of this paper is to reduce that uncertainty via a candid discussion of the barriers confronting open source software adoption and potential remedies to those barriers. These barriers and their remedies, summarized in Table 2, are discussed in detail. © 2010 ACM.","","Article","Scopus"
"QIU S.; GERMAN D.M.; INOUE K.","QIU, Shi (57205073835); GERMAN, Daniel M. (57207886015); INOUE, Katsuro (7601540520)","57205073835; 57207886015; 7601540520","An exploratory study of copyright inconsistency in the linux kernel","2021","IEICE Transactions on Information and Systems","10.1587/transinf.2020EDP7107","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100728417&doi=10.1587%2ftransinf.2020EDP7107&partnerID=40&md5=6a4f8a8e8626e518928647d87f8ab15e","Software copyright claims an exclusive right for the software copyright owner to determine whether and under what conditions others can modify, reuse, or redistribute this software. For Free and Open Source Software (FOSS), it is very important to identify the copyright owner who can control those activities with license compliance. Copyright notice is a few sentences mostly placed in the header part of a source file as a comment or in a license document in a FOSS project, and it is an important clue to establish the ownership of a FOSS project. Repositories of FOSS projects contain rich and varied information on the development including the source code contributors who are also an important clue to establish the ownership. In this paper, as a first step of understanding copyright owner, we will explore the situation of the software copyright in the Linux kernel, a typical example of FOSS, by analyzing and comparing two kinds of datasets, copyright notices in source files and source code contributors in the software repositories. The discrepancy between two kinds of analysis results is defined as copyright inconsistency. The analysis result has indicated that copyright inconsistencies are prevalent in the Linux kernel. We have also found that code reuse, affiliation change, refactoring, support function, and others' contributions potentially have impacts on the occurrence of the copyright inconsistencies in the Linux kernel. This study exposes the difficulty in managing software copyright in FOSS, highlighting the usefulness of future work to address software copyright problems. © 2021 The Institute of Electronics.","Mining software repositories; Open source software; Software copyright; Software maintenance","Article","Scopus"
"Harp S.; Carpenter T.; Hatcliff J.","Harp, Steven (26643340100); Carpenter, Todd (57195517828); Hatcliff, John (57204342409)","26643340100; 57195517828; 57204342409","A reference architecture for secure medical devices","2018","Biomedical Instrumentation and Technology","10.2345/0899-8205-52.5.357","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054587990&doi=10.2345%2f0899-8205-52.5.357&partnerID=40&md5=d367fd759ea2866f366d549d4cb38c3e","We propose a reference architecture aimed at supporting the safety and security of medical devices. The ISOSCELES (Intrinsically Secure, Open, and Safe Cyber-Physically Enabled, Life-Critical Essential Services) architecture is justified by a collection of design principles that leverage recent advances in software component isolation based on hypervisor and other separation technologies. The instantiation of the architecture for particular medical devices is supported by a development process based on Architecture Analysis and Design Language. The architecture models support safety and security analysis as part of a broader risk management framework. The models also can be used to derive skeletons of the device software and to configure the platform's separation policies and an extensive set of services. We are developing prototypes of the architecture and example medical device instantiations on low-cost boards that can be used in product solutions. The prototype and supporting development and assurance artifacts are being released under an open-source license. © 2018 AAMI.","","Article","Scopus"
"Feller J.; Finnegan P.; Hayes J.","Feller, Joseph (7005159947); Finnegan, Patrick (57201518771); Hayes, Jeremy (57199470849)","7005159947; 57201518771; 57199470849","Delivering the 'whole product': Business model impacts and agility challenges in a network of open source firms","2008","Journal of Database Management","10.4018/jdm.2008040105","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-50549094975&doi=10.4018%2fjdm.2008040105&partnerID=40&md5=fbaf442256f663f6817f4ac473626c84","It has been argued that competitive necessities will increasingly require OSS companies to participate in cooperative business networks in order to offer the complete product/service (whole product) demanded by customers. It is envisaged that these business networks will enhance the business models of participant firms by supplementing their value-adding activities and increasing responsiveness to customers. However, while such propositions have intuitive appeal, there is a lack of empirical research on such networks. This article examines Zea Partners, a network of small open source companies cooperating to deliver the 'whole product' in the area of content management systems (CMSs). It investigates how participation in the network augments the business models of participant companies and identifies the business agility challenges faced by the network. The article concludes that reconciling the coordination needs of OSS networks with the operational practices of participant firms is a critical issue if such networks are to achieve adaptive efficiency to deliver whole products in a 'bazaar-friendly' manner. Copyright © 2008, IGI Global.","Agility; Business models; Business networks; Open source software","Article","Scopus"
"Piva E.; Rossi-Lamastra C.","Piva, Evila (12753610200); Rossi-Lamastra, Cristina (57197758938)","12753610200; 57197758938","The license choices of SMEs doing business with open source software: Empirical evidence on italian firms","2012","International Journal of Open Source Software and Processes","10.4018/jossp.2012010102","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875288249&doi=10.4018%2fjossp.2012010102&partnerID=40&md5=252ae94c174f13c8c61f1e8b99539e66","In the past decade, Open Source (OS) licenses have attracted the interest of many scholars. However, there is still a limited understanding of the license choices made by small and medium enterprises doing business with OS (OS SMEs). The present paper aims at filling this gap. The authors argue that, because of firm specificities, OS SMEs tend to prefer copyleft licenses. Their arguments are corroborated by empirical evidence from a survey on 146 Italian OS SMEs. This evidence documents that OS SMEs are not plagued by the GPL fear theorized by the OS founding fathers. Conversely, these firms use copyleft licenses to more easily in-source knowledge from the community of OS users and developers. At the same time, license choices are influenced by the ideological motivations that OS SMEs inherit from their owner-managers. Copyright © 2012, IGI Global.","Copyleft; Intellectual property rights; Licenses; Open source; Small and medium enterprises (SMEs)","Article","Scopus"
"Cocco L.; Concas G.; Marchesi M.","Cocco, Luisanna (37861007600); Concas, Giulio (57105938400); Marchesi, Michele (7005947166)","37861007600; 57105938400; 7005947166","Simulation of the on demand software model, including vendors offering source code availability","2014","International Journal of Modelling and Simulation","10.2316/Journal.205.2014.3.205-5896","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923873985&doi=10.2316%2fJournal.205.2014.3.205-5896&partnerID=40&md5=24b05d4f4affbc242966d10cd0cc9de7","In recent years, the power balance between software firms and enterprise customers has been heavily changing. The contractual power of customers is increasing and the firms must take this fact into account. Stated the common need to save money, the opportunities to adopt new software solutions with tight budgets, or with substantial savings, are limited. The better way to obtain operational savings seems to be shifting to the use of open source software, obtaining in this way all the benefits of this software typology: lower costs, greater adherence to open standards, a broader vendor choice and service suppliers, no vendor lock-in and flexible, incremental architectures. In this work, a business model is proposed to analyse the competition among on-demand customer relationship management (CRM) firms, in particular among firms offering CRM products with or without source code availability. The model can also be customized to study other kinds of markets, and other assumptions can be made for studying their implications to the software business.","Free/libre open source software; Market strategy; Software business; Software market simulation","Article","Scopus"
"Slivka J.; Sladić G.; Milosavljević B.; Kovačević A.","Slivka, J. (36700444700); Sladić, G. (6506063604); Milosavljević, B. (55948342700); Kovačević, A. (27967812900)","36700444700; 6506063604; 55948342700; 27967812900","RSSalg software: A tool for flexible experimenting with co-training based semi-supervised algorithms","2017","Knowledge-Based Systems","10.1016/j.knosys.2017.01.024","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010952738&doi=10.1016%2fj.knosys.2017.01.024&partnerID=40&md5=a6c8e8de3620f9861853afdbb6760d5e","RSSalg software is a tool for experimenting with Semi-Supervised Learning (SSL), a set of machine learning techniques able to use both labeled and unlabeled data for training. The goal is to reduce human effort regarding data labeling while preserving model quality. RSSalg software encompasses the implementation of co-training, a multi-view SSL technique and RSSalg, its single-view alternative. Our tool enables easy comparison of different SSL algorithms. It provides a cross-validation procedure and supports standard metrics for performance evaluation. The tool is free and open source, available on GitHub under the GNU General Public License. It is implemented in Java language using Weka library. © 2017","Co-training; Ensemble methods; Java; Semi-supervised learning; Weka","Article","Scopus"
"Smith A.M.; Niemeyer K.E.; Katz D.S.; Barba L.A.; Githinji G.; Gymrek M.; Huff K.D.; Madan C.R.; Mayes A.C.; Moerman K.M.; Prins P.; Ram K.; Rokem A.; Teal T.K.; Guimera R.V.; Vanderplas J.T.","Smith, Arfon M. (55498582500); Niemeyer, Kyle E. (35196816200); Katz, Daniel S. (49661664400); Barba, Lorena A. (8294521800); Githinji, George (55165382700); Gymrek, Melissa (35183061200); Huff, Kathryn D. (55636448200); Madan, Christopher R. (35759289000); Mayes, Abigail Cabunoc (57201086122); Moerman, Kevin M. (26429845700); Prins, Pjotr (17233874100); Ram, Karthik (15751626600); Rokem, Ariel (6507945628); Teal, Tracy K. (35312485800); Guimera, Roman Valls (55930860100); Vanderplas, Jacob T. (35111982900)","55498582500; 35196816200; 49661664400; 8294521800; 55165382700; 35183061200; 55636448200; 35759289000; 57201086122; 26429845700; 17233874100; 15751626600; 6507945628; 35312485800; 55930860100; 35111982900","Journal of Open Source Software (JOSS): Design and first-year review","2018","PeerJ Computer Science","10.7717/peerj-cs.147","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043392618&doi=10.7717%2fpeerj-cs.147&partnerID=40&md5=4130e15920cf9af83dcd6e549f064e21","This article describes the motivation, design, and progress of the Journal of Open Source Software (JOSS). JOSS is a free and open-access journal that publishes articles describing research software. It has the dual goals of improving the quality of the software submitted and providing a mechanism for research software developers to receive credit. While designed to work within the current merit system of science, JOSS addresses the dearth of rewards for key contributions to science made in the form of software. JOSS publishes articles that encapsulate scholarship contained in the software itself, and its rigorous peer review targets the software components: functionality, documentation, tests, continuous integration, and the license. A JOSS article contains an abstract describing the purpose and functionality of the software, references, and a link to the software archive. The article is the entry point of a JOSS submission, which encompasses the full set of software artifacts. Submission and review proceed in the open, on GitHub. Editors, reviewers, and authors work collaboratively and openly. Unlike other journals, JOSS does not reject articles requiring major revision; while not yet accepted, articles remain visible and under review until the authors make adequate changes (or withdraw, if unable to meet requirements). Once an article is accepted, JOSS gives it a digital object identifier (DOI), deposits its metadata in Crossref, and the article can begin collecting citations on indexers like Google Scholar and other services. Authors retain copyright of their JOSS article, releasing it under a Creative Commons Attribution 4.0 International License. In its first year, starting in May 2016, JOSS published 111 articles, with more than 40 additional articles under review. JOSS is a sponsored project of the nonprofit organization NumFOCUS and is an affiliate of the Open Source Initiative (OSI). © 2018 Smith et al.","Code review; Computational research; Open-source software; Research software; Scholarly publishing; Software citation","Article","Scopus"
"Visne I.; Dilaveroglu E.; Vierlinger K.; Lauss M.; Yildiz A.; Weinhaeusel A.; Noehammer C.; Leisch F.; Kriegner A.","Visne, Ilhami (24342218900); Dilaveroglu, Erkan (24341014800); Vierlinger, Klemens (22136596600); Lauss, Martin (22934765500); Yildiz, Ahmet (24342512500); Weinhaeusel, Andreas (6603343674); Noehammer, Christa (22135789000); Leisch, Friedrich (7005468665); Kriegner, Albert (55962397500)","24342218900; 24341014800; 22136596600; 22934765500; 24342512500; 6603343674; 22135789000; 7005468665; 55962397500","RGG: A general GUI Framework for R scripts","2009","BMC Bioinformatics","10.1186/1471-2105-10-74","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-62549110425&doi=10.1186%2f1471-2105-10-74&partnerID=40&md5=27275c0f899a9ff06aec8b4e4ec0baf7","Background: R is the leading open source statistics software with a vast number of biostatistical and bioinformatical analysis packages. To exploit the advantages of R, extensive scripting/programming skills are required. Results: We have developed a software tool called R GUI Generator (RGG) which enables the easy generation of Graphical User Interfaces (GUIs) for the programming language R by adding a few Extensible Markup Language (XML) - tags. RGG consists of an XML-based GUI definition language and a Java-based GUI engine. GUIs are generated in runtime from defined GUI tags that are embedded into the R script. User-GUI input is returned to the R code and replaces the XML-tags. RGG files can be developed using any text editor. The current version of RGG is available as a stand-alone software (RGGRunner) and as a plug-in for JGR. Conclusion: RGG is a general GUI framework for R that has the potential to introduce R statistics (R packages, built-in functions and scripts) to users with limited programming skills and helps to bridge the gap between R developers and GUI-dependent users. RGG aims to abstract the GUI development from individual GUI toolkits by using an XML-based GUI definition language. Thus RGG can be easily integrated in any software. The RGG project further includes the development of a web-based repository for RGG-GUIs. RGG is an open source project licensed under the Lesser General Public License (LGPL) and can be downloaded freely at http://rgg.r-forge.r-project.org. © 2009 Visne et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Moraes J.P.; Polato I.; Wiese I.; Saraiva F.; Pinto G.","Moraes, João Pedro (57211035409); Polato, Ivanilton (14056929200); Wiese, Igor (6603482090); Saraiva, Filipe (57189248122); Pinto, Gustavo (54941690500)","57211035409; 14056929200; 6603482090; 57189248122; 54941690500","From one to hundreds: multi-licensing in the JavaScript ecosystem","2021","Empirical Software Engineering","10.1007/s10664-020-09936-2","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103349814&doi=10.1007%2fs10664-020-09936-2&partnerID=40&md5=09768c93514460ddc1688d66e7618cc3","Open source licenses create a legal framework that plays a crucial role in the widespread adoption of open source projects. Without a license, any source code available on the internet could not be openly (re)distributed. Although recent studies provide evidence that most popular open source projects have a license, developers might lack confidence or expertise when they need to combine software licenses, leading to a mistaken project license unification. This license usage is challenged by the high degree of reuse that occurs in the heart of modern software development practices, in which third-party libraries and frameworks are easily and quickly integrated into a software codebase. This scenario creates what we call “multi-licensed” projects, which happens when one project has components that are licensed under more than one license. Although these components exist at the file-level, they naturally impact licensing decisions at the project-level. In this paper, we conducted a mix-method study to shed some light on these questions. We started by parsing 1,426,263 (source code and non-source code) files available on 1,552 JavaScript projects, looking for license information. Among these projects, we observed that 947 projects (61%) employ more than one license. On average, there are 4.7 licenses per studied project (max: 256). Among the reasons for multi-licensing is to incorporate the source code of third-party libraries into the project’s codebase. When doing so, we observed that 373 of the multi-licensed projects introduced at least one license incompatibility issue. We also surveyed with 83 maintainers of these projects aimed to cross-validate our findings. We observed that 63% of the surveyed maintainers are not aware of the multi-licensing implications. For those that are aware, they adopt multiple licenses mostly to conform with third-party libraries’ licenses. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC part of Springer Nature.","JavaScript projects; Multi-licensing; Open source licenses","Article","Scopus"
"Hasselbring W.; Carr L.; Hettrick S.; Packer H.; Tiropanis T.","Hasselbring, Wilhelm (26643500000); Carr, Leslie (7202903038); Hettrick, Simon (6603649027); Packer, Heather (36662649700); Tiropanis, Thanassis (16053715500)","26643500000; 7202903038; 6603649027; 36662649700; 16053715500","From FAIR research data toward FAIR and open research software","2020","IT - Information Technology","10.1515/itit-2019-0040","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079667635&doi=10.1515%2fitit-2019-0040&partnerID=40&md5=37201dc194bf1464ec5e2f6bd800eadc","The Open Science agenda holds that science advances faster when we can build on existing results. Therefore, research data must be FAIR (Findable, Accessible, Interoperable, and Reusable) in order to advance the findability, reproducibility and reuse of research results. Besides the research data, all the processing steps on these data - as basis of scientific publications - have to be available, too. For good scientific practice, the resulting research software should be both open and adhere to the FAIR principles to allow full repeatability, reproducibility, and reuse. As compared to research data, research software should be both archived for reproducibility and actively maintained for reusability. The FAIR data principles do not require openness, but research software should be open source software. Established open source software licenses provide sufficient licensing options, such that it should be the rare exception to keep research software closed. We review and analyze the current state in this area in order to give recommendations for making research software FAIR and open. © 2020 Hasselbring et al., published by De Gruyter 2020.","FAIR principles; open source software; research software","Article","Scopus"
"Lim K.; Han J.; Kim B.-C.; Cho S.-J.; Park M.; Han S.","Lim, Kyeonghwan (57191477174); Han, Jungkyu (57199737420); Kim, Byoung-Chir (57209326898); Cho, Seong-Je (12240436200); Park, Minkyu (55730438800); Han, Sangchul (57207284731)","57191477174; 57199737420; 57209326898; 12240436200; 55730438800; 57207284731","Open-source android app detection considering the effects of code obfuscation","2018","Journal of Wireless Mobile Networks, Ubiquitous Computing, and Dependable Applications","10.22667/JOWUA.2018.09.30.050","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059555805&doi=10.22667%2fJOWUA.2018.09.30.050&partnerID=40&md5=0c5ddb29a2a18a1e7f2a2e3cd0633577","As open source software (Open Source Software, OSS) is becoming more and more popular, the risk of open-source license violation also increases. According to 2018 open source security and risk analysis report of Synopsys, 96% of applications (apps) include open source software and 74% of them them have licensing issues. To address this problem, many researchers have studied open-source licensing and OSS detection. However, most ones have conducted at source code level and have not considered the effects of code obfuscation. In this paper, we propose an effective technique to extract software birthmarks (i.e., features) from executable code of Android apps and find out whether the executable code is created from OSS by comparing the birthmarks of the executable code and those of known open-source apps. The proposed technique uses class hierarchy information (CHI) and control flow graphs (CFGs) as software birthmarks of Java bytecode code level. The CFG birthmark is robust against code obfuscation attacks and thus effective to detect open-source apps although their codes are obfuscated. We validate the proposed OSS detection technique through experiments on obfuscated apps. © 2019, Innovative Information Science and Technology Research Group. All rights reserved.","Class hierarchy information; Control flow graph; Open source software; Similarity","Article","Scopus"
"Li X.; Moreschini S.; Pecorelli F.; Taibi D.","Li, Xiaozhou (56203689000); Moreschini, Sergio (57196187277); Pecorelli, Fabiano (57210934334); Taibi, Davide (55920884000)","56203689000; 57196187277; 57210934334; 55920884000","OSSARA: Abandonment Risk Assessment for Embedded Open Source Components","2022","IEEE Software","10.1109/MS.2022.3163011","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127459156&doi=10.1109%2fMS.2022.3163011&partnerID=40&md5=c85a70fdbe3677dfa983f0110bdce363","Systems with unmaintained embedded open source software (OSS) components are vulnerable to severe risks. This article introduces the OSS Abandonment Risk Assessment model to help companies avoid potentially dire consequences.  © 1984-2012 IEEE.","","Article","Scopus"
"Kapitsaki G.M.; Kramer F.; Tselikas N.D.","Kapitsaki, Georgia M. (24801845800); Kramer, Frederik (55780326900); Tselikas, Nikolaos D. (6506637365)","24801845800; 55780326900; 6506637365","Automating the license compatibility process in open source software with SPDX","2017","Journal of Systems and Software","10.1016/j.jss.2016.06.064","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85003510868&doi=10.1016%2fj.jss.2016.06.064&partnerID=40&md5=c0d6df0b27c54343e58f0645709c5921","Free and Open Source Software (FOSS) promotes software reuse and distribution at different levels for both creator and users, but at the same time imposes some challenges in terms of FOSS licenses that can be selected and combined. The main problem linked to this selection is the presence of a large set of licenses that define different rights and obligations in software use. The problem becomes more evident in cases of complex combinations of software that carries different – often conflicting – licenses. In this paper we are presenting our work on automating license compatibility by proposing a process that examines the structure of Software Package Data Exchange (SPDX) for license compatibility issues assisting in their correct use and combination. We are offering the possibility to detect license violations in existing software projects and make suggestions on appropriate combinations of different software packages. We are also elaborating on the complexity and ambiguity of licensing detection in software products through representative case studies. Our work constitutes a useful process towards automating the analysis of software systems in terms of license use and compatibilities. © 2016 Elsevier Inc.","License compatibility; License violations; Open Source Software; Software Package Data Exchange","Article","Scopus"
"Alic A.S.; Almeida J.; Aloisio G.; Andrade N.; Antunes N.; Ardagna D.; Badia R.M.; Basso T.; Blanquer I.; Braz T.; Brito A.; Elia D.; Fiore S.; Guedes D.; Lattuada M.; Lezzi D.; Maciel M.; Meira W., Jr; Mestre D.; Moraes R.; Morais F.; Pires C.E.; Kozievitch N.P.; Santos W.D.; Silva P.; Vieira M.","Alic, Andy S. (57000301200); Almeida, Jussara (35586158500); Aloisio, Giovanni (57192403748); Andrade, Nazareno (7003429497); Antunes, Nuno (57217858593); Ardagna, Danilo (6508040906); Badia, Rosa M. (6603994224); Basso, Tania (36473118700); Blanquer, Ignacio (21734509800); Braz, Tarciso (57202890601); Brito, Andrey (25923297400); Elia, Donatello (56405261900); Fiore, Sandro (8937144900); Guedes, Dorgival (6603589964); Lattuada, Marco (36907433300); Lezzi, Daniele (22334444700); Maciel, Matheus (55486033000); Meira, Wagner (6701307771); Mestre, Demetrio (56094866600); Moraes, Regina (55743865300); Morais, Fabio (12783880400); Pires, Carlos Eduardo (35176316700); Kozievitch, Nádia P. (36245283500); Santos, Walter dos (8356099100); Silva, Paulo (57203164598); Vieira, Marco (7202140748)","57000301200; 35586158500; 57192403748; 7003429497; 57217858593; 6508040906; 6603994224; 36473118700; 21734509800; 57202890601; 25923297400; 56405261900; 8937144900; 6603589964; 36907433300; 22334444700; 55486033000; 6701307771; 56094866600; 55743865300; 12783880400; 35176316700; 36245283500; 8356099100; 57203164598; 7202140748","BIGSEA: A Big Data analytics platform for public transportation information","2019","Future Generation Computer Systems","10.1016/j.future.2019.02.011","19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061791021&doi=10.1016%2fj.future.2019.02.011&partnerID=40&md5=ae9d0eddf339e9d91708d978b3b544ee","Analysis of public transportation data in large cities is a challenging problem. Managing data ingestion, data storage, data quality enhancement, modelling and analysis requires intensive computing and a non-trivial amount of resources. In EUBra-BIGSEA (Europe–Brazil Collaboration of Big Data Scientific Research Through Cloud-Centric Applications) we address such problems in a comprehensive and integrated way. EUBra-BIGSEA provides a platform for building up data analytic workflows on top of elastic cloud services without requiring skills related to either programming or cloud services. The approach combines cloud orchestration, Quality of Service and automatic parallelisation on a platform that includes a toolbox for implementing privacy guarantees and data quality enhancement as well as advanced services for sentiment analysis, traffic jam estimation and trip recommendation based on estimated crowdedness. All developments are available under Open Source licenses (http://github.org/eubr-bigsea, https://hub.docker.com/u/eubrabigsea/). © 2019 Elsevier B.V.","","Article","Scopus"
"Zhao Y.; Liang R.; Chen X.; Zou J.","Zhao, Yuhang (57207734782); Liang, Ruigang (57205634095); Chen, Xiang (57189091783); Zou, Jing (57205629730)","57207734782; 57205634095; 57189091783; 57205629730","Evaluation indicators for open-source software: a review","2021","Cybersecurity","10.1186/s42400-021-00084-8","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107206051&doi=10.1186%2fs42400-021-00084-8&partnerID=40&md5=a0d2bf31800ce363cfe8a5334313d116","In recent years, the widespread applications of open-source software (OSS) have brought great convenience for software developers. However, it is always facing unavoidable security risks, such as open-source code defects and security vulnerabilities. To find out the OSS risks in time, we carry out an empirical study to identify the indicators for evaluating the OSS. To achieve a comprehensive understanding of the OSS assessment, we collect 56 papers from prestigious academic venues (such as IEEE Xplore, ACM Digital Library, DBLP, and Google Scholar) in the past 21 years. During the process of the investigation, we first identify the main concerns for selecting OSS and distill five types of commonly used indicators to assess OSS. We then conduct a comparative analysis to discuss how these indicators are used in each surveyed study and their differences. Moreover, we further undertake a correlation analysis between these indicators and uncover 13 confirmed conclusions and four cases with controversy occurring in these studies. Finally, we discuss several possible applications of these conclusions, which are insightful for the research on OSS and software supply chain. © 2021, The Author(s).","Correlation; Evaluation; Indicator; License; Open-source Software; Vulnerability","Article","Scopus"
"Henley M.; Kemp R.","Henley, Mark (57190411514); Kemp, Richard (8956539500)","57190411514; 8956539500","Open Source Software: An introduction","2008","Computer Law and Security Report","10.1016/j.clsr.2007.11.003","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979835750&doi=10.1016%2fj.clsr.2007.11.003&partnerID=40&md5=17fa1032e84df5f9b84de214622e6522","This article sets out the origins of Open Source Software and considers its progression from programming hobby to a mainstream commercial strategy for acquiring and maintaining competitive advantage. It looks at the types of open source licences in use and summarises the features of the most common. Some of the legal controversies arising from the use of open source licences are explained and guidance is given on how a corporate IT strategy might be adapted to manage the associated risks. © 2007 Kemp Little LLP.","","Article","Scopus"
"Tuunanen T.; Koskinen J.; Kärkkäinen T.","Tuunanen, Timo (14819947900); Koskinen, Jussi (9239546600); Kärkkäinen, Tommi (7004529257)","14819947900; 9239546600; 7004529257","Automated software license analysis","2009","Automated Software Engineering","10.1007/s10515-009-0054-z","40","https://www.scopus.com/inward/record.uri?eid=2-s2.0-68149155533&doi=10.1007%2fs10515-009-0054-z&partnerID=40&md5=e31a55f9930ff43b3c9b46b1a4919a4e","Software license is a legal instrument governing the usage or redistribution of copyright-protected software. License analysis is an elaborate undertaking, especially in case of large software consisting of numerous modules under different licenses. This paper describes an automated approach for supporting software license analysis. The approach is implemented in a reverse engineering tool called ASLA. We provide a detailed description of the architecture and features of the tool. The tool is evaluated on the basis of an analysis of 12 OSS (open source software) packages. The results show that licenses for (on average) 89% of the source code files can be identified by using ASLA and that the efficiency of the automated analysis is (on average) 111 files per second. In a further comparison with two other open source license analyzers-OSLC and FOSSology-ASLA shows a competitive performance. The results validate the general feasibility of the ASLA approach in the context of analyzing non-trivial OSS packages. © 2009 Springer Science+Business Media, LLC.","Open source software; Program comprehension; Reverse engineering; Software licenses; Software reuse","Article","Scopus"
"Krishnamurthy S.","Krishnamurthy, Sandeep (7202383517)","7202383517","A managerial overview of open source software","2003","Business Horizons","10.1016/S0007-6813(03)00071-5","66","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0042365091&doi=10.1016%2fS0007-6813%2803%2900071-5&partnerID=40&md5=fd78840ec06a9e3cf1444c892fad5b81","Open source software programs such as Linux and Apache give any interested party access to the source code, leading to a distributed innovation model in which users actively participate in the product's development. Often free, OSS products are distributed under many public licenses, are more reliable, and provide greater flexibility and choice. On the other hand, OSS leads to a proliferation of versions, and may appeal only to high-end users. The system leads to fascinating competitive and cooperative relationships among companies, between a company and a community, and among communities. How can managers choose?","","Article","Scopus"
"Katsamakas E.; Janamanchi B.; Raghupathi W.; Gao W.","Katsamakas, Evangelos (22985533000); Janamanchi, Balaji (10046048900); Raghupathi, Wullianallur (6603002503); Gao, Wei (14031480000)","22985533000; 10046048900; 6603002503; 14031480000","A Classification Analysis  of the Success of Open Source Health Information Technology Projects","2009","International Journal of Healthcare Information Systems and Informatics","10.4018/jhisi.2009071002","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85001576961&doi=10.4018%2fjhisi.2009071002&partnerID=40&md5=ec72eaf9f0b4e955b90bd842326a7597","As the number of open source software (OSS) projects in healthcare grows rapidly, researchers are faced with the challenge of understanding and explaining the success of the open source phenomenon. This article proposes a research framework that examines the roles of project sponsorship, license type, development status and technological complements in the success of open source health information technology (HIT) projects and it develops a systematic method for classifying projects based on their success potential. Drawing from economic theory, a novel proposition in the authors’ framework suggests that higher project-license restrictiveness will increase OSS adoption, because organizations will be more confident that the OSS project will remain open source in the future. Applying the framework to a sample of open source software projects in healthcare, the authors find that although project sponsorship and license restrictiveness influence project metrics, they are not significant predictors of project success categorization. On the other hand, development status, operating system and programming language are significant predictors of an OSS project's success categorization. Application implications and future research directions are discussed. © 2009, IGI Global. All rights reserved.","Health Care; Health Information Technology (HIT); License Restrictiveness; Open Source Software (OSS); Project Sponsorship; Project Success; Software Development","Article","Scopus"
"Lindman J.","Lindman, Juho (18836374100)","18836374100","Similarities of open data and open source: Impacts on business","2014","Journal of Theoretical and Applied Electronic Commerce Research","10.4067/S0718-18762014000300006","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905656102&doi=10.4067%2fS0718-18762014000300006&partnerID=40&md5=689d1f5b87b12a18a2b2ec14afe1941a","What are the similarities of open data and open source software when building a business? Despite their differences as phenomena (one is about applications and one is about data), the two also have many similarities. Both for example share the idea that the transparency of the artifact enables contribution. Many developers of open data have experience with open source development. But do the companies that build their offerings on open data and open source have similarities, and if so, what are the similarities? Drawing on fieldwork and interviews with software entrepreneurs and managers, this paper investigates these questions through an empirical focus on openness in business and clarifies the links between commercial organizations engaged with open source and open data. The article reports similarities on how the managers use the terms open data and open source to describe their business dynamic. These similarities are of importance to those who are interested in developing services that rely on open source or open data or who are interested in community management and legal and business issues or policy. © 2014 Universidad de Talca - Chile.","Business model; Developer communities; Open data; Open source; Software business","Article","Scopus"
"August T.; Chen W.; Zhu K.","August, Terrence (15055334000); Chen, Wei (55716043900); Zhu, Kevin (7201425580)","15055334000; 55716043900; 7201425580","Competition among proprietary and open-source software firms: The role of licensing in strategic contribution","2021","Management Science","10.1287/mnsc.2020.3674","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106551183&doi=10.1287%2fmnsc.2020.3674&partnerID=40&md5=13e0e92f7d4ba4e7eca4ebcaad643ac8","In enterprise software markets, firms are increasingly using services-based business models built on open-source software (OSS) to compete with established, proprietary software firms. Because third-party firms can also strategically contribute to OSS and compete in the services market, the nature of competition between OSS constituents and proprietary software firms can be complex. Moreover, their incentives are likely influenced by the licensing schemes that govern OSS. We study a three-player game and examine how open-source licensing affects competition among an open-source originator, an open-source contributor, and a proprietor competing in an enterprise software market. In this regard, we examine (1) how quality investments and prices are endogenously determined in equilibrium, (2) how license restrictiveness impacts equilibrium investments and the quality of offerings, and (3) how license restrictiveness affects consumer surplus and social welfare. Although some in the open-source community often advocate restrictive licenses such as theGNUGeneral Public License because it is not always in the best interest of the originator for the contributor to invest greater development effort, such licensing can actually be detrimental to both consumer surplus and social welfare when it exacerbates this incentive conflict. We find such an outcome in markets characterized by software providers with similar development capabilities yet cast in favor of the proprietor. In contrast, when these capabilities either become more dispersed or remain similar but tilt in favor of open source, a more restrictive license instead encourages greater effort from the OSS contributor, leads to higher OSS quality, and provides a larger societal benefit.  © 2020 INFORMS.","Co-creation; Collaborative development; Licensing; Open-source software; Product quality; Software competition; Software services market; Strategic contributions to open-source software","Article","Scopus"
"Martin M.G.","Martin, Marcus G. (57211598693)","57211598693","MCCCS Towhee: A tool for monte carlo molecular simulation","2013","Molecular Simulation","10.1080/08927022.2013.828208","201","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888391717&doi=10.1080%2f08927022.2013.828208&partnerID=40&md5=746f7558507bd7a84fa9d2401c2c5fc6","The history of the Monte Carlo for complex chemical systems Towhee open source Monte Carlo molecular simulation tool is discussed. A proof is given that the Widom insertion method for computing the chemical potential is formally correct even when combined with the most general version of arbitrary trial distribution configurational-bias Monte Carlo. A simulation strategy for computing single component vapour-liquid phase coexistence curves is presented as a guide for inexperienced practitioners of Monte Carlo simulations. A review of papers that cite the Towhee code is presented. The paper concludes with a discussion about releasing and sustaining a simulation package that uses an open source software license. © 2013 © 2013 Taylor & Francis.","","Article","Scopus"
"Riepula M.","Riepula, Mikko (41862286800)","41862286800","Sharing source code with clients: A hybrid business and development model","2011","IEEE Software","10.1109/MS.2011.53","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959716371&doi=10.1109%2fMS.2011.53&partnerID=40&md5=a5165a4468d4a8dd6026e98c78c12aea","Open innovation and the recent emphasis on client involvement imply the emergence of hybrid software licensing models combining the limited openness of source code with traditional value appropriation logic. A practical hybrid licensing model responds to the needs of both business-to-business software vendors in vertical domains and consultancies that must maintain separate quasi-products. The central idea is that the vendor of commoditized products also licenses source code to select clients, who become participants in and subscribers to an ongoing closed development community. The tools and techniques are readily available from open source development, but the motivations and relationship management work differently than in a pure open source context. © 2011 IEEE.","client coproduction; client innovation; client-shared source; corporate source; distributed development; gated source; hybrid OSS; inner source; open source; OSS 2.0; shared source; software business model; software commodification; software commoditization; software development; software engineering; software licensing","Article","Scopus"
"German D.; Di Penta M.","German, Daniel (57207886015); Di Penta, Massimiliano (6602794138)","57207886015; 6602794138","A method for open source license compliance of Java applications","2012","IEEE Software","10.1109/MS.2012.50","25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860459649&doi=10.1109%2fMS.2012.50&partnerID=40&md5=74ad30e871de1241b15878e047867181","Open source license compliance (OSLC) is the process of ensuring that an organization satisfies the licensing requirements of the open source software it reuses, whether for its internal use or as a part of a product it ships. The major challenges of OSLC include component identification, provenance discovery, license identification, and licensing requirements analysis. Kenen is an approach that assists organizations in OSLC for Java components. © 1984-2012 IEEE.","copyright; legal compliance; licensing; open source; provenance","Article","Scopus"
"Fortin F.-A.; De Rainville F.-M.; Gardner M.-A.; Parizeau M.; Gagńe C.","Fortin, F́elix-Antoine (55334089800); De Rainville, François-Michel (24586701800); Gardner, Marc-Andŕe (48161157200); Parizeau, Marc (12140404700); Gagńe, Christian (12140356400)","55334089800; 24586701800; 48161157200; 12140404700; 12140356400","DEAP: Evolutionary algorithms made easy","2012","Journal of Machine Learning Research","","1206","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864943278&partnerID=40&md5=8575303ff8bc2a10c2d9285d5cbcd0a1","DEAP is a novel evolutionary computation framework for rapid prototyping and testing of ideas. Its design departs from most other existing frameworks in that it seeks to make algorithms explicit and data structures transparent, as opposed to the more common black-box frameworks. Freely available with extensive documentation at http://deap.gel.ulaval.ca, DEAP is an open source project under an LGPL license. © 2012 Félix-Antoine Fortin, François-Michel De Rainville, Marc-André Gardner, Marc Parizeau, and Christian Gagné.","Distributed evolutionary algorithms; Software tools","Article","Scopus"
"Deka G.C.","Deka, Ganesh Chandra (55027383700)","55027383700","A Survey of cloud database systems","2014","IT Professional","10.1109/MITP.2013.1","26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899533303&doi=10.1109%2fMITP.2013.1&partnerID=40&md5=e2df5435a30de6769454bc3d86505dd1","This survey of 15 popular cloud databases provides an overview of each system and its storage platform, license type, and programming language used for writing the source code of the NoSQLs. It also considers important features such as data handling techniques and billing practices. © 2014 IEEE.","cloud database; NoSQL; open source software","Article","Scopus"
"Peng G.; Mu J.; Di Benedetto C.A.","Peng, Gang (36009172100); Mu, Jifeng (22985957500); Di Benedetto, C. Anthony (6701339505)","36009172100; 22985957500; 6701339505","Learning and open source software license choice","2013","Decision Sciences","10.1111/deci.12036","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84882675869&doi=10.1111%2fdeci.12036&partnerID=40&md5=a6f7cc8b662557d281b72bb62701783d","Licensing is the defining characteristic of open source software (OSS) and often has tremendous impact on the success of OSS projects. However, OSS licenses are very different from those for proprietary software, and our understanding of the choice of OSS licenses is very limited. In this study, we explore this important decision from a learning perspective. We build collaboration networks and trace paths through which potential learning and knowledge flow across projects using a dataset derived from SourceForge. We identify that both experiential learning and vicarious learning have significant influence on OSS license choice. We provide reasons why experiential learning and vicarious learning affect decision-making regarding OSS license choice, and explore important contingencies under which the two modes of learning are more effective. We find that leadership roles on prior projects and similarities between projects significantly moderate these two modes of learning, respectively. More importantly, we argue and empirically illustrate that experiential learning is more effective than vicarious learning in influencing OSS license choice. Our research sheds new light on our understanding of license choice for OSS projects and provides practical guidelines for future OSS development. © 2013 Decision Sciences Institute.","Decision-making; Experiential Learning; License Choice; Open Source Software; Social Networks; Vicarious Learning","Article","Scopus"
"Macdonald M.","Macdonald, Michaela (55946240600)","55946240600","Open source licensing in the networked ERA","2013","Masaryk University Journal of Law and Technology","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888873922&partnerID=40&md5=036b65e2620f16897dcc83703b330881","The underlying principles of open source software are 'openness' and interoperability. The licensing infrastructure ensures that these values will be preserved. However, the ideology may be under threat in the networked era. Cloud computing is a maturing technology practice whose success is contingent on utilizing open source software. Open source licences apply when software is distributed - mere running or making available does not trigger the protection. The new licence, Affero GPL, aims to prevent a potential proprietary lock-in in the cloud. This article argues that the attempt is futile. The freedom to modify software may be relevant for hobbyists, not for the majority of commercial enterprises. In the current technology set-up the values of open source worth preserving are accessibility, interoperability, and re-usability. And these will not be saved thanks to a licensing scheme, but thanks to an open and flexible architecture.","Affero GPL; Cloud computing; Distribution; Making available; Open source","Article","Scopus"
"O'Mahony S.","O'Mahony, Siobhán (56250956400)","56250956400","The governance of open source initiatives: What does it mean to be community managed?","2007","Journal of Management and Governance","10.1007/s10997-007-9024-7","104","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547338376&doi=10.1007%2fs10997-007-9024-7&partnerID=40&md5=b4b7d4ab22f53536cf8a616ae9751894","The concept of 'open source' software initially referred to software projects managed by grassroots communities in public forums. Since 1998, the concept has been adapted and diffused to new settings that extend beyond software. While the open source community has maintained control over which software licenses can be considered 'open source', little attention has been paid to the elements that constitute community management. More private parties now contribute to OSS communities and more hybrid governance models have emerged. Before we can understand how hybrid models differ from a community managed model, a more precise definition is needed. This essay takes a step in this direction by identifying five core principles critical to community-managed governance. © Springer Science+Business Media, LLC 2007.","Community management; Governance; Open source software; Software development","Article","Scopus"
"Kemp R.","Kemp, Richard (8956539500)","8956539500","Current developments in Open Source Software","2009","Computer Law and Security Review","10.1016/j.clsr.2009.09.009","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-71649086148&doi=10.1016%2fj.clsr.2009.09.009&partnerID=40&md5=70ab19310869a791d5112e8b384479fe","Open Source Software (OSS) has hit the mainstream in recent years and its scope is set to increase. Best seen as a range of associated licensing techniques, there are many different types of OSS licences. Coupled with a lack of settled case law and rapidly developing market practice, legal interpretation of the OSS world presents challenges to lawyers. Of the 'top 20' OSS licences, the GPL is the most commonly used and among the most radical in legal effect. The GPL's legal radicalism centres on its Article 2(b) concept of 'copyleft'. Copyleft is an inheritance requirement to pass on the GPL's terms to other software that 'contains' or is 'derived from' the initially used GPL software. I illustrations of Article 2(b) issues from the Linux and Java worlds are provided. Current case law (such as it is) is then overviewed. Finally, contractual and policy implications of OSS governance are then reviewed as the increasing uptake of OSS in the organisation is mirrored in the growing importance of OSS governance. © 2009 Kemp Little/LLP.","Copyleft; Free software; FSF; Governance; GPL; Java; Linux; Open Source","Article","Scopus"
"McRitchie K.; Spiewak R.","McRitchie, Karen (55486079500); Spiewak, Rick (25823987000)","55486079500; 25823987000","Re-using open source software in your software delivery","2016","CrossTalk","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959906541&partnerID=40&md5=b229c6e5a1d81771c412374820b1f3db","Open source software is generally available with few restrictions (depending on license) to be reused by other developers. Reuse of software presents both potential cost and schedule savings and corresponding risks to both cost and schedule. The key defining characteristic which distinguishes between risk and reward in this scenario is the quality of the software to be re-used. Wellestablished metrics and best practices in software development can be applied and assessed when examining open-source software for potential re-use.","","Article","Scopus"
"Papoutsoglou M.; Kapitsaki G.M.; German D.; Angelis L.","Papoutsoglou, Maria (57128423800); Kapitsaki, Georgia M. (24801845800); German, Daniel (57207886015); Angelis, Lefteris (6602528674)","57128423800; 24801845800; 57207886015; 6602528674","An analysis of open source software licensing questions in Stack Exchange sites","2022","Journal of Systems and Software","10.1016/j.jss.2021.111113","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117943388&doi=10.1016%2fj.jss.2021.111113&partnerID=40&md5=61f51f0ceda8405f8414a67dc4976740","Free and open source software is widely used in the creation of software systems, whereas many organizations choose to provide their systems as open source. Open source software carries licenses that determine the conditions under which the original software can be used. Appropriate use of licenses requires relevant expertise by the practitioners, and has an important legal angle. Educators and employers need to ensure that developers have the necessary training to understand licensing risks and how they can be addressed. At the same time, it is important to understand which issues practitioners face when they are using a specific open source license, when they are developing new open source software products or when they are reusing open source software. In this work, we examine questions posed about open source software licensing using data from the following Stack Exchange sites: Stack Overflow, Software Engineering, Open Source and Law. We analyze the indication of specific licenses and topics in the questions, investigate the attention the posts receive and trends over time, whether appropriate answers are provided and which type of questions are asked. Our results indicate that practitioners need, among other, clarifications about licensing specific software when other licenses are used, and for understanding license content. The results of the study can be useful for educators and employers, organizations that are authoring open source software licenses and developers for understanding the issues faced when using licenses, whereas they are relevant to other software engineering research areas, such as software reusability. © 2021 Elsevier Inc.","Open source software; Software licenses; Stack Exchange; Topic modeling","Article","Scopus"
"Dejanović I.; Milosavljević G.; Vaderna R.","Dejanović, I. (56473610200); Milosavljević, G. (6508132948); Vaderna, R. (57015596700)","56473610200; 6508132948; 57015596700","Arpeggio: A flexible PEG parser for Python","2016","Knowledge-Based Systems","10.1016/j.knosys.2015.12.004","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956597739&doi=10.1016%2fj.knosys.2015.12.004&partnerID=40&md5=ca202fefaa263195839ae1babbac8b80","Arpeggio is a recursive descent parser with full backtracking and memoization based on PEG (Parsing Expression Grammar) grammars. This category of parsers is known as packrat parsers. It is implemented in the Python programming language and works as a grammar interpreter. Arpeggio has a very good support for error reporting, debugging, and grammar and parse tree visualization. It is used in industrial environments and teaching Domain-Specific Languages course at the Faculty of Technical Sciences in Novi Sad. Arpeggio is a foundation of a high-level DSL meta-language and tool - textX. It is a free and open-source software available at GitHub under MIT license. © 2015 Elsevier B.V. All rights reserved.","DSL; Packrat; Parser; PEG; Python; TextX","Article","Scopus"
"Lundell B.; Gamalielsson J.; Katz A.","Lundell, Björn (7004530817); Gamalielsson, Jonas (6506812796); Katz, Andrew (57195941890)","7004530817; 6506812796; 57195941890","On Implementation of Open Standards in Software: To What Extent Can ISO Standards be Implemented in Open Source Software?","2015","International Journal of Standardization Research","10.4018/IJSR.2015010103","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019244771&doi=10.4018%2fIJSR.2015010103&partnerID=40&md5=b8f03b9b10d30811c76b13f9b14ee3ab","Several European countries, as well as the European Commission, have acknowledged the importance of open standards (under various definitions of that term) and have taken steps accordingly. Formal (e.g. ISO) standards are often referred to in software development and procurement, but may not necessarily also be open standards. The authors consider the application of formal standards where national policy promotes their use, and, since much contemporary software development involves open source software, they further consider the interaction between the requirement to comply with open standards, and the implementation of open and formal standards in open source software, with particular reference to patent licensing. It is shown that not all formal standards are open standards. SSO policies and procedures regarding the notification of standards-essential patents (SEPs) present challenges for organisations wishing to implement standards in software since such policies and procedures need to be compliant with procurement requirements, patent licences and open source software licences. This paper draws out some implications for those organisations (differentiating where appropriate between small companies and other organisations) and suggests a number of ways of addressing the challenges identified. Use of formal standards may create barriers for implementation in open source software and inhibit an open and inclusive business-friendly ecosystem, and to avoid such barriers is of particular importance for small companies that are essential players in an innovative and international society. © Copyright 2015, IGI Global.","Formal standards; Licensing; Open source software; Open standards; Patents","Article","Scopus"
"Sen R.; Subramaniam C.; Nelson M.L.","Sen, Ravi (9737868800); Subramaniam, Chandrasekar (8136647600); Nelson, Matthew L. (7403461430)","9737868800; 8136647600; 7403461430","Open source software licenses: Strong-copyleft, non-copyleft, or somewhere in between?","2011","Decision Support Systems","10.1016/j.dss.2011.07.004","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80455160314&doi=10.1016%2fj.dss.2011.07.004&partnerID=40&md5=e033a726e44cb4d72d8f9d9bd6ed1897","Studies on open source software (OSS) have shown that the license under which an OSS is released has an impact on the success or failure of the software. In this paper, we model the relationship between an OSS developer's utility, the effort that goes into developing an OSS, his attitude towards the freedom to choose an OSS license, and the choice of OSS license. We find that the larger the effort to develop OSS, the more is the likelihood that the OSS license would be free from restrictions. Interestingly, the result holds even when all OSS developers prefer restrictive licenses or less-restrictive license. The results suggest that least-restrictive or non-copyleft license will dominate other types of OSS license when a large effort is required to develop derivative software. On the other hand, most-restrictive or strong-copyleft licenses will be the dominant license when minimal effort is required to develop the original OSS and the derivative software. © 2011 Elsevier B.V. All rights reserved.","Copyleft; Copyright; FLOSS; Open source; OSS; Software license","Article","Scopus"
"Ghosh R.A.","Ghosh, Rishab Aiyer (25030115500)","25030115500","Licence fees and GDP per capita: The case for open source in developing countries","2007","First Monday","10.5210/fm.v0i0.1783","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019074370&doi=10.5210%2ffm.v0i0.1783&partnerID=40&md5=46015316b7e56f897436f0449da49947","There is a strong case for free software (also known as open source or libre software) being deployed widely in developing countries. This paper describes three reasons in particular: free software is a skills enabling platform; it is far cheaper; and it is more adaptable to local needs. The free software development community provides an environment of intensive interactive skills development at little explicit cost, which is particularly useful for local development of skills, especially in economically disadvantaged regions. Meanwhile, the controversy over total costs of ownership (TCO) of free vs. proprietary software is not applicable to developing countries and other regions with low labour costs, where the TCO advantage lies with free software, and the share of licence fees in TCO is much higher than in (richer) high labour cost countries. The note concludes with a table comparing license fees for proprietary software against GDP per capita for 176 countries. © First Monday, 1995-2017.","","Article","Scopus"
"Calderón P.A.T.; Paredes E.A.A.","Calderón, Pedro Alexis Torres (57205611963); Paredes, Emigdio Antonio Alfaro (57193533227)","57205611963; 57193533227","MEPES: Methodology for evaluating the performance of e-mail servers","2018","International Journal of Open Source Software and Processes","10.4018/IJOSSP.2018100103","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060804766&doi=10.4018%2fIJOSSP.2018100103&partnerID=40&md5=17235ef7340834d7598c2de55f06221a","The purpose of the article was to develop a methodology for evaluating performance of e-mail servers and to compare the performance of e-mail servers based on free software (freeware and open source software) with the performance of payment licensed e-mail servers, with an integrated focus. For obtaining this purpose, a descriptive and experimental study was developed, which population included 33 e-mail servers. Two e-mail servers with free license (Sendmail and Postfix) and two e-mail servers with payment license (Microsoft Exchange and Lotus Domino) were compared. For evaluating the performance (antispam capacity, antivirus filtering, and server resource consumption), special applications for that purpose were used. Finally, it was determined that the two products of e-mail servers implemented with free software (Sendmail and Postfix) had higher performance than the two licensed e-mail servers (Microsoft Exchange and Lotus Domino) which were implemented, under the conditions given in this research. Copyright © 2018, IGI Global.","E-mail servers; Free software; Licensed software; Methodology; Performance","Article","Scopus"
"Demil B.; Lecocq X.","Demil, Benot (28367573500); Lecocq, Xavier (6504235147)","28367573500; 6504235147","Neither market nor hierarchy nor network: The emergence of bazaar governance","2006","Organization Studies","10.1177/0170840606067250","177","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33749865157&doi=10.1177%2f0170840606067250&partnerID=40&md5=71eaa0985a72721051593b6b56d79e85","A growing body of literature describes the open source phenomenon in the software industry. Drawing on transaction cost economics, we propose that open source projects illustrate a new generic governance structure - which we label bazaar governance - based on a specific legal contract: the open licence. We characterize this structure in terms of its strengths and weaknesses and compare it to market, firm and network forms. Low levels of control and weak incentives intensity are distinctive features of bazaar, lending a high uncertainty to governed transactions. However, bazaar governance promotes the openness of open source communities, which can generate strong positive network externalities and subsequent efficiency in cumulative transactions. Our theoretical developments offer a potential basis for future research. Copyright © 2006 SAGE Publications.","Bazaar governance; Governance structure; Open source; Transaction cost economics","Article","Scopus"
"De Francisci Morales G.; Bifet A.","De Francisci Morales, Gianmarco (25924812500); Bifet, Albert (23093088900)","25924812500; 23093088900","SAMOA: Scalable advanced massive online analysis","2015","Journal of Machine Learning Research","","123","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923923168&partnerID=40&md5=ac8e988deb13f345aace9623d5b40df1","samoa (Scalable Advanced Massive Online Analysis) is a platform for mining big data streams. It provides a collection of distributed streaming algorithms for the most common data mining and machine learning tasks such as classification, clustering, and regression, as well as programming abstractions to develop new algorithms. It features a pluggable architecture that allows it to run on several distributed stream processing engines such as Storm, S4, and Samza. samoa is written in Java, is open source, and is available at http://samoa-project.net under the Apache Software License version 2.0. © 2015 Gianmarco De Francisci Morales and Albert Bifet.","Classification; Clustering; Data streams; Distributed systems; Machine learning; Regression; Toolbox","Article","Scopus"
"Bellifemine F.; Caire G.; Poggi A.; Rimassa G.","Bellifemine, Fabio (6701738119); Caire, Giovanni (57223453344); Poggi, Agostino (7101947836); Rimassa, Giovanni (56092584300)","6701738119; 57223453344; 7101947836; 56092584300","JADE: A software framework for developing multi-agent applications. Lessons learned","2008","Information and Software Technology","10.1016/j.infsof.2007.10.008","248","https://www.scopus.com/inward/record.uri?eid=2-s2.0-36549031203&doi=10.1016%2fj.infsof.2007.10.008&partnerID=40&md5=a01e216085139bcdc6e1c54e7728bf2e","Since a number of years agent technology is considered one of the most innovative technologies for the development of distributed software systems. While not yet a mainstream approach in software engineering at large, a lot of work on agent technology has been done, many research results and applications have been presented, and some software products exists which have moved from the research community to the industrial community. One of these is JADE, a software framework that facilitates development of interoperable intelligent multi-agent systems and that is distributed under an Open Source License. JADE is a very mature product, used by a heterogeneous community of users both in research activities and in industrial applications. This paper presents JADE and its technological components together with a discussion of the possible reasons for its success and lessons learned from the somewhat detached perspective possible nine years after its inception. © 2007 Elsevier B.V. All rights reserved.","Agent technology; Distributed systems; Open source software","Article","Scopus"
"Sinha A.; Niranjan D.K.; Singh A.","Sinha, Amit (57218962907); Niranjan, Dharmesh Kumar (57211606857); Singh, Alka (57211340731)","57218962907; 57211606857; 57211340731","Free & open source software (Foss) in website designing","2019","International Journal of Engineering and Advanced Technology","10.35940/ijeat.A1028.109119","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074594534&doi=10.35940%2fijeat.A1028.109119&partnerID=40&md5=545e57e086aeac52de9d0b0cbec36225","People want website to be fast, user-friendly, secure & free to use. Web sites have become a critical part of business, and the tools to create and deploy Web sites are becoming more flexible and easier to use. This paper talks about the role of FOSS in Website Designing. FOSS proves to be a boon for website developers in the way that they are secure, robust and free to use & modify. The open source tools available in the market facilitate the tool-box of a website developer. The use of FOSS increases the productivity, provide a secure Environment & also save a website developer of getting screwed under the copyright act. This paper talks about the technologies which FOSS world currently offers to the website developers and also the revolution which is awaiting to flourish the market. It also incorporates a study of the recent developments & the way market is becoming more dependent on FOSS. For example, PHP is the basic element of the most famous social networking website today, the Facebook. Also, GMAIL is entirely based on the open source language, Python. ©BEIESP.","Free & Open Source Software; GNU Public License; Open Source; Website Designing","Article","Scopus"
"Arner E.; Hayashizaki Y.; Daub C.O.","Arner, Erik (7006368112); Hayashizaki, Yoshihide (35355246400); Daub, Carsten O. (6603641082)","7006368112; 35355246400; 6603641082","NGSView: An extensible open source editor for next-generation sequencing data","2009","Bioinformatics","10.1093/bioinformatics/btp611","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-75249085150&doi=10.1093%2fbioinformatics%2fbtp611&partnerID=40&md5=186191cd0dc34b5d603ff5750c16565e","High-throughput sequencing technologies introduce novel demands on tools available for data analysis. We have developed NGSView (Next Generation Sequence View), a generally applicable, flexible and extensible next-generation sequence alignment editor. The software allows for visualization and manipulation of millions of sequences simultaneously on a desktop computer, through a graphical interface. NGSView is available under an open source license and can be extended through a well documented API. © The Author(s) 2009. Published by Oxford University Press.","","Article","Scopus"
"Gao J.; Xu D.","Gao, Jianjiong (55370612000); Xu, Dong (7404074295)","55370612000; 7404074295","The Musite open-source framework for phosphorylation-site prediction","2010","BMC Bioinformatics","10.1186/1471-2105-11-S12-S9","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650806643&doi=10.1186%2f1471-2105-11-S12-S9&partnerID=40&md5=248e85fe687c56fc526c1ea504ac6404","Background: With the rapid accumulation of phosphoproteomics data, phosphorylation-site prediction is becoming an increasingly active research area. More than a dozen phosphorylation-site prediction tools have been released in the past decade. However, there is currently no open-source framework specifically designed for phosphorylation-site prediction except Musite.Results: Here we present the Musite open-source framework for building applications to perform machine learning based phosphorylation-site prediction. Musite was implemented with six modules loosely coupled with each other. With its well-designed Java application programming interface (API), Musite can be easily extended to integrate various sources of biological evidence for phosphorylation-site prediction.Conclusions: Released under the GNU GPL open source license, Musite provides an open and extensible framework for phosphorylation-site prediction. The software with its source code is available at http://musite.sourceforge.net. © 2010 Gao and Xu; licensee BioMed Central Ltd.","","Article","Scopus"
"Higashi Y.; Ohira M.; Manabe Y.","Higashi, Yunosuke (57189488361); Ohira, Masao (16023175500); Manabe, Yuki (36661027300)","57189488361; 16023175500; 36661027300","Automating License Rule Generation to Help Maintain Rule-based OSS License Identification Tools","2023","Journal of Information Processing","10.2197/ipsjjip.31.2","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146505793&doi=10.2197%2fipsjjip.31.2&partnerID=40&md5=2c7a9c61f6b73485d34bf4aa5bbe9210","Many license identification tools have been proposed to support OSS reuse. License identification tools automatically identify OSS licenses declared in source files. Ninka is one of the most accurate license identification tools. Because OSS licenses are often newly created or inherited, rules built into license identification tools need to be created and updated on a regular basis. However, when a large number of unknown licenses are detected in large OSS products, it is not easy to manually create new rules. In our previous studies, we proposed a method for clustering license statements that Ninka determined to be unknown. In this paper, we propose a method to automatically generate license rules from the clustered license statements. Our approach further filters the license statements from the created clusters to extract sequential patterns and converts the extracted patterns into regular expressions. We conducted conduct a case study where our method is applied to 1,821, 3,561 and 2,838 unknown license statement files respectively collected from FreeBSD v10.3.0, Linux Kernel v4.4.6, and Debian v7.8.0, to confirm the usefulness of our method. As a result, we confirmed that our method successfully generated license rules that take into consideration the orthographical variants and that our method also efficiently identified licenses with a small number of license rules. Furthermore, we found that adding the license rules generated by our method to Ninka improves the licensing rule performance. © 2023 Information Processing Society of Japan.","License Identification; License Rules Generation; OSS License; Sequential Pattern Mining","Article","Scopus"
"Lee S.; German D.M.; Hwang S.-W.; Kim S.","Lee, Sanghoon (36023740500); German, Daniel M. (57207886015); Hwang, Seung-won (9734566500); Kim, Sunghun (12241083400)","36023740500; 57207886015; 9734566500; 12241083400","Crowdsourcing identification of license violations","2015","Journal of Computing Science and Engineering","10.5626/JCSE.2015.9.4.190","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008255741&doi=10.5626%2fJCSE.2015.9.4.190&partnerID=40&md5=3655630a564dc651851d979856a31071","Free and open source software (FOSS) has created a large pool of source codes that can be easily copied to create new applications. However, a copy should preserve copyright notice and license of the original file unless the license explicitly permits such a change. Through software evolution, it is challenging to keep original licenses or choose proper licenses. As a result, there are many potential license violations. Despite the fact that violations can have high impact on protecting copyright, identification of violations is highly complex. It relies on manual inspections by experts. However, such inspection cannot be scaled up with open source software released daily worldwide. To make this process scalable, we propose the following two methods: use machine-based algorithms to narrow down the potential violations; and guide non-experts to manually inspect violations. Using the first method, we found 219 projects (76.6%) with potential violations. Using the second method, we show that the accuracy of crowds is comparable to that of experts. Our techniques might help developers identify potential violations, understand the causes, and resolve these violations. © 2015. The Korean Institute of Information Scientists and Engineers.","Clone detection; Crowdsourcing; Software license; Violation","Article","Scopus"
"Krämer M.; Würz H.M.; Altenhofen C.","Krämer, Michel (57199808934); Würz, Hendrik M. (57197827226); Altenhofen, Christian (56733013300)","57199808934; 57197827226; 56733013300","Executing cyclic scientific workflows in the cloud","2021","Journal of Cloud Computing","10.1186/s13677-021-00229-7","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104021097&doi=10.1186%2fs13677-021-00229-7&partnerID=40&md5=e3261d7cad458016a3e9b54b71d4c014","We present an algorithm and a software architecture for a cloud-based system that executes cyclic scientific workflows whose structure may change during run time. Existing approaches either rely on workflow definitions based on directed acyclic graphs (DAGs) or require workarounds to implement cyclic structures. In contrast, our system supports cycles natively, avoids workarounds, and as such reduces the complexity of workflow modelling and maintenance. Our algorithm traverses workflow graphs and transforms them iteratively into linear sequences of executable actions. We call these sequences process chains. Our software architecture distributes the process chains to multiple compute nodes in the cloud and oversees their execution. We evaluate our approach by applying it to two practical use cases from the domains of astronomy and engineering. We also compare it with two existing workflow management systems. The evaluation demonstrates that our algorithm is able to execute dynamically changing workflows with cycles and that design and maintenance of complex workflows is easier than with existing solutions. It also shows that our software architecture can run process chains on multiple compute nodes in parallel to significantly speed up the workflow execution. An implementation of our algorithm and the software architecture is available with the Steep Workflow Management System that we released under an open-source license. The resources for the first practical use case are also available as open source for reproduction. © 2021, The Author(s).","Cloud computing; Distributed systems; Scientific workflow management systems; Workflow scheduling","Article","Scopus"
"Abdul Qadoos Bilal Khan M.; Shahbaz A.; Shahzad F.","Abdul Qadoos Bilal Khan, M. (37071968700); Shahbaz, Ahmed (37073485800); Shahzad, Farrukh (57213080222)","37071968700; 37073485800; 57213080222","A systematic mapping on selection of open source software license economic and social perspective","2011","Journal of Theoretical and Applied Information Technology","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79953675357&partnerID=40&md5=ee6a5ee19dffc839dd576165d3c1ba02","Open source software license is a contract under which any software release is called open source software. In 1980's, R. Stallman formed free software foundation which later introduced GNU GPL license. Any software which is release under this license is called open source software. Open source software is software which is free of cost and provides equal right to both contributors and users to redistribute, inspect and modification of its code. Therefore it has been attracted a large number of contributors from their community toward open source software movement. This also encouraged introducing different types of open source software licenses. Different open source software license introduces different types of benefits for both contributors and users. There are many factors, which can influence on a contributor's decision about the selection of open source software license. Therefore we gather motivation factors for which a contributor participates in open source software and also gather motivation factors on which a contributor takes decision about selecting open source software license. In this paper we conduct systematic mapping study. In this systematic mapping we accumulate publications on the motivation factors for which contributors participate in open source software and we also accumulate publications on motivation factors which influence on contributors in selection of open source software license. From the frequency of publications we found out the trends in this area of research. In this systematic mapping we included evaluation research, review paper mostly. © 2005 - 2011 JATIT & LLS. All rights reserved.","Open source software; Open source software license; Systematic mapping","Article","Scopus"
"Allyn M.R.; Misra R.B.","Allyn, Mark R. (36805646000); Misra, Ram B. (7203049852)","36805646000; 7203049852","Motivation of open source developers: Do license type and status hierarchy matter?","2009","International Journal of Open Source Software and Processes","10.4018/jossp.2009100104","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651538394&doi=10.4018%2fjossp.2009100104&partnerID=40&md5=4e06de61ce5708a16be1ab5c0b38d157","The motivational drivers of open source software developers have been researched by various investigators since about 2000. This work shows that developers are motivated by different extrinsic and intrinsic drivers, among them community aspirations, reciprocity and fairness, creative impulses, and monetary and career ambitions. There has been some work done in studying whether the profile of developer motivations is constant across open source projects or is sensitive to project organizational design. Among the many factors that could influence the mix of motives of OS developers is the license under which the work is performed. Licenses range in openness between those such as the GNU GPL that severely restrict the freedom of developers to mingle their OS code with proprietary code to those such as BSD licenses which allow programmers much greater latitude in integrating open source code with proprietary code. In addition to formal rules, meritocracies emerge to reward effort and performance, and also to direct, coordinate, and control other participants. The authors discuss these variables and how they may be related to motivations. © 2010, IGI Global.","Code; Hierarchy; Motivation; Open source licenses; Open source software","Article","Scopus"
"Kaltenberger F.; Silva A.P.; Gosain A.; Wang L.; Nguyen T.-T.","Kaltenberger, Florian (55897560600); Silva, Aloizio P. (15064555600); Gosain, Abhimanyu (24821939300); Wang, Luhan (55926026700); Nguyen, Tien-Thinh (55382357800)","55897560600; 15064555600; 24821939300; 55926026700; 55382357800","OpenAirInterface: Democratizing innovation in the 5G Era","2020","Computer Networks","10.1016/j.comnet.2020.107284","37","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084171589&doi=10.1016%2fj.comnet.2020.107284&partnerID=40&md5=064f90c3bcde5180c0855e3bdd27027a","OpenAirInterfaceTM (OAI) is an open-source project that implements the 3rd Generation Partnership Project (3GPP) technology on general purpose x86 computing hardware and Off-The-Shelf (COTS) Software Defined Radio (SDR) cards like the Universal Software Radio Peripheral (USRP). It makes it possible to deploy and operate a 4G Long-Term Evolution (LTE) network today and 5G New Radio (NR) networks in the future at a very low cost. Moreover, the open-source code can be adapted to different use cases and deployment and new functionality can be implemented, making it an ideal platform for both industrial and academic research. The OAI Software Alliance (OSA) is a non-profit consortium fostering a community of industrial as well as research contributors. It also developed the OAI public license which is an open source license that allows contributors to implement their own patented technology without having to relinquish their intellectual property rights. This new clause is in agreement with the Fair, Reasonable And Non-Discriminatory (FRAND) clause found in 3GPP. This paper describes the current OAI state-of-the-art of the development, the OAI community and development process, as well as the OAI public license and its usage by academia and industry. © 2020 Elsevier B.V.","5G; LTE; Network softwarization; New radio technology; Open Air Interface","Article","Scopus"
"Choi N.","Choi, Namjoo (26028551500)","26028551500","The application profiles and development characteristics of library Open Source Software projects","2014","Library Hi Tech","10.1108/LHT-09-2013-0127","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927523903&doi=10.1108%2fLHT-09-2013-0127&partnerID=40&md5=69cdd5966e8425127f638cf6b7177e6e","Purpose – Little is known as to the breadth and diversity of Open Source Software (OSS) applications for libraries and the development characteristics that influence the sustainability and success of projects creating them. The purpose of this paper is to address this gap by analyzing a large sample of library OSS projects. Design/methodology/approach – A total of 594 library OSS projects (469 from SourceForge and 125 from Foss4lib) are classified by type and further differentiated and assessed across a number of criteria including, but not limited to, sponsorship status, license type, and development status. Findings – While various types of library OSS applications were found to be under development and in use, the results show that there has been a steady decrease in the number of projects initiated since 2009. Although sponsorship was significantly positively associated with several indicators of OSS project success, the proportion of sponsored projects was relatively small compared to the proportions reported in some other contexts. In total, 71 percent of the projects have a restrictive license scheme, suggesting that the OSS ideology is valued among library OSS projects. The results also indicate that library OSS projects exhibit several characteristics that differ from the traditional developer-oriented OSS projects in terms of their technical environment. Originality/value – This study, as the first of its kind, offers a broader, more quantitative picture of the state of library OSS applications as well as the development characteristics of projects developing them. Several implications for research and practice, and directions for future research are provided. © Emerald Group Publishing Limited.","Library systems; Open Source Software; Software development; Software licensing; Software sponsorship","Article","Scopus"
"Müller T.","Müller, Tristan (36934027300)","36934027300","How to choose a free and open source integrated library system","2011","OCLC Systems and Services","10.1108/10650751111106573","39","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79551658326&doi=10.1108%2f10650751111106573&partnerID=40&md5=9fa07e563650ab766bfd4956a4db8d25","Purpose: This paper seeks to present the results of an analysis of 20 free and open source ILS platforms offered to the library community. These software platforms were subjected to a three-step analysis, whereby the results aim to assist librarians and decision makers in selecting an open source ILS, based on objective criteria. Design/methodology/approach: The methodology applied involves three broad steps. The first step consists of evaluating all the available ILSs and keeping only those that qualify as truly open source or freely-licensed software. During this step, the correlation between the practices within the community and the terms associated with the free or open software license was measured. The second step involves evaluating the community behind each open source or free ILS project, according to a set of 40 criteria in order to determine the attractiveness and sustainability of each project. The third step entails subjecting the remaining ILSs to an analysis of almost 800 functions and features to determine which ILSs are most suited to the needs of libraries. The final score is used to identify strengths, weaknesses and differentiating or similar features of each ILS. Findings: More than 20 open source ILSs were submitted to this methodology, but only three passed all the steps: Evergreen, Koha, and PMB. The main goal is not to identify the best open source ILS, but rather to highlight from which, of the batch of dozens of open source ILSs, librarians and decision makers can choose without worrying about how perennial or sustainable each open or free project is, as well as understanding which ILS provides them with the functionalities to meet the needs of their institutions. Practical implications: This paper offers a basic model so that librarians and decision makers can make their own analysis and adapt it to the needs of their libraries. Originality/value: This methodology meets the best practices in technology selection, with a multiple criteria decision analysis. It can also be easily adapted to the needs of all libraries. © Emerald Group Publishing Limited.","Computer software; Libraries; Library systems","Article","Scopus"
"Mukerji B.; Maheshwari B.; Kumar U.; Kumar V.","Mukerji, Bhasker (38862598200); Maheshwari, Bharat (7003385355); Kumar, Uma (7102636340); Kumar, Vinod (35240370300)","38862598200; 7003385355; 7102636340; 35240370300","Open source software: emerging business models","2010","International Journal of Information and Decision Sciences","10.1504/IJIDS.2010.037229","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951713436&doi=10.1504%2fIJIDS.2010.037229&partnerID=40&md5=4251258daa8f2340f7da90b194cef450","Several small and large firms have devised business models and strategies to use open source software (OSS) gainfully. However, despite the increasing popularity and success of some OSS, there is very little academic literature that provides clarity and guidance on developing business models with OSS. This paper contributes to the existing knowledge by critically analysing the various open source business models and then building a set of business models that encompass the current trends in this field. The models presented are supported by descriptions of organisations that have used them successfully. © 2010 Inderscience Enterprises Ltd.","open source software; OSS; OSS business model; OSS community; OSS licences","Article","Scopus"
"Park J.-S.; Kim S.-H.","Park, Jun-Seok (56192401600); Kim, Soo-Hong (7601579454)","56192401600; 7601579454","Safe architecture design strategies of the proprietary Software through analysis of GPL license family","2014","Contemporary Engineering Sciences","10.12988/ces.2014.49176","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951288384&doi=10.12988%2fces.2014.49176&partnerID=40&md5=25d2f707909910403e7cd7d8f92c0b7a","Open Source Software(OSS) is being used extensively around the world with the emergence of its various advantages, but cases of violations of it are also increasing due to the lack of understanding in licenses. However, the researches on the violation of OSS licenses are focused on the areas of law, patent and economy, and it is rare to find a research paper on the violation of structural licenses that can occur in the actual development of software. We have analyzed cases of violation of licenses in GPL group, the typical OSS licenses, schematized it to develop a model based on which will be used to study architecture design strategies to avoid violation of copyright. © 2014 Jun-Seok Park and Soo-Hong Kim.","Conflict; Open source license; Proprietary; Snippet; Violation","Article","Scopus"
"Runeson P.; Olsson T.; Linåker J.","Runeson, Per (57202664772); Olsson, Thomas (52365610500); Linåker, Johan (56426528100)","57202664772; 52365610500; 56426528100","Open Data Ecosystems — An empirical investigation into an emerging industry collaboration concept","2021","Journal of Systems and Software","10.1016/j.jss.2021.111088","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115889980&doi=10.1016%2fj.jss.2021.111088&partnerID=40&md5=c6ddc28853e79df7e1af1d2c836e8802","Software systems are increasingly depending on data, particularly with the rising use of machine learning, and developers are looking for new sources of data. Open Data Ecosystems (ODE) is an emerging concept for data sharing under public licenses in software ecosystems, similar to Open Source Software (OSS). It has certain similarities to Open Government Data (OGD), where public agencies share data for innovation and transparency. We aimed to explore open data ecosystems involving commercial actors. Thus, we organized five focus groups with 27 practitioners from 22 companies, public organizations, and research institutes. Based on the outcomes, we surveyed three cases of emerging ODE practice to further understand the concepts and to validate the initial findings. The main outcome is an initial conceptual model of ODEs’ value, intrinsics, governance, and evolution, and propositions for practice and further research. We found that ODE must be value driven. Regarding the intrinsics of data, we found their type, meta-data, and legal frameworks influential for their openness. We also found the characteristics of ecosystem initiation, organization, data acquisition and openness be differentiating, which we advise research and practice to take into consideration. © 2021 The Author(s)","Empirical study; Open data; Open data ecosystem; Open innovation","Article","Scopus"
"Kochev N.; Jeliazkova N.; Tancheva G.","Kochev, Nikolay (7801569368); Jeliazkova, Nina (8378341000); Tancheva, Gergana (57219198863)","7801569368; 8378341000; 57219198863","Ambit-SLN: an Open Source Software Library for Processing of Chemical Objects via SLN Linear Notation","2021","Molecular Informatics","10.1002/minf.202100027","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111832381&doi=10.1002%2fminf.202100027&partnerID=40&md5=6619e24ec39098c98d788fd4461eb605","SLN (SYBYL Line Notation) is the most comprehensive and rich linear notation for representation of chemical objects of various kinds facilitating a wide range of cheminformatics algorithms. Though, it is not the most popular linear notation nowadays, SLN has capabilities for supporting the most challenging tasks of the present day cheminformatics research. We present Ambit-SLN, a new software library for cheminformatics processing of chemical objects via linear notation SLN. Ambit-SLN is developed as a part of the cheminformatics platform AMBIT. It is an open-source tool, distributed under LGPL license, written in Java and based on the Chemistry Development Kit. Ambit-SLN includes a parser for the full SLN syntax of chemical structures and substructure search queries including support for macro and Markush atoms, global and local dictionaries and user defined properties which can be stored and used by the Ambit data model. The Ambit-SLN library includes functionalities for substructure matching based on SLN query strings and utilities for conversion of SLN objects to other chemical formats such as SMILES and SMARTS. The functionality for Markush atom expansion can be used for generation of combinatorial structure sets. © 2021 Wiley-VCH GmbH","Ambit; cheminformatics; linear notation; Markush structure; SLN; structure conversion; structure representation; substructure searching","Article","Scopus"
"Bunting P.; Clewley D.; Lucas R.M.; Gillingham S.","Bunting, Peter (34568088000); Clewley, Daniel (35810095700); Lucas, Richard M. (55816939900); Gillingham, Sam (6508060899)","34568088000; 35810095700; 55816939900; 6508060899","The Remote Sensing and GIS Software Library (RSGISLib)","2014","Computers and Geosciences","10.1016/j.cageo.2013.08.007","82","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887828475&doi=10.1016%2fj.cageo.2013.08.007&partnerID=40&md5=54272ab8e7033ac9d94c951f425fe97e","Key to the successful application of remotely sensed data to real world problems is software that is capable of performing commonly used functions efficiently over large datasets, whilst being adaptable to new techniques. This paper presents an open source software library that was developed through research undertaken at Aberystwyth University for environmental remote sensing, particularly in relation to vegetation science. The software was designed to fill the gaps within existing software packages and to provide a platform to ease the implementation of new and innovative algorithms and data processing techniques. Users interact with the software through an XML script, where XML tags and attributes are used to parameterise the available commands, which have now grown to more than 300. A key feature of the XML interface is that command options are easily recognisable to the user because of their logical and descriptive names. Through the XML interface, processing chains and batch processing are supported. More recently a Python binding has been added to RSGISLib allowing individual XML commands to be called as Python functions. To date the Python binding has over 100 available functions, mainly concentrating on image utilities, segmentation, calibration and raster GIS. The software has been released under a GPL3 license and makes use of a number of other open source software libraries (e.g., GDAL/OGR), a user guide and the source code are available at http://www.rsgislib.org. © 2013 Elsevier Ltd.","GIS; Open source; Raster; Remote sensing; Software; Vector","Article","Scopus"
"Wessel M.; De Souza B.M.; Steinmacher I.; Wiese I.S.; Polato I.; Chaves A.P.; Gerosa M.A.","Wessel, Mairieli (57204421132); De Souza, Bruno Mendes (57209060615); Steinmacher, Igor (36609225300); Wiese, Igor S. (6603482090); Polato, Ivanilton (14056929200); Chaves, Ana Paula (25929057200); Gerosa, Marco A. (10043515400)","57204421132; 57209060615; 36609225300; 6603482090; 14056929200; 25929057200; 10043515400","The power of bots: Understanding bots in OSS projects","2018","Proceedings of the ACM on Human-Computer Interaction","10.1145/3274451","73","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064157845&doi=10.1145%2f3274451&partnerID=40&md5=9b136fc43db8f92bbd51f215980b01ba","Leveraging the pull request model of social coding platforms, Open Source Software (OSS) integrators review developers' contributions, checking aspects like license, code quality, and testability. Some projects use bots to automate predened, sometimes repetitive tasks, thereby assisting integrators' and contributors' work. Our research investigates the usage and impact of such bots. We sampled 351 popular projects from GitHub and found that 93 (26%) use bots. We classied the bots, collected metrics from before and after bot adoption, and surveyed 228 developers and integrators. Our results indicate that bots perform numerous tasks. Although integrators reported that bots are useful for maintenance tasks, we did not nd a consistent, statistically signicant dierence between before and after bot adoption across the analyzed projects in terms of number of comments, commits, changed les, and time to close pull requests. Our survey respondents deem the current bots as not smart enough and provided insights into the bots' relevance for specic tasks, challenges, and potential new features. We discuss some of the raised suggestions and challenges in light of the literature in order to help GitHub bot designers reuse and test ideas and technologies already investigated in other contexts. © 2018 Association for Computing Machinery.","Automated agents; Bots; Chatbots; Open source software; Pull request; Pull-based model","Article","Scopus"
"Żok K.","Żok, Krzysztof (57211337079)","57211337079","THE REFERENCE to “A WORK OR SOFTWARE” AS the FACTOR DETERMINING the SCOPE of the EUROPEAN UNION PUBLIC LICENCE (EUPL) V. 1.2","2021","Masaryk University Journal of Law and Technology","10.5817/MUJLT2021-2-2","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117579558&doi=10.5817%2fMUJLT2021-2-2&partnerID=40&md5=c8aa13436a6102648eeab44ea52a2a43","Free and open source software (FOSS) has undoubtedly become an important element of intellectual property law. It is therefore not surprising that the European Commission developed its own non-proprietary licence, i.e. the European Union Public Licence (EUPL). The article examines the reference to ‘a work of software’ to determine the scope of the licence. For this purpose, the paper discusses the reasons for the creation of the EUPL, the relationship between a work and software as well as the structure of a computer program. The following considerations also include the compatible licences listed in the EUPL Appendix. The article concludes that the reference to a work or software is not accidental because it removes serious doubts arising from the concept of a computer program. Thus, this legal solution may facilitate the wider adoption of the licence. © 2021 Masaryk University Journal of Law and Technology. All rights reserved.","Computer Program; Copyright Law; European Law; European Union Public Licence (EUPL); Non-proprietary Software Licences","Article","Scopus"
"Pruett J.; Choi N.","Pruett, Joseph (55861916800); Choi, Namjoo (26028551500)","55861916800; 26028551500","A comparison between select open source and proprietary integrated library systems","2013","Library Hi Tech","10.1108/LHT-01-2013-0003","25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884515682&doi=10.1108%2fLHT-01-2013-0003&partnerID=40&md5=eaae2eb539cfb939033dfe31d3ac3bf6","As libraries face budget cuts, open source integrated library systems are an attractive alternative to proprietary choices. Even though open source software is free to acquire, administrators must consider factors other than initial purchase price. This study aims to provide direction and context for libraries considering migration to an open source integrated library system. The comparison is qualitative and uses case studies, license agreements and copyright law, and user manuals and brochures. These comparisons divide into four areas: functions, adoption and technical support, usability, and economics. Major functions that libraries need in an integrated library system are available for open source software. There are no significant differences in usability between open source and proprietary integrated library systems. Internal IT provides a significant role in open source adoption. The relatively new type of open source software licensing may cause confusion for libraries and software developers. This study considers initial migrations to open source integrated library systems as a key component in overall software adoption. The study qualitatively examines the migration process comparing extant case studies. In addition, the examination of licensing agreements and copyright as well as a comparative review of essential functions are provided. © 2013, Emerald Group Publishing Limited","Integrated library systems; Library management systems; Library systems; Open source; Open source software; Software licenses; Technical support; Usability","Article","Scopus"
"Osterloh M.; Rota S.","Osterloh, Margit (57204638224); Rota, Sandra (15842614600)","57204638224; 15842614600","Open source software development-Just another case of collective invention?","2007","Research Policy","10.1016/j.respol.2006.10.004","163","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846883291&doi=10.1016%2fj.respol.2006.10.004&partnerID=40&md5=3b3f4cff042a60b268a30310384932dd","Do open source software (OSS) projects represent a new innovation model? Under what conditions can it be employed in other contexts? ""Collective invention"" regimes usually ended when a dominant design emerged. This is not the case with OSS. Firstly, the OSS community developed the institutional innovation of OSS licenses enabling OSS software to survive as a common property. Secondly, these licenses are mainly enforced by pro-socially motivated contributors. We characterize the conditions under which OSS communities develop and sustain pro-social commitments. We point out the vulnerability of these conditions to developments in patent legislation. © 2007.","Collective invention; Copyleft; Intrinsic motivation; New innovaton models; Open source software","Article","Scopus"
"Sharma S.; Sugumaran V.; Rajagopalan B.","Sharma, Srinarayan (55491686500); Sugumaran, Vijayan (57210215570); Rajagopalan, Balaji (55628574891)","55491686500; 57210215570; 55628574891","A framework for creating hybrid-open source software communities","2002","Information Systems Journal","10.1046/j.1365-2575.2002.00116.x","155","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036108945&doi=10.1046%2fj.1365-2575.2002.00116.x&partnerID=40&md5=99b2b17b25b7d67549ecb5b2c4a15462","The open source software (OSS) model is a fundamentally new and revolutionary way to develop software. The success of the OSS model is also setting the stage for a structural change in the software industry; it is beginning to transform software industry from manufacturing to a service industry. Despite the success of the OSS model, for-profit organizations are having difficulty building a business model around the open source paradigm. Whereas there are some isolated empirical studies, little rigorous research has been done on how traditional organizations can implement and benefit from OSS practices. This research explores how organizations can foster an environment similar to OSS to manage their software development efforts to reap its numerous advantages. Drawing on organizational theory, we develop a framework that guides the creation and management of a hybrid-OSS community within an organization. We discuss the implications of this framework and suggest areas for future research.","Features of OSS; Hybrid-OSS community; Open source software; OSS framework; Software development","Article","Scopus"
"Dequeker C.; Laine E.; Carbone A.","Dequeker, Chloé (57197853077); Laine, Elodie (24331907100); Carbone, Alessandra (57196175695)","57197853077; 24331907100; 57196175695","INTerface Builder: A Fast Protein-Protein Interface Reconstruction Tool","2017","Journal of Chemical Information and Modeling","10.1021/acs.jcim.7b00360","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035335908&doi=10.1021%2facs.jcim.7b00360&partnerID=40&md5=8f8f0ca8fd831eb141c3de3ae2d8ec5c","INTerface Builder (INTBuilder) is a fast, easy-to-use program to compute protein-protein interfaces. It is designed to retrieve interfaces from molecular docking software outputs in an empirically determined linear complexity. INTBuilder directly reads the output formats of popular docking programs like ATTRACT, HEX, MAXDo, and ZDOCK, as well as a more generic format and Protein Data Bank (PDB) files. It identifies interacting surfaces at both residue and atom resolutions. INTerface Builder is an open source software written in C and freely available for noncommercial use (CeCILL license) at https://www.lcqb.upmc.fr/INTBuilder. © 2017 American Chemical Society.","","Article","Scopus"
"Menegon S.; Sarretta A.; Depellegrin D.; Farella G.; Venier C.; Barbanti A.","Menegon, Stefano (12786659400); Sarretta, Alessandro (16029521000); Depellegrin, Daniel (36682343400); Farella, Giulio (57164797800); Venier, Chiara (54928529600); Barbanti, Andrea (6701554111)","12786659400; 16029521000; 36682343400; 57164797800; 54928529600; 6701554111","Tools4MSP: An open source software package to support Maritime Spatial Planning","2018","PeerJ Computer Science","10.7717/peerj-cs.165","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055743585&doi=10.7717%2fpeerj-cs.165&partnerID=40&md5=fc58a62869ef099b6707a07e7a5538de","This paper presents the Tools4MSP software package, a Python-based Free and Open Source Software (FOSS) for geospatial analysis in support of Maritime Spatial Planning (MSP) and marine environmental management. The suite was initially developed within the ADRIPLAN data portal, that has been recently upgraded into the Tools4MSP Geoplatform (data.tools4msp.eu), an integrated web platform that supports MSP through the application of different tools, e.g., collaborative geospatial modelling of cumulative effects assessment (CEA) and marine use conflict (MUC) analysis. The package can be used as stand-alone library or as collaborative webtool, providing user- friendly interfaces appropriate to decision-makers, regional authorities, academics and MSP stakeholders. An effective MSP-oriented integrated system of web-based software, users and services is proposed. It includes four components: the Tools4MSP Geoplatform for interoperable and collaborative sharing of geospatial datasets and for MSP-oriented analysis, the Tools4MSP package as stand-alone library for advanced geospatial and statistical analysis, the desktop applications to simplify data curation and the third party data repositories for multidisciplinary and multilevel geospatial datasets integration. The paper presents an application example of the Tools4MSP GeoNode plugin and an example of Tools4MSP stand-alone library for CEA in the Adriatic Sea. The Tools4MSP and the developed software have been released as FOSS under the GPL 3 license and are currently under further development. © 2018 Menegon et al.","Cumulative Effects Assessment; GeoNode; Maritime spatial planning; Open Source; Python; SDI; Tools4MSP software","Article","Scopus"
"Trinkenreich B.; Guizani M.; Wiese I.; Sarma A.; Steinmacher I.","Trinkenreich, Bianca (56786270500); Guizani, Mariam (57219609576); Wiese, Igor (6603482090); Sarma, Anita (7004458190); Steinmacher, Igor (36609225300)","56786270500; 57219609576; 6603482090; 7004458190; 36609225300","Hidden Figures: Roles and Pathways of Successful OSS Contributors","2020","Proceedings of the ACM on Human-Computer Interaction","10.1145/3415251","27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094204872&doi=10.1145%2f3415251&partnerID=40&md5=8834ba5a58f158d971a20c2950bd1ca3","Open Source Software (OSS) development is a collaborative endeavor where expert developers, distributed around the globe create software solutions. Given this characteristic, OSS communities have been studied as technical communities, where stakeholders join and evolve in their careers based on their (often voluntary) code contributions to the project. However, the OSS landscape is slowly changing with more people and companies getting involved in OSS. This means that projects now need people in non-technical roles and activities to keep the project sustainable and evolving. In this paper, we focus on understanding the roles and activities that are part of the current OSS landscape and the different career pathways in OSS. By conducting and analyzing 17 interviews with OSS contributors who are well known in the community, we provide empirical evidence of the existence and importance of community-centric roles (e.g advocate, license manager, community founder) in addition to the well-known project-centric ones (e.g maintainer, core member). However, the community-centric roles typically remain hidden, since these roles may not leave traces in software repositories typically analyzed by researchers. We found that people can build a career in OSS through different roles and activities, with different backgrounds, including those not related to writing software. Furthermore, people's career pathways are fluid, moving between project and community-centric roles. Our work highlights that communities and researchers need to take action to acknowledge the importance of these varied roles, making these roles visible and well-recognized, which can ultimately help attract and retain more people in the OSS projects.  © 2020 ACM.","career; collaborative development; open-source; role","Article","Scopus"
"Rajala R.; Westerlund M.; Möller K.","Rajala, Risto (23477936100); Westerlund, Mika (23478525300); Möller, Kristian (7202900756)","23477936100; 23478525300; 7202900756","Strategic flexibility in open innovation - designing business models for open source software","2012","European Journal of Marketing","10.1108/03090561211248071","44","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866682723&doi=10.1108%2f03090561211248071&partnerID=40&md5=8f296bd1eaee9fefca7f7daf09a4d0a2","Purpose: This paper seeks to explore how market orientation facilitates the strategic flexibility of business models grounded in open innovation. The authors suggest that the new paradigm of open innovation may impact a firm's adaptability and responsiveness under conditions of environmental flux. However, extending innovation capacity by opening the innovation process poses major challenges for firms. The aims of this study are to explore the characteristics of open innovation activity and to contemplate the role of strategic flexibility in the design of business models based upon open innovation. Design/methodology/approach: The study draws upon a qualitative research approach through a longitudinal case study in the field of open source software (OSS). The empirical case illustrates how an OSS firm utilizes signals in its environment to flexibly alter its business model. Findings: A business model that embodies open innovation raises dilemmas between open and closed innovation paradigms. However, the authors' case highlights that an ambidextrous approach that combines market orientation with the principles of open innovation increases profitability, shortens time to market through effective market access, and enhances innovation capability. Research limitations/implications: The results have profound implications for industrial marketers, managers, management consultants and business educators. They can use the insights gleaned from this research to guide the development of business models that involve open innovation. The results indicate that firms involved in open innovation need reactive strategic flexibility to cope with the environmental diversity and variability. However, this study analyzes a single case in the field of OSS and one should be cautious when generalizing the findings. Originality/value: This paper improves the understanding of the relationship between flexibility and market orientation. It combines two areas that have previously been discussed separately, i.e. market orientation and open innovation. © Emerald Group Publishing Limited.","Business models; Management strategy; Market orientation; Open innovation; Open source; Strategic flexibility","Article","Scopus"
"Kemp R.","Kemp, Richard (8956539500)","8956539500","Open source software (OSS) governance in the organisation","2010","Computer Law and Security Review","10.1016/j.clsr.2010.01.008","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955576260&doi=10.1016%2fj.clsr.2010.01.008&partnerID=40&md5=40d1b4f30dbd04224b6767f33a6c247d","Going into the century's second decade, Open Source Software (OSS) is ubiquitous. But there remains a disconnect between OSS use and its effective management. In order to ensure that OSS is used in a way which complies with relevant licence requirements and reduces risk (for example, of adverse action from the OSS community and IP leakage through unintended application of the 'copyleft' terms of the GPL2); organisations should consider putting in place an effective OSS governance mechanism. OSS governance should take account of the people context, seeking to get buy-in from all stakeholder groups inside and outside the organisation. The high-level OSS strategy should then be agreed between the stakeholders, consistently with other statements of operational strategy. The next level down is the OSS policy statement, which should be clear, brief, event-driven, able to settle 80% of OSS decisions arising day to day and set out what information is to be collected and tracked. Finally, appropriate processes should be put in place to take the strain of OSS governance. Organisations should consider appointing an Open Source Compliance Officer and acquiring a software based indicator tool enabling a number of key governance processes (code review, setting agreed 'do's and dont's') to be automated. © 2010 Xiaolu Zhang. Published by Elsevier Ltd. Allrights reserved.","Compliance; Governance; Open source; Policy; Processes; Risk management; Software; Strategy","Article","Scopus"
"Pallottino F.; Menesatti P.; Antonucci F.; Figorilli S.; Proto A.R.; Costa C.","Pallottino, F. (16031753700); Menesatti, P. (6602984740); Antonucci, F. (24821146100); Figorilli, S. (55192443300); Proto, A.R. (25651995400); Costa, C. (23105352100)","16031753700; 6602984740; 24821146100; 55192443300; 25651995400; 23105352100","Image analysis based open source conveyor belt prototype for wood pellet and chip quality assessment","2016","Contemporary Engineering Sciences","10.12988/ces.2016.68138","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011890856&doi=10.12988%2fces.2016.68138&partnerID=40&md5=d7dd16efd38004e5a5060ce76510499b","Pellet represent a well spread commodity for energy production in Europe with a rapidly increasing market. Previous studies evidenced as the color could be used for visual prediction of pellets quality through RGB calibration methodologies paired with image analysis techniques. The open source software and hardware available nowadays represent a great possibility for prototypes development due to their affordable nature and commercially suitable license. Therefore, this work point to the development of an image analysis based open source conveyor belt prototype for pellet quality assessment. The realized open source system, coupled with image analysis, could allow a rapid characterization of wood pellet and chip. Moreover, being based on open source technologies, it resulted to be low cost and could be able to characterize large quantities of products. The system, following a proper calibration, may be used in future for products quality labelling and certifications. © F. Pallottino et al.","Arduino; Image analysis; Quality assessment; Wood chip; Wood pellet","Article","Scopus"
"Alsmadi I.; Saeed S.","Alsmadi, Izzat (17433667400); Saeed, Saqib (55513978200)","17433667400; 55513978200","A software development process for open source and open competition projects","2013","International Journal of Business Information Systems","10.1504/IJBIS.2013.050662","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870714084&doi=10.1504%2fIJBIS.2013.050662&partnerID=40&md5=d339d56aa9c0ccd56b529d4ca6eca7ce","Open source and offshore software development projects have changed the typical business model of companies. Such projects are often developed through loosely coupled teams/individuals having weak official belongings and communicating through modern communication tools instead of physical meetings. In contrast to a typical business model, project economics are not so important in project completion. In this paper we highlight the distinguished elements of such software development approaches to present guidelines for innovative software process model supporting such development paradigm. Copyright © 2013 Inderscience Enterprises Ltd.","Agile methodologies; Software design; Software development lifecycle; Software process; Software process models","Article","Scopus"
"Belmonte Á.; Zafra A.; Gibaja E.","Belmonte, Álvaro (57729560100); Zafra, Amelia (8285021900); Gibaja, Eva (6507695428)","57729560100; 8285021900; 6507695428","MIML library: A modular and flexible library for multi-instance multi-label learning","2022","Neurocomputing","10.1016/j.neucom.2022.05.068","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131412875&doi=10.1016%2fj.neucom.2022.05.068&partnerID=40&md5=e54791f4ffaa89b62c6dafc39d94e729","MIML library is a Java software tool to develop, test, and compare classification algorithms for multi-instance multi-label (MIML) learning. The library includes 43 algorithms and provides a specific format and facilities for data managing and partitioning, holdout and cross-validation methods, standard metrics for performance evaluation, and generation of reports. In addition, algorithms can be executed through xml configuration files without needing to program. It is platform-independent, extensible, free, open-source, and available on GitHub under the GNU General Public License. © 2022 Elsevier B.V.","Classification; Mulan; Multi-instance learning; Multi-label learning; Weka","Article","Scopus"
"Cano A.; Luna J.M.; Zafra A.; Ventura S.","Cano, Alberto (36170312300); Luna, José María (36170791300); Zafra, Amelia (8285021900); Ventura, Sebastián (8846948400)","36170312300; 36170791300; 8285021900; 8846948400","A classification module for genetic programming algorithms in JCLEC","2015","Journal of Machine Learning Research","","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930669400&partnerID=40&md5=443a2931dea74bfd457e45d0e427d98a","JCLEC-Classification is a usable and extensible open source library for genetic programming classification algorithms. It houses implementations of rule-based methods for classification based on genetic programming, supporting multiple model representations and providing to users the tools to implement any classifier easily. The software is written in Java and it is available from http://jclec.sourceforge.net/classification under the GPL license. ©2015 Alberto Cano, José María Luna, Amelia Zafra and Sebastián Ventura.","Classification; Evolutionary algorithms; Genetic programming; JCLEC","Article","Scopus"
"Harutyunyan N.; Bauer A.; Riehle D.","Harutyunyan, Nikolay (57202691944); Bauer, Andreas (57207845742); Riehle, Dirk (55901065900)","57202691944; 57207845742; 55901065900","Industry requirements for FLOSS governance tools to facilitate the use of open source software in commercial products","2019","Journal of Systems and Software","10.1016/j.jss.2019.08.001","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072534077&doi=10.1016%2fj.jss.2019.08.001&partnerID=40&md5=fbbc9ac3473e48e133d34e38d8e28cad","Virtually all software products incorporate free/libre and open source software (FLOSS) components. However, ungoverned use of FLOSS components can result in legal and financial risks, and risks to a firm's intellectual property. To avoid these risks, companies must govern their FLOSS use through open source governance processes and by following industry best practices. A particular challenge is license compliance. To manage the complexity of governance and compliance, companies should use tools and well-defined processes. This paper investigates and presents industry requirements for FLOSS governance tools, followed by an evaluation of the suggested requirements. We chose eleven companies with an advanced understanding of open source governance and interviewed their FLOSS governance experts to derive a theory of industry requirements for tooling. We extended our previous work adding the requirement category on the architecture model for software products. We then analyzed the features of leading governance tools and used this analysis to evaluate two categories of our theory: FLOSS license scanning and FLOSS components in product bills of materials. The result is a list of FLOSS governance requirements. For practical relevance, we cast our theory as a requirements specification for FLOSS governance tools. © 2019","Company requirements for FLOSS tools; FLOSS; FLOSS governance tools; FOSS; Open source governance; Open source software","Article","Scopus"
"Elpern J.; Dascalu S.","Elpern, Jeff (36805502100); Dascalu, Sergiu (6602297823)","36805502100; 6602297823","A framework for understanding the open source revolution","2009","International Journal of Open Source Software and Processes","10.4018/jossp.2009070101","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651576890&doi=10.4018%2fjossp.2009070101&partnerID=40&md5=be7b344209cb6905bb7813e75806bf5e","Traditional software engineering methodologies have mostly evolved from the environment of proprietary, large-scale software systems. Here, software design principles operate within a hierarchical decision-making context. Development of banking, enterprise resource and complex weapons systems all fit this paradigm. However, another paradigm for developing software-intensive systems has emerged, the paradigm of open source software. Although from a traditional perspective open source projects might look like chaos, their real-world results have been spectacular. This chapter presents open source software development as a fundamentally new paradigm driven by economics and facilitated by new processes. The new paradigm's revolutionary aspects are explored, a framework for describing the massive impact brought about by the new paradigm is proposed, and directions of future research are outlined. The proposed frame work's goals are to help the understanding of the open source paradigm as a new economic revolution and stimulate research in designing open source software. Copyright © 2009, IGI Global.","GNU Manifesto; GNU Public License; Open Source; Open Source Revolution; Paradigm Shift; Proprietary Source; Software Design Principles; Software Engineering Methodologies; System Architecture","Article","Scopus"
"Sen R.; Subramaniam C.; Nelson M.L.","Sen, Ravi (9737868800); Subramaniam, Chandrasekar (8136647600); Nelson, Matthew L. (7403461430)","9737868800; 8136647600; 7403461430","Determinants of the choice of open source software license","2008","Journal of Management Information Systems","10.2753/MIS0742-1222250306","66","https://www.scopus.com/inward/record.uri?eid=2-s2.0-66549100192&doi=10.2753%2fMIS0742-1222250306&partnerID=40&md5=d606f0f5c759f3ed59514246679a1f52","In this paper, we examine how the motivations and attitudes of open source software (OSS) developers affect their preference among the three common OSS license types-Strong-Copyleft, Weak-Copyleft, and Non-Copyleft. Despite the importance of the license type and developers to OSS projects, there is little understanding in open source literature of the license choice from a developer's perspective. The results from our empirical study of OSS developers reveal that the intrinsic motivation of challenge (problem solving) is associated with the developers' preference for licenses with moderate restrictions, while the extrinsic motivation of status (through peer recognition) is associated with developers' preference for licenses with least restrictions. We also find that when choosing an OSS license, a developer's attitude toward the software redistribution rights conflicts with his or her attitude toward preserving the social benefits of open source. A major implication of our findings is that OSS managers who want to attract a limited number of highly skilled programmers to their open source project should choose a restrictive OSS license. Similarly, managers of software projects for social programs could attract more developers by choosing a restrictive OSS license. © 2009 M.E. Sharpe, Inc.","Copyleft; Copyright; FLOSS; Open source; OSS; Software license","Article","Scopus"
"Caneill M.; Germán D.M.; Zacchiroli S.","Caneill, Matthieu (56380641100); Germán, Daniel M. (57207886015); Zacchiroli, Stefano (22434266000)","56380641100; 57207886015; 22434266000","The Debsources Dataset: two decades of free and open source software","2017","Empirical Software Engineering","10.1007/s10664-016-9461-5","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990963244&doi=10.1007%2fs10664-016-9461-5&partnerID=40&md5=86f3623eec2b44915040ce4c4c6546a9","We present the Debsources Dataset: source code and related metadata spanning two decades of Free and Open Source Software (FOSS) history, seen through the lens of the Debian distribution. The dataset spans more than 3 billion lines of source code as well as metadata about them such as: size metrics (lines of code, disk usage), developer-defined symbols (ctags), file-level checksums (SHA1, SHA256, TLSH), file media types (MIME), release information (which version of which package containing which source code files has been released when), and license information (GPL, BSD, etc). The Debsources Dataset comes as a set of tarballs containing deduplicated unique source code files organized by their SHA1 checksums (the source code), plus a portable PostgreSQL database dump (the metadata). A case study is run to show how the Debsources Dataset can be used to easily and efficiently instrument very long-term analyses of the evolution of Debian from various angles (size, granularity, licensing, etc.), getting a grasp of major FOSS trends of the past two decades. The Debsources Dataset is Open Data, released under the terms of the CC BY-SA 4.0 license, and available for download from Zenodo with DOI reference 10.5281/zenodo.61089. © 2016, Springer Science+Business Media New York.","Dataset; Debian; Free software; Open source; Software evolution; Source code","Article","Scopus"
"Yu X.; Zhao B.; Huang H.; Tian M.; Zhang S.; Song H.; Li Z.; Huang K.; Gao Y.","Yu, Xiaxia (57209644779); Zhao, Bingshuai (57223439494); Huang, Haofan (57220035895); Tian, Mu (57222712119); Zhang, Sai (57223431499); Song, Hongping (57210433911); Li, Zengshan (57223440126); Huang, Kun (55481915600); Gao, Yi (55731337800)","57209644779; 57223439494; 57220035895; 57222712119; 57223431499; 57210433911; 57223440126; 55481915600; 55731337800","An Open Source Platform for Computational Histopathology","2021","IEEE Access","10.1109/ACCESS.2021.3080429","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105875062&doi=10.1109%2fACCESS.2021.3080429&partnerID=40&md5=91e5f46fc4aba0fb217d5fdf45822042","Computational histopathology is a fast emerging field which converts the traditional glass slide based department to a new examination platform. Such a paradigm shift also brings the in silico computation to the field. Much research have been presented in the past decades on the algorithm development for pathology image analysis. On the other hand, a comprehensive software platform with advanced visualization and computation capability, large developer community, flexible plugin mechanism, and friendly transnational license, would be extremely beneficial for the entire community. In this work, we present SlicerScope: an open platform for whole slide histopathology image computing based on the highly successful 3D Slicer. We present rationale on the choice of such an architecture, introducing new modules/tools for giga-pixel whole slide image viewing, and four specific analytical modules for qualitative presentation, nucleus level analysis, tissue scale computation, and 3D pathology. The entire software is publicly available at https://slicerscope.github.io/, facilitating the algorithmic, clinical, and transnational researches. © 2013 IEEE.","computational pathology; Open-source platform; reproducibility","Article","Scopus"
"Savelyev A.","Savelyev, Alexander (57192936912)","57192936912","Open source: The Russian experience (legislation and practice)","2013","Information and Communications Technology Law","10.1080/13600834.2013.778520","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876306482&doi=10.1080%2f13600834.2013.778520&partnerID=40&md5=b941ff318c6882520d8d3a14c2f560dc","The emergence of so-called free or open-source software and the growth of its economic importance in various industries make questions regarding the legal status of free/open-source licenses especially important. In December 2010, new draft amendments to the Civil Code were published, introducing new concepts in order to reflect the ideas pursued by these types of licenses. This article analyzes existing problems with the legal status of free/open-source licenses, whether proposed amendments may solve them, and what risks they may create. Since Russia is among the first countries trying to include provisions on free/open-source licenses in its legislation, such analysis may be of interest to foreign lawmakers since the concept of open source is universal all over the world. © 2013 Copyright Taylor and Francis Group, LLC.","free software; GPL; open source","Article","Scopus"
"Riehle D.","Riehle, Dirk (55901065900)","55901065900","The single-vendor commercial open course business model","2012","Information Systems and e-Business Management","10.1007/s10257-010-0149-x","28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856232970&doi=10.1007%2fs10257-010-0149-x&partnerID=40&md5=a4832d94179478126f98ef709564eaa1","Single-vendor commercial open source software projects are open source software projects that are owned by a single firm that derives a direct and significant revenue stream from the software. Single-vendor commercial open source at first glance represents an economic paradox: How can a firm earn money if it is making its product available for free as open source? This paper presents the core properties of single-vendor open source business models and discusses how they work. Using a single-vendor open source approach, firms can get to market faster with a superior product at lower cost than possible for traditional competitors. The paper shows how these benefits accrue from an engaged and self-supporting user community. Lacking any prior comprehensive reference, this paper is based on an analysis of public statements by practitioners of single-vendor open source. It forges the various anecdotes into a coherent description of revenue generation strategies and relevant business functions. © 2010 Springer-Verlag.","Business model; Collaborative development; Commercial open source; Commercial open source business model; Dual-licensing strategy; Go-to-market strategy; Open core business model; Open source; Open source licensing; Open source marketing; Open source product management; Open source sales; Single-vendor open source; Software engineering","Article","Scopus"
"Kleinke B.","Kleinke, Brian (57850456000)","57850456000","Challenges and Lessons Learned Introducing an Evolving Open Source Technology into an Established Legacy Ada and C++ Program","2021","Ada User Journal","10.1145/3463478.3463485","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136236497&doi=10.1145%2f3463478.3463485&partnerID=40&md5=ae205ee13965403d3f36816c9890254e","When the Federal Aviation Administration (FAA) launched the System Wide Information Management (SWIM) initiative, the FAA had the goal of using the same portable, open infrastructure across all participating systems in the National Airspace System (NAS). Around 2008 for SWIM Segment 1, the FAA chose Iona Software's Free/Open Source Software (FOSS) based bundle, which was known and supported under the Fuse brand. The FAA obtained the licenses used by programs, including EnRoute Automation Modernization (ERAM), through Iona, which was later acquired by Progress and RedHat. © 2020 Leidos. All rights reserved.","","Article","Scopus"
"Colazo J.; Fang Y.","Colazo, Jorge (36977215600); Fang, Yulin (8716021900)","36977215600; 8716021900","Impact of license choice on open source software development activity","2009","Journal of the American Society for Information Science and Technology","10.1002/asi.21039","82","https://www.scopus.com/inward/record.uri?eid=2-s2.0-65649113222&doi=10.1002%2fasi.21039&partnerID=40&md5=9a95f58bc1b3ff5127415d0412dc9bbc","The Open Source Software (OSS) development model has emerged as an important competing paradigm to proprietary alternatives; however, insufficient research exists to understand the influence of some OSS project characteristics on the level of activity of the development process.Abasic such characteristic is the selection of the project's software license. Drawing upon social movement theory, our study examined the relationship between OSS licenses and project activity. Some OSS licenses include a ""copyleft"" clause, which requires that if derivative products are to be released, it must be done under the license the original product had. We hypothesize that copylefted licenses, as opposed to noncopylefted licenses, are associated with higher developer membership and coding activity, faster development speed, and longer developer permanence in the project To test the hypotheses, we used archival data sources of working OSS projects spanning several years of development time.We discuss practical and theoretical implications of the results as well as future research ideas.","","Article","Scopus"
"Vendome C.; Bavota G.; Penta M.D.; Linares-Vásquez M.; German D.; Poshyvanyk D.","Vendome, Christopher (57021999600); Bavota, Gabriele (57220148228); Penta, Massimiliano Di (6602794138); Linares-Vásquez, Mario (54684418100); German, Daniel (57207886015); Poshyvanyk, Denys (13613571900)","57021999600; 57220148228; 6602794138; 54684418100; 57207886015; 13613571900","License usage and changes: a large-scale study on gitHub","2017","Empirical Software Engineering","10.1007/s10664-016-9438-4","23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020033576&doi=10.1007%2fs10664-016-9438-4&partnerID=40&md5=8854e37b29ad157bd8c1251cb52edb99","Open source software licenses determine, from a legal point of view, under which conditions software can be integrated and redistributed. The reason why developers of a project adopt (or change) a license may depend on various factors, e.g., the need for ensuring compatibility with certain third-party components, the perspective towards redistribution or commercialization of the software, or the need for protecting against somebody else’s commercial usage of the software. This paper reports a large empirical study aimed at quantitatively and qualitatively investigating when and why developers adopt or change software licenses. Specifically, we first identify license changes in 1,731,828 commits, representing the entire history of 16,221 Java projects hosted on GitHub. Then, to understand the rationale of license changes, we perform a qualitative analysis on 1,160 projects written in seven different programming languages, namely C, C++, C#, Java, Javascript, Python, and Ruby—following an open coding approach inspired by grounded theory—on commit messages and issue tracker discussions concerning licensing topics, and whenever possible, try to build traceability links between discussions and changes. On one hand, our results highlight how, in different contexts, license adoption or changes can be triggered by various reasons. On the other hand, the results also highlight a lack of traceability of when and why licensing changes are made. This can be a major concern, because a change in the license of a system can negatively impact those that reuse it. In conclusion, results of the study trigger the need for better tool support in guiding developers in choosing/changing licenses and in keeping track of the rationale of license changes. © 2016, Springer Science+Business Media New York.","Empirical studies; Mining software repositories; Software licenses","Article","Scopus"
"Plumejeaud-Perreau; Quinton E.; Pignol C.; Linyer H.; Ancelin J.; Cipière S.; Heintz W.; Rouan M.; Damy S.; Bretagnolle V.","Plumejeaud-Perreau (57209074637); Quinton, Eric (57200239450); Pignol, Cécile (55597858400); Linyer, Hector (57209076281); Ancelin, Julin (57209077287); Cipière, Sébastien (55001819300); Heintz, Wilfried (45661457700); Rouan, Mathias (25636272000); Damy, Sylvie (14623819800); Bretagnolle, Vincent (7004180492)","57209074637; 57200239450; 55597858400; 57209076281; 57209077287; 55001819300; 45661457700; 25636272000; 14623819800; 7004180492","Towards better traceability of field sampling data","2019","Computers and Geosciences","10.1016/j.cageo.2019.04.009","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066432942&doi=10.1016%2fj.cageo.2019.04.009&partnerID=40&md5=072a5fafaf1c390615a72f71b5411e42","Ensuring traceability of both field experimental data and laboratory sampling data for a reproducible research remains a challenge nowadays. Between the time when geolocalized specimens are taken, and the time the resulting data ends up in analysis published within a study, many manual operations take place that are prone to generate errors. The French nodes of the European Long-Term Socio-Ecological Research Infrastructure called ”Zones Ateliers” propose a solution as generic as possible to this problem of monitoring of the samples and the data associated with them. Compared to existing solutions such as Laboratory Information Management Systems, we target a robust solution for labelling adapted to outdoor working conditions, with the management of storages and movements of samples. We designed and realized a software package tested from end to end, using open source licenses and cheap hardware, including small printers (mobile or not) and Raspberry Pis. This system provides sufficient flexibility so that it can facilitate working with a wide variety of existing protocols. One of the most interesting feature consists to record all contextual data associated with the samples, which constitute important parameters of the subsequent analyses. Furthermore, not only traceability is thus guaranteed, but also we can expect a reduced handling times and an increased streamlining of the storage of samples that will improve the return on investment. © 2019 Elsevier Ltd","Data traceability; Labels printing; QR code; Samples management","Article","Scopus"
"Santos C.D.D., Jr.","Santos, Carlos Denner D60os (36700519000)","36700519000","Changes in free and open source software licenses: managerial interventions and variations on project attractiveness","2017","Journal of Internet Services and Applications","10.1186/s13174-017-0062-3","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026914900&doi=10.1186%2fs13174-017-0062-3&partnerID=40&md5=c3fd4143f92d300f015897b772a8efed","The license adopted by an open source software is associated with its success in terms of attractiveness and maintenance of an active ecosystem of users, bug reporters, developers, and sponsors because what can and cannot be done with the software and its derivatives in terms of improvement and market distribution depends on legal terms there specified. By knowing this licensing effect through scientific publications and their experience, project managers became able to act strategically, loosening up the restrictions associated with their source code due to sponsor interests, for example; or the contrary, tightening restrictions up to guarantee source code openness, adhering to the “forever free” strategy. But, have project managers behaved strategically like that, changing their projects license? Up to this paper, we did not know if and what types of changes in these legal allowances project managers have made and, more importantly, whether such managerial interventions are associated with variations in intervened project attractiveness (i.e., related to their numbers of web hits, downloads and members). This paper accomplishes these two goals and demonstrates that: 1) managers of free and open source software projects do change the distribution rights of their source code through a change in the (group of) license(s) adopted; and 2) variations in attractiveness are associated with the strategic choice of a licensing schema. To reach these conclusions, a unique dataset of open source projects that have changed license was assembled in a comparative form, analyzing intervened projects over its monthly periods of different licenses. Based on a sample of more than 3500 active projects over 44 months obtained from the FLOSSmole repository of Sourceforge.net data, 756 projects that had changed their source code distribution allowances and restrictions were identified and analyzed. A dataset on these projects’ type of changes was assembled to enable a descriptive and exploratory analysis of the types of license interventions observed over a period of almost four years anchored on projects’ attractiveness. More than 35 types of interventions were detected. The results indicate that variations in attractiveness after a license intervention are not symmetric; that is, if a change from license schema A to B is beneficial to attractiveness, a change from B to A is not necessarily prejudicial. This and other interesting findings are discussed in detail. In general, the results here reported support the current literature knowledge that the restrictions imposed by the license on the source code distribution are associated with market success vis-a-vis project attractiveness, but they also suggest that the state-of-the-science is superficial in terms of what is known about why these differences in attractiveness can be observed. The complexity of the results indicates to free software managers that no licensing schema should be seen as the right one, and its choice should be carefully made, considering project strategic goals as perceived relevant to stakeholders of the application and its production. These conclusions create awareness of several limitations of our current knowledge, which are discussed along with guidelines to understand them deeper in future research endeavors. © 2017, The Author(s).","Attractiveness; Free software; Governance; GPL; Information technology; Intellectual property; Open source; Open source software; Project and people management; Software license; Software project","Article","Scopus"
"Gordaliza P.M.; Mateos-Pérez J.M.; Montesinos P.; Guzmán-de-Villoria J.A.; Desco M.; Vaquero J.J.","Gordaliza, P.M. (56491169700); Mateos-Pérez, J.M. (42961978600); Montesinos, P. (55873915600); Guzmán-de-Villoria, J.A. (6507503276); Desco, M. (35602555600); Vaquero, J.J. (15763461400)","56491169700; 42961978600; 55873915600; 6507503276; 35602555600; 15763461400","Development and validation of an open source quantification tool for DSC-MRI studies","2015","Computers in Biology and Medicine","10.1016/j.compbiomed.2015.01.002","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921526308&doi=10.1016%2fj.compbiomed.2015.01.002&partnerID=40&md5=40be6845eefb6f40bdd655da2774ba0b","Motivation: This work presents the development of an open source tool for the quantification of dynamic susceptibility-weighted contrast-enhanced (DSC) perfusion studies. The development of this tool is motivated by the lack of open source tools implemented on open platforms to allow external developers to implement their own quantification methods easily and without the need of paying for a development license. Materials and methods: This quantification tool was developed as a plugin for the ImageJ image analysis platform using the Java programming language. A modular approach was used in the implementation of the components, in such a way that the addition of new methods can be done without breaking any of the existing functionalities. For the validation process, images from seven patients with brain tumors were acquired and quantified with the presented tool and with a widely used clinical software package. The resulting perfusion parameters were then compared. Results: Perfusion parameters and the corresponding parametric images were obtained. When no gamma-fitting is used, an excellent agreement with the tool used as a gold-standard was obtained (R2>0.8 and values are within 95% CI limits in Bland-Altman plots). Conclusion: An open source tool that performs quantification of perfusion studies using magnetic resonance imaging has been developed and validated using a clinical software package. It works as an ImageJ plugin and the source code has been published with an open source license. © 2015 Elsevier Ltd.","ImageJ; Magnetic resonance imaging; Open source; Perfusion; Software tool","Article","Scopus"
"Kumar V.; Gordon B.R.; Srinivasan K.","Kumar, Vineet (57558820500); Gordon, Brett R. (24830025500); Srinivasan, Kannan (7202489639)","57558820500; 24830025500; 7202489639","Competitive strategy for open source software","2011","Marketing Science","10.1287/mksc.1110.0669","23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-83455200302&doi=10.1287%2fmksc.1110.0669&partnerID=40&md5=a2df94f682ad6b64fba4dbb65f6287a9","Commercial open source software (COSS) products-privately developed software based on publicly available source code-represent a rapidly growing, multibillion-dollar market. A unique aspect of competition in the COSS market is that many open source licenses require firms to make certain enhancements public, creating an incentive for firms to free ride on the contributions of others. This practice raises a number of puzzling issues. First, why should a firm further develop a product if competitors can freely appropriate these contributions? Second, how does a market based on free riding produce high-quality products? Third, from a public policy perspective, does the mandatory sharing of enhancements raise or lower consumer surplus and industry profits? We develop a two-sided model of competition between COSS firms to address these issues. Our model consists of (1) two firms competing in a vertically differentiated market, in which product quality is a mix of public and private components, and (2) a market for developers that firms hire after observing signals of their contributions to open source. We demonstrate that free-riding behavior is supported in equilibrium, that a mandatory sharing setting can result in high-quality products, and that free riding can actually increase profits and consumer surplus. © 2011 INFORMS.","Game theory; Open source software; Product strategy; Signaling","Article","Scopus"
"Lin Y.-H.; Ko T.-M.; Chuang T.-R.; Lin K.-J.","Lin, Yi-Hsuan (55944767000); Ko, Tung-Mei (55944939500); Chuang, Tyng-Ruey (7202738622); Lin, Kwei-Jay (7403967547)","55944767000; 55944939500; 7202738622; 7403967547","Open source licenses and the creative commons framework: License selection and comparison","2006","Journal of Information Science and Engineering","","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-31344473650&partnerID=40&md5=496253aedc655e68e9e351dda1685a23","Numerous licenses confuse new participants in the free/open source software (FOSS) world. In this paper, we provide a general introduction to eleven commonly-used FOSS licenses. By applying seven specific considerations that are proposed in our study, developers can identify which license suits their needs best. We further use the above considerations to rank these FOSS licenses, which are Open Source Initiative (OSI)-aproved, in terms of their degree of openness. The recently established Creative Commons (CC), based on FOSS concepts, provides yet another model for licensing creative works. We attempt to use the CC licensing model to analyze FOSS licenses, so that new participants can better understand these licenses. By examining these FOSS licenses with CC's four differentiating elements (attribution; noncommercial; no derivative works; share alike), we construct a table with which new participants could understand FOSS and the above categories with the knowledge of the CC licensing model. We also rank these licenses based on CC's differentiating elements and offer a different approach to examine the openness of FOSS licenses.","Copyleft; Copyright; Creative Commons; FOSS; Free software; License; Open source; Program","Article","Scopus"
"Jenabidehkordi A.; Fu X.; Rabczuk T.","Jenabidehkordi, Ali (57201898466); Fu, Xiaolong (57218882057); Rabczuk, Timon (56502462200)","57201898466; 57218882057; 56502462200","An open source peridynamics code for dynamic fracture in homogeneous and heterogeneous materials","2022","Advances in Engineering Software","10.1016/j.advengsoft.2022.103124","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129384555&doi=10.1016%2fj.advengsoft.2022.103124&partnerID=40&md5=2e8fe6a753ab6e61eea019259fef8acb","We present a novel open source peridynamics software for modeling two- and three-dimensional dynamic fracture in homogeneous and heterogeneous solids. The software and its implementation is described in detail and made available on GitHub and under MIT license. The capability of the software is demonstrated through several numerical examples including a wave propagation problem. Furthermore, 3D fracture simulations in a polymer-matrix composite at the meso-scale is shown to demonstrate the capability of the code to model complex microstructure including the interaction between interface fracture and fracture in the bulk. © 2022 Elsevier Ltd","Open-source software; PD; Peri-dynamic; Relation-based software; Software architecture","Article","Scopus"
"Yadav V.; Karmakar S.; Kalbar P.P.; Dikshit A.K.","Yadav, Vinay (57188738983); Karmakar, Subhankar (13805286500); Kalbar, Pradip P. (37761633100); Dikshit, A.K. (7003835614)","57188738983; 13805286500; 37761633100; 7003835614","PyTOPS: A Python based tool for TOPSIS","2019","SoftwareX","10.1016/j.softx.2019.02.004","31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062622675&doi=10.1016%2fj.softx.2019.02.004&partnerID=40&md5=0acacce4f58c05f3d35305c6d205d7f8","The Technique for Order Preference by Similarity to Ideal Solution (TOPSIS) method determines the best solution from a set of alternatives with certain attributes. The best alternative is chosen based on its Euclidean distance from the ideal solution. TOPSIS is widely used in various multi-attribute decision making problems such as supply chain logistics, marketing management, environmental management or chemical engineering. Despite the extensive use of this method, there is no free and open-source software (FOSS) for TOPSIS with comprehensive post-analysis extensions. Therefore, this paper describes a Python-3 based tool PyTOPS for TOPSIS with the Berkeley Software Distribution (BSD)-3-Clause license. © 2019 The Authors","Python; TOPSIS","Article","Scopus"
"Bonaccorsi A.; Giannangeli S.; Rossi C.","Bonaccorsi, Andrea (7005502691); Giannangeli, Silvia (24766285200); Rossi, Cristina (57197758938)","7005502691; 24766285200; 57197758938","Entry strategies under competing standards: Hybrid business models in the open source software industry","2006","Management Science","10.1287/mnsc.1060.0547","279","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745598162&doi=10.1287%2fmnsc.1060.0547&partnerID=40&md5=97516fbde371d97b0f6f845476359ca8","The paper analyzes the strategies of software firms that have entered the open source (OS) field. The notion of the OS business model is discussed in the light of a substantial body of theoretical literature concerning strategic management and the economics of innovation, as well as specialized literature on OS. Empirical evidence based on a survey of 146 Italian software firms shows that firms have adapted to an environment dominated by incumbent standards by combining the offering of proprietary and OS software under different licensing schemes, thus choosing a hybrid business model. The paper examines the determinants of the degree of openness toward OS and discusses the stability of hybrid models in the evolution of the industry. © 2006 INFORMS.","Hybrid business models; Network externalities; Open source; Software industry; Switching costs","Article","Scopus"
"Dias L.F.; Steinmacher I.; Pinto G.","Dias, Luis Felipe (57193335822); Steinmacher, Igor (36609225300); Pinto, Gustavo (54941690500)","57193335822; 36609225300; 54941690500","Who drives company-owned OSS projects: internal or external members?","2018","Journal of the Brazilian Computer Society","10.1186/s13173-018-0079-x","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058932134&doi=10.1186%2fs13173-018-0079-x&partnerID=40&md5=3f84a457274c6079d24a4b620866c5a0","Open-source software (OSS) communities leverage the workforce of volunteers to keep the projects sustainable. Some companies support OSS projects by paying developers to contribute to them, while others share their products under OSS licenses, keeping their employees in charge of maintaining the projects. In this paper, we investigate the activity of internal (employees) and external (volunteers) developers in this kind of setting. We conducted a case study using a convenience sample of five well-known OSS projects: atom, electron, hubot, git-lfs, and linguist. Analyzing a rich set of ∼ 12K contributions performed by means of pull requests to these projects, complemented with a manual analysis of ∼ 500 accepted pull requests, we derived a list of interesting findings. For instance, we found that both internal and external developers are rather active when it comes to submitting pull requests and that the studied projects are receptive for external developers. Considering all the projects, internal developers are responsible for 43.3% of the pull requests performed (external developers placed 56.7%). We also found that even with high support from the external community, employees still play the central roles in the project. We also found that the majority of the external developers are casual contributors (developers that placed only a single contribution to the project). However, we also observed that some external members play core roles (in addition to submitting code), like triaging bugs, reviewing, and integrating code to the main branch. Finally, when manually inspecting some code changes, we observed that external developers’ contributions range from documentation to complex code. Our results can benefit companies willing to open-source their code and developers that want to take part and actively contribute to company-owned code. © 2018, The Author(s).","Company-owned OSS projects; Employees; Volunteers","Article","Scopus"
"Seppänen M.; Helander N.","Seppänen, Marko (8093091000); Helander, Nina (6506646558)","8093091000; 6506646558","Creating value through business models in Open Source Software","2014","International Journal of Open Source Software and Processes","10.4018/ijossp.2014040102","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924352784&doi=10.4018%2fijossp.2014040102&partnerID=40&md5=6eff66f4c3df4478759e2ff156fe396b","This paper explores how the use of a business model enables value creation in an Open Source Software (OSS) environment. Open Source offers one possibility for firms that are continuously looking for new opportunities and ways of organizing their business activities to increase the amount of value they can appropriate through their capabilities. The authors argue that this value can be attained by analysing value creation logic and the elements of business models. They demonstrate how value is created through business model elements and provide a list of questions that can help managers in their considerations with Open Source Software. Copyright © 2014, IGI Global.","Business models; Open Source Software (OSS); Organization; OSS context; Value creation logic","Article","Scopus"
"Edwards K.","Edwards, Kasper (32667612700)","32667612700","An economic perspective on software licenses - Open source, maintainers and user-developers","2005","Telematics and Informatics","10.1016/j.tele.2004.06.009","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-7444225899&doi=10.1016%2fj.tele.2004.06.009&partnerID=40&md5=ba47f9aaa0c2d3bb2ac8d721bd4603d8","This paper presents a model for understanding the behaviour of agents using and/or contributing to open source software. The model illustrates the behaviour of agents under three license regimes: (1) the GPL, (2) the BSD and (3) the Microsoft EULA. The latter license is not an open source license and is included as a reference as well as an example of a general situation where users do not contribute source code. The model uses economic theory of externalities and opportunity cost as a measure of agents' costs. The basic premise is that agents will only participate in developments if there is a net benefit. Agents are divided into firms and individuals, which can be either maintainers or user-developers. A maintainer is an agent responsible for releasing new versions of a program and a user-developer is an agent who uses a program but may also become a developer. It is observed through the model that the three licenses induce different incentives and dynamics for maintainers and user-developers and the paper explains, from an economic standpoint, the mechanisms that ensure that programs are developed and maintained under the three license regimes. © 2004 Published by Elsevier Ltd.","Incentives and economics; Licenses; Open source software","Article","Scopus"
"Pykäläinen T.","Pykäläinen, Timo (16040415100)","16040415100","Model for profiting from software innovations in the new era in computing","2007","Technovation","10.1016/j.technovation.2006.11.005","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33947105946&doi=10.1016%2fj.technovation.2006.11.005&partnerID=40&md5=ee6ebb54f2dccbbc1815c81b73a76b2c","The purpose of this paper is to create a new model for describing conditions for profiting from software innovations in the software industry. Proprietary software is threatened by the popularity of open source software (OSS), which challenges the traditional business models that have relied on proprietary technologies and closeness. OSS has strongly impacted on the software industry; as a result, the appropriateness of traditional business models should be questioned and alternative models sought. This leads to exploration for a new model to evaluate the conditions for profiting from software. The proposed model includes three dimensions: technology, complementary assets, and ideology. © 2006 Elsevier Ltd. All rights reserved.","Business innovation; Business model; Open source software (OSS); Software","Article","Scopus"
"Stewart K.J.; Ammeter A.P.; Maruping L.M.","Stewart, Katherine J. (57220608910); Ammeter, Anthony P. (6508253077); Maruping, Likoebe M. (8759433100)","57220608910; 6508253077; 8759433100","Impacts of license choice and organizational sponsorship on user interest and development activity in open source software projects","2006","Information Systems Research","10.1287/isre.1060.0082","217","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745038455&doi=10.1287%2fisre.1060.0082&partnerID=40&md5=dfc8238437c1aff1219420220fa3c068","What differentiates successful from unsuccessful open source software projects? This paper develops and tests a model of the impacts of license restrictiveness and organizational sponsorship on two indicators of success: user interest in, and development activity on, open source software development projects. Using data gathered from Freshmeat.net and project home pages, the main conclusions derived from the analysis are that (1) license restrictiveness and organizational sponsorship interact to influence user perceptions of the likely utility of open source software in such a way that users are most attracted to projects that are sponsored by nonmarket organizations and that employ nonrestrictive licenses, and (2) licensing and sponsorship address complementary developer motivations such that the influence of licensing on development activity depends on what kind of organizational sponsor a project has. Theoretical and practical implications are discussed, and the paper outlines several avenues for future research. © 2006 INFORMS.","Open source; Software development; Software licensing; Success","Article","Scopus"
"Xing M.","Xing, Mingqing (36603743700)","36603743700","Competition between commercial open source software firms under the GNU general public license","2013","Research Journal of Applied Sciences, Engineering and Technology","10.19026/rjaset.5.4209","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84877948455&doi=10.19026%2frjaset.5.4209&partnerID=40&md5=ecfeec3f83bf5cd5bb9e4fbc1c11f866","This study compares R&D incentives for commercial open source software (COSS) firms under the GNU General Public License (i.e., GPL). It is found that: (i) although the GPL requires firms open the codes of features, firms have incentives to invest in software features under private optimum; (ii) the firm with high software usability has much higher incentive to invest in software features, sets higher price, obtains more market share and profit than the one with low software usability does; (iii) firms invest too little in software features under GPL from a public policy perspective. © Maxwell Scientific Organization, 2013.","Commercial open source software; Competition; General public license; R&D; Software features; Software usability","Article","Scopus"
"Sojer M.; Henkel J.","Sojer, Manuel (15021403000); Henkel, Joachim (15822422700)","15021403000; 15822422700","License risks from ad hoc reuse of code from the internet","2011","Communications of the ACM","10.1145/2043174.2043193","23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-82155166806&doi=10.1145%2f2043174.2043193&partnerID=40&md5=14140334eb9fa16245cb735c9ef815b3","Reusing existing software artifacts when developing new software is an attractive way to reduce development costs and time to market while improving software quality.4 Code is the artifact most commonly reused in software development.16 Researchers have identified such reuse in commercial software development as a new facet of software reuse.13,22 Here, ""Internet code"" means code in the form of components (such as a library encapsulating required functionality) and snippets (such as containing a synchronization block) that can be downloaded from the Internet for free and without individual agreement with the originator; an important instance of such code is publicly available open source software (OSS). Internet code generally © 2011 ACM.","","Article","Scopus"
"Cheliotis G.","Cheliotis, Giorgos (6506298419)","6506298419","From open source to open content: Organization, licensing and decision processes in open cultural production","2009","Decision Support Systems","10.1016/j.dss.2009.02.006","38","https://www.scopus.com/inward/record.uri?eid=2-s2.0-67349184447&doi=10.1016%2fj.dss.2009.02.006&partnerID=40&md5=89d7e0c647409e2c6534985b3d68bd51","The organization of talent in online communities has been pivotal for the development of open source software. We are currently witnessing a related phenomenon that is at least of equal importance: the 'open-sourcing' of digital content through a dramatic increase in user-generated content and the development of appropriate licenses for users to share their works and build on each other's creativity. This article compares and contrasts (a) the objectives of software development vis-à-vis the development of new media content, (b) the organizational forms that have developed in respective online communities, and (c) the role that licensing plays in the production of 'functional' vis-à-vis 'cultural' goods. © 2009 Elsevier B.V. All rights reserved.","Creative commons; Cultural goods; Decision process; Free culture; Licensing; Open source; Social media; User-generated content","Article","Scopus"
"Wang H.; Wang C.","Wang, Huaiqing (36538229500); Wang, Chen (57192600260)","36538229500; 57192600260","Open source software adoption: A status report","2001","IEEE Software","10.1109/52.914753","60","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035279684&doi=10.1109%2f52.914753&partnerID=40&md5=103a056a2103a02424122e5e46e950f7","The open source software (OSS) concept is now ready for wide-scale commercial adaptation and deployment. However, the myriad number of OSS packages make actual adoption a real challenge. This article presents a straightforward and practical roadmap to navigate OSS adoption considerations.","","Article","Scopus"
"Spjuth O.; Helmus T.; Willighagen E.L.; Kuhn S.; Eklund M.; Wagener J.; Murray-Rust P.; Steinbeck C.; Wikberg J.E.S.","Spjuth, Ola (12808508000); Helmus, Tobias (23090771000); Willighagen, Egon L. (6507481906); Kuhn, Stefan (7103392232); Eklund, Martin (16033089900); Wagener, Johannes (15758600000); Murray-Rust, Peter (6701575246); Steinbeck, Christoph (7003655166); Wikberg, Jarl E.S. (7101610239)","12808508000; 23090771000; 6507481906; 7103392232; 16033089900; 15758600000; 6701575246; 7003655166; 7101610239","Bioclipse: An open source workbench for chemo- and bioinformatics","2007","BMC Bioinformatics","10.1186/1471-2105-8-59","98","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33847772616&doi=10.1186%2f1471-2105-8-59&partnerID=40&md5=d4d11e554d862223c7ee84ddfcdda901","Background: There is a need for software applications that provide users with a complete and extensible toolkit for chemo- and bioinformatics accessible from a single workbench. Commercial packages are expensive and closed source, hence they do not allow end users to modify algorithms and add custom functionality. Existing open source projects are more focused on providing a framework for integrating existing, separately installed bioinformatics packages, rather than providing user-friendly interfaces. No open source chemoinformatics workbench has previously been published, and no sucessful attempts have been made to integrate chemo- and bioinformatics into a single framework. Results: Bioclipse is an advanced workbench for resources in chemo- and bioinformatics, such as molecules, proteins, sequences, spectra, and scripts. It provides 2D-editing, 3D-visualization, file format conversion, calculation of chemical properties, and much more; all fully integrated into a user-friendly desktop application. Editing supports standard functions such as cut and paste, drag and drop, and undo/redo. Bioclipse is written in Java and based on the Eclipse Rich Client Platform with a state-of-the-art plugin architecture. This gives Bioclipse an advantage over other systems as it can easily be extended with functionality in any desired direction. Conclusion: Bioclipse is a powerful workbench for bio- and chemoinformatics as well as an advanced integration platform. The rich functionality, intuitive user interface, and powerful plugin architecture make Bioclipse the most advanced and user-friendly open source workbench for chemo- and bioinformatics. Bioclipse is released under Eclipse Public License (EPL), an open source license which sets no constraints on external plugin licensing; it is totally open for both open source plugins as well as commercial ones. Bioclipse is freely available at http://www.bioclipse.net. © 2007 Spjuth et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Maguire E.; González-Beltrán A.; Whetzel P.L.; Sansone S.-A.; Rocca-Serra P.","Maguire, Eamonn (25932135100); González-Beltrán, Alejandra (23396745000); Whetzel, Patricia L. (7801599843); Sansone, Susanna-Assunta (6603584690); Rocca-Serra, Philippe (6506036751)","25932135100; 23396745000; 7801599843; 6603584690; 6506036751","OntoMaton: A Bioportal powered ontology widget for Google Spreadsheets","2013","Bioinformatics","10.1093/bioinformatics/bts718","36","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874339769&doi=10.1093%2fbioinformatics%2fbts718&partnerID=40&md5=27a94f66b685068af68c2b799fe50cc0","Motivation: Data collection in spreadsheets is ubiquitous, but current solutions lack support for collaborative semantic annotation that would promote shared and interdisciplinary annotation practices, supporting geographically distributed players.Results: OntoMaton is an open source solution that brings ontology lookup and tagging capabilities into a cloud-based collaborative editing environment, harnessing Google Spreadsheets and the NCBO Web services. It is a general purpose, format-agnostic tool that may serve as a component of the ISA software suite. OntoMaton can also be used to assist the ontology development process.Availability: OntoMaton is freely available from Google widgets under the CPAL open source license; documentation and examples at: https://github.com/ISA-tools/OntoMaton. © 2013 The Author.","","Article","Scopus"
"Lindman J.; Rossi M.; Paajanen A.","Lindman, Juho (18836374100); Rossi, Matti (8865002300); Paajanen, Anna (36659780000)","18836374100; 8865002300; 36659780000","Matching open source software licenses with corresponding business models","2011","IEEE Software","10.1109/MS.2011.50","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959728992&doi=10.1109%2fMS.2011.50&partnerID=40&md5=80d1e72eaea79f4c9ac0c6957643e55b","Scores of software producers have turned toward open source licenses to improve service for their customers. For these companies, choosing the correct license determines business success. When the available open source stack and licensing options grow, so does the need to understand the interplay among licensing, sourcing decisions, and business goals. A model of license choice emphasizes different licenses and rationalizes the choice of an open source software (OSS) license. This is crucial for smaller companies and start-ups that don't have the tools and knowledge to perform a thorough investigation of all the consequences of their license choice every time they employ OSS. © 2011 IEEE.","copyrights; intellectual property; licensing; open source software; oss; stacks","Article","Scopus"
"Digdowiseiso K.; Sugiyanto E.; Setiawan H.D.","Digdowiseiso, Kumba (57201669993); Sugiyanto, Eko (57195471963); Setiawan, Heru Dian (57188865373)","57201669993; 57195471963; 57188865373","Business licensing and the Indonesia‘s master plan 2011 – 2025","2020","International Journal of Scientific and Technology Research","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078889502&partnerID=40&md5=a59f616bb90bad56924a067d2b20508f","In accordance with the local economic development context, the Coordinating Ministry of Economic Affairs recently announced a new Master Plan for the ""Acceleration and Expansion of Indonesia‘s Economic Development 2011-2025"". The second phase of the Master Plan from 2016 to 2020 will focus on ""quick wins"" and on preparing action plans for the ""debottlenecking"" of various pending regulations, licenses, incentives, as well as preparing the ground for major investments. Though the implementation of the first phase itself reveals a very ambitious short-term agenda for reform on cross-cutting policies, both domestic and foreign investors are hoping for an improved license system in the OSS. © IJSTR 2020.","Business Licensing; Indonesia; Master Plan; OSS","Article","Scopus"
"Xing M.","Xing, Mingqing (36603743700)","36603743700","Comparative study on innovation incentives for commercial open source software under different licenses","2013","Research Journal of Applied Sciences, Engineering and Technology","10.19026/rjaset.5.4916","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874734212&doi=10.19026%2frjaset.5.4916&partnerID=40&md5=eeb6862fb540ebebe1a63adb42c66a81","This study compares technological innovation incentives for commercial open source software under two typical licenses (the GNU General Public License and the Berkeley Software Distribution License, i.e., GPL and BSD). In the case of private optimum, the incentive towards software features (resp. usability) innovation is always higher (resp. lower) under BSD than under GPL. Contrast to the private optimum, the social planner expects more investment in software feature under both BSD and GPL, but less (resp. equivalent) investment in software usability under BSD (resp. GPL) © 2013 Maxwell Scientific Organization.","Bsd; Commercial open source software; Gpl; Innovation; Open source software; Software feature; Software usability","Article","Scopus"
"Gyaltsen-Lohuis E.; Hettinga M.; Janssen R.; Nauta J.M.; Visser S.","Gyaltsen-Lohuis, Elles (56678638300); Hettinga, Marike (23091031400); Janssen, Ruud (56001671300); Nauta, Jan M. (56678393000); Visser, Sikke (56001051400)","56678638300; 23091031400; 56001671300; 56678393000; 56001051400","Early stages of business modeling for open source home care technology: Lessons learned from an initial inventory","2014","International Journal on Advances in Life Sciences","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930841763&partnerID=40&md5=24ffe9107480a5861a917a2ca75b6ae5","Many eHealth innovations never get beyond the project phase. Initiating a viable business model in an early stage of the development of eHealth innovations enhances the chance of structural embedding the innovations in routine health care. This paper presents the early stages of business model development for an innovative IT supported home care system based on open source software. After a literary review on open source business models and the home care market, the eHix method, a business model approach developed by research group ICT Innovation in Health Care to is used build up the business model for the home care system. The structure of the eHix, a method in which one is only allowed to move to the next phase if the previous phase is completed, ensures an efficient and effective route to business modeling. Going through the first stage of the business modeling, it is clear that the mapping of intended target groups and their accompanying needs in various scenarios becomes key to determining the right value proposition for the intended home care system. In-depth analysis of all the stakeholders and their interest in the network then provides the essential criteria for the feasibility of the various scenarios. It is only after all the scenarios of the care system are mapped that the revenue models can be identified efficiently and further selective steps can be taken towards feasible business models that show the potential of the innovation to its full advantage. © by authors.","Business modeling; Home care technology; Open source software","Article","Scopus"
"Kim D.; Cho S.-J.; Park M.; Han S.","Kim, Dongjin (57203012556); Cho, Seong-Je (12240436200); Park, Minkyu (55730438800); Han, Sangchul (57207284731)","57203012556; 12240436200; 55730438800; 57207284731","Open source software detection using function parameter based software birthmark","2017","Journal of Internet Technology","10.6138/JIT.2017.18.4.20160130","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028471959&doi=10.6138%2fJIT.2017.18.4.20160130&partnerID=40&md5=c5801b362a5618d616d03d77429a0018","As more software companies widely use Open-Source Software (OSS), the risk of open-source license violation has grown increasingly high. Moreover, because the companies often receive software module from upstream suppliers in binary form, it is very hard to obtain the source code. Software distributed in binary form frequently includes third-party libraries without following their licenses. Therefore, it is necessary to develop a technique for detecting OSS or unlicensed third-party code in their software products at the binary level not source level. In this paper, we propose an efficient function parameter based software birthmark at the binary level and develop a scheme to detect OSS using the birthmark. The proposed birthmark is based on the attributes of function parameters such as the number, types, and order. These attributes represent an intrinsic property of a function and are resilient to compiler optimization too. The new birthmark makes use of type mapping of function parameters of each function. Our scheme first extracts the birthmarks from target binary files, and determines whether a binary file contains another binary (e.g., OSS component) by computing the similarity between the extracted birthmarks. We also present an OSS detection framework that can integrate various birthmarking schemes with similarity computation algorithms. Our framework selects an appropriate algorithm to measure software similarity depending on the binary file type of target executables. The framework provides semi-global alignment, local alignment, and sliding-window k-gram algorithms for efficient detection of an OSS component contained in a target executable. The efficiency and effectiveness of the proposed framework are demonstrated through extensive experimentation.","Function parameter; K-gram; Open-source software; Sequence alignment; Software birthmark","Article","Scopus"
"García-Nieto S.; Martínez M.; Salcedo J.; Laurí D.","García-Nieto, S. (17434216100); Martínez, M. (55728596300); Salcedo, J. (16639877500); Laurí, D. (25929470500)","17434216100; 55728596300; 16639877500; 25929470500","Practice tool based on open source SCADA for experimentation in nonlinear control using the inverted pendulum","2012","Computer Applications in Engineering Education","10.1002/cae.20381","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856837950&doi=10.1002%2fcae.20381&partnerID=40&md5=be45aa45219862b5364fdddc956d17c8","This paper presents the potential of open source software for designing educational tools in the automatization field. In particular, this paper presents a complete tool that students can use for studying and testing nonlinear control algorithms. The system has three different parts that students can evaluate and modify. Firstly, a virtual model represents the physical model and, in this case, an inverted pendulum is used. Secondly, the controller is implemented by a real-time distributed control system. Finally, the system can be managed with a JAVA application. Therefore, students have all the necessary elements to practice using nonlinear and complex systems. The main tools applied in the design are open source software and the developed platform is Generalized Public License(GPL). © 2009 Wiley Periodicals, Inc.","control theory; nonlinear systems; open source; remote laboratories","Article","Scopus"
"Bloessl B.; Segata M.; Sommer C.; Dressler F.","Bloessl, Bastian (55364532000); Segata, Michele (53264837400); Sommer, Christoph (7103256615); Dressler, Falko (8897738000)","55364532000; 53264837400; 7103256615; 8897738000","Performance Assessment of IEEE 802.11p with an Open Source SDR-Based Prototype","2018","IEEE Transactions on Mobile Computing","10.1109/TMC.2017.2751474","66","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030222080&doi=10.1109%2fTMC.2017.2751474&partnerID=40&md5=bbe15943d9a1d0a0a3b35463c1477e67","We present a complete simulation and experimentation framework for IEEE 802.11p. The core of the framework is a Software Defined Radio (SDR)-based Orthogonal Frequency Division Multiplexing (OFDM) transceiver that we validated extensively by means of simulations, interoperability tests, and, ultimately, by conducting a field test. Being SDR-based, the transceiver offers important benefits: It provides access to all data down to and including the physical layer, allowing for a better understanding of the system. Based on open and programmable hardware and software, the transceiver is completely transparent and all implementation details can be studied and, if needed, modified. Finally, it enables a seamless switch between simulations and experiments and, thus, helps to bridge the gap between theory and practice. Comparing the transceiver's performance with independent results from simulations and experiments, we underline its potential to be used as a tool for further studies of IEEE 802.11p networks both in field operational tests as well as for simulation-based development of novel physical layer solutions. To make the framework accessible to fellow researchers and to allow reproduction of the results, we released it under an Open Source license. © 2002-2012 IEEE.","GNU Radio; software defined radio; Vehicular Ad Hoc Network (VANET); Wireless LAN (WLAN)","Article","Scopus"
"Kemp R.; Gibbons C.","Kemp, Richard (8956539500); Gibbons, Caspar (57190411273)","8956539500; 57190411273","IPR indemnities in the open source and proprietary software worlds","2005","Computer Law and Security Report","10.1016/j.clsr.2005.08.004","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979846360&doi=10.1016%2fj.clsr.2005.08.004&partnerID=40&md5=68f5c9c3b2a41f45d589c2b326fc7090","Intellectual property right (IPR) indemnities in software licences - the commitment of the licensor to step up to the plate and bear the risk if the customer is challenged in its use of the software by a third party for infringing its IPR (see also An Indemnity Primer for IT Consumers: What You Need to Know, What You Want to Have, Jeffrey P Kushan, Sidley Austin Brown & Wood LLP, November 2004 - accessible on http://tinyurl.com/br4vb) - are assuming increasing importance in the competing marketing strategies of the open source software (OSS) and proprietary software vendors' camps as they engage for the hearts and minds of the IT departments of the world's largest customers. © 2005 Kemp Little LLP. Published by Elsevier Ltd. All rights reserved.","","Article","Scopus"
"Steiniger S.; Bocher E.","Steiniger, Stefan (18038653900); Bocher, Erwan (35108764600)","18038653900; 35108764600","An overview on current free and open source desktop GIS developments","2009","International Journal of Geographical Information Science","10.1080/13658810802634956","170","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349789930&doi=10.1080%2f13658810802634956&partnerID=40&md5=348e6adfd59e4866a3422d52207a4c2e","Over the past few years the world of free and open source geospatial software has experienced some major changes. For instance, the website FreeGIS.org currently lists 330 GIS-related projects. Besides the advent of new software projects and the growth of established projects, a new organisation known as the OSGeo Foundation has been established to offer a point of contact. This paper will give an overview on existing free and open source desktop GIS projects. To further the understanding of the open source software development, we give a brief explanation of associated terms and introduce the two most established software license types: the General Public License (GPL) and the Lesser General Public License (LGPL). After laying out the organisational structures, we describe the different desktop GIS software projects in terms of their main characteristics. Two main tables summarise information on the projects and functionality of the currently available software versions. Finally, the advantages and disadvantages of open source software, with an emphasis on research and teaching, are discussed. © 2009 Taylor & Francis.","Desktop GIS; Free software; Open source; Software projects","Article","Scopus"
"Douglas D.M.","Douglas, David M. (7203040010)","7203040010","A bundle of software rights and duties","2011","Ethics and Information Technology","10.1007/s10676-010-9229-3","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960972145&doi=10.1007%2fs10676-010-9229-3&partnerID=40&md5=21b6e3a9823618c50c7217c2870015ca","Like the ownership of physical property, the issues computer software ownership raises can be understood as concerns over how various rights and duties over software are shared between owners and users. The powers of software owners are defined in software licenses, the legal agreements defining what users can and cannot do with a particular program. To help clarify how these licenses permit and restrict users' actions, here I present a conceptual framework of software rights and duties that is inspired by the terms of various proprietary, open source, and free software licenses. To clarify the relationships defined by these rights and duties, this framework distinguishes between software creators (the original developer), custodians (those who can control its use), and users (those who utilise the software). I define the various rights and duties that can be shared between these parties and how these rights and duties relate to each other. I conclude with a brief example of how this framework can be used by defining the concepts of free software and copyleft in terms of rights and duties. © 2010 Springer Science+Business Media B.V.","Copyleft; Duties; Free software; Rights; Software licenses; Software ownership; Users","Article","Scopus"
"Georgeson P.; Syme A.; Sloggett C.; Chung J.; Dashnow H.; Milton M.; Lonsdale A.; Powell D.; Seemann T.; Pope B.","Georgeson, Peter (57188804248); Syme, Anna (14525788100); Sloggett, Clare (57028206500); Chung, Jessica (56941206600); Dashnow, Harriet (55360532000); Milton, Michael (57194323201); Lonsdale, Andrew (56398319600); Powell, David (55708387700); Seemann, Torsten (35273114400); Pope, Bernard (7005597341)","57188804248; 14525788100; 57028206500; 56941206600; 55360532000; 57194323201; 56398319600; 55708387700; 35273114400; 7005597341","Bionitio: Demonstrating and facilitating best practices for bioinformatics command-line software","2019","GigaScience","10.1093/gigascience/giz109","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072574632&doi=10.1093%2fgigascience%2fgiz109&partnerID=40&md5=3855835094bd0f75ba052e56a9a19573","Background: Bioinformatics software tools are often created ad hoc, frequently by people without extensive training in software development. In particular, for beginners, the barrier to entry in bioinformatics software development is high, especially if they want to adopt good programming practices. Even experienced developers do not always follow best practices. This results in the proliferation of poorer-quality bioinformatics software, leading to limited scalability and inefficient use of resources; lack of reproducibility, usability, adaptability, and interoperability; and erroneous or inaccurate results. Findings: We have developed Bionitio, a tool that automates the process of starting new bioinformatics software projects following recommended best practices. With a single command, the user can create a new well-structured project in 1 of 12 programming languages. The resulting software is functional, carrying out a prototypical bioinformatics task, and thus serves as both a working example and a template for building new tools. Key features include command-line argument parsing, error handling, progress logging, defined exit status values, a test suite, a version number, standardized building and packaging, user documentation, code documentation, a standard open source software license, software revision control, and containerization. Conclusions: Bionitio serves as a learning aid for beginner-to-intermediate bioinformatics programmers and provides an excellent starting point for new projects. This helps developers adopt good programming practices from the beginning of a project and encourages high-quality tools to be developed more rapidly. This also benefits users because tools are more easily installed and consistent in their usage. Bionitio is released as open source software under the MIT License and is available at https://github.com/bionitio-team/bionitio. © 2019 The Author(s) 2019. Published by Oxford University Press.","best practices; bioinformatics; software development; training","Article","Scopus"
"Georgiades E.","Georgiades, Eugenia (36010421500)","36010421500","Resolving conflicting interests: Software patents versus open source","2011","Information and Communications Technology Law","10.1080/13600834.2011.603964","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053192266&doi=10.1080%2f13600834.2011.603964&partnerID=40&md5=1c55610ae86de4f4c685ccf18a63cf38","The issue of granting software patents in the United States has a created a rift between the open source community and patent owners. One of the contributing factors causing conflict between the open source community and patent owners is the read granting of software patent applications by the United States Patent and Trademark Office (USPTO). The increasing volume of software patent applications received by the USPTO has strained the patent system and consequently software patent applications are granted without close examination of whether they meet the requirements for a valid patent. The conflict between patent owners and the open source community is exacerbated when alleged patent infringement occurs for software products that circulate in the technology industry that should be open and free to use within the open source community. Subsequently, this issue is complicated when the alleged patent infringement occurs. The threat of litigation is a financial burden that is too great to bear by small and medium enterprises and by developers who unknowingly use software protected by a patent, which results in paying license fees and/royalties to avoid costly litigation. The granting of software patents without scrutiny of prior art by the USPTO is restricting innovation within the information technology sector and hindering developers, programmers, and technology innovators from creating and innovating new and emerging technologies. Further, the granting of software patents without close examination by patent examiners restricts and contradicts the ethos and philosophy behind a grant of patent. © 2011 Taylor & Francis.","Conflicts; Infringement; Open source; Patent examination; Patents; Software patents","Article","Scopus"
"Rothfuss G.J.","Rothfuss, Gregor J. (8513833800)","8513833800","The state of open source CMSs","2005","Cutter IT Journal","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-20744442598&partnerID=40&md5=4a4414435c1f04f62eaa26e2da0e0c10","The state of open source content management system (CMS) is studied. Large open source projects are ideally positioned to drive commoditization and thus lower costs for the consumer. It is observed that the companies that learned how to participate in open source communities had no trouble making their needs heard. It is recommended to keep an eye on the open source landscape, even if one remain a buyer of proprietary software.","","Article","Scopus"
"Ghosh R.A.","Ghosh, Rishab Aiyer (25030115500)","25030115500","Licence fees and GDP per capita: The case for open source in developing countries","2003","First Monday","10.5210/fm.v8i12.1103","34","https://www.scopus.com/inward/record.uri?eid=2-s2.0-28144445496&doi=10.5210%2ffm.v8i12.1103&partnerID=40&md5=c552c046e4391f40a40ae60d9683ed31","There is a strong case for free software (also known as open source or libre software) being deployed widely in developing countries. This paper describes three reasons in particular: free software is a skills enabling platform; it is far cheaper; and it is more adaptable to local needs. The free software development community provides an environment of intensive interactive skills development at little explicit cost, which is particularly useful for local development of skills, especially in economically disadvantaged regions. Meanwhile, the controversy over total costs of ownership (TCO) of free vs. proprietary software is not applicable to developing countries and other regions with low labour costs, where the TCO advantage lies with free software, and the share of licence fees in TCO is much higher than in (richer) high labour cost countries. The note concludes with a table comparing license fees for proprietary software against GDP per capita for 176 countries. © 2003, First Monday.","","Article","Scopus"
"Ratib O.; Rosset A.","Ratib, Osman (7007144028); Rosset, Antoine (6603523170)","7007144028; 6603523170","Open-source software in medical imaging: Development of OsiriX","2006","International Journal of Computer Assisted Radiology and Surgery","10.1007/s11548-006-0056-2","38","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33845299176&doi=10.1007%2fs11548-006-0056-2&partnerID=40&md5=fbfb1746cc4fdf4ce9ecf2a2a90fa19d","Purpose Open source software (oss) development for medical imaging enables collaboration of individuals and groups to produce high-quality tools that meet user needs. This process is reviewed and illustrated with OsiriX, a fast DICOM viewer program for the Apple Macintosh. Materials and methods OsiriX is an oss for the Apple Macintosh under Mac OS X v10.4 or higher specifically designed for navigation and visualization of multimodality and multidimensional images: 2D Viewer, 3D Viewer, 4D Viewer (3D series with temporal dimension, for example: Cardiac-CT) and 5D Viewer (3D series with temporal and functional dimensions, for example: Cardiac-PET-CT). The 3D Viewer offers all modern rendering modes: multiplanar reconstruction, surface rendering, volume rendering and maximum Intensity projection. All these modes support 4D data and are able to produce image fusion between two different series (for example: PET-CT). OsiriX was developed using the Apple Xcode development environment and Cocoa framework as both a DICOM PACS workstation for medical imaging and an image processing software package for medical research (radiology and nuclear imaging), functional imaging, 3D imaging, confocal microscopy and molecular imaging. Results OsiriX is an open source program by Antoine Rosset, a radiologist and software developer, was designed specifically for the needs of advanced imaging modalities. The software program turns an Apple Macintosh into a DICOM PACS workstation for medical imaging and image processing. OsiriX is distributed free of charge under the GNU General Public License and its source code is available to anyone. This system illustrates how open software development for medical imaging tools can be successfully designed, implemented and disseminated. Conclusion oss development can provide useful cost effective tools tailored to specific needs and clinical tasks. The integrity and quality assurance of open software developed by a community of users does not follow the traditional conformance and certification required for commercial medical software programs. However, open software can lead to innovative solutions designed by users better suited for specific tasks. © CARS 2006.","","Article","Scopus"
"Wu Y.; Manabe Y.; Kanda T.; German D.M.; Inoue K.","Wu, Yuhao (57095239500); Manabe, Yuki (36661027300); Kanda, Tetsuya (55853578000); German, Daniel M. (57207886015); Inoue, Katsuro (7601540520)","57095239500; 36661027300; 55853578000; 57207886015; 7601540520","Analysis of license inconsistency in large collections of open source projects","2017","Empirical Software Engineering","10.1007/s10664-016-9487-8","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85001114526&doi=10.1007%2fs10664-016-9487-8&partnerID=40&md5=86fcde6439357f05edce98e0c7b073b1","Free and open source software (FOSS) plays an important role in source code reuse practice. They usually come with one or more software licenses written in the header part of source files, stating the requirements and conditions which should be followed when been reused. Removing or modifying the license statement by re-distributors will result in the inconsistency of license with its ancestor, and may potentially cause license infringement. In this paper, we describe and categorize different types of license inconsistencies and propose a method to detect them. Then we applied this method to Debian 7.5 and a collection of 10,514 Java projects on GitHub and present the license inconsistency cases found in these systems. With a manual analysis, we summarized various reasons behind these license inconsistency cases, some of which imply potential license infringement and require attention from the developers. This analysis also exposes the difficulty to discover license infringements, highlighting the usefulness of finding and maintaining source code provenance. © 2016, Springer Science+Business Media New York.","Code clone; License inconsistency; Software license","Article","Scopus"
"Colombo S.; Grilli L.; Rossi-Lamastra C.","Colombo, Stefano (34876449600); Grilli, Luca (6602373428); Rossi-Lamastra, Cristina (57197758938)","34876449600; 6602373428; 57197758938","Network Externalities, Incumbent's Competitive Advantage and the Degree of Openness of Software Start-Ups","2014","Computational Economics","10.1007/s10614-013-9385-8","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904259659&doi=10.1007%2fs10614-013-9385-8&partnerID=40&md5=92730618695270d0d1fe99e865b32f1d","This paper proposes a formal model that analyzes the degree of openness chosen by start-ups when entering the software industry. In line with the literature, we label as degree of openness the extent to which software start-ups mix open source (OS) and proprietary solutions in the portfolio of software products they offer. We relate the choice of the degree of openness to two key characteristics of the market segments in which software start-ups operate: the strength of the network externalities and the competitive advantage of the incumbent. Specifically, by modelling (price) competition between an incumbent and an entrant in two ways, i.e., the entrant is price-setter or price-taker, we derive the necessary condition(s) in terms of the strength of network externalities for observing the adoption of a business model that comprises the offering of both proprietary and OS solutions by the entrant (i.e., hybrid business model). Then, we highlight that, if a hybrid business model is the choice, the degree of openness chosen in equilibrium increases along with both the strength of the network externalities and the competitive advantage of the incumbent. This result holds indifferently whether the software start-up is modelled as a price-setter or a price-taker. An empirical test run on a sample of European start-ups in the software industry supports these theoretical predictions. © 2013 Springer Science+Business Media New York.","Degree of openness; Incumbent's competitive advantage; Network externalities; Open source; Software start-ups","Article","Scopus"
"Mouakhar K.; Tellier A.","Mouakhar, Khaireddine (57194718262); Tellier, Albéric (23111530200)","57194718262; 23111530200","How do Open Source software companies respond to institutional pressures? A business model perspective","2017","Journal of Enterprise Information Management","10.1108/JEIM-05-2015-0041","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021790211&doi=10.1108%2fJEIM-05-2015-0041&partnerID=40&md5=f282c23f06a53dd0c561f2176a5641db","Purpose: Open Source software companies (OSSCs) are confronted with institutional pressures from Open Source software (OSS) communities. They must find an acceptable balance between the expectations of these communities and their own business model. However, there are still few studies that try to analyse the OSSC business models. The purpose of this paper is to highlight OSSC typical business models by using rich empirical data. Design/methodology/approach: The methodology is based on a combination of quantitative analysis of a sample of 66 OSSCs and qualitative analysis of three typical situations resulting from that sample. Findings: The quantitative study enables the authors to highlight three typical business models. The in-depth study of three typical cases enables the authors to specify these OSSC business models. The authors can distinguish four key dimensions: the relationship developed with the OSS communities, the strategic manoeuvres made, the key resources and competitive positioning. Research limitations/implications: The results indicate that it is possible for firms to accommodate both profit and non-profit logics using different strategic manoeuvres to position themselves with regard to the Open Source institutional environment. Such accommodation requires the development of key resources and the adoption of suitable competitive positioning. Practical implications: This study allows the authors to highlight two main practical contributions for OSSCs’ directors. First, the different manoeuvres identified may help them to ensure coherence between their strategic choices and the business model chosen. Second, the results can help OSSC founders identify value creation mechanisms more clearly by analysing four key variables. Originality/value: This paper provides new insight about OSSCs business models. It aggregates four dimensions that provide a more “fine-grained” analysis of business models, while other studies often emphasise one dimension (usually the regime of appropriability). © 2017, © Emerald Publishing Limited.","Business model; Institutional pressures; Open Source software companies; Strategic responses","Article","Scopus"
"Chlipala G.E.; Krunic A.; Mo S.; Sturdy M.; Orjala J.","Chlipala, George E. (25927014100); Krunic, Aleksej (9041168500); Mo, Shunyan (55431285200); Sturdy, Megan (26433927600); Orjala, Jimmy (6701477142)","25927014100; 9041168500; 55431285200; 26433927600; 6701477142","CYANOS: A data management system for natural product drug discovery efforts using cultured microorganisms","2011","Journal of Chemical Information and Modeling","10.1021/ci100280a","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952593279&doi=10.1021%2fci100280a&partnerID=40&md5=36320f66db001f6b42d16a246725c6b0","A software package, termed ""CYANOS"", has been developed to facilitate the data management and mining for natural product drug discovery efforts. This system allows for the management of data associated with field collections, culture conditions, harvests, extractions, chemical separations, and biological evaluation. This software utilizes a MySQL database for data storage, which allows for reporting and data mining via third party tools. In addition, a Web-based interface was constructed to allow for multiuser access from a variety of desktop platforms. The code for this system is freely available and has been released under the Illinois Open Source license. © 2011 American Chemical Society.","","Article","Scopus"
"Butler S.; Gamalielsson J.; Lundell B.; Brax C.; Mattsson A.; Gustavsson T.; Feist J.; Kvarnström B.; Lönroth E.","Butler, Simon (57203032212); Gamalielsson, Jonas (6506812796); Lundell, Björn (7004530817); Brax, Christoffer (25654534300); Mattsson, Anders (36899074500); Gustavsson, Tomas (57208024075); Feist, Jonas (55508021700); Kvarnström, Bengt (57221979500); Lönroth, Erik (57194282770)","57203032212; 6506812796; 7004530817; 25654534300; 36899074500; 57208024075; 55508021700; 57221979500; 57194282770","Considerations and challenges for the adoption of open source components in software-intensive businesses","2022","Journal of Systems and Software","10.1016/j.jss.2021.111152","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122228228&doi=10.1016%2fj.jss.2021.111152&partnerID=40&md5=1a76191d935c3a5d37498d5b169511a9","Component-Based Software Development is a conventional way of working for software-intensive businesses and Open Source Software (OSS) components are frequently considered by businesses for adoption and inclusion in software products. Previous research has found a variety of practices used to support the adoption of OSS components, including formally specified processes and less formal, developer-led approaches, and that the practices used continue to develop. Evolutionary pressures identified include the proliferation of available OSS components and increases in the pace of software development as businesses move towards continuous integration and delivery. We investigate work practices used in six software-intensive businesses in the primary and secondary software sectors to understand current approaches to OSS component adoption and the challenges businesses face establishing effective work practices to evaluate OSS components. We find businesses have established processes for evaluating OSS components and communities that support more complex and nuanced considerations of the cost and risks of component adoption alongside matters such as licence compliance and functional requirements. We also found that the increasing pace and volume of software development within some businesses provides pressure to continue to evolve software evaluation processes. © 2021 The Authors","Component-based software development; Open source software; Software adoption","Article","Scopus"
"Koltun P.","Koltun, Philip (57190035834)","57190035834","Free and open source software use: Benefits and compliance obligations","2011","CrossTalk","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-81555199735&partnerID=40&md5=811ed1fa4bfe070baf7f322d4d96ebfb","Many systems developed for and deployed by the U.S. government now use Free and Open Source Software (FOSS). But FOSS use comes with potential license obligations. Essential compliance activities include identification of FOSS used in products along with communication of a FOSS bill of materials; review and approval of planned FOSS use; and satisfaction of license obligations. Compliance policies, processes, training, and tools enable contractors and government sponsors to use FOSS effectively. The Linux Foundation's Open Compliance Program provides many resources to assist with compliance.©2011 by Phadke Associates, Inc. All rights reserved.","","Article","Scopus"
"Cleyle S.; Sitas A.","Cleyle, S. (56012578000); Sitas, Anestis (14621804600)","56012578000; 14621804600","CDSware CERN Document Server Software)","2006","Library Hi Tech","10.1108/07378830610692172","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33748757235&doi=10.1108%2f07378830610692172&partnerID=40&md5=939404c0fd41ca2fb3fb51ef27bb682d","Purpose The purpose of this article is to describe CDSware CERN Document Server Software a software developed at CERN. Design/methodology/approach CDSware supports the creation of electronic preprint servers, Online Public Access Catalogs OPACs) and document systems on the web. It complies with the OAI-PMH Open Archive Initiative – Protocol for Metadata Harvesting) and uses MARC 21 as its underlying bibliographic standard. It is open source software, licensed under the terms of the GNU General Public License. Findings CDSware has been created for the handling of large repositories including various types of materials, like descriptions of museum objects, collections of confidential or public documents, etc. Practical implications All technical details of the software are described to enable comparison with all other open source software for managing and bibliographic organization of digitized context. Originality/value The paper presents a detailed description of highly technically and bibliographically) developed software in order to help libraries in deciding which open source software is more suitable for their digitization project. © 2006, Emerald Group Publishing Limited","Archives management; Computer software; Digital libraries; Information retrieval; Public domain software","Article","Scopus"
"Martínez V.; Berzal F.; Cubero J.-C.","Martínez, Víctor (57214590547); Berzal, Fernando (6602612825); Cubero, Juan-Carlos (55663885600)","57214590547; 6602612825; 55663885600","NOESIS: A Framework for Complex Network Data Analysis","2019","Complexity","10.1155/2019/1439415","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075041362&doi=10.1155%2f2019%2f1439415&partnerID=40&md5=92176a3ab02987eeffe7c5c80dceeb1a","Network data mining has attracted a lot of attention since a large number of real-world problems have to deal with complex network data. In this paper, we present NOESIS, an open-source framework for network-based data mining. NOESIS features a large number of techniques and methods for the analysis of structural network properties, network visualization, community detection, link scoring, and link prediction. The proposed framework has been designed following solid design principles and exploits parallel computing using structured parallel programming. NOESIS also provides a stand-alone graphical user interface allowing the use of advanced software analysis techniques to users without prior programming experience. This framework is available under a BSD open-source software license. © 2019 Víctor Martínez et al.","","Article","Scopus"
"Garzarelli G.; Limam Y.R.; Thomassen B.","Garzarelli, Giampaolo (21933452300); Limam, Yasmina Reem (25824357700); Thomassen, Bjøern (25824420500)","21933452300; 25824357700; 25824420500","Open source software and economic growth: A classical division of labor perspective","2008","Information Technology for Development","10.1002/itdj.20092","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-57249087349&doi=10.1002%2fitdj.20092&partnerID=40&md5=7b79da6770e697ef9c7fbb77d5f0f05e","The article turns to classical economic insights on the division of labor and to institutional reasoning to identify some costs and benefits of open source software (OSS) and proprietary software production. It suggests that, thanks to its licenses, OSS favors market expansion more than proprietary software does by tapping into spontaneous work input. The spontaneous tapping leads to a division of labor that exhibits what the article calls redundant economies. By generating a circle of knowledge growth, reuse, and sharing, redundant economies lead to increasing returns, which are crucial for economic growth. © 2008 Wiley Periodicals, Inc.","Division of labor; Extent of the market; Increasing returns; Institutions; Knowledge; Open source software; Redundant economies","Article","Scopus"
"Almeida D.A.; Murphy G.C.; Wilson G.; Hoye M.","Almeida, Daniel A. (56785369600); Murphy, Gail C. (7402791460); Wilson, Greg (8231224700); Hoye, Michael (57195063368)","56785369600; 7402791460; 8231224700; 57195063368","Investigating whether and how software developers understand open source software licensing","2019","Empirical Software Engineering","10.1007/s10664-018-9614-9","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046028692&doi=10.1007%2fs10664-018-9614-9&partnerID=40&md5=3930ac7d37723f9b7da226d98aef9f18","Software provided under open source licenses is widely used, from forming high-profile stand-alone applications (e.g., Mozilla Firefox) to being embedded in commercial offerings (e.g., network routers). Despite the high frequency of use of open source licenses, there has been little work about whether software developers understand the open source licenses that they use. To help understand whether or not developers understand the open source licenses they use, we conducted a survey that posed development scenarios involving three popular open source licenses (GNU GPL 3.0, GNU LGPL 3.0 and MPL 2.0) both alone and in combination. The 375 respondents to the survey, who were largely developers, gave answers consistent with those of a legal expert’s opinion in 62% of 42 cases. Although developers clearly understood cases involving one license, they struggled when multiple licenses were involved. To understand the context in which licensing issues arise in practice, we analyzed real-world questions posed by developers about the three licenses considered in the survey on online question-and-answer communities. We also interviewed practicing developers about license interaction problems they have faced. Among several lessons, we learnt that licensing issues can constrain software evolution and that developers are cautious of more restrictive licenses. Our results indicate a need for tool support to help guide developers in understanding the structure of the code and the technical details of a project while taking into account the exact requirements imposed by the licenses involved. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","Empirical studies; Open source; Software licenses","Article","Scopus"
"Xing M.","Xing, Mingqing (36603743700)","36603743700","Comparative study on innovation incentives for commercial open source software under different licenses","2013","Research Journal of Applied Sciences, Engineering and Technology","10.19026/rjaset.5.4484","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876307253&doi=10.19026%2frjaset.5.4484&partnerID=40&md5=b7a854c0c4109f91cd2b0d15a3c61c90","This study compares technological innovation incentives for commercial open source software under two typical licenses (the GNU General Public License and the Berkeley Software Distribution License, i.e., GPL and BSD). In the case of private optimum, the incentive towards software features (resp. usability) innovation is always higher (resp. lower) under BSD than under GPL. Contrast to the private optimum, the social planner expects more investment in software feature under both BSD and GPL, but less (resp. equivalent) investment in software usability under BSD (resp. GPL) ©Maxwell Scientific Organization, 2013.","BSD; Commercial open source; Gpl; Open source software; Software feature software usability.; Software innovation","Article","Scopus"
"Monden A.; Okahara S.; Manabe Y.; Matsumoto K.","Monden, Akito (6603291770); Okahara, Satoshi (37003266200); Manabe, Yuki (36661027300); Matsumoto, Kenichi (55378267900)","6603291770; 37003266200; 36661027300; 55378267900","Guilty or not guilty: Using clone metrics to determine open source licensing violations","2011","IEEE Software","10.1109/MS.2010.159","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952126469&doi=10.1109%2fMS.2010.159&partnerID=40&md5=8417e79c81fd8141fe6a8c1e5e0072aa","Unintentionally violating open source software (OSS) licenses by reusing OSS code is a serious problem for both software companies and OSS developers. The simplest intuitive way to identify such reuse is to measure code clonesduplicated code fragmentsbetween a suspected program and an existing OSS program. The question then becomes, what is the lower bound of code clone measurements needed to conclude that the suspected program is guilty (reused code exists) and the upper bound needed to conclude that it is not guilty? In their analysis of 1,225 pairs of OSS products, the authors found 121 with reused code. They experimentally explored the boundaries for three code clone metrics: maximum clone length (MCL), number of clone pairs (NCP), and local product similarity (LSim). Using these metrics, they identified guilty, not guilty, and suspicious programs. © 2011 IEEE.","open source software reuse; product metrics; software licensing violations","Article","Scopus"
"Rees C.A.; Demeter J.; Matese J.C.; Botstein D.; Sherlock G.","Rees, Christian A. (7103265989); Demeter, Janos (7005807499); Matese, John C. (6701415184); Botstein, David (7102711191); Sherlock, Gavin (55660443800)","7103265989; 7005807499; 6701415184; 7102711191; 55660443800","GeneXplorer: An interactive web application for microarray data visualization and analysis","2004","BMC Bioinformatics","10.1186/1471-2105-5-141","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-13244255321&doi=10.1186%2f1471-2105-5-141&partnerID=40&md5=a87127d65fe97b25bf94d0c618621a22","Background: When publishing large-scale microarray datasets, it is of great value to create supplemental websites where either the full data, or selected subsets corresponding to figures within the paper, can be browsed. We set out to create a CGI application containing many of the features of some of the existing standalone software for the visualization of clustered microarray data. Results: We present GeneXplorer, a web application for interactive microarray data visualization and analysis in a web environment. GeneXplorer allows users to browse a microarray dataset in an intuitive fashion. It provides simple access to microarray data over the Internet and uses only HTML and JavaScript to display graphic and annotation information. It provides radar and zoom views of the data, allows display of the nearest neighbors to a gene expression vector based on their Pearson correlations and provides the ability to search gene annotation fields. Conclusions: The software is released under the permissive MIT Open Source license, and the complete documentation and the entire source code are freely available for download from CPAN http://search.cpan.org/dist/Microarray-GeneXplorer/. © 2004 Rees et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Subramaniam C.; Sen R.; Nelson M.L.","Subramaniam, Chandrasekar (8136647600); Sen, Ravi (9737868800); Nelson, Matthew L. (7403461430)","8136647600; 9737868800; 7403461430","Determinants of open source software project success: A longitudinal study","2009","Decision Support Systems","10.1016/j.dss.2008.10.005","176","https://www.scopus.com/inward/record.uri?eid=2-s2.0-57749120274&doi=10.1016%2fj.dss.2008.10.005&partnerID=40&md5=4fd2540d278a2f0802d72f31c12894cb","In this paper, we investigate open source software (OSS) success using longitudinal data on OSS projects. We find that restrictive OSS licenses have an adverse impact on OSS success. On further analysis, restrictive OSS license is found to be negatively associated with developer interest, but is positively associated with the interest of non-developer users and project administrators. We also show that developer and non-developer interest in the OSS project and the project activity levels in any time period significantly affect the project success measures in subsequent time period. The implications of our findings for OSS research and practice are discussed. © 2008 Elsevier B.V. All rights reserved.","Longitudinal study; Open source project; OSS; Software project success","Article","Scopus"
"Alspaugh T.A.; Scacchi W.; Asuncion H.U.","Alspaugh, Thomas A. (36892797100); Scacchi, Walt (7004343180); Asuncion, Hazeline U. (23134725400)","36892797100; 7004343180; 23134725400","Software licenses in context: The challenge of heterogeneously-licensed systems","2010","Journal of the Association for Information Systems","10.17705/1jais.00241","40","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650360654&doi=10.17705%2f1jais.00241&partnerID=40&md5=96304398596578b10d00e1b993b0987f","The prevailing approach to free/open source software and licenses has been that each system is developed, distributed, and used under the terms of a single license. But it is increasingly common for information systems and other software to be composed with components from a variety of sources, and with a diversity of licenses. This may result in possible license conflicts and organizational liability for failure to fulfill license obligations. Research and practice to date have not kept up with this sea-change in software licensing arising from free/open source software development. System consumers and users consequently rely on ad hoc heuristics (or costly legal advice) to determine which license rights and obligations are in effect, often with less than optimal results; consulting services are offered to identify unknowing unauthorized use of licensed software in information systems; and researchers have shown how the choice of a (single) specific license for a product affects project success and system adoption. Legal scholars have examined how pairs of software licenses conflict but only in simple contexts. We present an approach for understanding and modeling software licenses, as well as for analyzing conflicts among groups of licenses in realistic system contexts, and for guiding the acquisition, integration, or development of systems with free/open source components in such an environment. This work is based on an empirical analysis of representative software licenses and of heterogeneously-licensed systems. Our approach provides guidance for achieving a ""best-of-breed"" component strategy while obtaining desired license rights in exchange for acceptable obligations.","Case study; Design theory; Open source software; Semantic modeling; Software licenses; System architecture","Article","Scopus"
"Muñoz-Quijada M.; Sanz L.; Guzman-Miranda H.","Muñoz-Quijada, Maria (57205300329); Sanz, Luis (57195454995); Guzman-Miranda, Hipolito (24586918500)","57205300329; 57195454995; 24586918500","Sw-vhdl co-verification environment using open source tools","2020","Electronics (Switzerland)","10.3390/electronics9122104","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097387788&doi=10.3390%2felectronics9122104&partnerID=40&md5=9652b57766b893e79c36c154abb1fbf3","The verification of complex digital designs often involves the use of expensive simulators. The present paper proposes an approach to verify a specific family of complex hardware/software systems, whose hardware part, running on an FPGA, communicates with a software counterpart executed on an external processor, such as a user/operator software running on an external PC. The hardware is described in VHDL and the software may be described in any computer language that can be interpreted or compiled into a (Linux) executable file. The presented approach uses open source tools, avoiding expensive license costs and usage restrictions. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Co-verification; Open source tools; System verification; VHDL","Article","Scopus"
"Schausberger S.E.; Kaltseis R.; Drack M.; Cakmak U.D.; Major Z.; Bauer S.","Schausberger, Stefan E. (24282308500); Kaltseis, Rainer (37261408600); Drack, Michael (55813863900); Cakmak, Umut D. (36520872100); Major, Zoltan (16309858800); Bauer, Siegfried (13409302000)","24282308500; 37261408600; 55813863900; 36520872100; 16309858800; 13409302000","Cost-Efficient Open Source Desktop Size Radial Stretching System With Force Sensor","2015","IEEE Access","10.1109/ACCESS.2015.2433398","19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959852150&doi=10.1109%2fACCESS.2015.2433398&partnerID=40&md5=453c5d593fafb2207453a9b31cea1662","The rapid and efficient development of soft active materials requires readily available, compact testing equipment. We propose a desktop-sized, cost-efficient, and open source radial stretching system as an alternative to commercially available biaxial and uniaxial stretching devices. It allows for doubling the diameter of an elastomer membrane while measuring the applied force. Our development enables significant cost reduction ( $<300$ €) and increase the availability of equibiaxial deformation measurements for scientific material analysis. Construction plans, source code, and electronic circuit diagrams are freely available under a creative commons license. © 2013 IEEE.","arduino; creative commons; elastomers; IEEE Open Access; material research; mechanics; model; soft active materials; stretchable electronics; teaching","Article","Scopus"
"Wenig P.; Odermatt J.","Wenig, Philip (35148798500); Odermatt, Juergen (55959521900)","35148798500; 55959521900","OpenChrom: A cross-platform open source software for the mass spectrometric analysis of chromatographic data","2010","BMC Bioinformatics","10.1186/1471-2105-11-405","114","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955072168&doi=10.1186%2f1471-2105-11-405&partnerID=40&md5=5c47b807168e0e3bcb17b2ab8ffbb797","Background: Today, data evaluation has become a bottleneck in chromatographic science. Analytical instruments equipped with automated samplers yield large amounts of measurement data, which needs to be verified and analyzed. Since nearly every GC/MS instrument vendor offers its own data format and software tools, the consequences are problems with data exchange and a lack of comparability between the analytical results. To challenge this situation a number of either commercial or non-profit software applications have been developed. These applications provide functionalities to import and analyze several data formats but have shortcomings in terms of the transparency of the implemented analytical algorithms and/or are restricted to a specific computer platform.Results: This work describes a native approach to handle chromatographic data files. The approach can be extended in its functionality such as facilities to detect baselines, to detect, integrate and identify peaks and to compare mass spectra, as well as the ability to internationalize the application. Additionally, filters can be applied on the chromatographic data to enhance its quality, for example to remove background and noise. Extended operations like do, undo and redo are supported.Conclusions: OpenChrom is a software application to edit and analyze mass spectrometric chromatographic data. It is extensible in many different ways, depending on the demands of the users or the analytical procedures and algorithms. It offers a customizable graphical user interface. The software is independent of the operating system, due to the fact that the Rich Client Platform is written in Java. OpenChrom is released under the Eclipse Public License 1.0 (EPL). There are no license constraints regarding extensions. They can be published using open source as well as proprietary licenses. OpenChrom is available free of charge at http://www.openchrom.net. © 2010 Wenig and Odermatt; licensee BioMed Central Ltd.","","Article","Scopus"
"Verschelde J.; Yu X.","Verschelde, Jan (7004309758); Yu, Xiangcheng (56637340600)","7004309758; 56637340600","Polynomial homotopy continuation on GPUs","2015","ACM Communications in Computer Algebra","10.1145/2893803.2893810","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959292880&doi=10.1145%2f2893803.2893810&partnerID=40&md5=97f0e62f68c512000657601eb72422ac","The purpose of the software presentation is to announce a library to track many solution paths defined by a polynomial homotopy on a Graphics Processing Unit (GPU). Developed on NVIDIA graphics cards with CUDA SDKs, our code is released under the GNU GPL license. Via the C interface to PHCpack, we can call our GPU library from Python.","","Article","Scopus"
"Singh P.V.; Phelps C.","Singh, Param Vir (55463329200); Phelps, Corey (7103297490)","55463329200; 7103297490","Networks, social influence, and the choice among competing innovations: Insights from open source software licenses","2013","Information Systems Research","10.1287/isre.1120.0449","57","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885154253&doi=10.1287%2fisre.1120.0449&partnerID=40&md5=06d5d3a4d6efbe6b2488750f71150078","Existing research provides little insight into how social influence affects the adoption and diffusion of competing innovative artifacts and how the experiences of organizational members who have worked with particular innovations in their previous employers affect their current organizations' adoption decision. We adapt and extend the heterogeneous diffusion model from sociology and examine the conditions under which prior adopters of competing open source software (OSS) licenses socially influence how a new OSS project chooses among such licenses and how the experiences of the project manager of a new OSS project with particular licenses affects its susceptibility to this social influence. We test our predictions using a sample of 5,307 open source projects hosted at SourceForge. Our results suggest the most important factor determining a new project's license choice is the type of license chosen by existing projects that are socially closer to it in its interproject social network. Moreover, we find that prior adopters of a particular license are more infectious in their influence on the license choice of a new project as their size and performance rankings increase. We also find that managers of new projects who have been members of more successful prior OSS projects and who have greater depth and diversity of experience in the OSS community are less susceptible to social influence. Finally, we find a project manager is more likely to adopt a particular license type when his or her project occupies a similar social role as other projects that have adopted the same license. These results have implications for research on innovation adoption and diffusion, open source software licensing, and the governance of economic exchange. © 2013 Informs.","Innovation adoption and diffusion; Open source software license; Social influence; Social networks","Article","Scopus"
"De Laat P.B.","De Laat, Paul B. (6701483323)","6701483323","Copyright or copyleft? An analysis of property regimes for software development","2005","Research Policy","10.1016/j.respol.2005.07.003","95","https://www.scopus.com/inward/record.uri?eid=2-s2.0-28044452899&doi=10.1016%2fj.respol.2005.07.003&partnerID=40&md5=34c9ca62f0db4daf308d3ae10ad14161","Two property regimes for software development may be distinguished. Within corporations, on the one hand, a Private Regime obtains which excludes all outsiders from access to a firm's software assets. It is shown how the protective instruments of secrecy and both copyright and patent have been strengthened considerably during the last two decades. On the other, a Public Regime among hackers may be distinguished, initiated by individuals, organizations or firms, in which source code is freely exchanged. It is argued that copyright is put to novel use here: claiming their rights, authors write 'open source licenses' that allow public usage of the code, while at the same time regulating the inclusion of users. A 'regulated commons' is created. The analysis focuses successively on the most important open source licenses to emerge, the problem of possible incompatibility between them (especially as far as the dominant General Public License is concerned), and the fragmentation into several user communities that may result. © 2005 Elsevier B.V. All rights reserved.","Commons; Intellectual property rights; Licensing; Open source; Software","Article","Scopus"
"Kamp P.-H.","Kamp, Poul-Henning (36140167500)","36140167500","Quality software costs money - Heartbleed was free","2014","Communications of the ACM","10.1145/2631095","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905247064&doi=10.1145%2f2631095&partnerID=40&md5=0ee9451fd43469740712be336a59c47f","Poul-Henning Kamp, one of the primary developers of the FreeBSD operating system, discusses about the funding for Free and open source software (FOSS). One way to fund FOSS is simply to hire the FOSS maintainers, with the understanding they spend some amount of company time and resources on the project. Companies should add their support of FOSS to their lists of corporate social responsibilities, along with their sponsorships of local soccer teams and their funding of scholarships. Another way to fund FOSS is for software projects to set up foundations to collect money and hire developers. This is a relatively complex and expensive undertaking. The Varnish Moral License (VML) is not an ideal funding model in the sense that with a single exception, none of the big corporations that deliver massive amounts of HTTP traffic with Varnish has participated.","","Article","Scopus"
"Dong Q.; Luo G.; Haynor D.; O’Reilly M.; Linnau K.; Yaniv Z.; Jarvik J.G.; Cross N.","Dong, Qifei (57216841101); Luo, Gang (7401536289); Haynor, David (7005723263); O’Reilly, Michael (57189249126); Linnau, Ken (6701568709); Yaniv, Ziv (8555308800); Jarvik, Jeffrey G. (7006612269); Cross, Nathan (57194449345)","57216841101; 7401536289; 7005723263; 57189249126; 6701568709; 8555308800; 7006612269; 57194449345","DicomAnnotator: a Configurable Open-Source Software Program for Efficient DICOM Image Annotation","2020","Journal of Digital Imaging","10.1007/s10278-020-00370-w","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087886093&doi=10.1007%2fs10278-020-00370-w&partnerID=40&md5=33c5dd1f1f42da3bf5f4994057de5f4a","Modern, supervised machine learning approaches to medical image classification, image segmentation, and object detection usually require many annotated images. As manual annotation is usually labor-intensive and time-consuming, a well-designed software program can aid and expedite the annotation process. Ideally, this program should be configurable for various annotation tasks, enable efficient placement of several types of annotations on an image or a region of an image, attribute annotations to individual annotators, and be able to display Digital Imaging and Communications in Medicine (DICOM)-formatted images. No current open-source software program fulfills these requirements. To fill this gap, we developed DicomAnnotator, a configurable open-source software program for DICOM image annotation. This program fulfills the above requirements and provides user-friendly features to aid the annotation process. In this paper, we present the design and implementation of DicomAnnotator. Using spine image annotation as a test case, our evaluation showed that annotators with various backgrounds can use DicomAnnotator to annotate DICOM images efficiently. DicomAnnotator is freely available at https://github.com/UW-CLEAR-Center/DICOM-Annotator under the GPLv3 license. © 2020, Society for Imaging Informatics in Medicine.","DICOM; Image annotation; Machine learning; Open source; Software design","Article","Scopus"
"Baron J.; Willis J.; Lee R.-A.","Baron, Josh (36679780200); Willis, Jerry (57213060296); Lee, Reba-Anna (36680302900)","36679780200; 57213060296; 36680302900","Creating higher education academic and information technology resources in an international context","2010","Computers in the Schools","10.1080/07380569.2010.523885","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650287450&doi=10.1080%2f07380569.2010.523885&partnerID=40&md5=8e78b1ecda5e4c840e2467fd74d37f50","A number of contemporary factors have combined to create a situation that encourages and supports international collaboration among institutions of higher education. Factors such as the globalization of the economy, the increasingly international nature of higher education, and the development of an inexpensive and virtually worldwide system of communication, the Internet, have all played their part. This paper focuses on one aspect of international collaboration-the creation and dissemination of information resources and information/educational technologies, such as software. Movements such as Open Source and Open Access have encouraged colleges and universities to consider alternatives to the dominant model for acquiring everything from college textbooks to academic computing software. Today for-profit companies supply most such resources to institutions, faculty, and students. The open source software approach is an alternative based on collaboration between both institutions and individuals, and it is a viable alternative to commercial, for-profit development and dissemination systems. Today, open access journals, for example, compete with journals from commercial publishers and provide free access to anyone via the Internet. Resources such as the courseware management system, Moodle, and the multipurpose software package, Sakai, are examples of open source software-developed resources that are widely used today in higher education. The OpenCourseware initiative at Massachusetts Institute of Technology is an example of free and open dissemination of course resources. Variations of the open source software model support the creation of everything from infrastructure software such as Sakai to remixable textbooks. Remixing is, in fact, a major advantage of the approach Connexions, based at Rice University, has taken to create information resources for educational use. Open access, open source, and other similar approaches can be subsumed under the term open education. That movement is a viable, and rapidly growing, alternative for the creation and distribution of information and information technology resources for higher education that is particularly suited to collaborative, international partnerships. © Taylor & Francis Group, LLC.","Bologna Accords; Bologna Process; Collaboration; Colleges; Connexions; Crowd sourcing; Decoupling; Freeware; General Public License; Globalization; Higher education; International; Learning design lenses; Moodle; Open access; Open education; Open source; Open source software; OpenCourseware; Partnerships; Public domain; Remixable textbooks; Remixing; Sakai; Shareware; Universities","Article","Scopus"
"Thomas R.","Thomas, R. (57195326543)","57195326543","SEDOBS: A tool to create simulated galaxy observations","2020","Astronomy and Computing","10.1016/j.ascom.2019.100354","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076844081&doi=10.1016%2fj.ascom.2019.100354&partnerID=40&md5=c00b3346c03e4f3d4fcb97aa1626152f","SEDOBS is a python software designed to produce large samples of simulated galaxy observations. It allows for the creation of several types of mock observation such as photometry, spectroscopy, multi-spectroscopy and full spectro-photometric combinations. It has been primarily created to test galaxy template fitting method against any configuration of data. It has been designed to be user-friendly to manipulate. SEDOBS is an open source software and it is published under the GNU general public license (v3). It is distributed from a github repository with an extensive documentation and can be installed from the python official repository (pip). © 2019 Elsevier B.V.","Galaxy; Observations; Photometry; Simulation; Spectroscopy","Article","Scopus"
"Morentin A.; Fontes G.; Hillesheim M.M.; Meynard T.; Flumian D.; Bourdon J.; Piquet H.","Morentin, A. (57204976257); Fontes, G. (13105979900); Hillesheim, M. Mannes (57204976561); Meynard, T. (56228847500); Flumian, D. (44661245700); Bourdon, J. (56943141900); Piquet, H. (6602355201)","57204976257; 13105979900; 57204976561; 56228847500; 44661245700; 56943141900; 6602355201","OpenComp3d: An open-source framework dedicated to design in power electronics","2019","Mathematics and Computers in Simulation","10.1016/j.matcom.2018.11.006","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058227431&doi=10.1016%2fj.matcom.2018.11.006&partnerID=40&md5=fdeee5151b0534099a23d32a6aef2a2a","This paper is an overview of an innovative optimization framework developed for the design of power converters, which is available under MIT licence in a github repository (https://github.com/Laplace-cs/OpenComp3d). In the first part, the general principles, structure and standards are presented. In the second part, an example is performed to optimize the output inductor of a buck converter showing the advantages of the proposed methodology. © 2018 International Association for Mathematics and Computers in Simulation (IMACS)","Power electronics optimization; Software prototyping","Article","Scopus"
"Richardson C.N.; Sime N.; Wells G.N.","Richardson, Chris N. (57203088284); Sime, Nathan (57194940690); Wells, Garth N. (7202078742)","57203088284; 57194940690; 7202078742","Scalable computation of thermomechanical turbomachinery problems","2019","Finite Elements in Analysis and Design","10.1016/j.finel.2018.11.002","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057370701&doi=10.1016%2fj.finel.2018.11.002&partnerID=40&md5=905d3d129d214e4c809d08718d514f78","A commonly held view in the turbomachinery community is that finite element methods are not well-suited for very large-scale thermomechanical simulations. We seek to dispel this notion by presenting performance data for a collection of realistic, large-scale thermomechanical simulations. We describe the necessary technology to compute problems with O(107) to O(109) degrees-of-freedom, and emphasise what is required to achieve near linear computational complexity with good parallel scaling. Performance data is presented for turbomachinery components with up to 3.3 billion degrees-of-freedom. The software libraries used to perform the simulations are freely available under open source licenses. The performance demonstrated in this work opens up the possibility of system-level thermomechanical modelling, and lays the foundation for further research into high-performance formulations for even larger problems and for other physical processes, such as contact, that are important in turbomachinery analysis. © 2018 Elsevier B.V.","Finite element analysis; Multigrid; Parallel computing; Thermomechanical modelling; Turbomachinery","Article","Scopus"
"Hertz J.L.","Hertz, Joshua L. (8569518100)","8569518100","gruepr, a Software Tool for Optimally Partitioning Students onto Teams","2021","Computers in Education Journal","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139411893&partnerID=40&md5=7a451783a94e6ed5e46ec07fc078288d","Choosing how to split a group of students into teams for project work can be a time-intensive task for an instructor. An instructor might have a complex set of parameters to optimize, perhaps desiring each team to have a certain number of times throughout the week where they can meet, while also seeking to create teams that are homogeneous in some characteristics and heterogeneous in other characteristics. Demographic composition may also be considered, and perhaps the instructor has certain students that must be placed on the same team or must be placed on different teams. Maybe teams will be formed several times, and no student should have the same teammate twice. A few software tools can be found in the literature to assist an instructor with this task, but few of them seem to be easily and freely accessible. This paper describes a new software tool named gruepr, written in C++ by the author. The code has been released under an open source license, and both the code and compiled binaries with a modern, graphical user interface for Windows and macOS have been made freely available. An important design goal was that usage of the software would come at no cost to any instructor who wanted to use it, and accordingly the survey instrument used by gruepr to survey the students is the free Google Form platform. Other important design goals were that the software was easy to use and highly flexible to the instructor’s desired definition of what constitutes an optimal team. Within gruepr, an instructor can create a Google Form survey with a highly customizable set of questions. The Google Form is created in the instructor’s own Google Drive. After the students have submitted their survey responses, the instructor opens in gruepr the file of downloaded results and sets a flexible set of teaming options. Gruepr then uses a genetic optimization algorithm to partition the students onto teams. The code takes advantage of multi-threading parallelization and generally finds a reasonably optimal partitioning of students in a few minutes or less on a modern laptop computer. © 2021 American Society for Engineering Education. All rights reserved.","grouping; open source; student teams; teamwork","Article","Scopus"
"Spinellis D.","Spinellis, Diomidis (35566637400)","35566637400","Choosing and using open source components","2011","IEEE Software","10.1109/MS.2011.54","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955556457&doi=10.1109%2fMS.2011.54&partnerID=40&md5=4cbbbba47dc6ae2049701a4a661561cc","Choose open source components based on a few simple criteria associated with the software's legal status, its fitness, and its quality. BSD-style licenses are quite liberal, while GNU licenses make life difficult for proprietary offerings. Consider the project's technological fit, its popularity, the quality of its code and documentation, the frequency of new releases, the strength of its community, and the ease of pushing your changes upstream. You can reuse complete classes or files, use a complete library, or have your code communicate with a separately running process. Avoid modifying the open source code to fit your needs, but if you do keep changes to a minimum, keep them localized, have them follow the project's code style, and contribute them back to the project. © 2011 IEEE.","adoption; component choice; open source","Article","Scopus"
"Möller M.; Boutarfa L.; Strassemeyer J.","Möller, Markus (15762914300); Boutarfa, Lucas (57217147626); Strassemeyer, Jörn (18538526800)","15762914300; 57217147626; 18538526800","PhenoWin – An R Shiny application for visualization and extraction of phenological windows in Germany","2020","Computers and Electronics in Agriculture","10.1016/j.compag.2020.105534","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086437483&doi=10.1016%2fj.compag.2020.105534&partnerID=40&md5=0e4cf5a14a00b921cbb557de01ad6780","There is an increasing need for small scale information about the temporal shifting of the phenological crop development for applications like fertilization, irrigation, crop and soil protection, weather index insurance, yield prediction, crop classification or as bio-indicator of climate change. This application note introduces PhenoWin, a tool to extract and visualize phenological windows for any given year from 1993 onward and user-defined regions in Germany. Phenological windows represent successive start and end dates of development stages for different main crops, which have been interpolated using the phenological model PHASE. PhenoWin was implemented using R language and the R Shiny web framework. PhenoWin can be used as standalone application or can be embedded in web pages. Both, the used phenological data sets and the PhenoWin source code are available under open source license. © 2020 Elsevier B.V.","Germany; Phenology; R Shiny; Visualization","Article","Scopus"
"Guedj B.; Desikan B.S.","Guedj, Benjamin (23388770500); Desikan, Bhargav Srinivasa (57202579427)","23388770500; 57202579427","Pycobra: A python toolbox for ensemble learning and visualisation","2018","Journal of Machine Learning Research","","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048752028&partnerID=40&md5=0d6a96c63d4cf440910be9be73d89ba6","We introduce pycobra, a Python library devoted to ensemble learning (regression and classification) and visualisation. Its main assets are the implementation of several ensemble learning algorithms, a flexible and generic interface to compare and blend any existing machine learning algorithm available in Python libraries (as long as a predict method is given), and visualisation tools such as Voronoi tessellations. pycobra is fully scikit-learn compatible and is released under the MIT open-source license. pycobra can be downloaded from the Python Package Index (PyPi) and Machine Learning Open Source Software (MLOSS). The current version (along with Jupyter notebooks, extensive documentation, and continuous integration tests) is available at https://github.com/bhargavvader/pycobra and official documentation website is https://modal.Lille.inria.fr/pycobra. © 2018 Benjamin Guedj and Bhargav Srinivasa Desikan.","Ensemble methods; Machine learning; Open source software; Python; Voronoi tesselation","Article","Scopus"
"Koes D.R.; Camacho C.J.","Koes, David Ryan (6504625843); Camacho, Carlos J. (7006303658)","6504625843; 7006303658","Pharmer: Efficient and exact pharmacophore search","2011","Journal of Chemical Information and Modeling","10.1021/ci200097m","116","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959746008&doi=10.1021%2fci200097m&partnerID=40&md5=6e35257b3d5a450e086a72649fc36a5e","Pharmacophore search is a key component of many drug discovery efforts. Pharmer is a new computational approach to pharmacophore search that scales with the breadth and complexity of the query, not the size of the compound library being screened. Two novel methods for organizing pharmacophore data, the Pharmer KDB-tree and Bloom fingerprints, enable Pharmer to perform an exact pharmacophore search of almost two million structures in less than a minute. In general, Pharmer is more than an order of magnitude faster than existing technologies. The complete source code is available under an open-source license at http://pharmer.sourceforge.net. © 2011 American Chemical Society.","","Article","Scopus"
"Wang J.","Wang, Jing (55966738900)","55966738900","Survival factors for Free Open Source Software projects: A multi-stage perspective","2012","European Management Journal","10.1016/j.emj.2012.03.001","26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862756997&doi=10.1016%2fj.emj.2012.03.001&partnerID=40&md5=5df87fc127c67d8cdd2fa0427dbdd631","This paper uses a large data set of Free Open Source Software (FOSS) projects obtained from SourceForge.net to investigate survival factors at various stages of a FOSS project's lifecycle. It distinguishes FOSS projects that are still at the initial stage of development from those at the growth stage, and posits that the relative importance of the identified survival factors changes as FOSS projects evolve from one stage to the next. The results demonstrate the changing effect of factors over time affecting FOSS survival. Restrictive FOSS licenses and large internal and external networks are found to present advantages for projects that are at the initial stage, but the advantages dissipate as the projects move into the growth stage. Projects with high-quality external networks, greater levels of user/developer participation and service quality, and projects targeted at technical users have a higher likelihood of surviving at both stages. These findings show that a FOSS project team needs to be aware of the conditioning effect of time and focus on the appropriate mix of survival factors as the project moves from one stage to the next. © 2012 Elsevier Ltd.","Developer characteristics; Free Open Source Software; Social networks; Software characteristics; Survival","Article","Scopus"
"August T.; Shin H.; Tunca T.I.","August, Terrence (15055334000); Shin, Hyoduk (35574801000); Tunca, Tunay I. (12790312600)","15055334000; 35574801000; 12790312600","Generating value through open source: Software service market regulation and licensing policy","2018","Information Systems Research","10.1287/isre.2017.0726","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043999409&doi=10.1287%2fisre.2017.0726&partnerID=40&md5=d40b73fe2a9ca85f4dbad2bf2d677ff8","In the software industry, commercial open-source software vendors have recognized that providing services to help businesses derive greater value in the implementation of open source-based systems can be a profitable business model. Moreover, society may greatly benefit when software originators choose an open-source development strategy as their products become widely available, readily customizable, and open to community contributions. In this study, we present an economic model to study how software licensing attributes affect a software originator's decisions, aiming to provide policy makers with insights into how welfare-improving, open-source outcomes can be incentivized. We show that when a competing contributor is apt at reaping the benefits of software development investment, a less restrictive open source license (e.g., Berkeley Software Distribution, or BSD style) can improve welfare. On the other hand, when the originator is better at leveraging investment and service costs are high, a more restrictive license (e.g., General Public License, or GPL style) can be best for social welfare even when a contributor can cost-efficiently develop the software. © 2017 INFORMS.","Open-source software; Proprietary software; Services market; Software licensing","Article","Scopus"
"Eckert R.; Stuermer M.; Myrach T.","Eckert, Remo (57189509473); Stuermer, Matthias (23668920700); Myrach, Thomas (6508360630)","57189509473; 23668920700; 6508360630","Alone or Together? Inter-organizational affiliations of open source communities","2019","Journal of Systems and Software","10.1016/j.jss.2018.12.007","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058217527&doi=10.1016%2fj.jss.2018.12.007&partnerID=40&md5=2493ccb1189a4abc53a479240f2ca534","Many of today's open source software (OSS) communities operate beneath an umbrella organization, while others are organized entirely independently, and yet others follow a strategy somewhere in between, sharing certain resources and services. In our paper, we analyze four mature OSS communities (GENIVI, PolarSys, LibreOffice and PostgreSQL) representing different organizational forms. Our qualitative case studies illustrate that OSS communities preferring to control all of their resources are organized autonomously, while those focused mainly on software development are integrated into an umbrella organization. An interjacent strategy is pursued by OSS communities affiliated with an intermediary form of organization that takes care of legal and financial issues, without prescribing organizational structures or a specific license. The findings of our case studies show that there is no one-size-fits-all approach for OSS communities and each strategy has specific advantages and disadvantages. Arguing with the theoretical concepts of Resource Dependence Theory (RDT) and Transaction Cost Economics (TCE), we are able to relate the findings of our qualitative empirical study to theoretical concepts explaining different organizational behavior. Therefore, this study contributes new insights concerning the inter-organizational affiliations of OSS communities thus responding to the question why different forms of OSS community governance exist. © 2018 Elsevier Inc.","Collaborative software development; Open source software; OSS foundations; OSS governance","Article","Scopus"
"Lakka S.; Stamati T.; Michalakelis C.; Martakos D.","Lakka, Spyridoula (54383655400); Stamati, Teta (6506964629); Michalakelis, Christos (23501949400); Martakos, Dracoulis (6602811431)","54383655400; 6506964629; 23501949400; 6602811431","The ontology of the oSS business Model: An Exploratory Study","2011","International Journal of Open Source Software and Processes","10.4018/jossp.2011010103","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80054863714&doi=10.4018%2fjossp.2011010103&partnerID=40&md5=9cd336d0577287ddf69363f000af1edd","This study focuses on theory building providing a holistic conceptual framework that consists of an ontology based OSS business model and an OSS business model taxonomy. The study extends existing theory in OSS business models and corresponding taxonomies, based on the structured-case methodological approach. An exploratory study is conducted in two research cycles, for the identification, validation, and evaluation of the critical constructs of an OSS business model. Results reveal that OSS business models differ from traditional software business models, having specific features that affect the software value chain, the infrastructure, and the revenue model of an OSS oriented firm. Copyright © 2011, IGI Global.","Business model; Business model taxonomy; Information systems; Interpretive approach; Open source software; Structured-case method","Article","Scopus"
"Sharma P.; Nagarajan M.; Mohanakrishnan P.; Swaminathan P.I.","Sharma, Paawan (57191431244); Nagarajan, Murali (24765343000); Mohanakrishnan, Prabhakaran (7004863103); Swaminathan, Pichai Iyer (56603685600)","57191431244; 24765343000; 7004863103; 56603685600","Signal processing analysis of temperature fluctuations for a fuel subassembly using Scilab","2012","International Journal of Modelling and Simulation","10.2316/Journal.205.2012.3.205-5647","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863899697&doi=10.2316%2fJournal.205.2012.3.205-5647&partnerID=40&md5=eb4239d5d59c3cbdc9d939c667996652","This paper investigates the simulation study of signal processing of temperature fluctuations and their use in determining malfunctions in coolant fluid flow in a fuel subassembly, By the use of SCILAB software. SCILAB is free open source software with a GNU general public license (GPL) compatible license. Its main features includes a arge number of mathematical functions, high level programming language, 2-D and 3-D graphics, advanced data structures and user defined data types. With respect to our purpose, this tool acts as an excellent setup for performing data analysis, signal processing and statistics. The variation of RMS fluctuation for different value of time with temperature increase has been investigated for aiding in program development for FPGA for use in real time monitoring.","RMS value; SCILAB; Subassembly blockage; Temperature fluctuations","Article","Scopus"
"Chen S.","Chen, Shuo (35753166700)","35753166700","Open standards and license choice in open source software","2016","Journal of Management Information and Decision Sciences","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017176697&partnerID=40&md5=3bdf144560613fe52001f241d05c5219","Open standards are important in markets for Internet technology to ensure interoperability of software components across the Internet. Many applications of the Internet technology experience network effects.Owners of open source software may benefit from network effects and influence future standards development through their license choice. This study analyzes the data of 118 open source software projects that develop Internet technology to explore the relationship between open standards and the license choice made by software owners. It tests the hypothesis of standardization and the hypothesis of commercialization. Results of the statistical analysis show that programmers devote more efforts to Internet projects using nonrestrictive licenses due to the importance of network effects and standards development in Internet technology. Further investigation of a larger sample of all open source software projects shows that projects with the topic of Internet are more likely to choose nonrestrictive licenses than the restrictive ones, especially when the intended audience is developer or system administrator. The results lend support to the theory of network effects and the standardization hypothesis.","","Article","Scopus"
"Qiu S.; German D.M.; Inoue K.","Qiu, Shi (57205073835); German, Daniel M. (57207886015); Inoue, Katsuro (7601540520)","57205073835; 57207886015; 7601540520","Empirical study on dependency-related license violation in the javascript package ecosystem","2021","Journal of Information Processing","10.2197/IPSJJIP.29.296","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105405578&doi=10.2197%2fIPSJJIP.29.296&partnerID=40&md5=d6fb9a7354234798eeddfd85ab11f48a","Open source software (OSS) is software whose source code can be reused under some particular terms and conditions. These terms and conditions are usually described by one or more software licenses written in the header part of the source files. A license may violate another one according to the terms and conditions. Making software by reusing OSS as dependency may cause dependency-related license violation if the developers overlook the license of the dependency. In this paper, we first conduct an empirical study on npm-a JavaScript-based software ecosystem-to study the prevalence of dependency-related license violation. The result suggests that only a few packages (0.644%) in npm have dependency-related license violations. However, we also observe that including the packages licensed under copyleft licenses in the dependency network potentially causes a high dependency-related license violation. We then conduct a preliminary questionnaire on the authors of packages detected as having dependency-related license violations to study the developers’ attitudes. The results reveal: 1) the developers’ overlooking and misunderstanding of the dependency-related license violations; 2) the difficulties in managing dependency-related license violations and the developers’ demands for help. © 2021 Information Processing Society of Japan.","License violation; Open source software; OSS ecosystem; Software license; Software maintenance","Article","Scopus"
"Hohmann L.; Olson M.","Hohmann, Luke (6602128541); Olson, Michael (36841979100)","6602128541; 36841979100","Making Open Source Make Money","2003","Cutter IT Journal","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0347762481&partnerID=40&md5=d311b6a99efcb6c64b356fd8dab93053","Various aspects of successful business and license models for open source work are discussed. The Sleepycat software which used an innovative approach to open source and created a sustainable, profitable company is studied. It is observed that the Sleepycat provides their software for no charge provided, provided one make the complete source code for application freely available at no charge. The influence of market maturity on business models is also elaborated.","","Article","Scopus"
"Deodhar S.J.; Saxena K.B.C.; Gupta R.K.; Ruohonen M.","Deodhar, Swanand J. (36460766700); Saxena, K.B.C. (35070255400); Gupta, Rajen K. (55241271700); Ruohonen, Mikko (6505948028)","36460766700; 35070255400; 55241271700; 6505948028","Strategies for software-based hybrid business models","2012","Journal of Strategic Information Systems","10.1016/j.jsis.2012.06.001","34","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870345949&doi=10.1016%2fj.jsis.2012.06.001&partnerID=40&md5=bcb663568c3d6e3a558a6f430e5afce9","The open source approach to software development has been used by software organizations in tandem with their existing business models, which are based on proprietary software licensing. This led to the creation of hybrid business models that merge open source and proprietary paradigms. This paper explores the practices used by software product vendors using hybrid business models and proposes strategies emerging out of these practices using interpretive, single case study research design. © 2012 Elsevier B.V. All rights reserved.","Case study research; Open source software; Software business model; Software strategies","Article","Scopus"
"Kapitsaki G.M.; Charalambous G.","Kapitsaki, Georgia M. (24801845800); Charalambous, Georgia (57215349159)","24801845800; 57215349159","Modeling and Recommending Open Source Licenses with findOSSLicense","2021","IEEE Transactions on Software Engineering","10.1109/TSE.2019.2909021","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106016994&doi=10.1109%2fTSE.2019.2909021&partnerID=40&md5=41d40b7a77e846744001d9d569b2bb67","Open source software is widely used in the software industry and the academia. Licenses applied to open source software provide the terms for its further use and distribution. Decisions regarding licensing for new software systems are essential for the system's future use. In this paper, we introduce findOSSLicense, a license recommender that guides users into choosing the appropriate open source license for their software under creation. We also introduce our license modeling concept that is used in the recommendation process. The license modeling captures the properties usually found in existing open source licenses following an analysis performed on license texts. The recommendation process of findOSSLicense is based on a hybrid recommender that uses constraint-based, content-based and collaborative filtering giving also space for flexibility in the use of the system by its end-users who can adapt some system properties. User input, but also external sources of information including existing open source projects, are considered for the creation of the recommendations, whereas licenses used in third party software employed in the software are examined on a limited basis. findOSSLicense has been evaluated with the participation of users of various expertise.  © 1976-2012 IEEE.","Open source software; recommender systems; software reusability; software tools","Article","Scopus"
"Rubenstein R.O.Y.","Rubenstein, R.O.Y. (16203878100)","16203878100","Open season","2009","Total Telecom","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-67949120250&partnerID=40&md5=2a157678048c9be99f46811943aa6ab8","Developers and mobile manufacturers are turning to open source mobile for software development to aid innovation and ensure that operators can deliver new services rapidly and cost-effectively. The LiMo Foundation, founded in January 2007 and backed by operators and handset makers such as NTT DoCoMo, Vodafone and Samsung, is using open source to develop a Linux-based operating system. Open source will also benefit the industry by reducing the number of operating systems. The three operating system initiatives used by Vodafone all meet the open source definition in making available their source code for free to members. LiMo has a public licence that grants members access to the source code and permission to modify it. A challenge for the handset makers is ensuring that the collaborative software is not taken down different paths by the members such that compatibility is lost and the software fragments.","","Article","Scopus"
"Kuehnel A.-K.","Kuehnel, Anne-Kathrin (57208997529)","57208997529","Microsoft, open source and the software ecosystem: Of predators and prey—the leopard can change its spots","2008","Information and Communications Technology Law","10.1080/13600830802204229","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650412909&doi=10.1080%2f13600830802204229&partnerID=40&md5=d1169ece34939242f658dc1b43e75753","Over the past few years, Microsoft has promoted a project called ‘Shared Source Initiative’, which allows certain customers (e.g., research institutions and independent software vendors) access to its source code on a restricted basis. As part of this initiative, Microsoft introduced some licences that appear to give unrestricted access to source code and closely resemble ‘traditional’ Open Source licences. In July 2007, two of these ‘shared source’ licenses (the Microsoft Community Licence and the Microsoft Permissive Licence) were submitted to the Open Source Initiative (OSI) and subsequently approved by the OSI as certified Open Source licences. Thus Microsoft's Shared Source Initiative and its partial embrace of Open Source appear to be a significant step towards closing the ideological rift between developers of proprietary software and the Free/Open Source software movement, and more than just another attempt to appease consumers and/or critics in terms of software transparency. By analysing the ‘evolution’ of Microsoft's Shared Source licences, this article aims to shed some light on the question what is needed for a ‘predator’ (i.e., proprietary, software developer) such as Microsoft to become ‘prey’ (i.e., be part of the Open Source community). This article concludes that, although Microsoft's efforts are to be lauded, it is highly unlikely that the company will embrace fully the Open Source philosophy in the near future. © 2008, Taylor & Francis Group, LLC.","Microsoft Shared Sources licences; Open Source licences; Open Source software; software ecosystem","Article","Scopus"
"Sullivan J.L.","Sullivan, John L. (55451461900)","55451461900","Free, open source software advocacy as a social justice movement: The expansion of f/oss movement discourse in the 21st century","2011","Journal of Information Technology and Politics","10.1080/19331681.2011.592080","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860412161&doi=10.1080%2f19331681.2011.592080&partnerID=40&md5=aaa39a280928fa39d1312d4fddd7ad5e","This article argues that the rhetorical discourse found among free, open source software (F/OSS) movements is being expanded beyond the traditional constituency of software hackers to encompass a larger group of non-expert users and other advocacy organizations. In so doing, the initial goals of free software advocates are being dramatically expanded to include broader aims of digital freedom and social justice. Utilizing the concept of social movements from political sociology, this article first outlines the key aims and discourses surrounding the free software movement by discussing the emergence and development of F/OSS efforts such as the GNU/Linux operating system and the GNU Public License (GPL). Second, I provide examples of how the free software discourses have been adopted, altered, and expanded by a number of organized groups over the past decade. These groups, such as the Creative Commons, digital privacy advocates, and global development agencies, have adopted some of the core concepts of free software, while greatly expanding their meaning and purpose to suit their own advocacy aims. Finally, I argue that the adoption of free software discourse among these newer groups is also having a recursive effect upon the free software movement by encouraging free software advocates to conceptualize F/OSS as part of a broader movement of digital rights and social justice. In the conclusion, the prospects for the emergence of a larger technological and cultural freedom movement in the future are assessed. © Taylor & Francis Group, LLC.","Creative Commons; Digital rights; Free software; Linux; Social justice; Social movement","Article","Scopus"
"Freeman E.H.","Freeman, Edward H. (37107418100)","37107418100","Open source software and the sco litigation","2006","Information Systems Security","10.1201/1086.1065898X/46183.15.3.20060701/94182.2","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023795089&doi=10.1201%2f1086.1065898X%2f46183.15.3.20060701%2f94182.2&partnerID=40&md5=d38ccaa686b8c181d9323f42e0b6d8b9","In 1980, Congress amended the federal copyright statutes to cover computer programs. The courts interpreted these statutes to protect the creator of software from copying, as well as translating into another programming language. Translations into foreign languages (i.e., French or Spanish) are also prohibited. Commercial software developers use licenses and the threat of legal action to protect their investment against unauthorized copying. © 2006 Taylor & Francis.","","Article","Scopus"
"Goth G.","Goth, Greg (55203290800)","55203290800","Open source business models: Ready for prime time","2005","IEEE Software","10.1109/MS.2005.157","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-28244477344&doi=10.1109%2fMS.2005.157&partnerID=40&md5=80d7ecd34323d8d71c0a1520cfef4a65","For five years, the open source ecosystem has matured into a shoulder-to-shoulder companion for commercial proprietary software. A new tapestry of community resources, venture capitals, and informal networks of open source veterans championing new applications is being woven through industries and academia. One illustration of the market's acceptance of open source as business-ready is the success of SpikeSource. In addition, the healthcare industry is also seeing the first inklings of industry-specific savings and innovation through open code. With this new era of opportunity, a concomitant amount of competition between startups and old-line vendors, between license types, and even between open source and proprietary applications under the same corporate umbrella is very evident.","","Article","Scopus"
"Hemphill T.A.","Hemphill, Thomas A. (7004192032)","7004192032","Government technology acquisition policy: The case of proprietary versus open source software","2005","Bulletin of Science, Technology and Society","10.1177/0270467605282245","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-28844462335&doi=10.1177%2f0270467605282245&partnerID=40&md5=3bce5a0bcc4be97483dfc29f19784d85","This article begins by explaining the concepts of proprietary and open source software technology, which are now competing in the marketplace. A review of recent individual and cooperative technology development and public policy advocacy efforts, by both proponents of open source software and advocates of proprietary software, subsequently follows, with supporting positions articulated. This is followed by an analysis of the results of a recent draft of a Center for Strategic & International Studies global study of government initiatives to incorporate open source software as an option in their institutional operations. The article concludes with analysis and recommendations on public policies for appropriate software technology assessment policy. For governments, the encouragement of neutral standards (i.e., not favoring one software business model), open competition for research funding of software development, and nondiscrimination in computer software procurement policies will result in the most effective and efficient procurement decisions. Copyright © 2005 Sage Publications.","Free software; General public license; Government policies; Intellectual property; Linux","Article","Scopus"
"Brosgol B.M.","Brosgol, Benjamin M. (6602641192)","6602641192","How to succeed in the software business while giving away the source code: The adacore experience","2019","IEEE Software","10.1109/MS.2019.2934044","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070667251&doi=10.1109%2fMS.2019.2934044&partnerID=40&md5=a1e1878ec5c007802ca7f2f7a414ae2f","Open source software or, more accurately, freely licensed open source software (FLOSS) at first appears to present a dilemma when adopted as part of a business model. If users are allowed to access, modify, and/or redistribute the source code, how does a company protect its intellectual property and, more fundamentally, sell something that can be easily and legally reproduced. © 1984-2012 IEEE.","","Article","Scopus"
"Kang Y.; Son S.R.","Kang, Youngok (57202115485); Son, SeRin (57202118952)","57202115485; 57202118952","An analysis of open source GIS software business models and case studies","2016","Spatial Information Research","10.1007/s41324-016-0070-6","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091980620&doi=10.1007%2fs41324-016-0070-6&partnerID=40&md5=12c94000bacce45ddd88cf3c6087cfd4","In this paper, we try to draw implications by analyzing both the prospective business models and case studies of advanced oversea enterprises which are performing a successful business in the field of open source GIS software. First, we can classify the business models of open source software into 12 types including service support, consulting, dual licensing, etc. According to our analysis, the service and support business model takes the highest percentage in the business of open source GIS software, and consulting does the second highest, and then dual licensing in the order. Second, we selected and analyzed two companies such as “Boundless” and “Azavea” that are performing the business most successfully in the field of open source GIS software. By analyzing these two companies, we obtained some common grounds and implications as follows: first, proactive activities in the community of open source software are needed to make the business model successful. Second, the companies that are relatively weak in technology capability have a tendency of creating revenue by developing and selling the solution-based products. Third, the companies that have high level of technology capability can generate revenue by developing and selling various kinds of products by adding the company owned technology to the enterprise software which has developed in the open source project. Fourth, successful companies have a business strategy which provide the necessary solutions through a collaboration with the companies that have a specific technology or a key solution. © 2016, Korean Spatial Information Society.","Business model; Case study; Open source GIS software; Open source software","Article","Scopus"
"Sen R.; Singh S.S.; Borle S.","Sen, Ravi (9737868800); Singh, Siddhartha S. (7407872847); Borle, Sharad (6507209416)","9737868800; 7407872847; 6507209416","Open source software success: Measures and analysis","2012","Decision Support Systems","10.1016/j.dss.2011.09.003","56","https://www.scopus.com/inward/record.uri?eid=2-s2.0-82255179349&doi=10.1016%2fj.dss.2011.09.003&partnerID=40&md5=906d13e72f8211e71ed21039ce67f565","Despite a growing body of research on OSS production, much remains to be learned. One important issue concerns the measures of OSS project success and its determinants. In this paper, we empirically study the determinants of OSS success as measured by the number of subscribers and developers working on an OSS project. Furthermore, we demonstrate that our model forecasts these success measures more accurately as compared to a naive model. We find that OSS projects that develop software to work on Windows/UNIX/Linux operating systems, and developed using C or its derivative languages experience larger increase in subscribers and attract more developers than projects that do not have these characteristics. OSS projects with semi-restrictive licenses have fewer subscribers and attract fewer developers. Interestingly, OSS projects that accept financial donations and are targeted at IS/IT professionals have more subscribers than others, although these characteristics do not affect the developer base. The number of subscribers and developers increases with the age of the OSS project. Finally, the impact of developers on subscribers and subscribers on developers is positive and significant. © 2011 Elsevier B.V. All rights reserved.","FLOSS (free/libre/open source software); Longitudinal study; OSS (open source software); Software project success; Subscriber base","Article","Scopus"
"Cervera E.","Cervera, Enric (35606198600)","35606198600","GPU-accelerated vision for robots: Improving system throughput using OpenCV and CUDA","2020","IEEE Robotics and Automation Magazine","10.1109/MRA.2020.2977601","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083435403&doi=10.1109%2fMRA.2020.2977601&partnerID=40&md5=442bd8c235e3afc51eb79b241f724357","OpenCV is an open source computer vision and machine learning library for C/C++/Python available for Windows, Linux, macOS, and Android platforms. It contains low-level image processing functions as well as high-level algorithms such as object identification, face recognition, and action classification in videos. OpenCV has become very popular, with more than 47,000 people in its user community and 18 million downloads (see https://opencv.org/about/). Under a Berkeley Software Distribution (BSD) license, it can be used for both academic and commercial applications. © 1994-2011 IEEE.","","Article","Scopus"
"Fosfuri A.; Giarratana M.S.; Luzzi A.","Fosfuri, Andrea (56122169000); Giarratana, Marco S. (6701572896); Luzzi, Alessandra (21740998300)","56122169000; 6701572896; 21740998300","The penguin has entered the building: The commercialization of open source software products","2008","Organization Science","10.1287/orsc.1070.0321","123","https://www.scopus.com/inward/record.uri?eid=2-s2.0-60449100100&doi=10.1287%2forsc.1070.0321&partnerID=40&md5=45e17822d06a13c4e36316ca9ccff814","Previous literature on open source software (OSS) mostly analyzes organizational issues within communities of developers and users. This paper focuses on for-profit organizations that release software products under OSS licenses, and argues that variations in their endowments of intellectual property rights, namely patents and trademarks, help to determine which firms will tend to incorporate OSS into commercial products. We explain whether and under what conditions preexisting stocks of intellectual property rights can be useful complementary assets that allow firms to benefit directly or indirectly from commercializing OSS products, and test our hypotheses on a novel data set built on firms' announcements of OSS product releases in the specialized press between 1995 and 2003. We find three robust results: (a) firms with large stocks of software patents are more likely to release OSS products; (b) firms with large stocks of software trademarks are less likely to release OSS products; (c) firms with large stocks of hardware trademarks are more likely to release OSS products. © 2008 INFORMS.","Complementary assets; Open source software; Patents and trademarks; Product introductions","Article","Scopus"
"Glance D.G.; Kerr J.; Reid A.","Glance, David G. (36709716800); Kerr, Jeremy (55560435800); Reid, Alex (55560953200)","36709716800; 55560435800; 55560953200","Factors affecting the use of open source software in tertiary education institutions","2004","First Monday","10.5210/fm.v9i2.1121","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-32144447835&doi=10.5210%2ffm.v9i2.1121&partnerID=40&md5=61e96c043cae676ba31a32957ba0c3dd","Open Source Software (OSS) is software that has been released under a license which requires the distribution of the software's source code with any binaries. It is often available at no cost and is mostly supported by developers providing their services for free. Considerable interest has been shown in OSS by tertiary education institutions (TEIs) because of the promise of a reduced total cost of ownership of the software, potentially better support, freedom from vendor lock-in, ability to tailor the software and pedagogic benefits of being able to view the source code. To find out the extent of use of OSS by TEIs in Australia, New Zealand and the United Kingdom, a survey was sent out to technical personnel at all TEIs in these countries. The results of the survey show that OSS is already being used by all TEIs who responded to the survey and that the major reasons for this was lower Total Cost of Ownership and freedom from software vendor dependence. It is clear however that the majority of the OSS software being used is in server infrastructure with a lesser amount being used on normal desktop machines. © 2004, First Monday.","","Article","Scopus"
"Bicudo E.; Faulkner A.; Li P.","Bicudo, Edison (37076696700); Faulkner, Alex (7101950225); Li, Phoebe (57195152612)","37076696700; 7101950225; 57195152612","Software, risks, and liabilities: ongoing and emergent issues in 3D bioprinting","2021","Journal of Risk Research","10.1080/13669877.2020.1848904","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097399983&doi=10.1080%2f13669877.2020.1848904&partnerID=40&md5=a2b061548509a5e0df03338cdfbaed15","The growing use of software in biomedicine has enlarged the capacities of researchers and clinicians. This, one might expect, would enhance the precision and safety of biomedicine. However, it has been recognized that software can bring about new risks to the field of medicine and medical devices, requiring at least some degree of caution from the different players responsible for technology governance and risk management. This phenomenon is focused on in this paper, from the viewpoint of 3D bioprinting. Bioprinting is the production of bioactive structures in a layer-by-layer deposition of cells, with the use of devices called bioprinters. The latter can only function by receiving instructions from software. This paper focuses on some software-supported techniques that are key for bioprinting. It shows that a growing range of software packages has been used in bioprinting, a trend that is greatly fostered by open source software. In this evolution, the clinical potentialities of bioprinting come closer to their realization. At the same time, however, uncertainties emerge, related to issues such as data protection, use of biological samples, and others. The growing use of open source software complexifies the scenario, because it leads to a multiplication of actors directly or indirectly involved in the technology’s development, making it difficult to trace liabilities and damages. As no national regulation has been produced to tackle such uncertainties, they have been (provisionally and precariously) addressed in the licenses of software packages. In the years to come, as clinical products eventually spring from bioprinting research, more robust governance schemes will have to emerge in which risks and liabilities are dealt with more carefully by different players. Moreover, regulations will have to address the practice of combining different software packages in the same bioprinting process, as well as the growing globalization of bioprinting research and commercial exploration. © 2020 Informa UK Limited, trading as Taylor & Francis Group.","Bioprinting; liabilities; risks; software; software licenses; technology governance","Article","Scopus"
"Hemphill T.A.","Hemphill, Thomas A. (7004192032)","7004192032","A taxonomy of closed and open source software industry business models","2006","International Journal of Innovation and Technology Management","10.1142/S0219877006000661","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-74049123316&doi=10.1142%2fS0219877006000661&partnerID=40&md5=1648af7038f770070a8409476f0b3140","This paper explores the closed source/open source software model dialectic and presents a conceptual framework of an emerging both source software business model useful for formulating firm technology strategy. The author reviews the academic literature and popular business press, extracting definitions and concepts underlying these software models; explains the concept of a business model and makes the case for the knowledge-based view of the firm as the approach to software industry business model development; describes, in detail, the proprietary, open source and both source software models; identifies the primary motivations behind the managerial development and adoption of the both source business software model (cost containment) and the implementation challenges firm's face (an upsurge in copyright and patent infringement suits concerning adoption of open source code); and concludes with a series of research questions pertaining to the economic viability of open source license business models, the effectiveness of indemnification strategies against copyright and patent infringement, and the managerial motivations behind choosing patent over copyright protection of software inventions. © World Scientific Publishing Company.","Business model; Closed source; Open source","Article","Scopus"
"Ghosh R.A.","Ghosh, Rishab Aiyer (25030115500)","25030115500","Licence fees and gdp per capita: The case for open source in developing countries","2007","First Monday","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891705539&partnerID=40&md5=28edd544844bc972e1408b1e4f537b96","There is a strong case for free software (also known as open source or libre software) being deployed widely in developing countries. This paper describes three reasons in particular: free software is a skills enabling platform; it is far cheaper; and it is more adaptable to local needs. The free software development community provides an environment of intensive interactive skills development at little explicit cost, which is particularly useful for local development of skills, especially in economically disadvantaged regions. Meanwhile, the controversy over total costs of ownership (TCO) of free vs. proprietary software is not applicable to developing countries and other regions with low labour costs, where the TCO advantage lies with free software, and the share of licence fees in TCO is much higher than in (richer) high labour cost countries. The note concludes with a table comparing license fees for proprietary software against GDP per capita for 176 countries ©2003, Rishab Aiyer Ghosh.","","Article","Scopus"
"Scanlon T.P.","Scanlon, Thomas P. (57211512643)","57211512643","Critical Factors for Open Source Advancement in the U.S. Department of Defense","2019","IEEE Software","10.1109/MS.2019.2933769","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070710258&doi=10.1109%2fMS.2019.2933769&partnerID=40&md5=f1b4aa8f930ebb5677af202d7711b88f","Leveraging open source components in Department of Defense (DoD) software systems remains challenging and is often met with resistance. This article describes several factors that will increase the likelihood of successfully deploying open source in DoD projects. © 2019 IEEE.","","Article","Scopus"
"Higashi Y.; Ohira M.; Kashiwa Y.; Manabe Y.","Higashi, Yunosuke (57189488361); Ohira, Masao (16023175500); Kashiwa, Yutaro (56685200200); Manabe, Yuki (36661027300)","57189488361; 16023175500; 56685200200; 36661027300","Hierarchical clustering of OSS license statements toward automatic generation of license rules","2019","Journal of Information Processing","10.2197/ipsjjip.27.42","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062322792&doi=10.2197%2fipsjjip.27.42&partnerID=40&md5=6994c47c164901174fdc620e94d9bafa","Reusing open source software (OSS) components for one’s own software products has become common in the modern software development. Automated license identification tools have been proposed to help developers identify OSS licenses, since a large number of licenses sometimes must be checked before attempting to reuse. Of the existing tools, Ninka [1] can most correctly identify licenses of each source file by using regular expressions. In case Ninka does not have license identification rules for unknown licenses, Ninka reports these as “unknown licenses” which must be checked by developers manually. Since completely-new or derived OSS licenses appear nearly every year, a license identification tool should be appropriately maintained by adding regular expressions corresponding to the new licenses. The final goal of our study is to construct a method to automatically create candidate license rules to be added to a license identification tool such as Ninka. Toward achieving the goal, files identified as unknown licenses must be classified by license firstly. In this paper, we propose a hierarchical clustering which divides unknown licenses into clusters of files with a single license. We conduct a case study to confirm the usefulness of our clustering method when it is applied for classifying 2,801, 1,230 and 2,446 unknown license statement files for Linux Kernel v4.4.6, FreeBSD v10.3.0 and Debian v7.8.0 respectively. As a result, it is confirmed that our method can create clusters which are suitable as candidates for generating license rules automatically. © 2019 Information Processing Society of Japan.","Clustering; License generation rules; License identification; OSS license","Article","Scopus"
"Kapitsaki G.M.; Tselikas N.D.; Kyriakou K.-I.D.; Papoutsoglou M.","Kapitsaki, Georgia M. (24801845800); Tselikas, Nikolaos D. (6506637365); Kyriakou, Kyriakos-Ioannis D. (55839941700); Papoutsoglou, Maria (57128423800)","24801845800; 6506637365; 55839941700; 57128423800","Help me with this: A categorization of open source software problems","2022","Information and Software Technology","10.1016/j.infsof.2022.107034","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135904165&doi=10.1016%2fj.infsof.2022.107034&partnerID=40&md5=3170cbda783c04eee3e6131155efdb50","Context: Free and Open Source Software is widely used in the research community and the software industry. In this context, developers come across various issues they need to handle in order to use and create software responsibly and without causing legal violations. For instance, using open source software that carries a specific license or how contributions to open source software should be handled are among the issues that need to be considered. Objective: As practitioners turn primarily to Q&A sites to seek help, it is important to understand which specific open source software issues they face. In this research, our main objective is to provide a categorization of open source software problems present in the user questions of the Open Source Stack Exchange site and perform a meta-analysis on the encountered questions. Method: We have performed a qualitative study analyzing manually 1,500 most popular posts in the Open Source Stack Exchange site and have mapped them to categories and more generic clusters. The coding task was performed in iterations with the participation of three of the authors. Agreement was calculated and cases of disagreement were resolved. Meta-analysis on questions and answers was also performed for discussion purposes. Results: We have created 26 categories of problems discussed in the Open Source Stack Exchange site, and grouped them into 6 clusters. Our results show that posts on license texts/conditions and license/copyright notices are more common, whereas posts on license differences are the most popular in terms of views by other users. Conclusion: The results can assist any participant of the open source software community to understand on which basic issues she should focus on to gain a good understanding of open source software. They are also useful for improving education on open source software and community support using the implications presented for each category. © 2022 Elsevier B.V.","Free and Open Source Software; Q&A sites; Stack Exchange","Article","Scopus"
"Scacchi W.; Alspaugh T.A.","Scacchi, Walt (7004343180); Alspaugh, Thomas A. (36892797100)","7004343180; 36892797100","Understanding the role of licenses and evolution in open architecture software ecosystems","2012","Journal of Systems and Software","10.1016/j.jss.2012.03.033","39","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861097522&doi=10.1016%2fj.jss.2012.03.033&partnerID=40&md5=25854498ca2611d7720c8f68d111bb28","The role of software ecosystems in the development and evolution of open architecture systems whose components are subject to different licenses has received insufficient consideration. Such systems are composed of components potentially under two or more licenses, open source or proprietary or both, in an architecture in which evolution can occur by evolving existing components, replacing them, or refactoring. The software licenses of the components both facilitate and constrain the system's ecosystem and its evolution, and the licenses' rights and obligations are crucial in producing an acceptable system. Consequently, software component licenses and the architectural composition of a system help to better define the software ecosystem niche in which a given system lies. Understanding and describing software ecosystem niches for open architecture systems is a key contribution of this work. An example open architecture software system that articulates different niches is employed to this end. We examine how the architecture and software component licenses of a composed system at design time, build time, and run time help determine the system's software ecosystem niche and provide insight and guidance for identifying and selecting potential evolutionary paths of system, architecture, and niches. © 2012 Elsevier Inc. All rights reserved.","Open source software; Software architecture; Software ecosystems; Software evolution; Software licenses","Article","Scopus"
"Kierkegaard P.; Adrian A.","Kierkegaard, Patrick (36910697000); Adrian, Angela (21739415500)","36910697000; 21739415500","Wikitopia: Balancing intellectual property rights within open source research databases","2010","Computer Law and Security Review","10.1016/j.clsr.2010.07.008","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77957950512&doi=10.1016%2fj.clsr.2010.07.008&partnerID=40&md5=f7a9962401712b81cb67f042ab36078a","Wiki ""communities"" based on the open access ideology allow any visitor to easily add, remove or edit content. However, there are a slew of ethics and policy challenges inherent in their use. Open source software developers are faced with the dilemma of openly sharing their intellectual property and prevent others from claiming proprietary rights from the code they freely shared to the public? Intellectual Property rights licensing, ironically, is the route by which open software developers have chosen to regulate their free code in cyberspace. Open source code is generally free on the surface; but in reality, it comes with obligations which are enforceable by law. Aside from the potential liability for intellectual property infringement, the use of open software raises competition law and tort liability issues. The European Union has developed the European Public License which is written in conformity with the copyright, product liability and consumer protection laws of the 27 member states. The EU Commission has also proposed a new Directive which will extend the principles of consumer protection rules to cover licensing agreements of products like software. This paper will address the various legal issues that may arise in open source community sharing. © 2010 Patrick Van Eecke & Maarten Truyens. Published by Elsevier Ltd. All rights reserved.","CopyLeft; GNU; Intellectual property rights; Open source; Research databases; Wikitopia","Article","Scopus"
"Liu Y.; Noei E.; Lyons K.","Liu, Yuyang (57225001435); Noei, Ehsan (57188964966); Lyons, Kelly (35307281500)","57225001435; 57188964966; 35307281500","How README files are structured in open source Java projects","2022","Information and Software Technology","10.1016/j.infsof.2022.106924","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130278651&doi=10.1016%2fj.infsof.2022.106924&partnerID=40&md5=0ebe40c8030319388eb7acf83f50abba","Context: Recent studies on open source platforms, such as GitHub, provide insights into how developers engage with software artifacts such as README files. Since README files are usually the first item users interact with in a repository, it is important that README files provide users with the information needed to engage with the corresponding repository. Objective: We investigate and compare README files of open source Java projects on GitHub in order to (i) determine the degree to which README files are aligned with the official guidelines, (ii) identify the common patterns in the structure of README files, and (iii) characterize the relationship between README file structure and popularity of associated repositories. Method: We apply statistical analyzes and clustering methods on 14,901 Java repositories to identify structural patterns of README files and the relationship of README file structure to repository stars. Results: While the majority of README files do not align with the GitHub guidelines, repositories whose README files follow the GitHub guidelines tend to receive more stars. We identify 32 clusters of common README file structures and the features associated with each structure. We show that projects with README files that contain project name, usage information, installation instructions, license information, code snippets, or links to images tend to get more stars. Conclusion: README file structure shares a statistically significant relationship with popularity as measured by number of stars; however, the most frequent README file structures are associated with less popular repositories on GitHub. Our findings can be used to understand the importance of README file structures and their relationship with popularity. © 2022 Elsevier B.V.","Clustering; Empirical study; README files; Software popularity","Article","Scopus"
"Savelyev A.","Savelyev, Alexander (57192936912)","57192936912","Legal aspects of ownership in modified open source software and its impact on Russian software import substitution policy","2017","Computer Law and Security Review","10.1016/j.clsr.2016.11.014","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008199934&doi=10.1016%2fj.clsr.2016.11.014&partnerID=40&md5=46f2e7c516b8424465cd9221c849f9d3","In my previous publication, I tried to show how personal data legislation might be used for achieving the purposes of national sovereignty1 Alexander Savelyev. Russia's new personal data localization regulations: A step forward or a self-imposed sanction? // [2016] 32 Computer Law & Security Review 128–145. In this paper, I will demonstrate how open source software may be used for achieving similar purposes. However, the interplay between local copyright law, public procurement law and open source community norms creates many issues relating to the legal status and ownership in modified software, based on open source. This is especially so in the case of so-called copyleft open source licenses, where a collision occurs between copyright, as an absolute right enforceable against the world, and the copyleft provisions of license agreements, which may be treated as “rights in personam” enforceable only against the licensee. The exclusive right to derivative software as an independent object of copyright, may come into conflict with restrictions inherited from incoming copyleft licenses. This paper provides an overview and analysis of such problems faced by Russian software developers, attempting to comply with Russian import substitution provisions, by using open source components. Although it is based on Russian law, it may be applicable to other jurisdictions, since general aspects of copyright law and its interaction with private international law and contract law drive it. The paper concludes that the developer of software, containing code licensed under GPL or other copyleft provisions, receives full exclusive right to the derivative software and can commercialize it as he sees appropriate, subject only to possible claims of breach of contract rather than copyright infringement. This opens wide perspectives for using open source components regardless of the type of license used as bricks for building a de-globalized economy and society based on principles of information sovereignty. © 2017 Alexander Savelyev","Derivative computer program; Import substitution; Information sovereignty; Lex protectionis; Open source software","Article","Scopus"
"Ragkhitwetsagul C.; Krinke J.; Paixao M.; Bianco G.; Oliveto R.","Ragkhitwetsagul, Chaiyong (56422351700); Krinke, Jens (6603760534); Paixao, Matheus (55837555300); Bianco, Giuseppe (57206776479); Oliveto, Rocco (15136561900)","56422351700; 6603760534; 55837555300; 57206776479; 15136561900","Toxic Code Snippets on Stack Overflow","2021","IEEE Transactions on Software Engineering","10.1109/TSE.2019.2900307","28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061983117&doi=10.1109%2fTSE.2019.2900307&partnerID=40&md5=019960d3f0ae3cf0d4a3c75420424697","Online code clones are code fragments that are copied from software projects or online sources to Stack Overflow as examples. Due to an absence of a checking mechanism after the code has been copied to Stack Overflow, they can become toxic code snippets, e.g., they suffer from being outdated or violating the original software license. We present a study of online code clones on Stack Overflow and their toxicity by incorporating two developer surveys and a large-scale code clone detection. A survey of 201 high-reputation Stack Overflow answerers (33 percent response rate) showed that 131 participants (65 percent) have ever been notified of outdated code and 26 of them (20 percent) rarely or never fix the code. 138 answerers (69 percent) never check for licensing conflicts between their copied code snippets and Stack Overflow's CC BY-SA 3.0. A survey of 87 Stack Overflow visitors shows that they experienced several issues from Stack Overflow answers: mismatched solutions, outdated solutions, incorrect solutions, and buggy code. 85 percent of them are not aware of CC BY-SA 3.0 license enforced by Stack Overflow, and 66 percent never check for license conflicts when reusing code snippets. Our clone detection found online clone pairs between 72,365 Java code snippets on Stack Overflow and 111 open source projects in the curated Qualitas corpus. We analysed 2,289 non-trivial online clone candidates. Our investigation revealed strong evidence that 153 clones have been copied from a Qualitas project to Stack Overflow. We found 100 of them (66 percent) to be outdated, of which 10 were buggy and harmful for reuse. Furthermore, we found 214 code snippets that could potentially violate the license of their original software and appear 7,112 times in 2,427 GitHub projects. © 1976-2012 IEEE.","Code clone detection; outdated code; software licensing; stack overflow","Article","Scopus"
"Gambardella A.; Hall B.H.","Gambardella, Alfonso (54984906100); Hall, Bronwyn H. (7401720259)","54984906100; 7401720259","Proprietary versus public domain licensing of software and research products","2006","Research Policy","10.1016/j.respol.2006.04.004","45","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745467029&doi=10.1016%2fj.respol.2006.04.004&partnerID=40&md5=f0e337496001a1c0955426edbd774959","We study the production of knowledge when many researchers or inventors are involved, in a setting where tensions can arise between individual public and private contributions. We first show that, without some kind of coordination, production of the public knowledge good (science or research software or database) is sub-optimal. Then we demonstrate that if 'lead' researchers are able to establish a norm of contribution to the public good, a better outcome can be achieved, and we show that the general public license (GPL) used in the provision of open source software is one such mechanism. Our results are then applied to the specific setting where the knowledge being produced is software or a database that will be used by academic researchers and possibly by private firms, using as an example a product familiar to economists, econometric software. We conclude by discussing some of the ways in which pricing can ameliorate the problem of providing these products to academic researchers. © 2006.","Databases; Intellectual property; Open source; Scientific research; Software","Article","Scopus"
"Liu B.; Yang B.; Xu C.; Xia J.; Dai M.; Ji Z.; You F.; Dong X.; Shi X.; Fu F.","Liu, Benyuan (56047917900); Yang, Bin (55712724400); Xu, Canhua (16204531000); Xia, Junying (36457882100); Dai, Meng (37030594400); Ji, Zhenyu (36240046300); You, Fusheng (15023750300); Dong, Xiuzhen (35193642900); Shi, Xuetao (55629257800); Fu, Feng (50661362900)","56047917900; 55712724400; 16204531000; 36457882100; 37030594400; 36240046300; 15023750300; 35193642900; 55629257800; 50661362900","pyEIT: A python based framework for Electrical Impedance Tomography","2018","SoftwareX","10.1016/j.softx.2018.09.005","23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054324896&doi=10.1016%2fj.softx.2018.09.005&partnerID=40&md5=d537cd94ea095915ee01a90fa4970e89","We present a Python-based, open source Electrical Impedance Tomography (EIT) library called pyEIT. It is a multiplatform software released under the Apache License v2.0. pyEIT has a clean architecture and is well documented. It implements state-of-the-art EIT imaging algorithms and is also capable of simple 2D/3D meshing. pyEIT is written in Python. It accelerates the analysis of offline EIT data and can be incorporated into clinical EIT applications. In this paper, we focus on illustrating the fundamental design principles of pyEIT by using some intuitive examples about EIT forward computing and inverse solving. © 2018","Electrical Impedance Tomography; Finite element method; Inverse problems; Unstructrual mesh","Article","Scopus"
"Perr J.; Appleyard M.M.; Sullivan P.","Perr, Jon (36560266900); Appleyard, Melissa M. (7006510539); Sullivan, Patrick (57199770800)","36560266900; 7006510539; 57199770800","Open for business: Emerging business models in open source software","2010","International Journal of Technology Management","10.1504/IJTM.2010.035984","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77958020718&doi=10.1504%2fIJTM.2010.035984&partnerID=40&md5=dbd2d3c584dcfde86b9fd0dd922c29d1","Open source software (OSS) has come of age, and a number of maturing business models allow OSS companies to make a profit even when their product is distributed for free. This article considers the dynamics of value creation fuelling the proliferation of OSS and examines the business model factors that enable value capture. After interviewing leaders from over 20 OSS firms and organisations through early 2006, we found that three factors were consistently important in defining a vendor's adoption of a given business model: software licence choice, which takes into account intellectual property ownership; management of developer communities; and the unique features of the markets and product categories in which the vendor participates. Considering these factors, we characterise seven business models. One striking finding is that it is rare to find business-model purity. The majority of firms in our sample are pursuing either blended business models or multiple models simultaneously. Copyright © 2010 Inderscience Enterprises Ltd.","Business models; Community management; Open source software; OSS; Value capture; Value creation","Article","Scopus"
"Scacchi W.; Alspaugh T.A.","Scacchi, Walt (7004343180); Alspaugh, Thomas A. (36892797100)","7004343180; 36892797100","Issues in development and maintenance of open architecture software systems","2017","CrossTalk","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022017657&partnerID=40&md5=24f5c42e41059337029318aa42b9c282","This article identifies and describes six emerging issues that affect the engineering of open architecture software systems that integrate proprietary and open source software components. These interdependent issues identify problems for software engineering research and practice associated with: (a) unknown or unclear open architecture software representations; (b) systems subject to heterogeneous software licenses; (c) cybersecurity of open architecture software systems; (d) build, release, and deployment processes and process automation; (e) evolution practices for open architecture software; and (f) new business models affecting the acquisition costs of open architecture software components. © 2016 Carnegie Mellon University.","","Article","Scopus"
"Hebal H.; Koziol Z.; Lisesivdin S.B.; Steed R.","Hebal, H. (56398510400); Koziol, Z. (57225257958); Lisesivdin, S.B. (16242267700); Steed, R. (57220325820)","56398510400; 57225257958; 16242267700; 57220325820","General-purpose open-source 1D self-consistent Schrödinger-Poisson Solver: Aestimo 1D","2021","Computational Materials Science","10.1016/j.commatsci.2020.110015","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090036050&doi=10.1016%2fj.commatsci.2020.110015&partnerID=40&md5=5ffb376c3c8c00e7683602720c369e1e","We present a general-purpose numerical quantum mechanical solver using Schrödinger-Poisson equations called Aestimo 1D. The solver provides self-consistent solutions to the Schrödinger and Poisson equations for a given semiconductor heterostructure built with materials including elementary, binary, ternary, and quaternary semiconductors and their doped structures. The software can be used to calculate electronic band structures of heterostructures either using a single-band or multi-band k.p envelope function approximation. The software is fully open-source and it is released under the GNU general public license version 3 for full freedom of usage for applications in the fields of nano-electronics, optoelectronics, and solid-state device simulations. © 2020 Elsevier B.V.","2DEG; Aestimo1D; Schrödinger-Poisson","Article","Scopus"
"Alcaraz Calero J.M.; Aguado J.G.","Alcaraz Calero, Jose M. (25721805600); Aguado, Juan Gutierrez (57220986469)","25721805600; 57220986469","MonPaaS: An adaptive monitoring platformas a service for cloud computing infrastructures and services","2015","IEEE Transactions on Services Computing","10.1109/TSC.2014.2302810","84","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921505689&doi=10.1109%2fTSC.2014.2302810&partnerID=40&md5=836be849310781770e642533656fd7c8","This paper presents a novel monitoring architecture addressed to the cloud provider and the cloud consumers. This architecture offers a monitoring platform-as-a-Service to each cloud consumer that allows to customize the monitoring metrics. The cloud provider sees a complete overview of the infrastructure whereas the cloud consumer sees automatically her cloud resources and can define other resources or services to be monitored. This is accomplished by means of an adaptive distributed monitoring architecture automatically deployed in the cloud infrastructure. This architecture has been implemented and released under GPL license to the community as 'MonPaaS', open source software for integrating Nagios and OpenStack. An intensive empirical evaluation of performance and scalability have been done using a real deployment of a cloud computing infrastructure in which more than 3,700 VMs have been executed. © 2008-2012 IEEE.","Cloud computing; monitoring software; monitoring virtual infrastructures; monitoring-as-a-service","Article","Scopus"
"Kocoń J.; Marcińczuk M.","Kocoń, Jan (55345399800); Marcińczuk, Michał (24832449400)","55345399800; 24832449400","Supervised approach to recognise Polish temporal expressions and rule-based interpretation of timexes","2017","Natural Language Engineering","10.1017/S1351324916000255","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988693231&doi=10.1017%2fS1351324916000255&partnerID=40&md5=52c5a3b0d26baa7e00d828f47c350cf3","A key challenge of the Information Extraction in Natural Language Processing is the ability to recognise and classify temporal expressions (timexes). It is a crucial source of information about when something happens, how often something occurs or how long something lasts. Timexes extracted automatically from text, play a major role in many Information Extraction systems, such as question answering or event recognition. We prepared a broad specification of Polish timexes - PLIMEX. It is based on the state-of-the-art annotation guidelines for English, mainly TIMEX2 and TIMEX3 (a part of TimeML - Markup Language for Temporal and Event Expressions). We have expanded our specification for a description of the local meaning of timexes, based on LTIMEX annotation guidelines for English. Temporal description supports further event identification and extends event description model, focussing on anchoring events in time, events ordering and reasoning about the persistence of events. We prepared the specification, which is designed to address these issues, and we annotated all documents in Polish Corpus of Wroclaw University of Technology (KPWr) using our annotation guidelines. We also adapted our Liner2 machine learning system to recognise Polish timexes and we propose two-phase method to select a subset of features for Conditional Random Fields sequence labelling method. This article presents the whole process of corpus annotation, evaluation of inter-annotator agreement, extending Liner2 system with new features and evaluation of the recognition models before and after feature selection with the analysis of statistical significance of differences. Liner2 with presented models is available as open source software under the GNU General Public License. © Cambridge University Press 2016.","","Article","Scopus"
"Siala K.; Odersky L.","Siala, Kais (56998605700); Odersky, Leonhard (56990045800)","56998605700; 56990045800","pyGRETA, pyCLARA, pyPRIMA: A pre-processing suite to generate flexible model regions for energy system models","2021","SoftwareX","10.1016/j.softx.2021.100860","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118601457&doi=10.1016%2fj.softx.2021.100860&partnerID=40&md5=3d6c8ad8debf91f389da55fb73e36b21","This paper presents a combination of three pre-processing tools that allow energy system modelers to define the number and shape of their model regions flexibly. Firstly, weather reanalysis data and other geographic maps are combined in pyGRETA to downscale wind and solar data and obtain renewable energy potential maps in high spatial resolution, while pyPRIMA can provide the spatial distribution of the energy demand and a pre-processed network of transmission lines. Secondly, the raster maps and the transmission grid are fed into pyCLARA to obtain a shapefile of regions with homogeneous characteristics. Thirdly, the obtained shapefile is used in pyGRETA to generate representative time series of renewable power generation, and in pyPRIMA to pre-process the rest of the data (power plants, demand, grid, etc.) to prepare input files for model frameworks. The three tools have a similar software architecture and are available in GitHub with an open source license and a detailed description. A minimal working example shows how they can operate together to ensure a high degree of modeling flexibility. © 2021 The Authors","Clustering; Energy system modeling; Pre-processing; Spatial complexity","Article","Scopus"
"Croucher A.; O'Sullivan M.; O'Sullivan J.; Yeh A.; Burnell J.; Kissling W.","Croucher, Adrian (6603315654); O'Sullivan, Michael (7202497690); O'Sullivan, John (56472007800); Yeh, Angus (25932418600); Burnell, John (7006961126); Kissling, Warwick (56274846700)","6603315654; 7202497690; 56472007800; 25932418600; 7006961126; 56274846700","Waiwera: A parallel open-source geothermal flow simulator","2020","Computers and Geosciences","10.1016/j.cageo.2020.104529","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085269847&doi=10.1016%2fj.cageo.2020.104529&partnerID=40&md5=c8969dce9f4bc890055b1e007d541b2f","Waiwera is a new reservoir simulator designed to address the current and future challenges posed by modelling geothermal systems. It incorporates several innovations aimed at improving the robustness of phase transitions and steady-state model convergence, including a modified treatment of the multi-phase gravity term. The Waiwera code is parallelised and makes extensive use of the PETSc scientific computation library. It is written in object-oriented Fortran 2003 and released under a free, open-source software license. Results from demonstration problems show a high degree of consistency with comparable simulators such as TOUGH2, improved phase transition and steady-state convergence behaviour, good parallel scalability on large problems and demonstrate the suitability of Waiwera for complex models of real geothermal reservoirs. © 2020 Elsevier Ltd","Multiphase flow simulation; Numerical simulator; Parallelisation; Waiwera","Article","Scopus"
"Albert I.; Thakar J.; Li S.; Zhang R.; Albert R.","Albert, István (7005522163); Thakar, Juilee (6701782926); Li, Song (56193293800); Zhang, Ranran (56163983300); Albert, Réka (7202686127)","7005522163; 6701782926; 56193293800; 56163983300; 7202686127","Boolean network simulations for life scientists","2008","Source Code for Biology and Medicine","10.1186/1751-0473-3-16","203","https://www.scopus.com/inward/record.uri?eid=2-s2.0-58049164511&doi=10.1186%2f1751-0473-3-16&partnerID=40&md5=464a39937f45784ea138f9096185e898","Modern life sciences research increasingly relies on computational solutions, from large scale data analyses to theoretical modeling. Within the theoretical models Boolean networks occupy an increasing role as they are eminently suited at mapping biological observations and hypotheses into a mathematical formalism. The conceptual underpinnings of Boolean modeling are very accessible even without a background in quantitative sciences, yet it allows life scientists to describe and explore a wide range of surprisingly complex phenomena. In this paper we provide a clear overview of the concepts used in Boolean simulations, present a software library that can perform these simulations based on simple text inputs and give three case studies. The large scale simulations in these case studies demonstrate the Boolean paradigms and their applicability as well as the advanced features and complex use cases that our software package allows. Our software is distributed via a liberal Open Source license and is freely accessible from http://booleannet.googlecode.com © 2008 Albert et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Fostier J.","Fostier, Jan (15063921100)","15063921100","BLAMM: BLAS-based algorithm for finding position weight matrix occurrences in DNA sequences on CPUs and GPUs","2020","BMC Bioinformatics","10.1186/s12859-020-3348-6","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081895216&doi=10.1186%2fs12859-020-3348-6&partnerID=40&md5=d6e35323d8fc3b5d4c6264bf34ab9a7c","Background: The identification of all matches of a large set of position weight matrices (PWMs) in long DNA sequences requires significant computational resources for which a number of efficient yet complex algorithms have been proposed. Results: We propose BLAMM, a simple and efficient tool inspired by high performance computing techniques. The workload is expressed in terms of matrix-matrix products that are evaluated with high efficiency using optimized BLAS library implementations. The algorithm is easy to parallelize and implement on CPUs and GPUs and has a runtime that is independent of the selected p-value. In terms of single-core performance, it is competitive with state-of-the-art software for PWM matching while being much more efficient when using multithreading. Additionally, BLAMM requires negligible memory. For example, both strands of the entire human genome can be scanned for 1404 PWMs in the JASPAR database in 13 min with a p-value of 10-4 using a 36-core machine. On a dual GPU system, the same task can be performed in under 5 min. Conclusions: BLAMM is an efficient tool for identifying PWM matches in large DNA sequences. Its C++ source code is available under the GNU General Public License Version 3 at https://github.com/biointec/blamm. © 2020 The Author(s).","Basic linear algebra subprograms (BLAS); Graphics processing units (GPUs); High performance computing (HPC); Position weight matrix (PWM)","Article","Scopus"
"Gudyś A.; Sikora M.; Wróbel Ł.","Gudyś, Adam (36782214300); Sikora, Marek (7006570203); Wróbel, Łukasz (42962774800)","36782214300; 7006570203; 42962774800","RuleKit: A comprehensive suite for rule-based learning","2020","Knowledge-Based Systems","10.1016/j.knosys.2020.105480","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077913907&doi=10.1016%2fj.knosys.2020.105480&partnerID=40&md5=508f99e8ba2b88f4b185ee1ef4bf1d0e","Rule-based models are often used for data analysis as they combine interpretability with predictive power. We present RuleKit, a versatile tool for rule learning. Based on a sequential covering induction algorithm, it is suitable for classification, regression, and survival problems. The presence of a user-guided induction facilitates verifying hypotheses concerning data dependencies which are expected or of interest. The powerful and flexible experimental environment allows straightforward investigation of different induction schemes. The analysis can be performed in batch mode, through RapidMiner plug-in, or R package. The software is available at GitHub (https://github.com/adaa-polsl/RuleKit) under GNU AGPL-3.0 license. © 2020 The Authors","Classification; Knowledge discovery; Regression; Rule learning; Survival analysis; User-guided induction","Article","Scopus"
"Jacobsen A.; Krogh A.; Kauppinen S.; Lindow M.","Jacobsen, Anders (23050656800); Krogh, Anders (57205707402); Kauppinen, Sakari (6701777297); Lindow, Morten (8921409900)","23050656800; 57205707402; 6701777297; 8921409900","MiRMaid: A unified programming interface for microRNA data resources","2010","BMC Bioinformatics","10.1186/1471-2105-11-29","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77649115847&doi=10.1186%2f1471-2105-11-29&partnerID=40&md5=0ef4d8b05fef61738239f792baa261ca","Background: MicroRNAs (miRNAs) are endogenous small RNAs that play a key role in post-transcriptional regulation of gene expression in animals and plants. The number of known miRNAs has increased rapidly over the years. The current release (version 14.0) of miRBase, the central online repository for miRNA annotation, comprises over 10.000 miRNA precursors from 115 different species. Furthermore, a large number of decentralized online resources are now available, each contributing with important miRNA annotation and information.Results: We have developed a software framework, designated here as miRMaid, with the goal of integrating miRNA data resources in a uniform web service interface that can be accessed and queried by researchers and, most importantly, by computers. miRMaid is built around data from miRBase and is designed to follow the official miRBase data releases. It exposes miRBase data as inter-connected web services. Third-party miRNA data resources can be modularly integrated as miRMaid plugins or they can loosely couple with miRMaid as individual entities in the World Wide Web. miRMaid is available as a public web service but is also easily installed as a local application. The software framework is freely available under the LGPL open source license for academic and commercial use.Conclusion: miRMaid is an intuitive and modular software platform designed to unify miRBase and independent miRNA data resources. It enables miRNA researchers to computationally address complex questions involving the multitude of miRNA data resources. Furthermore, miRMaid constitutes a basic framework for further programming in which microRNA-interested bioinformaticians can readily develop their own tools and data sources. © 2010 Jacobsen et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Riester M.; Singh A.P.; Brannon A.R.; Yu K.; Campbell C.D.; Chiang D.Y.; Morrissey M.P.","Riester, Markus (22135891300); Singh, Angad P. (55979728700); Brannon, A.Rose (8243435100); Yu, Kun (37035527700); Campbell, Catarina D. (8672919800); Chiang, Derek Y. (7004319617); Morrissey, Michael P. (57193124203)","22135891300; 55979728700; 8243435100; 37035527700; 8672919800; 7004319617; 57193124203","PureCN: Copy number calling and SNV classification using targeted short read sequencing","2016","Source Code for Biology and Medicine","10.1186/s13029-016-0060-z","55","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006152885&doi=10.1186%2fs13029-016-0060-z&partnerID=40&md5=dab63f4383d6ba0b8ac97795bbf88164","Background: Matched sequencing of both tumor and normal tissue is routinely used to classify variants of uncertain significance (VUS) into somatic vs. germline. However, assays used in molecular diagnostics focus on known somatic alterations in cancer genes and often only sequence tumors. Therefore, an algorithm that reliably classifies variants would be helpful for retrospective exploratory analyses. Contamination of tumor samples with normal cells results in differences in expected allelic fractions of germline and somatic variants, which can be exploited to accurately infer genotypes after adjusting for local copy number. However, existing algorithms for determining tumor purity, ploidy and copy number are not designed for unmatched short read sequencing data. Results: We describe a methodology and corresponding open source software for estimating tumor purity, copy number, loss of heterozygosity (LOH), and contamination, and for classification of single nucleotide variants (SNVs) by somatic status and clonality. This R package, PureCN, is optimized for targeted short read sequencing data, integrates well with standard somatic variant detection pipelines, and has support for matched and unmatched tumor samples. Accuracy is demonstrated on simulated data and on real whole exome sequencing data. Conclusions: Our algorithm provides accurate estimates of tumor purity and ploidy, even if matched normal samples are not available. This in turn allows accurate classification of SNVs. The software is provided as open source (Artistic License 2.0) R/Bioconductor package PureCN (http://bioconductor.org/packages/PureCN/). © 2016 The Author(s).","Cell lines; Copy number; Heterogeneity; Hybrid capture; Loss of heterozygosity; Ploidy; Purity; Whole exome sequencing","Article","Scopus"
"Verschueren R.; Frison G.; Kouzoupis D.; Frey J.; Duijkeren N.; Zanelli A.; Novoselnik B.; Albin T.; Quirynen R.; Diehl M.","Verschueren, Robin (57191242442); Frison, Gianluca (55375799300); Kouzoupis, Dimitris (57188845379); Frey, Jonathan (57210811958); Duijkeren, Niels van (57189330139); Zanelli, Andrea (57188860510); Novoselnik, Branimir (36904804200); Albin, Thivaharan (49861114200); Quirynen, Rien (55376137500); Diehl, Moritz (7005392102)","57191242442; 55375799300; 57188845379; 57210811958; 57189330139; 57188860510; 36904804200; 49861114200; 55376137500; 7005392102","acados—a modular open-source framework for fast embedded optimal control","2022","Mathematical Programming Computation","10.1007/s12532-021-00208-8","19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116828773&doi=10.1007%2fs12532-021-00208-8&partnerID=40&md5=a091b4634f39cbe00b1b3badcab19f00","This paper presents the acados software package, a collection of solvers for fast embedded optimization intended for fast embedded applications. Its interfaces to higher-level languages make it useful for quickly designing an optimization-based control algorithm by putting together different algorithmic components that can be readily connected and interchanged. Since the core of acados is written on top of a high-performance linear algebra library, we do not sacrifice computational performance. Thus, we aim to provide both flexibility and performance through modularity, without the need to rely on automatic code generation, which facilitates maintainability and extensibility. The main features of acados are: efficient optimal control algorithms targeting embedded devices implemented in C, linear algebra based on the high-performance BLASFEO Frison (ACM Transactions on Mathematical Software (TOMS) 44: 1–30, 2018) library, user-friendly interfaces to Matlab and Python, and compatibility with the modeling language of CasADi Andersson (Mathematical Programming Computation 11: 136, 2019). acados is free and open-source software released under the permissive BSD 2-Clause license. © 2021, Springer-Verlag GmbH Germany, part of Springer Nature and Mathematical Optimization Society.","Direct optimal control; Optimization algorithms","Article","Scopus"
"Farrer R.A.","Farrer, Rhys A. (25937288800)","25937288800","HaplotypeTools: a toolkit for accurately identifying recombination and recombinant genotypes","2021","BMC Bioinformatics","10.1186/s12859-021-04473-1","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119611918&doi=10.1186%2fs12859-021-04473-1&partnerID=40&md5=cdf439a4ff995560865c9d108a0a9050","Background: Identifying haplotypes is central to sequence analysis in diploid or polyploid genomes. Despite this, there remains a lack of research and tools designed for physical phasing and its downstream analysis. Results: HaplotypeTools is a new toolset to phase variant sites using VCF and BAM files and to analyse phased VCFs. Phasing is achieved via the identification of reads overlapping ≥ 2 heterozygous positions and then extended by additional reads, a process that can be parallelized across a computer cluster. HaplotypeTools includes various utility scripts for downstream analysis including crossover detection and phylogenetic placement of haplotypes to other lineages or species. HaplotypeTools was assessed for accuracy against WhatsHap using simulated short and long reads, demonstrating higher accuracy, albeit with reduced haplotype length. HaplotypeTools was also tested on real Illumina data to determine the ancestry of hybrid fungal isolate Batrachochytrium dendrobatidis (Bd) SA-EC3, finding 80% of haplotypes across the genome phylogenetically cluster with parental lineages BdGPL (39%) and BdCAPE (41%), indicating those are the parental lineages. Finally, ~ 99% of phasing was conserved between overlapping phase groups between SA-EC3 and either parental lineage, indicating mitotic gene conversion/parasexuality as the mechanism of recombination for this hybrid isolate. HaplotypeTools is open source and freely available from https://github.com/rhysf/HaplotypeTools under the MIT License. Conclusions: HaplotypeTools is a powerful resource for analyzing hybrid or recombinant diploid or polyploid genomes and identifying parental ancestry for sub-genomic regions. © 2021, The Author(s).","Batrachochytrium dendrobatidis; Haplotype; Hybridization; Phasing; Recombination; Recombination; Software","Article","Scopus"
"Lohan E.S.; Torres-Sospedra J.; Leppäkoski H.; Richter P.; Peng Z.; Huerta J.","Lohan, Elena Simona (6602677794); Torres-Sospedra, Joaquín (6506831140); Leppäkoski, Helena (15623495300); Richter, Philipp (55917091500); Peng, Zhe (57201502174); Huerta, Joaquín (56260161000)","6602677794; 6506831140; 15623495300; 55917091500; 57201502174; 56260161000","Wi-Fi crowdsourced fingerprinting dataset for indoor positioning","2017","Data","10.3390/data2040032","94","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036478256&doi=10.3390%2fdata2040032&partnerID=40&md5=eef9091b260421e2ed0ea61634f87571","Benchmark open-source Wi-Fi fingerprinting datasets for indoor positioning studies are still hard to find in the current literature and existing public repositories. This is unlike other research fields, such as the image processing field, where benchmark test images such as the Lenna image or Face Recognition Technology (FERET) databases exist, or the machine learning field, where huge datasets are available for example at the University of California Irvine (UCI) Machine Learning Repository. It is the purpose of this paper to present a new openly available Wi-Fi fingerprint dataset, comprised of 4648 fingerprints collected with 21 devices in a university building in Tampere, Finland, and to present some benchmark indoor positioning results using these data. The datasets and the benchmarking software are distributed under the open-source MIT license and can be found on the EU Zenodo repository. © 2017 by the authors. Licensee MDPI, Basel, Switzerland.","Crowdsourced data; Fingerprinting; Indoor positioning; Multi-floor building; Positioning software; Wi-Fi datasets","Article","Scopus"
"Ruano-Ordás D.; Fdez-Glez J.; Fdez-Riverola F.; Basto Fernandes V.; Méndez J.R.","Ruano-Ordás, David (55214026800); Fdez-Glez, Jorge (55811372200); Fdez-Riverola, Florentino (35580091100); Basto Fernandes, Vitor (53363129900); Méndez, José Ramón (9243599300)","55214026800; 55811372200; 35580091100; 53363129900; 9243599300","RuleSIM: a toolkit for simulating the operation and improving throughput of rule-based spam filters","2016","Software - Practice and Experience","10.1002/spe.2342","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84935052337&doi=10.1002%2fspe.2342&partnerID=40&md5=0b3823f7276c95a63efbe58dfbc6b9ef","This paper introduces RuleSIM, a toolkit comprising different simulation tools specifically designed to aid researchers concerned about spam-filtering throughput. RuleSIM allows easily designing, developing, simulating and comparing new scheduling heuristics using different filters and sets of e-mails. Simulation results can be both graphically analysed, by using different complementary views, and quantitatively compared through several measures. Moreover, the underlying RuleSIM API can be easily integrated with third-party Java optimization platforms to facilitate debugging and achieve better configurations for rule scheduling. RuleSIM is free software distributed under the terms of GNU Lesser General Public License, and both source code and documentation are publicly available at https://github.com/rulesim/v2.0. Copyright © 2015 John Wiley & Sons, Ltd. Copyright © 2015 John Wiley & Sons, Ltd.","computational resource management; filtering performance benchmark tool; rule scheduling optimization; rule-based spam systems; scheduling application; spam-filtering rules","Article","Scopus"
"Gobbi G.; Colombo C.; Miccoli S.; Vergani L.","Gobbi, Giorgia (55942790300); Colombo, Chiara (35204809400); Miccoli, Stefano (6508392147); Vergani, Laura (35335647500)","55942790300; 35204809400; 6508392147; 35335647500","A fully coupled implementation of hydrogen embrittlement in FE analysis","2019","Advances in Engineering Software","10.1016/j.advengsoft.2019.04.004","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068233496&doi=10.1016%2fj.advengsoft.2019.04.004&partnerID=40&md5=e23b4ee11e2eabc0daa2d0ad45bb548a","Proper understanding of hydrogen embrittlement in steel is of paramount importance in several engineering applications, e.g. oil & gas and hydrogen storage & transport. This phenomenon can be modelled by means of a mass diffusion analysis driven by mechanical fields, i.e. hydrostatic stress gradient and plastic strain. Since the mechanical response depends on the hydrogen content itself, continuum mechanics and mass diffusion equations are fully coupled. Accordingly in this paper a fully coupled–cohesive zone implementation is presented for the Abaqus Finite Element code, adopting the coupled thermal–stress analysis and the analogy between mass diffusion and heat transfer. The implementation requires extensive use of FORTRAN user subroutines and common blocks to share data, plus some auxiliary Python scripts. With the aim to provide a practical example to the use of the code, a FE model reproducing a fracture toughness test of C(T) specimen charged with atomic hydrogen is described. Moreover, a sensitivity analysis of the model shows the capability of the developed numerical tool in predicting hydrogen embrittlement. The code developed in this paper is open source under a permissive free software license. © 2019 Elsevier Ltd","Cohesive elements; Coupled analysis; Finite element method; Hydrogen embrittlement","Article","Scopus"
"Morales-Hernández M.; Sharif M.B.; Kalyanapu A.; Ghafoor S.K.; Dullo T.T.; Gangrade S.; Kao S.-C.; Norman M.R.; Evans K.J.","Morales-Hernández, M. (57201877575); Sharif, Md B. (57207777427); Kalyanapu, A. (33667693800); Ghafoor, S.K. (6602266187); Dullo, T.T. (56711275700); Gangrade, S. (57190953533); Kao, S.-C. (17346380600); Norman, M.R. (10039602000); Evans, K.J. (15044268700)","57201877575; 57207777427; 33667693800; 6602266187; 56711275700; 57190953533; 17346380600; 10039602000; 15044268700","TRITON: A Multi-GPU open source 2D hydrodynamic flood model","2021","Environmental Modelling and Software","10.1016/j.envsoft.2021.105034","19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104922934&doi=10.1016%2fj.envsoft.2021.105034&partnerID=40&md5=a2c2527da31fab529d6a95ee63e88250","A new open source multi-GPU 2D flood model called TRITON is presented in this work. The model solves the 2D shallow water equations with source terms using a time-explicit first order upwind scheme based on an Augmented Roe's solver that incorporates a careful estimation of bed strengths and a local implicit formulation of friction terms. The scheme is demonstrated to be first order accurate, robust and able to solve for flows under various conditions. TRITON is implemented such that the model effectively utilizes heterogeneous architectures, from single to multiple CPUs and GPUs. Different test cases are shown to illustrate the capabilities and performance of the model, showing promising runtimes for large spatial and temporal scales when leveraging the computer power of GPUs. Under this hardware configuration, communication and input/output subroutines may impact the scalability. The code is developed under an open source license and can be freely downloaded in https://code.ornl.gov/hydro/triton. © 2021 Elsevier Ltd","2D flood model; High-resolution; Multi-GPU; Open source; Shallow water equations","Article","Scopus"
"Deorowicz S.; Gudyś A.","Deorowicz, Sebastian (14029848100); Gudyś, Adam (36782214300)","14029848100; 36782214300","Whisper2: Indel-sensitive short read mapping","2021","SoftwareX","10.1016/j.softx.2021.100692","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104081011&doi=10.1016%2fj.softx.2021.100692&partnerID=40&md5=fff05d1c4efd20fda4ff2c63e85a5e2a","Identification of genetic variants is of crucial importance in the forthcoming era of precision medicine. Since the majority of variant callers require mapping reads to a reference genome, the reliability of the latter is a key factor determining accuracy of the downstream analyses. We present Whisper2, a short-read-mapping software providing superior quality of indel variant calling. Its running times place it among the fastest existing tools. The software is available at GitHub (https://github.com/refresh-bio/whisper) under GNU GPL 3 license. © 2021","High throughput sequencing; Short read mapping; Variant calling","Article","Scopus"
"Sicotte H.; Rider D.N.; Poland G.A.; Dhiman N.; Kocher J.-P.A.","Sicotte, Hugues (24597815800); Rider, David N. (57210606118); Poland, Gregory A. (7006264623); Dhiman, Neelam (7004587492); Kocher, Jean-Pierre A. (57202964001)","24597815800; 57210606118; 7006264623; 7004587492; 57202964001","SNPPicker: High quality tag SNP selection across multiple populations","2011","BMC Bioinformatics","10.1186/1471-2105-12-129","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955457459&doi=10.1186%2f1471-2105-12-129&partnerID=40&md5=d20dd3e4a4e145ffebec7e3ee731b80d","Background: Linkage Disequilibrium (LD) bin-tagging algorithms identify a reduced set of tag SNPs that can capture the genetic variation in a population without genotyping every single SNP. However, existing tag SNP selection algorithms for designing custom genotyping panels do not take into account all platform dependent factors affecting the likelihood of a tag SNP to be successfully genotyped and many of the constraints that can be imposed by the user.Results: SNPPicker optimizes the selection of tag SNPs from common bin-tagging programs to design custom genotyping panels. The application uses a multi-step search strategy in combination with a statistical model to maximize the genotyping success of the selected tag SNPs. User preference toward functional SNPs can also be taken into account as secondary criteria. SNPPicker can also optimize tag SNP selection for a panel tagging multiple populations. SNPPicker can optimize custom genotyping panels including all the assay-specific constraints of Illumina's GoldenGate and Infinium assays.Conclusions: A new application has been developed to maximize the success of custom multi-population genotyping panels. SNPPicker also takes into account user constraints including options for controlling runtime. Perl Scripts, Java source code and executables are available under an open source license for download at http://mayoresearch.mayo.edu/mayo/research/biostat/software.cfm. © 2011 Sicotte et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Kalainathan D.; Goudet O.; Dutta R.","Kalainathan, Diviyan (57217222596); Goudet, Olivier (56495360900); Dutta, Ritik (57210725485)","57217222596; 56495360900; 57210725485","Causal discovery toolbox: Uncovering causal relationships in python","2020","Journal of Machine Learning Research","","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086800504&partnerID=40&md5=77a45dda701ff2560ac97ecc43e8e337","This paper presents a new open source Python framework for causal discovery from observational data and domain background knowledge, aimed at causal graph and causal mechanism modeling. The Cdt package implements an end-to-end approach, recovering the direct dependencies (the skeleton of the causal graph) and the causal relationships between variables. It includes algorithms from the 'Bnlearn' (Scutari, 2018) and 'Pcalg' (Kalisch et al., 2018) packages, together with algorithms for pairwise causal discovery such as ANM (Hoyer et al., 2009). Cdt is available under the MIT License at https://github.com/FenTechSolutions/CausalDiscoveryToolbox. © 2020 Diviyan Kalainathan, Olivier Goudet, Ritik Dutta. License: CC-BY 4.0, see https://creativecommons.org/licenses/by/4.0/. Attribution requirements are provided at http://jmlr.org/papers/v21/19-187.html.","Causal Discovery; Constraint-based methods; Graph recovery; Markov blanket; Open source; Pairwise causality; Score-based methods","Article","Scopus"
"Cassidy K.C.; Šefcík J.; Raghav Y.; Chang A.; Durrant J.D.","Cassidy, Kevin C. (57211977278); Šefcík, Jan (57218682513); Raghav, Yogindra (57216207617); Chang, Alexander (57216209324); Durrant, Jacob D. (12239804300)","57211977278; 57218682513; 57216207617; 57216209324; 12239804300","ProteinVR: Web-based molecular visualization in virtual reality","2020","PLoS Computational Biology","10.1371/journal.pcbi.1007747","23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082837656&doi=10.1371%2fjournal.pcbi.1007747&partnerID=40&md5=756ab1ce4233c816d3c5935571f97eb8","Protein structure determines biological function. Accurately conceptualizing 3D protein/ ligand structures is thus vital to scientific research and education. Virtual reality (VR) enables protein visualization in stereoscopic 3D, but many VR molecular-visualization programs are expensive and challenging to use; work only on specific VR headsets; rely on complicated model-preparation software; and/or require the user to install separate programs or plugins. Here we introduce ProteinVR, a web-based application that works on various VR setups and operating systems. ProteinVR displays molecular structures within 3D environments that give useful biological context and allow users to situate themselves in 3D space. Our web-based implementation is ideal for hypothesis generation and education in research and large-classroom settings. We release ProteinVR under the open-source BSD- 3-Clause license. A copy of the program is available free of charge from http://durrantlab. com/protein-vr/, and a working version can be accessed at http://durrantlab.com/pvr/. © 2020 Cassidy et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Article","Scopus"
"Liu R.; Dickerson J.","Liu, Ruolin (55936724200); Dickerson, Julie (7103186003)","55936724200; 7103186003","Strawberry: Fast and accurate genome-guided transcript reconstruction and quantification from RNA-Seq","2017","PLoS Computational Biology","10.1371/journal.pcbi.1005851","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036476747&doi=10.1371%2fjournal.pcbi.1005851&partnerID=40&md5=08c4a5eba4a17d62fc0e2905de961c06","We propose a novel method and software tool, Strawberry, for transcript reconstruction and quantification from RNA-Seq data under the guidance of genome alignment and independent of gene annotation. Strawberry consists of two modules: assembly and quantification. The novelty of Strawberry is that the two modules use different optimization frameworks but utilize the same data graph structure, which allows a highly efficient, expandable and accurate algorithm for dealing large data. The assembly module parses aligned reads into splicing graphs, and uses network flow algorithms to select the most likely transcripts. The quantification module uses a latent class model to assign read counts from the nodes of splicing graphs to transcripts. Strawberry simultaneously estimates the transcript abundances and corrects for sequencing bias through an EM algorithm. Based on simulations, Strawberry outperforms Cufflinks and StringTie in terms of both assembly and quantification accuracies. Under the evaluation of a real data set, the estimated transcript expression by Strawberry has the highest correlation with Nanostring probe counts, an independent experiment measure for transcript expression. Availability: Strawberry is written in C++14, and is available as open source software at https://github.com/ruolin/strawberry under the MIT license. © 2017 Liu, Dickerson.","","Article","Scopus"
"Hickerson M.J.; Stahl E.; Takebayashi N.","Hickerson, Michael J. (6603267379); Stahl, Eli (57196467867); Takebayashi, Naoki (6603334580)","6603267379; 57196467867; 6603334580","msBayes: Pipeline for testing comparative phylogeographic histories using hierarchical approximate Bayesian computation","2007","BMC Bioinformatics","10.1186/1471-2105-8-268","111","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548065664&doi=10.1186%2f1471-2105-8-268&partnerID=40&md5=21b79f50e95d444c7f948e5338dcdb72","Background: Although testing for simultaneous divergence (vicariance) across different population-pairs that span the same barrier to gene flow is of central importance to evolutionary biology, researchers often equate the gene tree and population/species tree thereby ignoring stochastic coalescent variance in their conclusions of temporal incongruence. In contrast to other available phylogeographic software packages, msBayes is the only one that analyses data from multiple species/population pairs under a hierarchical model. Results: msBayes employs approximate Bayesian computation (ABC) under a hierarchical coalescent model to test for simultaneous divergence (TSD) in multiple co-distributed population-pairs. Simultaneous isolation is tested by estimating three hyper-parameters that characterize the degree of variability in divergence times across co-distributed population pairs while allowing for variation in various within population-pair demographic parameters (sub-parameters) that can affect the coalescent. msBayes is a software package consisting of several C and R programs that are run with a Perl ""front-end"". Conclusion: The method reasonably distinguishes simultaneous isolation from temporal incongruence in the divergence of co-distributed population pairs, even with sparse sampling of individuals. Because the estimate step is decoupled from the simulation step, one can rapidly evaluate different ABC acceptance/rejection conditions and the choice of summary statistics. Given the complex and idiosyncratic nature of testing multi-species biogeographic hypotheses, we envision msBayes as a powerful and flexible tool for tackling a wide array of difficult research questions that use population genetic data from multiple co-distributed species. The msBayes pipeline is available for download at http://msbayes.sourceforge.net/ under an open source license (GNU Public License). The msBayes pipeline is comprised of several C and R programs that are run with a Perl ""front-end"" and runs on Linux, Mac OS-X, and most POSIX systems. Although the current implementation is for a single locus per species-pair, future implementations will allow analysis of multi-loci data per species pair. © 2007 Hickerson et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Pakarinen T.; Ojala J.","Pakarinen, Tomppa (57213592871); Ojala, Jarkko (55701252000)","57213592871; 55701252000","Profeel—An open source dosimetry data visualization and analysis software","2021","Computer Methods and Programs in Biomedicine","10.1016/j.cmpb.2021.106457","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117166353&doi=10.1016%2fj.cmpb.2021.106457&partnerID=40&md5=f4ff58419caaaae02c8995b136c4f7f5","Background and objectives: This article presents Profeel, a Matlab (MathWorks Inc., MA) based open source dosimetry data visualization and analysis software. Profeel aims to support quality assurance, dosimetry and research in the field of radiotherapy by providing an environment to visualize, process and analyse measured and simulated dosimetry data from several data sources used in radiotherapy practice and research. Methods: The processing and analysis tools are based on routinely used dosimetry analysis methods, such as gamma analysis, different data normalizations and data filtering. Additionally the Profeel performs an automatic 1 dimensional profile and percentage depth dose analysis in accordance with International Electrotechnical Commission definitions. All data can be operated by user created custom functions and lower dimensionality data can be extracted from volume doses and dose planes. Results: Profeel supports data import in all 3 dimensions and offers an intuitive user interface to perform data visualization, processing and analysis between simulated and measured data. Profeel and its source code are distributed free of charge under the General Public Licence (GPL). Conclusions: Profeel has shown to be an agile tool for fulfilling various needs of several researchers and since Profeel is under constant development and is an open source project, community needs, issues and bug reports are taken into account in the development. © 2021 The Author(s)","Dosimetry; Matlab; Quality assurance; Radiotherapy","Article","Scopus"
"Vujovic S.; Ulhøi J.P.","Vujovic, Sladjana (23471205400); Ulhøi, John Parm (6603612816)","23471205400; 6603612816","Online innovation: The case of open source software development","2008","European Journal of Innovation Management","10.1108/14601060810845268","30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-38349168648&doi=10.1108%2f14601060810845268&partnerID=40&md5=170b829de9b6d634336bbe3125d833e0","Purpose - The aim of this paper is to investigate the role of online networking during the innovation process, including its role(s) in communication, cooperation and coordination. The paper neither implicitly assumes that online computer-based networking is a prerequisite for the innovation process nor denies the possibility that innovation can emerge and successfully survive without it. It merely presupposes that, in cases of innovation where information and communication technologies play a substantial role, non-proprietarity may offer an interesting alternative to innovations based on proprietary knowledge. Design/methodology/approach - The paper borrows from the theory of communities-of-practice, which takes into account social relations, contacts, and the transfer and incorporation of knowledge. Open source innovation is not the exclusive preserve of computer nerds, but also has implications for existing software manufacturers. The paper therefore includes the case of IBM, a company which has successfully integrated this new and more open way of collaboration into its business model. Findings - The paper concludes that online computer-based innovation fundamentally challenges current ways of communicating, cooperating and coordinating during the innovation and product development process. Moreover, it challenges the traditional business model in that it forces the actors involved to shift the focus from the innovation itself to the identification of new supporting services higher up the value chain. Last, but not least, it blurs the boundary between development and use, since the developer remains the key user. Research limitations/ implications - The paper addresses the implications for future research in the area. Practical implications - The paper addresses implications for practitioners directly involved in innovation and product development. Originality/value - This paper develops a conceptual framework for understanding product development based on non-proprietary knowledge, which cannot be adequately accounted for by traditional corporate innovation theory alone. © Emerald Group Publishing Limited.","Communication technologies; Innovation; Internet; Open systems; Resource management","Article","Scopus"
"Feliks M.; Field M.J.","Feliks, Mikolaj (16052352200); Field, Martin J. (7201475778)","16052352200; 7201475778","Pcetk: A pDynamo-based Toolkit for Protonation State Calculations in Proteins","2015","Journal of Chemical Information and Modeling","10.1021/acs.jcim.5b00262","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945563357&doi=10.1021%2facs.jcim.5b00262&partnerID=40&md5=daf03bbbb16529a96e03a1ec58a2a9f4","Pcetk (a pDynamo-based continuum electrostatic toolkit) is an open-source, object-oriented toolkit for the calculation of proton binding energetics in proteins. The toolkit is a module of the pDynamo software library, combining the versatility of the Python scripting language and the efficiency of the compiled languages, C and Cython. In the toolkit, we have connected pDynamo to the external Poisson-Boltzmann solver, extended-MEAD. Our goal was to provide a modern and extensible environment for the calculation of protonation states, electrostatic energies, titration curves, and other electrostatic-dependent properties of proteins. Pcetk is freely available under the CeCILL license, which is compatible with the GNU General Public License. The toolkit can be found on the Web at the address http://github.com/mfx9/pcetk. The calculation of protonation states in proteins requires a knowledge of pKa values of protonatable groups in aqueous solution. However, for some groups, such as protonatable ligands bound to protein, the pKaaq values are often difficult to obtain from experiment. As a complement to Pcetk, we revisit an earlier computational method for the estimation of pKaaq values that has an accuracy of ±0.5 pKa-units or better. Finally, we verify the Pcetk module and the method for estimating pKaaq values with different model cases. © 2015 American Chemical Society.","","Article","Scopus"
"Campbell-Kelly M.; Garcia-Swartz D.D.","Campbell-Kelly, Martin (6602737239); Garcia-Swartz, Daniel D. (23984681500)","6602737239; 23984681500","The move to the middle: Convergence of the open-source and proprietary software industries","2010","International Journal of the Economics of Business","10.1080/13571516.2010.483091","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954171371&doi=10.1080%2f13571516.2010.483091&partnerID=40&md5=3d18e456ad22034d20ca661ccd4157d5","In this paper we focus on open-source software within the broader framework of the software industry. More specifically, we compare proprietary and open-source software (OSS) companies in terms of three criteria: (a) approaches to the production of software; (b) business models; and (c) strategic interactions. We postulate three convergence hypotheses. First, there is evidence of convergence in production approaches: leading OSS firms tend to rely on R&D and acquisitions as intensely as leading proprietary companies do. Second, there is evidence of convergence in business models: through dual-licensing models, top OSS firms derive substantial portions of their revenues from licenses, just as many proprietary companies do. Third, there is evidence of convergence in strategic interactions: the competitive strategies that a company follows do not really hinge on the 'proprietary versus open-source' dichotomy, but on whether a firm feels threatened in the software layer where its core assets are located. This evidence of convergence raises a number of interesting questions for economic theory and for the analysis of the industry's future evolution. © 2010 International Journal of the Economics of Business.","Business Models; Industry Studies; Open-Source Software; Price Discrimination; Production of Software; Software","Article","Scopus"
"Burgos E.S.; Adam E.J.","Burgos, Enrique S. (57847082800); Adam, Eduardo J. (57846867700)","57847082800; 57846867700","Graphical user interface editor for Octave applications","2020","Engineering Reports","10.1002/eng2.12269","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136009857&doi=10.1002%2feng2.12269&partnerID=40&md5=3dff56a8c544054940f2afe01f13d0b9","The use of calculation software for pedagogical purposes in degree courses is a central tool for addressing disciplinary knowledge in engineering careers. Particularly, open source and free license tools generally have lower associated costs than their propriety equivalents while offering a similarly rich set of functionalities. This document presents a software tool called guiEditor designed to create script applications based on graphical interfaces for GNU Octave. guiEditor is a visual editor, which incorporates different functionalities aimed at allowing the development of graphical applications based on basic programming knowledge. Within the development environment it incorporates, in addition to the typical controls of the graphical interfaces, new controls that extend the script language used. In addition, as an example of the development environment potential, two applications created with guiEditor are presented. The assessment made by the students about a third application, called ltitool, which has been used in degree courses to address Process Control topics, is also presented. © 2020 The Authors. Engineering Reports published by John Wiley & Sons Ltd.","calculation software; control system; GNU Octave; GUI","Article","Scopus"
"Ferraz I.N.; Dos Santos C.D., Jr.","Ferraz, Isabela Neves (57204047072); Dos Santos, Carlos Denner (36700519000)","57204047072; 36700519000","Organization of free and open source software projects: In-between the community and traditional governance","2021","Brazilian Business Review","10.15728/BBR.2021.18.3.6","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106391995&doi=10.15728%2fBBR.2021.18.3.6&partnerID=40&md5=c052039536fbdce70df3977e42f64ad1","This work aimed to understand what community-based free software projects are and what governance characteristics (structure and control) differentiate them from traditional organizations, thus spurring further reflections on this business model. A literature review was conducted to outline the main perceptions on this topic, as well as qualitative exploratory research, involving documentary analysis and interviews with four Brazilian participants who work in the management of projects.. The exploratory research was a preliminary contact with the investigated field to make the arguments presented more reliable. Among the reflections, it is observed that even though it is possible to distinguish community-based free software projects from traditional organizations, a crucial factor not always considered are the transformations resulting from the development of these projects. It is necessary that the studies consider the context of functioning, as well as the changes and interorganizational relationships established by the projects over time. Considering these issues, it is believed that approximations between projects and traditional organizations can occur, even if community characteristics are maintained. © 2021 FUCAPE Business School. All rights reserved.","Communities; Control; Free software projects; Governance; Structure","Article","Scopus"
"Lataniotis C.; Marelli S.; Sudret B.","Lataniotis, C. (57190256675); Marelli, S. (25929446300); Sudret, B. (6603259697)","57190256675; 25929446300; 6603259697","The Gaussian Process Modeling Module in UQLab","2018","Journal of Soft Computing in Civil Engineering","10.22115/SCCE.2018.129323.1062","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065700815&doi=10.22115%2fSCCE.2018.129323.1062&partnerID=40&md5=ae6148d5e0e4836b82aab1be9b3bcc5d","We introduce the Gaussian process (GP) modeling module developed within the UQLab software framework. The novel design of the GP-module aims at providing seamless integration of GP modeling into any uncertainty quantification workflow, as well as a standalone surrogate modeling tool. We first briefly present the key mathematical tools on the basis of GP modeling (a.k.a. Kriging), as well as the associated theoretical and computational framework. We then provide an extensive overview of the available features of the software and demonstrate its flexibility and userfriendliness. Finally, we showcase the usage and the performance of the software on several applications borrowed from different fields of engineering. These include a basic surrogate of a well-known analytical benchmark function; a hierarchical Kriging example applied to wind turbine aero-servo-elastic simulations and a more complex geotechnical example that requires a non-stationary, userdefined correlation function. The GP-module, like the rest of the scientific code that is shipped with UQLab, is open source (BSD license). © 2018 The Authors. Published by Pouyan Press.","Gaussian process modeling; Kriging; Matlab; Uncertainty Quantification; UQLab","Article","Scopus"
"Hebrard D.; Bouffier J.; Chadourne-Facon L.; Treinsoutrot D.","Hebrard, Dominique (37072386100); Bouffier, Jacques (36924463100); Chadourne-Facon, Lucie (56563083500); Treinsoutrot, Didier (55355184700)","37072386100; 36924463100; 56563083500; 55355184700","Use of the Orfeo ToolBox: A rise in competence in a collaborative environment; [Utilisation de l'Orfeo ToolBox: Une montee en competence dans un environnement collaboratif]","2015","Revue Francaise de Photogrammetrie et de Teledetection","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925278114&partnerID=40&md5=c20d6c98891492f5ed8c2fb27197e821","The French Ministry of Ecology, Sustainable Development and Energy (MEDDE) has adopted a satellite-based application plan in 2011. This document is a roadmap for its Satellite Application Task Force (&#171; P&#244;le de Comp&#233;tence et d&#39;innovation Application Satellitaires et T&#233;l&#233;communication &#187;: PCI-AST). Among various missions, the plan targets to increase the skills of the departments in using satellite technologies. In this context, PCI-AST is responsible for demonstrating the potential of satellite technologies especially in the field of Earth observation. Once this potential has been demonstrated, the goal is then to disseminate knowledge, methodologies and tools in the services of MEDDE. Various public policies in charge of the MEDDE&#39;s services and implemented by the local authorities are assessed by indicators. These indicators are describing the territories and the dynamic of their evolution. When the information needed to build these indicators are lacking in the usual data base, the usage of satellite technologies can be a relevant asset. At the same time, the growing use of free softwares in administrations encourages the innovative practices. In this way, choosing the Orfeo Toolbox to process satellite images is a natural continuity. Here, the tool is used as a support for a collaborative methodology that aims at involving the ones in charge of the public policies, the GIS specialists and the remote sensing specialists into a global approach. Thus.the Orfeo Toolbox is used for various thematics. Some illustrations of this usage are presented here-one for the characterization of the urban density and another for the localization of the coastline. It is also the privileged tool to implement a pedagogical suitcase for the training of the GIS specialist. The open source license allows considering a large scale deployment with reasonable costs.","","Article","Scopus"
"Aydin A.-K.; Haselden W.D.; Dang J.; Drew P.J.; Charpak S.; Boido D.","Aydin, Ali-Kemal (57217117843); Haselden, William D. (57212149227); Dang, Julie (57221813469); Drew, Patrick J. (27169633500); Charpak, Serge (6701800118); Boido, Davide (57217120547)","57217117843; 57212149227; 57221813469; 27169633500; 6701800118; 57217120547","Iliski, a software for robust calculation of transfer functions","2021","PLoS Computational Biology","10.1371/journal.pcbi.1008614","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108912343&doi=10.1371%2fjournal.pcbi.1008614&partnerID=40&md5=c073c5829c59aa629cb60e466669aac9","Understanding the relationships between biological processes is paramount to unravel pathophysiological mechanisms. These relationships can be modeled with Transfer Functions (TFs), with no need of a priori hypotheses as to the shape of the transfer function. Here we present Iliski, a software dedicated to TFs computation between two signals. It includes different pre-treatment routines and TF computation processes: deconvolution, deterministic and non-deterministic optimization algorithms that are adapted to disparate datasets. We apply Iliski to data on neurovascular coupling, an ensemble of cellular mechanisms that link neuronal activity to local changes of blood flow, highlighting the software benefits and caveats in the computation and evaluation of TFs. We also propose a workflow that will help users to choose the best computation according to the dataset. Iliski is available under the open-source license CC BY 4.0 on GitHub (https://github.com/alike-aydin/Iliski) and can be used on the most common operating systems, either within the MATLAB environment, or as a standalone application. Copyright: © 2021 Aydin et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Article","Scopus"
"Faller D.; Reinheckel T.; Wenzler D.; Hagemann S.; Xiao K.; Honerkamp J.; Peters C.; Dandekar T.; Timmer J.","Faller, Daniel (7005085639); Reinheckel, Thomas (7003754266); Wenzler, Daniel (6508048121); Hagemann, Sascha (7003613639); Xiao, Ke (57206462055); Honerkamp, Josef (7003514869); Peters, Christoph (7402558914); Dandekar, Thomas (7006832936); Timmer, Jens (35510296600)","7005085639; 7003754266; 6508048121; 7003613639; 57206462055; 7003514869; 7402558914; 7006832936; 35510296600","An Open Source Protein Gel Documentation System for Proteome Analyses","2004","Journal of Chemical Information and Computer Sciences","10.1021/ci034174m","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-1542530887&doi=10.1021%2fci034174m&partnerID=40&md5=baf5f1fece45aa2e84739ad981854ec5","Data organization and data mining represents one of the main challenges for modern high throughput technologies in pharmaceutical chemistry and medical chemistry. The presented open source documentation and analysis system provides an integrated solution (tutorial, setup protocol, sources, executables) aimed at substituting the traditionally used lab-book. The data management solution provided incorporates detailed information about the processing of the gels and the experimental conditions used and includes basic data analysis facilities which can be easily extended. The sample database and User-Interface are available free of charge under the GNU license from http://webber.physik.uni- freiburg.de/~fallerd/tutorial.htm.","","Article","Scopus"
"Pelletier D.; Rouxel J.; Fauvarque O.; Hanon D.; Gestalin J.-P.; Lebot M.; Dreano P.; Furet E.; Tardivel M.; Bras Y.L.; Royaux C.; Leguen G.","Pelletier, Dominique (7101836602); Rouxel, Justin (55934179200); Fauvarque, Olivier (55542484000); Hanon, David (57345273100); Gestalin, Jean-Paul (57344673200); Lebot, Morgann (57345430300); Dreano, Paul (57344967300); Furet, Enora (57345273200); Tardivel, Morgan (57194454293); Bras, Yvan Le (57192403623); Royaux, Coline (57226793448); Leguen, Guillaume (57345430400)","7101836602; 55934179200; 55542484000; 57345273100; 57344673200; 57345430300; 57344967300; 57345273200; 57194454293; 57192403623; 57226793448; 57345430400","Kosmos: An open source underwater video lander for monitoring coastal fishes and habitats","2021","Sensors","10.3390/s21227724","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119319666&doi=10.3390%2fs21227724&partnerID=40&md5=6eb3cc7d70f486d0db1b5e1ac4e6bc40","Background: Monitoring the ecological status of coastal ecosystems is essential to track the consequences of anthropogenic pressures and assess conservation actions. Monitoring requires periodic measurements collected in situ, replicated over large areas and able to capture their spatial distribution over time. This means developing tools and protocols that are cost-effective and provide consistent and high-quality data, which is a major challenge. A new tool and protocol with these capabilities for non-extractively assessing the status of fishes and benthic habitats is presented here: the KOSMOS 3.0 underwater video system. Methods: The KOSMOS 3.0 was conceived based on the pre-existing and successful STAVIRO lander, and developed within a digital fabrication laboratory where collective intelligence was contributed mostly voluntarily within a managed project. Our suite of mechanical, electrical, and software engineering skills were combined with ecological knowledge and field work experience. Results: Pool and aquarium tests of the KOSMOS 3.0 satisfied all the required technical specifications and operational testing. The prototype demonstrated high optical performance and high consistency with image data from the STAVIRO. The project’s outcomes are shared under a Creative Commons Attribution CC-BY-SA license. The low cost of a KOSMOS unit (~1400 €) makes multiple units affordable to modest research or monitoring budgets. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Benthic habitat; Citizen science; Coastal ecosystems; Collective intelligence; Fishes; Monitoring; Open source; STAVIRO; Underwater video","Article","Scopus"
"Rutter L.; Cook D.","Rutter, Lindsay (41361774200); Cook, Dianne (7403472483)","41361774200; 7403472483","bigPint: A Bioconductor visualization package that makes big data pint-sized","2020","PLoS Computational Biology","10.1371/journal.pcbi.1007912","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087876354&doi=10.1371%2fjournal.pcbi.1007912&partnerID=40&md5=94f1cd84aa4c3f2abbbdef82796f2e3b","Interactive data visualization is imperative in the biological sciences. The development of independent layers of interactivity has been in pursuit in the visualization community. We developed bigPint, a data visualization package available on Bioconductor under the GPL-3 license (https://bioconductor.org/packages/release/bioc/html/bigPint.html). Our software introduces new visualization technology that enables independent layers of interactivity using Plotly in R, which aids in the exploration of large biological datasets. The bigPint package presents modernized versions of scatterplot matrices, volcano plots, and litre plots through the implementation of layered interactivity. These graphics have detected normalization issues, differential expression designation problems, and common analysis errors in public RNA-sequencing datasets. Researchers can apply bigPint graphics to their data by following recommended pipelines written in reproducible code in the user manual. In this paper, we explain how we achieved the independent layers of interactivity that are behind bigPint graphics. Pseudocode and source code are provided. Computational scientists can leverage our open-source code to expand upon our layered interactive technology and/or apply it in new ways toward other computational biology tasks.  © 2020 Rutter, Cook.","","Article","Scopus"
"Lemire D.; Kaser O.; Kurz N.; Deri L.; O'Hara C.; Saint-Jacques F.; Ssi-Yan-Kai G.","Lemire, Daniel (10238969400); Kaser, Owen (57207523414); Kurz, Nathan (56594618300); Deri, Luca (6602182293); O'Hara, Chris (57200284870); Saint-Jacques, François (57200275226); Ssi-Yan-Kai, Gregory (57188855526)","10238969400; 57207523414; 56594618300; 6602182293; 57200284870; 57200275226; 57188855526","Roaring bitmaps: Implementation of an optimized software library","2018","Software - Practice and Experience","10.1002/spe.2560","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040591046&doi=10.1002%2fspe.2560&partnerID=40&md5=de2a2877db59ba2569eedb074940e5cc","Compressed bitmap indexes are used in systems such as Git or Oracle to accelerate queries. They represent sets and often support operations such as unions, intersections, differences, and symmetric differences. Several important systems such as Elasticsearch, Apache Spark, Netflix's Atlas, LinkedIn's Pivot, Metamarkets' Druid, Pilosa, Apache Hive, Apache Tez, Microsoft Visual Studio Team Services, and Apache Kylin rely on a specific type of compressed bitmap index called Roaring. We present an optimized software library written in C implementing Roaring bitmaps: CRoaring. It benefits from several algorithms designed for the single-instruction–multiple-data instructions available on commodity processors. In particular, we present vectorized algorithms to compute the intersection, union, difference, and symmetric difference between arrays. We benchmark the library against a wide range of competitive alternatives, identifying weaknesses and strengths in our software. Our work is available under a liberal open-source license. Copyright © 2018 John Wiley & Sons, Ltd.","bitmap indexes; database indexes; Jaccard index; SIMD instructions; vectorization","Article","Scopus"
"Oliphant T.E.","Oliphant, Travis E. (57223409879)","57223409879","Python for scientific computing","2007","Computing in Science and Engineering","10.1109/MCSE.2007.58","2282","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34247500374&doi=10.1109%2fMCSE.2007.58&partnerID=40&md5=5789c03dcb5cc88f20d42eedee7cef64","Python is an interpreted language with expressive syntax, which transforms itself into a high-level language suited for scientific and engineering code. Some of its features include a liberal open source license, ability to run on many platforms, powerful interactive interpreter, ability to expand with earlier compiled code, ability to interact with a wide variety of other software, and a large number of library modules. An important factor in the utility of Python as a computing language is its clear syntax, which can make code easy to understand and maintain. This language also contributes to the construction of maintainable code by separating code into logical groups such as modules, class, and functions, in addition to offering clean syntax. Python can be easily extended with a large C-API for calling Python functionality from C programming language, connecting to non-Python compiled code, and extending the language itself by creating new Python types in C language.","","Article","Scopus"
"Ozden S.G.; Smith A.E.; Gue K.R.","Ozden, S.G. (57193897060); Smith, A.E. (7406755420); Gue, K.R. (6602427511)","57193897060; 7406755420; 6602427511","A computational software system to design order picking warehouses","2021","Computers and Operations Research","10.1016/j.cor.2021.105311","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105691020&doi=10.1016%2fj.cor.2021.105311&partnerID=40&md5=48d799ee2fa7becbf7cbcbcdd48f41ed","Even though order picking is the most costly operation in a warehouse, current design practices have used the same principles (straight rows with parallel pick aisles and perpendicular cross aisles) to reduce travel distances between pick locations for more than sixty years. We present an open-source computational software system for facilitating the design of warehouse layouts to near-optimality considering average walking distance of the picker as the objective function. This software is particularly novel because a wide variety of traditional and innovative designs are automatically generated and evaluated. For the warehouse design parameters we consider the rectangular aspect ratio of the floor plan, the number and location of cross aisles, the number and location of pick aisles, and the location of a single input/output location. The main components of the design system are importing pick list profile data, creating the warehouse layout design as a network, product allocation (slotting) of SKUs through the warehouse, routing of pickers on a sample of orders using an exact routing algorithm, and design optimization using a meta-heuristic. We provide both mathematical and computational descriptions of the algorithms used by the software system, describe the types of problems that can be solved, and summarize our computational experience. This software is open source available on a GitHub website under an MIT license. © 2021 Elsevier Ltd","Computational tool; Open source; Optimization; Warehouse design","Article","Scopus"
"Geramifard A.; Dann C.; Klein R.H.; Dabney W.; How J.P.","Geramifard, Alborz (15055567000); Dann, Christoph (55352624000); Klein, Robert H. (56422992100); Dabney, William (55364888900); How, Jonathan P. (7006512768)","15055567000; 55352624000; 56422992100; 55364888900; 7006512768","RLPy: A value-function-based reinforcement learning framework for education and research","2015","Journal of Machine Learning Research","","33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962209748&partnerID=40&md5=1448c7df4e417889ab10535cba0d3910","RLPy is an object-oriented reinforcement learning software package with a focus on valuefunction-based methods using linear function approximation and discrete actions. The framework was designed for both educational and research purposes. It provides a rich library of fine-grained, easily exchangeable components for learning agents (e.g., policies or representations of value functions), facilitating recently increased specialization in reinforcement learning. RLPy is written in Python to allow fast prototyping, but is also suitable for large-scale experiments through its built-in support for optimized numerical libraries and parallelization. Code profiling, domain visualizations, and data analysis are integrated in a self-contained package available under the Modified BSD License at http://github.com/rlpy/rlpy. All of these properties allow users to compare various reinforcement learning algorithms with little effort. © 2015 Alborz Geramifard, Christoph Dann, Robert H. Klein, William Dabney, and Jonathan P. How.","Empirical evaluation; Open source; Reinforcement learning; Value-function","Article","Scopus"
"Melchert O.; Demircan A.","Melchert, Oliver (24450581400); Demircan, Ayhan (7004830314)","24450581400; 7004830314","GNLStools.py: A generalized nonlinear Schrödinger Python module implementing different models of input pulse quantum noise","2022","SoftwareX","10.1016/j.softx.2022.101232","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142455490&doi=10.1016%2fj.softx.2022.101232&partnerID=40&md5=5780166e1e98f6c4f0dce5eb97af102b","We provide Python tools enabling numerical simulation and analysis of the propagation dynamics of ultrashort laser pulses in nonlinear waveguides. The modeling approach is based on the widely used generalized nonlinear Schrödinger equation for the pulse envelope. The presented software implements the effects of linear dispersion, pulse self-steepening, and the Raman effect. The focus lies on the implementation of input pulse shot noise, i.e. classical background fields that mimic quantum noise, which are often not thoroughly presented in the scientific literature. We discuss and implement commonly adopted quantum noise models based on pure spectral phase noise, as well as Gaussian noise. Coherence properties of the resulting spectra can be calculated. We demonstrate the functionality of the software by reproducing results for a supercontinuum generation process in a photonic crystal fiber, documented in the scientific literature. The presented Python tools are open-source and released under the MIT license in a publicly available software repository. © 2022 The Author(s)","Generalized nonlinear Schrödinger equation; Python; Quantum noise; Spectral coherence","Article","Scopus"
"Zagordi O.; Bhattacharya A.; Eriksson N.; Beerenwinkel N.","Zagordi, Osvaldo (27268092100); Bhattacharya, Arnab (57191736906); Eriksson, Nicholas (57207894876); Beerenwinkel, Niko (57203029155)","27268092100; 57191736906; 57207894876; 57203029155","ShoRAH: Estimating the genetic diversity of a mixed sample from next-generation sequencing data","2011","BMC Bioinformatics","10.1186/1471-2105-12-119","193","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955125679&doi=10.1186%2f1471-2105-12-119&partnerID=40&md5=cc9f18fc90fe717878e087a7fae822bf","Background: With next-generation sequencing technologies, experiments that were considered prohibitive only a few years ago are now possible. However, while these technologies have the ability to produce enormous volumes of data, the sequence reads are prone to error. This poses fundamental hurdles when genetic diversity is investigated.Results: We developed ShoRAH, a computational method for quantifying genetic diversity in a mixed sample and for identifying the individual clones in the population, while accounting for sequencing errors. The software was run on simulated data and on real data obtained in wet lab experiments to assess its reliability.Conclusions: ShoRAH is implemented in C++, Python, and Perl and has been tested under Linux and Mac OS X. Source code is available under the GNU General Public License at http://www.cbg.ethz.ch/software/shorah. © 2011 Zagordi et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Thielen B.; Heinen S.; Schomburg D.","Thielen, Bernhard (15761297200); Heinen, Stephanie (33867598300); Schomburg, Dietmar (15920858600)","15761297200; 33867598300; 15920858600","mSpecs: A software tool for the administration and editing of mass spectral libraries in the field of metabolomics","2009","BMC Bioinformatics","10.1186/1471-2105-10-229","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-69349086671&doi=10.1186%2f1471-2105-10-229&partnerID=40&md5=c1fffdbb24eff2be3dd73c69c6aa3abb","Background: Metabolome analysis with GC/MS has meanwhile been established as one of the ""omics"" techniques. Compound identification is done by comparison of the MS data with compound libraries. Mass spectral libraries in the field of metabolomics ought to connect the relevant mass traces of the metabolites to other relevant data, e.g. formulas, chemical structures, identification numbers to other databases etc. Since existing solutions are either commercial and therefore only available for certain instruments or not capable of storing such information, there is need to provide a software tool for the management of such data. Results: Here we present mSpecs, an open source software tool to manage mass spectral data in the field of metabolomics. It provides editing of mass spectra and virtually any associated information, automatic calculation of formulas and masses and is extensible by scripts. The graphical user interface is capable of common techniques such as copy/ paste, undo/redo and drag and drop. It owns import and export filters for the major public file formats in order to provide compatibility to commercial instruments. Conclusion: mSpecs is a versatile tool for the management and editing of mass spectral libraries in the field of metabolomics. Beyond that it provides capabilities for the automatic management of libraries though its scripting functionality. mSpecs can be used on all major platforms and is licensed under the GNU General Public License and available at http://mspecs.tu-bs.de. © 2009 Thielen et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Mader C.A.; Kenway G.K.W.; Yildirim A.; Martins J.R.R.A.","Mader, Charles A. (24338338200); Kenway, Gaetan K. W. (57203187352); Yildirim, Anil (57210816597); Martins, Joaquim R. R. A. (57203217536)","24338338200; 57203187352; 57210816597; 57203217536","ADflow: An open-source computational fluid dynamics solver for aerodynamic and multidisciplinary optimization","2020","Journal of Aerospace Information Systems","10.2514/1.I010796","64","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090328865&doi=10.2514%2f1.I010796&partnerID=40&md5=d84ba4796f8be1cd718432794da723b8","Computational fluid dynamics through the solution of the Navier–Stokes equations with turbulence models has become commonplace. However, simply solving these equations is not sufficient to be able to perform efficient design optimization with a flow solver in the loop. This paper discusses the recommendations for developing a flow solver that is suitable for efficient aerodynamic and multidisciplinary design optimization. One of the major recommendations is to be able to load the flow solver as a library that provides direct memory access to the relevant data. Other recommendations are to use a higher-level language for scripting and to pay special attention to solution warm starting, code efficiency, flow solver robustness, and solution failure handling. As an example of a flow solver that follows these recommendations, the open-source flow solver ADflow is presented. Results from aerodynamic optimization, aerostructural analysis, and aerostructural optimization using ADflow demonstrate the performance advantages claimed in the recommendations. The publication of these recommendations and the availability of the source code open the door for other solvers to adopt the same application programming interface. ADflow is part of a wider aerodynamic shape optimization tool suite that is also available under an open-source license. © 2020 by Charles A. Mader, Gaetan K.W. Kenway, Anil Yildirim, and Joaquim R.R.A.","","Article","Scopus"
"Cunningham H.; Tablan V.; Roberts A.; Bontcheva K.","Cunningham, Hamish (56249644700); Tablan, Valentin (55951946200); Roberts, Angus (7404499087); Bontcheva, Kalina (6602790600)","56249644700; 55951946200; 7404499087; 6602790600","Getting More Out of Biomedical Documents with GATE's Full Lifecycle Open Source Text Analytics","2013","PLoS Computational Biology","10.1371/journal.pcbi.1002854","244","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874763020&doi=10.1371%2fjournal.pcbi.1002854&partnerID=40&md5=13bc05b975b19fb077f41e1d85492228","This software article describes the GATE family of open source text analysis tools and processes. GATE is one of the most widely used systems of its type with yearly download rates of tens of thousands and many active users in both academic and industrial contexts. In this paper we report three examples of GATE-based systems operating in the life sciences and in medicine. First, in genome-wide association studies which have contributed to discovery of a head and neck cancer mutation association. Second, medical records analysis which has significantly increased the statistical power of treatment/outcome models in the UK's largest psychiatric patient cohort. Third, richer constructs in drug-related searching. We also explore the ways in which the GATE family supports the various stages of the lifecycle present in our examples. We conclude that the deployment of text mining for document abstraction or rich search and navigation is best thought of as a process, and that with the right computational tools and data collection strategies this process can be made defined and repeatable. The GATE research programme is now 20 years old and has grown from its roots as a specialist development tool for text processing to become a rather comprehensive ecosystem, bringing together software developers, language engineers and research staff from diverse fields. GATE now has a strong claim to cover a uniquely wide range of the lifecycle of text analysis systems. It forms a focal point for the integration and reuse of advances that have been made by many people (the majority outside of the authors' own group) who work in text processing for biomedicine and other areas. GATE is available online <1> under GNU open source licences and runs on all major operating systems. Support is available from an active user and developer community and also on a commercial basis. © 2013 Cunningham et al.","","Article","Scopus"
"Eckels J.; Nathe C.; Nelson E.K.; Shoemaker S.G.; Nostrand E.V.; Yates N.L.; Ashley V.C.; Harris L.J.; Bollenbeck M.; Fong Y.; Tomaras G.D.; Piehler B.","Eckels, Josh (37053561400); Nathe, Cory (25652112100); Nelson, Elizabeth K. (37054544100); Shoemaker, Sara G. (7006515928); Nostrand, Elizabeth V. (55757623500); Yates, Nicole L. (26021617300); Ashley, Vicki C. (56392824200); Harris, Linda J. (35740330800); Bollenbeck, Mark (57225232890); Fong, Youyi (52063251000); Tomaras, Georgia D. (6507517468); Piehler, Britt (37054387000)","37053561400; 25652112100; 37054544100; 7006515928; 55757623500; 26021617300; 56392824200; 35740330800; 57225232890; 52063251000; 6507517468; 37054387000","Quality control, analysis and secure sharing of Luminex® immunoassay data using the open source LabKey Server platform","2013","BMC Bioinformatics","10.1186/1471-2105-14-145","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876790151&doi=10.1186%2f1471-2105-14-145&partnerID=40&md5=58d38659bca401a02641de3d8ebf54a5","Background: Immunoassays that employ multiplexed bead arrays produce high information content per sample. Such assays are now frequently used to evaluate humoral responses in clinical trials. Integrated software is needed for the analysis, quality control, and secure sharing of the high volume of data produced by such multiplexed assays. Software that facilitates data exchange and provides flexibility to perform customized analyses (including multiple curve fits and visualizations of assay performance over time) could increase scientists' capacity to use these immunoassays to evaluate human clinical trials.Results: The HIV Vaccine Trials Network and the Statistical Center for HIV/AIDS Research and Prevention collaborated with LabKey Software to enhance the open source LabKey Server platform to facilitate workflows for multiplexed bead assays. This system now supports the management, analysis, quality control, and secure sharing of data from multiplexed immunoassays that leverage Luminex xMAP® technology. These assays may be custom or kit-based. Newly added features enable labs to: (i) import run data from spreadsheets output by Bio-Plex Manager™ software; (ii) customize data processing, curve fits, and algorithms through scripts written in common languages, such as R; (iii) select script-defined calculation options through a graphical user interface; (iv) collect custom metadata for each titration, analyte, run and batch of runs; (v) calculate dose-response curves for titrations; (vi) interpolate unknown concentrations from curves for titrated standards; (vii) flag run data for exclusion from analysis; (viii) track quality control metrics across runs using Levey-Jennings plots; and (ix) automatically flag outliers based on expected values. Existing system features allow researchers to analyze, integrate, visualize, export and securely share their data, as well as to construct custom user interfaces and workflows.Conclusions: Unlike other tools tailored for Luminex immunoassays, LabKey Server allows labs to customize their Luminex analyses using scripting while still presenting users with a single, graphical interface for processing and analyzing data. The LabKey Server system also stands out among Luminex tools for enabling smooth, secure transfer of data, quality control information, and analyses between collaborators. LabKey Server and its Luminex features are freely available as open source software at http://www.labkey.com under the Apache 2.0 license. © 2013 Eckels et al.; licensee BioMed Central Ltd.","","Article","Scopus"
"Khramtsova E.A.; Stranger B.E.","Khramtsova, Ekaterina A. (57194755585); Stranger, Barbara E. (6507901873)","57194755585; 6507901873","Assocplots: A Python package for static and interactive visualization of multiple-group GWAS results","2017","Bioinformatics","10.1093/bioinformatics/btw641","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046719843&doi=10.1093%2fbioinformatics%2fbtw641&partnerID=40&md5=65d060e3bf3cf65d1fefb95fcbb0076a","Over the last decade, genome-wide association studies (GWAS) have generated vast amounts of analysis results, requiring development of novel tools for data visualization. Quantile-quantile (QQ) plots and Manhattan plots are classical tools which have been utilized to visually summarize GWAS results and identify genetic variants significantly associated with traits of interest. However, static visualizations are limiting in the information that can be shown. Here, we present Assocplots, a Python package for viewing and exploring GWAS results not only using classic static Manhattan and QQ plots, but also through a dynamic extension which allows to interactively visualize the relationships between GWAS results from multiple cohorts or studies. Availability and Implementation: The Assocplots package is open source and distributed under the MIT license via GitHub (https://github.com/khramts/assocplots) along with examples, documentation and installation instructions. © 2016 The Authors 2016. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com.","","Article","Scopus"
"De Oliveira Martins L.; Bloomfield S.; Stoakes E.; Grant A.J.; Page A.J.; Mather A.E.","De Oliveira Martins, Leonardo (18436304900); Bloomfield, Samuel (57194380704); Stoakes, Emily (57217632502); Grant, Andrew J. (10045178700); Page, Andrew J. (9736752200); Mather, Alison E. (16319287800)","18436304900; 57194380704; 57217632502; 10045178700; 9736752200; 16319287800","Tatajuba: Exploring the distribution of homopolymer tracts","2022","NAR Genomics and Bioinformatics","10.1093/nargab/lqac003","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125142108&doi=10.1093%2fnargab%2flqac003&partnerID=40&md5=840bb0c1fbc6e51ac2c697ed5d8712d2","Length variation of homopolymeric tracts, which induces phase variation, is known to regulate gene expression leading to phenotypic variation in a wide range of bacterial species. There is no specialized bioinformatics software which can, at scale, exhaustively explore and describe these features from sequencing data. Identifying these is non-trivial as sequencing and bioinformatics methods are prone to introducing artefacts when presented with homopolymeric tracts due to the decreased base diversity. We present tatajuba, which can automatically identify potential homopolymeric tracts and help predict their putative phenotypic impact, allowing for rapid investigation. We use it to detect all tracts in two separate datasets, one of Campylobacter jejuni and one of three Bordetella species, and to highlight those tracts that are polymorphic across samples. With this we confirm homopolymer tract variation with phenotypic impact found in previous studies and additionally find many more with potential variability. The software is written in C and is available under the open source licence GNU GPLv3.  © 2022 The Author(s). Published by Oxford University Press on behalf of NAR Genomics and Bioinformatics.","","Article","Scopus"
"Dafermos G.; van Eeten M.J.G.","Dafermos, George (15077793000); van Eeten, Michel J.G. (6603185658)","15077793000; 6603185658","Images of innovation in discourses of free and open source software","2014","First Monday","10.5210/fm.v19i12.4210","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920268650&doi=10.5210%2ffm.v19i12.4210&partnerID=40&md5=f1b52918a029f0721c4a05d4b7b78146","In this study, we examine the relationship between innovation and free/open source software (FOSS) based on the views of contributors to FOSS projects, using Q methodology as a method of discourse analysis to make visible the positions held by FOSS contributors and identify the discourses encountered in the FOSS community. In specific, our analysis reveals four discourses: four ways of expressing oneself used by FOSS contributors, which, aside from certain commonalities, postulate fundamentally different conceptions of innovation. Whereas the dispersion of FOSS contributors' subjectivity across four different discourses is indicative of the diversity and heterogeneity of the FOSS community, their commonalities, however, demarcate a common ground that all discourses share: points of agreement include the negative effect of patents on innovation, the predominant role of end users over manufacturers in the innovation process and the embrace of FOSS licenses as a key enabler of innovation. In the conclusion, we outline some implications for innovation management and policy. © First Monday, 1995-2014.","","Article","Scopus"
"Drwięga M.; Jakubiak J.","Drwięga, Michał (57188982331); Jakubiak, Janusz (6601982021)","57188982331; 6601982021","A set of depth sensor processing ros tools for wheeled mobile robot navigation","2017","Journal of Automation, Mobile Robotics and Intelligent Systems","10.14313/JAMRIS_2-2017/16","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021288078&doi=10.14313%2fJAMRIS_2-2017%2f16&partnerID=40&md5=dc78336475b14351b6ef1bb2bb5d0ab3","The paper presents a set of software tools dedicated to support mobile robot navigation. The tools are used to process an image from a depth sensor. They are imple­mented in ROS framework and they are compatible with standard ROS navigation packages. The software is relea­sed with an open source licence. First of the tools converts a 3D depth image to a 2D scan in polar coordinates. It provides projection of the obstacles, removes the ground plane from the image and compensates sensor tilt an­gle. The node is faster than the standard node within ROS and it has additional functions increasing range of possi­ble applications. The second tool allows detection of ne­gative obstacles i.e. located below the ground plane le­vel. The third tool estimates height and orientation of the sensor with RANSAC algorithm applied to the depth image. The paper presents also the results of usage of the tools with mobile platforms equipped with Microsoft Kinect sensors. The platforms are elements of the ReMeDi project within which the software was developed. © 2017, Industrial Research Institute for Automation and Measurements. All rights reserved.","Depth sensor; Kinect; Mobile robot; Navigation tools; RGB-D; ROS","Article","Scopus"
"Kopczynski D.; Barsnes H.; Njølstad P.R.; Sickmann A.; Vaudel M.; Ahrends R.","Kopczynski, Dominik (55497506800); Barsnes, Harald (12785887600); Njølstad, Pål R. (7004591440); Sickmann, Albert (7004512650); Vaudel, Marc (35560103600); Ahrends, Robert (6505716989)","55497506800; 12785887600; 7004591440; 7004512650; 35560103600; 6505716989","PeptideMapper: Efficient and versatile amino acid sequence and tag mapping","2017","Bioinformatics","10.1093/bioinformatics/btx122","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021825553&doi=10.1093%2fbioinformatics%2fbtx122&partnerID=40&md5=b5f2a2261190851f50211cfed0a30f23","The mapping of amino acid sequences is an essential task in bioinformatics. Notably, the mapping of peptide sequences on a proteome is required for the post-processing of proteomics results. However, this step can quickly become a bottleneck when working with extensive numbers of peptides or large protein sequence databases. Here, we present PeptideMapper, a novel amino acid sequence mapper for both peptide sequences and de novo sequencing identification results. By taking advantage of the latest advances in pattern matching, PeptideMapper achieves unprecedented performance (i.e. up to 1000 faster than state-of-the-art software) in terms of memory footprint and execution speed, with regards to both the indexing and the querying of protein sequence databases. Availability and Implementation: PeptideMapper is implemented in the open source Java CompOmics framework under the permissive Apache 2.0 license https://github.com/compomics/compomics-utilities. © 2017 The Author.","","Article","Scopus"
"Casadesus-Masanell R.; Llanes .G.","Casadesus-Masanell, Ramon (6507426720); Llanes, Gastón (36651127800)","6507426720; 36651127800","Mixed source","2011","Management Science","10.1287/mnsc.1110.1353","58","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960400872&doi=10.1287%2fmnsc.1110.1353&partnerID=40&md5=42ac4d9f0404975d84abee7175591137","We study competitive interaction between a profit-maximizing firm that sells software and complementary services, and a free open-source competitor. We examine the firm's choice of business model between the proprietary model (where all software modules are proprietary), the open-source model (where all modules are open source), and the mixed-source model (where some-but not all-modules are open). When a module is opened, users can access and improve the code, which increases quality and value creation. Opened modules, however, are available for others to use free of charge. We derive the set of possibly optimal business models when the modules of the firm and the open-source competitor are compatible (and thus can be combined) and incompatible, and show that (i) when the firm's modules are of high (low) quality, the firm is more open under incompatibility (compatibility) than under compatibility (incompatibility); (ii) firms are more likely to open substitute, rather than complementary, modules to existing open-source projects; and (iii) there may be no trade-off between value creation and value capture when comparing business models with different degrees of openness. © 2011 INFORMS.","Business models; Compatibility; Complementarity; Open source; User innovation; Value capture; Value creation","Article","Scopus"
"Balci H.; Dogrusoz U.; Ozgul Y.Z.; Atayev P.","Balci, Hasan (57192187830); Dogrusoz, Ugur (6602520561); Ozgul, Yusuf Ziya (57987023100); Atayev, Perman (57987072400)","57192187830; 6602520561; 57987023100; 57987072400","SyBLaRS: A web service for laying out, rendering and mining biological maps in SBGN, SBML and more","2022","PLoS Computational Biology","10.1371/journal.pcbi.1010635","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142940939&doi=10.1371%2fjournal.pcbi.1010635&partnerID=40&md5=bdbfc90bb550cf2c5f810f7b7e403343","Visualization is a key recurring requirement for effective analysis of relational data. Biology is no exception. It is imperative to annotate and render biological models in standard, widely accepted formats. Finding graph-theoretical properties of pathways as well as identifying certain paths or subgraphs of interest in a pathway are also essential for effective analysis of pathway data. Given the size of available biological pathway data nowadays, automatic layout is crucial in understanding the graphical representations of such data. Even though there are many available software tools that support graphical display of biological pathways in various formats, there is none available as a service for on-demand or batch processing of biological pathways for automatic layout, customized rendering and mining paths or subgraphs of interest. In addition, there are many tools with fine rendering capabilities lacking decent automatic layout support. To fill this void, we developed a web service named SyBLaRS (Systems Biology Layout and Rendering Service) for automatic layout of biological data in various standard formats as well as construction of customized images in both raster image and scalable vector formats of these maps. Some of the supported standards are more generic such as GraphML and JSON, whereas others are specialized to biology such as SBGNML (The Systems Biology Graphical Notation Markup Language) and SBML (The Systems Biology Markup Language). In addition, SyBLaRS supports calculation and highlighting of a number of wellknown graph-theoretical properties as well as some novel graph algorithms turning a specified set of objects of interest to a minimal pathway of interest. We demonstrate that SyBLaRS can be used both as an offline layout and rendering service to construct customized and annotated pictures of pathway models and as an online service to provide layout and rendering capabilities for systems biology software tools. SyBLaRS is open source and publicly available on GitHub and freely distributed under the MIT license. In addition, a sample deployment is available here for public consumption.  © 2022 Balci et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Article","Scopus"
"Liu X.; Yu Q.; Liao J.","Liu, Xiaoyan (56021214600); Yu, Qing (56415517700); Liao, Jianwei (14016090000)","56021214600; 56415517700; 14016090000","Fastdfs: A high performance distributed file system","2014","ICIC Express Letters, Part B: Applications","","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910146071&partnerID=40&md5=d8b96fba9d2ae0526fbf33cc8419899b","FastDFS is a lightweight, high performance distributed file system under the GNU General Public License; it uses a large amount of limited storage devices to solve the problems of managing a large number of files, and then supports highly concurrent I/O accesses, load balancing and adjusting the capacity of storage servers on the fly. The FastDFS file system can be merged with HTTP web servers, such as Apache web server and nginx, through using extensible module. Thus, it is quite suitable to provide I/O services for Internet applications including photo album and online video. © 2014 ICIC International.","Fault-tolerance; High performance; Lightweight distributed file system; Open source software","Article","Scopus"
"Fournier-Viger P.; Gomariz A.; Gueniche T.; Soltani A.; Wu C.-W.; Tseng V.S.","Fournier-Viger, Philippe (14048484800); Gomariz, Antonio (35748362800); Gueniche, Ted (55566766300); Soltani, Azadeh (14123895600); Wu, Cheng-Wei (8964576200); Tseng, Vincent S. (6507335623)","14048484800; 35748362800; 55566766300; 14123895600; 8964576200; 6507335623","SPMF: A java open-source pattern mining library","2015","Journal of Machine Learning Research","","322","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919772030&partnerID=40&md5=b0bc253fd9e34ac60aff32c348bbfe32","We present SPMF, an open-source data mining library offering implementations of more than 55 data mining algorithms. SPMF is a cross-platform library implemented in Java, specialized for discovering patterns in transaction and sequence databases such as frequent itemsets, association rules and sequential patterns. The source code can be integrated in other Java programs. Moreover, SPMF offers a command line interface and a simple graphical interface for quick testing. The source code is available under the GNU General Public License, version 3. The website of the project offers several resources such as documentation with examples of how to run each algorithm, a developer's guide, performance comparisons of algorithms, data sets, an active forum, a FAQ and a mailing list. ©2014 Philippe Fournier-Viger, Antonio Gomariz, Ted Gueniche, Azadeh Soltani, Cheng-Wei Wu, Vincent S. Tseng.","Data mining; Frequent pattern mining; Library; Open-source; Sequence database; Transaction database","Article","Scopus"
"Kutmon M.; van Iersel M.P.; Bohler A.; Kelder T.; Nunes N.; Pico A.R.; Evelo C.T.","Kutmon, Martina (36483203500); van Iersel, Martijn P. (24484040800); Bohler, Anwesha (56543191700); Kelder, Thomas (24450676300); Nunes, Nuno (56542990100); Pico, Alexander R. (17342562100); Evelo, Chris T. (7003950754)","36483203500; 24484040800; 56543191700; 24450676300; 56542990100; 17342562100; 7003950754","PathVisio 3: An Extendable Pathway Analysis Toolbox","2015","PLoS Computational Biology","10.1371/journal.pcbi.1004085","267","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924370843&doi=10.1371%2fjournal.pcbi.1004085&partnerID=40&md5=8f77c88b9d837974bce6dbb54e424351","PathVisio is a commonly used pathway editor, visualization and analysis software. Biological pathways have been used by biologists for many years to describe the detailed steps in biological processes. Those powerful, visual representations help researchers to better understand, share and discuss knowledge. Since the first publication of PathVisio in 2008, the original paper was cited more than 170 times and PathVisio was used in many different biological studies. As an online editor PathVisio is also integrated in the community curated pathway database WikiPathways.Here we present the third version of PathVisio with the newest additions and improvements of the application. The core features of PathVisio are pathway drawing, advanced data visualization and pathway statistics. Additionally, PathVisio 3 introduces a new powerful extension systems that allows other developers to contribute additional functionality in form of plugins without changing the core application.PathVisio can be downloaded from http://www.pathvisio.org and in 2014 PathVisio 3 has been downloaded over 5,500 times. There are already more than 15 plugins available in the central plugin repository. PathVisio is a freely available, open-source tool published under the Apache 2.0 license (http://www.apache.org/licenses/LICENSE-2.0). It is implemented in Java and thus runs on all major operating systems. The code repository is available at http://svn.bigcat.unimaas.nl/pathvisio. The support mailing list for users is available on https://groups.google.com/forum/#!forum/wikipathways-discuss and for developers on https://groups.google.com/forum/#!forum/wikipathways-devel. © 2015 Kutmon et al.","","Article","Scopus"
"Abeel T.; Van De Peer Y.; Saeys Y.","Abeel, Thomas (18533730700); Van De Peer, Yves (7006594796); Saeys, Yvan (6507925214)","18533730700; 7006594796; 6507925214","Java-ML: A machine learning library","2009","Journal of Machine Learning Research","","95","https://www.scopus.com/inward/record.uri?eid=2-s2.0-66549101951&partnerID=40&md5=141e242284c0e77159c222173827689b","Java-ML is a collection of machine learning and data mining algorithms, which aims to be a readily usable and easily extensible API for both software developers and research scientists. The interfaces for each type of algorithm are kept simple and algorithms strictly follow their respective interface. Comparing different classifiers or clustering algorithms is therefore straightforward, and implementing new algorithms is also easy. The implementations of the algorithms are clearly written, properly documented and can thus be used as a reference. The library is written in Java and is available from http://java-ml.sourceforge.net/ under the GNU GPL license. © 2009 Thomas Abeel.Yves de peer Yvan Saeys.","Classification; Clustering; Data mining; Feature selection; Java library; Machine learning; Open source","Article","Scopus"
"Spjuth O.; Alvarsson J.; Berg A.; Eklund M.; Kuhn S.; Mäsak C.; Torrance G.; Wagener J.; Willighagen E.L.; Steinbeck C.; Wikberg J.E.S.","Spjuth, Ola (12808508000); Alvarsson, Jonathan (35301938000); Berg, Arvid (35301750600); Eklund, Martin (16033089900); Kuhn, Stefan (7103392232); Mäsak, Carl (35303101700); Torrance, Gilleain (8632590000); Wagener, Johannes (15758600000); Willighagen, Egon L. (6507481906); Steinbeck, Christoph (7003655166); Wikberg, Jarl E.S. (7101610239)","12808508000; 35301938000; 35301750600; 16033089900; 7103392232; 35303101700; 8632590000; 15758600000; 6507481906; 7003655166; 7101610239","Bioclipse 2: A scriptable integration platform for the life sciences","2009","BMC Bioinformatics","10.1186/1471-2105-10-397","50","https://www.scopus.com/inward/record.uri?eid=2-s2.0-74049154443&doi=10.1186%2f1471-2105-10-397&partnerID=40&md5=a5be68f3d72a40f6d47747fa07d1a62c","Background: Contemporary biological research integrates neighboring scientific domains to answer complex questions in fields such as systems biology and drug discovery. This calls for tools that are intuitive to use, yet flexible to adapt to new tasks. Results: Bioclipse is a free, open source workbench with advanced features for the life sciences. Version 2.0 constitutes a complete rewrite of Bioclipse, and delivers a stable, scalable integration platform for developers and an intuitive workbench for end users. All functionality is available both from the graphical user interface and from a built-in novel domain-specific language, supporting the scientist in interdisciplinary research and reproducible analyses through advanced visualization of the inputs and the results. New components for Bioclipse 2 include a rewritten editor for chemical structures, a table for multiple molecules that supports gigabyte-sized files, as well as a graphical editor for sequences and alignments. Conclusion: Bioclipse 2 is equipped with advanced tools required to carry out complex analysis in the fields of bio- and cheminformatics. Developed as a Rich Client based on Eclipse, Bioclipse 2 leverages on today's powerful desktop computers for providing a responsive user interface, but also takes full advantage of the Web and networked (Web/Cloud) services for more demanding calculations or retrieval of data. The fact that Bioclipse 2 is based on an advanced and widely used service platform ensures wide extensibility, making it easy to add new algorithms, visualizations, as well as scripting commands. The intuitive tools for end users and the extensible architecture make Bioclipse 2 ideal for interdisciplinary and integrative research. Bioclipse 2 is released under the Eclipse Public License (EPL), a flexible open source license that allows additional plugins to be of any license. Bioclipse 2 is implemented in Java and supported on all major platforms; Source code and binaries are freely available at http://www.bioclipse.net. © 2009 Spjuth et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Espeso D.R.; Algar E.; Martínez-García E.; De Lorenzo V.","Espeso, David R. (56310335000); Algar, Elena (35423421300); Martínez-García, Esteban (57205565737); De Lorenzo, Víctor (7005588312)","56310335000; 35423421300; 57205565737; 7005588312","Exploiting geometric similarity for statistical quantification of fluorescence spatial patterns in bacterial colonies","2020","BMC Bioinformatics","10.1186/s12859-020-3490-1","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086063736&doi=10.1186%2fs12859-020-3490-1&partnerID=40&md5=4b072454efcc874100a3c64a5f848064","Background: Currently the combination of molecular tools, imaging techniques and analysis software offer the possibility of studying gene activity through the use of fluorescent reporters and infer its distribution within complex biological three-dimensional structures. For example, the use of Confocal Scanning Laser Microscopy (CSLM) is a regularly-used approach to visually inspect the spatial distribution of a fluorescent signal. Although a plethora of generalist imaging software is available to analyze experimental pictures, the development of tailor-made software for every specific problem is still the most straightforward approach to perform the best possible image analysis. In this manuscript, we focused on developing a simple methodology to satisfy one particular need: automated processing and analysis of CSLM image stacks to generate 3D fluorescence profiles showing the average distribution detected in bacterial colonies grown in different experimental conditions for comparison purposes. Results: The presented method processes batches of CSLM stacks containing three-dimensional images of an arbitrary number of colonies. Quasi-circular colonies are identified, filtered and projected onto a normalized orthogonal coordinate system, where a numerical interpolation is performed to obtain fluorescence values within a spatially fixed grid. A statistically representative three-dimensional fluorescent pattern is then generated from this data, allowing for standardized fluorescence analysis regardless of variability in colony size. The proposed methodology was evaluated by analyzing fluorescence from GFP expression subject to regulation by a stress-inducible promoter. Conclusions: This method provides a statistically reliable spatial distribution profile of fluorescence detected in analyzed samples, helping the researcher to establish general correlations between gene expression and spatial allocation under differential experimental regimes. The described methodology was coded into a MATLAB script and shared under an open source license to make it accessible to the whole community. © 2020 The Author(s).","Bacteria; Colonies; CSLM; Geometric similarity; GFP; Pattern; Software; Spatial distribution; Statistical analysis","Article","Scopus"
"Henttonen K.; Kääriäinen J.; Kylmäaho J.","Henttonen, Katja (25629488000); Kääriäinen, Jukka (23966551000); Kylmäaho, Jani (57200206657)","25629488000; 23966551000; 57200206657","Lifecycle management in government-driven open source projects - practical framework","2017","International Journal of Information Systems and Project Management","10.12821/ijispm050302","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040194892&doi=10.12821%2fijispm050302&partnerID=40&md5=fc0cc023e5f6c3c3f71aec8cfeaf066d","In many parts of the world, public sector organizations are increasingly interested in collaborating across organizational (and even national) boundaries to develop software solutions under an open licence. However, without sound lifecycle management practices, the full benefits of open collaboration are not achieved and projects fail to achieve sustained success. This paper introduces a lifecycle management model and framework for government-driven open-source projects and reports about its use in a real-life case study. Our focus is on lifecycle management activities which take place between deployment and end-of-life. The framework was developed iteratively through a series of focus group discussions with representatives of public sector organizations. After the framework had been taken into use in our real-life case project, individual qualitative interviews were conducted to collect experiences on its benefits and weaknesses. According to the initial evidence, the deployment of the framework seems to have brought concrete benefits to the project, e.g. by contributing positively to community growth, software quality and inter-organizational learning. © 2017, SciKA.","E-government; Free software; Information systems; Open source; Open-source software; Public information systems; Public sector; Public sector; Software evolution; Software lifecycle management","Article","Scopus"
"Bagaini A.; Croci E.; Molteni T.","Bagaini, Annamaria (57205431672); Croci, Edoardo (8153567100); Molteni, Tania (55327146700)","57205431672; 8153567100; 55327146700","Boosting energy home renovation through innovative business models: ONE-STOP-SHOP solutions assessment","2022","Journal of Cleaner Production","10.1016/j.jclepro.2021.129990","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120642989&doi=10.1016%2fj.jclepro.2021.129990&partnerID=40&md5=ebefb1cdc0f4ff32ba974a9344ab41a0","The building sector brings the main responsibility for energy consumption and GHG emissions in European countries. Although many policies have been placed across the EU to increase building energy performance, the current home energy renovation rate remains too low to achieve the EU's decarbonization targets. The One-stop-shop (OSS) concept is emerging as an innovative solution to boost energy home renovation and overcome barriers hindering the renovation process. The OSS is a physical or virtual place where customers obtain multiple products and services at one single point. Through literature review and desk research, 29 OSS initiatives have been analysed in the EU looking at their Business Models (BM). The paper aims to categorize and compare OSS BMs to increase knowledge about OSS functioning and capacity to affect and bring innovation to home renovation process. Three BM archetypes emerge, Facilitation model, Coordination model, and Development model. Within OSS archetypes, seven BM sub-categories have been identified and described. To provide insights for implementing new businesses and revitalizing the home renovation sector, OSS archetypes and sub-categories are compared and assessed, first considering four analytical frameworks and then looking at their capacity to overcome home renovation barriers. Results can be useful to foster energy home renovation by supporting the development of effective and targeted OSS initiatives across the EU. © 2021 Elsevier Ltd","Business model; Comparative assessment; Energy home renovation; One-stop-shop","Article","Scopus"
"Alsberg B.K.; Hagen O.J.","Alsberg, Bjørn K. (7003375183); Hagen, Ole Jacob (15055833700)","7003375183; 15055833700","How octave can replace Matlab in chemometrics","2006","Chemometrics and Intelligent Laboratory Systems","10.1016/j.chemolab.2006.04.025","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750694673&doi=10.1016%2fj.chemolab.2006.04.025&partnerID=40&md5=811d6594d9bad1fd8a3fe42673375809","Many chemometricians today are dependent on having access to Matlab for development of algorithms and analysis of data sets. This article describes some of the potential dangers with such a dependency and how it may affect the field of chemometrics as a whole. Instead of using a proprietary scripting language, it is here suggested that the field should find a solution based on free or open source software. The most realistic open source alternative to Matlab today is Octave which covers most of the Matlab syntax and data structures. However, until now it has been lacking an interactive graphics system like Matlab's Handle Graphics (HG) which is very important to chemometricians for viewing data and inspecting results from analyses. To rectify this situation we are developing the Oplot graphics system which is compatible with the HG syntax. The main structure of Oplot is described and how it compares with HG. Not all HG functionality is currently implemented, however the most common functions and objects are available such as figure, axes, line, image, text, plot, subplot, set, get, clf, hold on/off, grid on/off, labels and title. Ensuring that Octave/Oplot is as compatible with Matlab/HG as possible, will make it easier for chemometricians to make a switch. We argue that such a switch to an open source solution is necessary to ensure long term stability and control over our future scientific and technological developments. © 2006 Elsevier B.V. All rights reserved.","GNU Public Licence (GPL); Matlab; Octave; Open source; Oplot; Software dependency","Article","Scopus"
"Cooper K.; Hunter S.R.","Cooper, Kyle (56040127200); Hunter, Susan R. (26429466300)","56040127200; 26429466300","PyMOSO: Software for multiobjective simulation optimization with R-PERLE and R-MinRLE","2020","INFORMS Journal on Computing","10.1287/ijoc.2019.0902","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081117438&doi=10.1287%2fijoc.2019.0902&partnerID=40&md5=72d6c0725ad64248cc7afb16e0cfea0e","We present the PyMOSO software package for (1) solving multiobjective simulation optimization (MOSO) problems on integer lattices and (2) implementing and testing new simulation optimization (SO) algorithms. First, for solving MOSO problems on integer lattices, PyMOSO implements R-PERLE, a state-of-the-art algorithm for two objectives, and R-MinRLE, a competitive benchmark algorithm for three or more objectives. Both algorithms use pseudogradients, are designed for sampling efficiency, and return solutions that, under appropriate regularity conditions, provably converge to a local efficient set with probability 1 as the simulation budget increases. PyMOSO can interface with existing simulation software and can obtain simulation replications in parallel. Second, for implementing and testing new SO algorithms, PyMOSO includes pseudorandom number stream management, implements algorithm testing with independent pseudorandom number streams run in parallel, and computes the performance of algorithms with user-defined metrics. For convenience, we also include an implementation of R-SPLINE for problems with one objective. The PyMOSO source code is available under a permissive open-source license. Copyright: © 2020 INFORMS","Multiobjective; Simulation optimization; Software","Article","Scopus"
"Shah A.; Woolf P.","Shah, Abhik (57199471595); Woolf, Peter (7006942293)","57199471595; 7006942293","Python environment for Bayesian learning: Inferring the structure of Bayesian networks from knowledge and data","2009","Journal of Machine Learning Research","","19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-61749099368&partnerID=40&md5=9707227e6fdbde972b012f3ffdb0e9c5","In this paper, we introduce PEBL, a Python library and application for learning Bayesian network structure from data and prior knowledge that provides features unmatched by alternative software packages: the ability to use interventional data, flexible specification of structural priors, modeling with hidden variables and exploitation of parallel processing. PEBL is released under the MIT open-source license, can be installed from the Python Package Index and is available at http://pebl-project.googlecode.com.","Bayesian networks; Open source software; Python","Article","Scopus"
"Decugis S.; Teraoka F.","Decugis, Sébastien (35107157700); Teraoka, Fumio (7003622851)","35107157700; 7003622851","FreeDiameter: An open source framework for an authentication, authorization, and accounting infrastructure","2011","Computer Software","","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-82755170488&partnerID=40&md5=cd204623b53e53bb174a7fb439f64622","AAA (Authentication, Authorization, and Accounting) is one of the important functions indispensable for providing services on the Internet. Diameter Base Protocol was standardized in IETF as a successor of RADIUS, which is a widely used AAA protocol in the current Internet. Diameter solves the problems that RADIUS has such as support of multiple realms, reliable and secure message transport, and failover. There are several open source implementations of Diameter Base Protocol. However, none of them completely conforms to the specification. The first contribution of freeDiameter is that it is an open source of Diameter Base Protocol that completely conforms to the specification. It is written in C and based on a BSD-like license. In the Diameter architecture, a particular service on Diameter Base Protocol is defined as a Diameter application such as Diameter EAP application for WiFi network access control. The second contribution of freeDiameter is that the software architecture of freeDiameter makes it easy to implement Diameter applications as additional plug-ins. freeDiameter has already been distributed through our home page. freeDiameter with Diameter EAP application has been used in our laboratory for WiFi network access. It was also used for network control in the WIDE camp held in September 2010 for four days in which approximately 200 researchers attended. There was no problem on freeDiameter. This is good evidence of the stability of freeDiameter.","","Article","Scopus"
"Crowdis J.; He M.X.; Reardon B.; van Allen E.M.","Crowdis, Jett (57205230844); He, Meng Xiao (57200494836); Reardon, Brendan (57190380558); van Allen, Eliezer M. (26667243800)","57205230844; 57200494836; 57190380558; 26667243800","CoMut: Visualizing integrated molecular information with comutation plots","2020","Bioinformatics","10.1093/bioinformatics/btaa554","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091806851&doi=10.1093%2fbioinformatics%2fbtaa554&partnerID=40&md5=cd6f645654e706cf9dac6a1f821d389d","Motivation: Large-scale sequencing studies have created a need to succinctly visualize genomic characteristics of patient cohorts linked to widely variable phenotypic information. This is often done by visualizing the co-occurrence of variants with comutation plots. Current tools lack the ability to create highly customizable and publication quality comutation plots from arbitrary user data. Results: We developed CoMut, a stand-alone, object-oriented Python package that creates comutation plots from arbitrary input data, including categorical data, continuous data, bar graphs, side bar graphs and data that describes relationships between samples. Availability and implementation: The CoMut package is open source and is available at https://github.com/vanallenlab/comut under the MIT License, along with documentation and examples. A no installation, easy-to-use implementation is available on Google Colab (see GitHub). © The Author(s) 2020. Published by Oxford University Press. This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by-nc/4.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com","","Article","Scopus"
"Leviatan S.; Kalka I.N.; Vogl T.; Klompas S.; Weinberger A.; Segal E.","Leviatan, Sigal (57218938157); Kalka, Iris N. (57221249167); Vogl, Thomas (55506109600); Klompas, Shelley (57986385600); Weinberger, Adina (7101670072); Segal, Eran (35485628500)","57218938157; 57221249167; 55506109600; 57986385600; 7101670072; 35485628500","BIPS - A code base for designing and coding of a Phage ImmunoPrecipitation Oligo Library","2022","PLoS Computational Biology","10.1371/journal.pcbi.1010663","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142918716&doi=10.1371%2fjournal.pcbi.1010663&partnerID=40&md5=ee3996eb3c2d930372664d7cbd5dec8a","BIPS (Build Phage ImmunoPrecipitation Sequencing library) is a software that converts a list of proteins into a custom DNA oligonucleotide library for the PhIP-Seq system. The tool creates constant-length oligonucleotides with internal barcodes, while maintaining the original length of the peptide. This allows using large libraries, of hundreds of thousands of oligonucleotides, while saving on the costs of sequencing and maintaining the accuracy of oligonucleotide reads identification. BIPS is available under GNU public license from: https://github.com/kalkairis/BuildPhIPSeqLibrary.  © 2022 Leviatan et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Article","Scopus"
"Urbanczik R.","Urbanczik, Robert (7005953633)","7005953633","SNA - A toolbox for the stoichiometric analysis of metabolic networks","2006","BMC Bioinformatics","10.1186/1471-2105-7-129","32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33645536317&doi=10.1186%2f1471-2105-7-129&partnerID=40&md5=ec957a43a1019457a279d5a762ced544","Background: Despite recent algorithmic and conceptual progress, the stoichiometric network analysis of large metabolic models remains a computationally challenging problem. Results: SNA is a interactive, high performance toolbox for analysing the possible steady state behaviour of metabolic networks by computing the generating and elementary vectors of their flux and conversions cones. It also supports analysing the steady states by linear programming. The toolbox is implemented mainly in Mathematica and returns numerically exact results. It is available under an open source license from: http://bioinformatics.org/project/?group_id=546. Conclusion: Thanks to its performance and modular design, SNA is demonstrably useful in analysing genome scale metabolic networks. Further, the integration into Mathematica provides a very flexible environment for the subsequent analysis and interpretation of the result. © 2006 Urbanczik; licensee BioMed Central Ltd.","","Article","Scopus"
"Masoudi-Sobhanzadeh Y.; Motieghader H.; Masoudi-Nejad A.","Masoudi-Sobhanzadeh, Yosef (57193058049); Motieghader, Habib (57193065501); Masoudi-Nejad, Ali (55911393500)","57193058049; 57193065501; 55911393500","FeatureSelect: A software for feature selection based on machine learning approaches","2019","BMC Bioinformatics","10.1186/s12859-019-2754-0","68","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064084305&doi=10.1186%2fs12859-019-2754-0&partnerID=40&md5=00b6ba02c2c8bb7585da70e014691dd0","Background: Feature selection, as a preprocessing stage, is a challenging problem in various sciences such as biology, engineering, computer science, and other fields. For this purpose, some studies have introduced tools and softwares such as WEKA. Meanwhile, these tools or softwares are based on filter methods which have lower performance relative to wrapper methods. In this paper, we address this limitation and introduce a software application called FeatureSelect. In addition to filter methods, FeatureSelect consists of optimisation algorithms and three types of learners. It provides a user-friendly and straightforward method of feature selection for use in any kind of research, and can easily be applied to any type of balanced and unbalanced data based on several score functions like accuracy, sensitivity, specificity, etc. Results: In addition to our previously introduced optimisation algorithm (WCC), a total of 10 efficient, well-known and recently developed algorithms have been implemented in FeatureSelect. We applied our software to a range of different datasets and evaluated the performance of its algorithms. Acquired results show that the performances of algorithms are varying on different datasets, but WCC, LCA, FOA, and LA are suitable than others in the overall state. The results also show that wrapper methods are better than filter methods. Conclusions: FeatureSelect is a feature or gene selection software application which is based on wrapper methods. Furthermore, it includes some popular filter methods and generates various comparison diagrams and statistical measurements. It is available from GitHub (https://github.com/LBBSoft/FeatureSelect) and is free open source software under an MIT license. © 2019 The Author(s).","Classification; Feature selection; Gene selection; Machine learning; Regression","Article","Scopus"
"Melchert O.; Demircan A.","Melchert, Oliver (24450581400); Demircan, Ayhan (7004830314)","24450581400; 7004830314","pyGLLE: A Python toolkit for solving the generalized Lugiato–Lefever equation","2021","SoftwareX","10.1016/j.softx.2021.100741","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109070151&doi=10.1016%2fj.softx.2021.100741&partnerID=40&md5=8f3b73be085c9e9212be1f46572b9e8c","We present a Python toolkit for simulating the propagation dynamics of dissipative solitons in a variant of the Lugiato–Lefever equation (LLE) including dispersion terms of third and fourth order. In addition, the provided software allows to prepare initial conditions given by stationary localized solutions of the standard LLE in the anomalous group-velocity dispersion regime. Propagation scenarios for custom control parameters and initial conditions can be specified by the user via a simple class data structure. We demonstrate the implemented functionality by showing how to obtain stationary solutions of the standard LLE containing a dissipative soliton, and, demonstrating different characteristic propagation scenarios. The pyGLLE software package is open-source and released under the X11 License in a publicly available software repository. © 2021 The Authors","Dissipative solitons; Lugiato–Lefever equation; Nonlinear partial differential equations; Python","Article","Scopus"
"Maljaars J.M.; Richardson C.N.; Sime N.","Maljaars, Jakob M. (57193532352); Richardson, Chris N. (57203088284); Sime, Nathan (57194940690)","57193532352; 57203088284; 57194940690","LEOPART: A particle library for FENICS","2021","Computers and Mathematics with Applications","10.1016/j.camwa.2020.04.023","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085530984&doi=10.1016%2fj.camwa.2020.04.023&partnerID=40&md5=5194493a088c75d0388f5c7a344b7d53","This paper introduces LEOPART, an add-on for the open-source finite element software library FENICS to seamlessly integrate Lagrangian particle functionality with (Eulerian) mesh-based finite element (FE) approaches. LEOPART- which is so much as to say: ‘Lagrangian–Eulerian on Particles’ - contains tools for efficient, accurate and scalable advection of Lagrangian particles on simplicial meshes. In addition, LEOPART comes with several projection operators for exchanging information between the scattered particles and the mesh and vice versa. These projection operators are based on a variational framework, which allows extension to high-order accuracy. In particular, by implementing a dedicated PDE-constrained particle–mesh projection operator, LEOPART provides all the tools for diffusion-free advection, while simultaneously achieving optimal convergence and ensuring conservation of the projected particle quantities on the underlying mesh. A range of numerical examples that are prototypical to passive and active tracer methods highlight the properties and the parallel performance of the different tools in LEOPART. Lastly, future developments are identified. The source code for LEOPART is actively maintained and available under an open-source license at https://bitbucket.org/jakob_maljaars/leopart. © 2020 The Authors","FENICS; Finite elements; Open-source software; Particle tracking; Particle-in-cell; PDE-constrained optimization","Article","Scopus"
"Galili T.","Galili, Tal (51060906500)","51060906500","dendextend: An R package for visualizing, adjusting and comparing trees of hierarchical clustering","2015","Bioinformatics","10.1093/bioinformatics/btv428","774","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947476425&doi=10.1093%2fbioinformatics%2fbtv428&partnerID=40&md5=cd4e45c5b2e549e82fa4cc93a74923f3","Summary: dendextend is an R package for creating and comparing visually appealing tree diagrams. dendextend provides utility functions for manipulating dendrogram objects (their color, shape and content) as well as several advanced methods for comparing trees to one another (both statistically and visually). As such, dendextend offers a flexible framework for enhancing R's rich ecosystem of packages for performing hierarchical clustering of items. Availability and implementation: The dendextend R package (including detailed introductory vignettes) is available under the GPL-2 Open Source license and is freely available to download from CRAN at: (http://cran.r-project.org/package=dendextend). © The Author 2015. Published by Oxford University Press.","","Article","Scopus"
"Arner E.; Tammi M.T.; Tran A.-N.; Kindlund E.; Anderson B.","Arner, Erik (7006368112); Tammi, Martti T. (7006794182); Tran, Anh-Nhi (7103072345); Kindlund, Ellen (7801399641); Anderson, Bjorn (7401941929)","7006368112; 7006794182; 7103072345; 7801399641; 7401941929","DNPTrapper: An assembly editing tool for finishing and analysis of complex repeat regions","2006","BMC Bioinformatics","10.1186/1471-2105-7-155","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33646568477&doi=10.1186%2f1471-2105-7-155&partnerID=40&md5=bfcac8845d56c428e98af94aa8525616","Background: Many genome projects are left unfinished due to complex, repeated regions. Finishing is the most time consuming step in sequencing and current finishing tools are not designed with particular attention to the repeat problem. Results: We have developed DNPTrapper, a shotgun sequence finishing tool, specifically designed to address the problems posed by the presence of repeated regions in the target sequence. The program detects and visualizes single base differences between nearly identical repeat copies, and offers the overview and flexibility needed to rapidly resolve complex regions within a working session. The use of a database allows large amounts of data to be stored and handled, and allows viewing of mammalian size genomes. The program is available under an Open Source license. Conclusion: With DNPTrapper, it is possible to separate repeated regions that previously were considered impossible to resolve, and finishing tasks that previously took days or weeks can be resolved within hours or even minutes. © 2006Arner et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Larsen P.M.; Schmidt S.; SchiØtz J.","Larsen, Peter Mahler (57211604505); Schmidt, SØren (7401845490); SchiØtz, Jakob (57196232790)","57211604505; 7401845490; 57196232790","Robust structural identification via polyhedral template matching","2016","Modelling and Simulation in Materials Science and Engineering","10.1088/0965-0393/24/5/055007","384","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976407024&doi=10.1088%2f0965-0393%2f24%2f5%2f055007&partnerID=40&md5=67c55e0f11ffce76be2a858142917e6e","Successful scientific applications of large-scale molecular dynamics often rely on automated methods for identifying the local crystalline structure of condensed phases. Many existing methods for structural identification, such as common neighbour analysis, rely on interatomic distances (or thresholds thereof) to classify atomic structure. As a consequence they are sensitive to strain and thermal displacements, and preprocessing such as quenching or temporal averaging of the atomic positions is necessary to provide reliable identifications. We propose a new method, polyhedral template matching (PTM), which classifies structures according to the topology of the local atomic environment, without any ambiguity in the classification, and with greater reliability than e.g. common neighbour analysis in the presence of thermal fluctuations. We demonstrate that the method can reliably be used to identify structures even in simulations near the melting point, and that it can identify the most common ordered alloy structures as well. In addition, the method makes it easy to identify the local lattice orientation in polycrystalline samples, and to calculate the local strain tensor. An implementation is made available under a Free and Open Source Software license. © 2016 IOP Publishing Ltd.","alloy classification; analysis of molecular dynamics; atomic systems visualization; atomic-scale simulations; crystal structure; neighbor analysis; structure classification","Article","Scopus"
"Huang W.; Takebayashi N.; Qi Y.; Hickerson M.J.","Huang, Wen (55709670000); Takebayashi, Naoki (6603334580); Qi, Yan (36905132500); Hickerson, Michael J. (6603267379)","55709670000; 6603334580; 36905132500; 6603267379","MTML-msBayes: Approximate Bayesian comparative phylogeographic inference from multiple taxa and multiple loci with rate heterogeneity","2011","BMC Bioinformatics","10.1186/1471-2105-12-1","83","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650725611&doi=10.1186%2f1471-2105-12-1&partnerID=40&md5=fff8e4fee3a4089c731dc150c889a234","Background: MTML-msBayes uses hierarchical approximate Bayesian computation (HABC) under a coalescent model to infer temporal patterns of divergence and gene flow across codistributed taxon-pairs. Under a model of multiple codistributed taxa that diverge into taxon-pairs with subsequent gene flow or isolation, one can estimate hyper-parameters that quantify the mean and variability in divergence times or test models of migration and isolation. The software uses multi-locus DNA sequence data collected from multiple taxon-pairs and allows variation across taxa in demographic parameters as well as heterogeneity in DNA mutation rates across loci. The method also allows a flexible sampling scheme: different numbers of loci of varying length can be sampled from different taxon-pairs.Results: Simulation tests reveal increasing power with increasing numbers of loci when attempting to distinguish temporal congruence from incongruence in divergence times across taxon-pairs. These results are robust to DNA mutation rate heterogeneity. Estimating mean divergence times and testing simultaneous divergence was less accurate with migration, but improved if one specified the correct migration model. Simulation validation tests demonstrated that one can detect the correct migration or isolation model with high probability, and that this HABC model testing procedure was greatly improved by incorporating a summary statistic originally developed for this task (Wakeley's ΨW). The method is applied to an empirical data set of three Australian avian taxon-pairs and a result of simultaneous divergence with some subsequent gene flow is inferred.Conclusions: To retain flexibility and compatibility with existing bioinformatics tools, MTML-msBayes is a pipeline software package consisting of Perl, C and R programs that are executed via the command line. Source code and binaries are available for download at http://msbayes.sourceforge.net/ under an open source license (GNU Public License). © 2011 Huang et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Menzel M.; Koch P.; Glasenhardt S.; Gogol-Döring A.","Menzel, Michael (57211486526); Koch, Peter (57205654235); Glasenhardt, Stefan (56120833600); Gogol-Döring, Andreas (35772481600)","57211486526; 57205654235; 56120833600; 35772481600","Enhort: A platform for deep analysis of genomic positions","2019","PeerJ Computer Science","10.7717/peerj-cs.198","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074148280&doi=10.7717%2fpeerj-cs.198&partnerID=40&md5=a097050509db5d8ec44f00826652116a","The rise of high-throughput methods in genomic research greatly expanded our knowledge about the functionality of the genome. At the same time, the amount of available genomic position data increased massively, e.g., through genome-wide profiling of protein binding, virus integration or DNA methylation. However, there is no specialized software to investigate integration site profiles of virus integration or transcription factor binding sites by correlating the sites with the diversity of available genomic annotations. Here we present Enhort, a user-friendly software tool for relating large sets of genomic positions to a variety of annotations. It functions as a statistics based genome browser, not focused on a single locus but analyzing many genomic positions simultaneously. Enhort provides comprehensive yet easy-to-use methods for statistical analysis, visualization, and the adjustment of background models according to experimental conditions and scientific questions. Enhort is publicly available online at enhort.mni.thm.de and published under GNU General Public License. © 2019 Menzel et al.","Data analysis; Genome annotation; Integration profiling; Next-generation sequencing; Virology","Article","Scopus"
"Martinez-Llario J.; Gonzalez-Alcaide M.","Martinez-Llario, J. (24178343100); Gonzalez-Alcaide, M. (53866320400)","24178343100; 53866320400","Design of a Java spatial extension for relational databases","2011","Journal of Systems and Software","10.1016/j.jss.2011.06.072","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053572329&doi=10.1016%2fj.jss.2011.06.072&partnerID=40&md5=3111e815222f9182e4c56c7db9379254","Jaspa (Java Spatial) is a novel spatial extension for relational database management systems (RDBMSs). It is the result of a research project that aims to accomplish two goals: firstly, to fill the absence in the Free and Open Source Software (FOSS) world of a solid Java-based alternative to PostGIS, the leading spatial extension written in C. Secondly, to exploit the advantages of Java and the Java geospatial libraries over C in terms of portability and easiness to extend. Java programming for geospatial purposes is a flowering field and similar solutions to Jaspa have recently appeared, but none of them can equate with PostGIS due to lack of functionalities. Jaspa currently implements almost all PostGIS functionality. The next step will be the enrichment of the software with more sophisticated features: storage of spatial data in a topological structure within the RDBMS, cluster tolerance and geodetic functionalities. Jaspa is being developed at the Department of Cartographic Engineering, Geodesy and Photogrammetry of the Universidad Politécnica de Valencia and it has been published under an Open Source license on the OSOR.eu repository. This paper has been written by its creators with the aim of introducing users to its main capabilities. © 2011 Elsevier Inc. All rights reserved.","FOSS; GIS; Java; OGC; PostGIS; Spatial database","Article","Scopus"
"Camp J.; Lewis K.","Camp, Jean (7004669784); Lewis, K. (57197549045)","7004669784; 57197549045","Code as speech: A discussion of Bernstein v. USDOJ, Karn v. USDOS, and Junger v. Daley in light of the U.S. supreme court's recent shift to federalism","2001","Ethics and Information Technology","10.1023/a:1011427806551","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-11844284087&doi=10.1023%2fa%3a1011427806551&partnerID=40&md5=7af1dd2e79f781220f64fc93b4762eff","The purpose of this paper is to address the question of whether computer source code is speech protected by the First Amendment to the United States Constitution or whether it is merely functional, a ""machine"", designed to fulfill a set task and therefore bereft of protection. The answer to this question is a complex one. Unlike all other forms of ""speech"" computer source code holds a unique place in the law: it can be copyrighted, like a book and it can be patented like a machine or process.1 Case law, intellectual property law and encryption export regulations all reflect this contradictory dichotomy. © 2001 Kluwer Academic Publishers.","Artistic license; BSD; Code; Cryptography policy; Democracy; Encryption; Free software; Governance; GPL; Intellectual property; Law; Liability; Open source; Source code; Speech; UCITA","Article","Scopus"
"Berg J.A.; Belyeu J.R.; Morgan J.T.; Ouyang Y.; Bott A.J.; Quinlan A.R.; Gertz J.; Rutter J.","Berg, Jordan A. (57202951458); Belyeu, Jonathan R. (57203184385); Morgan, Jeffrey T. (57205625485); Ouyang, Yeyun (57202961534); Bott, Alex J. (56410661700); Quinlan, Aaron R. (57202032863); Gertz, Jason (8702761500); Rutter, Jared (7006540322)","57202951458; 57203184385; 57205625485; 57202961534; 56410661700; 57202032863; 8702761500; 7006540322","Xpressyourself: Enhancing, standardizing, and automating ribosome profiling computational analyses yields improved insight into data","2020","PLoS Computational Biology","10.1371/journal.pcbi.1007625","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078943435&doi=10.1371%2fjournal.pcbi.1007625&partnerID=40&md5=5736dfbcdbba2ffa28d3fc2f5e1b87d9","Ribosome profiling, an application of nucleic acid sequencing for monitoring ribosome activity, has revolutionized our understanding of protein translation dynamics. This technique has been available for a decade, yet the current state and standardization of publicly available computational tools for these data is bleak. We introduce XPRESSyourself, an analytical toolkit that eliminates barriers and bottlenecks associated with this specialized data type by filling gaps in the computational toolset for both experts and non-experts of ribosome profiling. XPRESSyourself automates and standardizes analysis procedures, decreasing time-to-discovery and increasing reproducibility. This toolkit acts as a reference implementation of current best practices in ribosome profiling analysis. We demonstrate this toolkit’s performance on publicly available ribosome profiling data by rapidly identifying hypothetical mechanisms related to neurodegenerative phenotypes and neuroprotective mechanisms of the small-molecule ISRIB during acute cellular stress. XPRESSyourself brings robust, rapid analysis of ribosome-profiling data to a broad and ever-expanding audience and will lead to more reproducible and accessible measurements of translation regulation. XPRESSyourself software is perpetually open-source under the GPL-3.0 license and is hosted at https://github.com/XPRESSyourself, where users can access additional documentation and report software issues. Copyright: © 2020 Berg et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Article","Scopus"
"Scoggins J.B.; Leroy V.; Bellas-Chatzigeorgis G.; Dias B.; Magin T.E.","Scoggins, James B. (36677999500); Leroy, Vincent (57218450657); Bellas-Chatzigeorgis, Georgios (57194857311); Dias, Bruno (57147242500); Magin, Thierry E. (22951325400)","36677999500; 57218450657; 57194857311; 57147242500; 22951325400","Mutation++: MUlticomponent Thermodynamic And Transport properties for IONized gases in C++","2020","SoftwareX","10.1016/j.softx.2020.100575","33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089234126&doi=10.1016%2fj.softx.2020.100575&partnerID=40&md5=cc47c91588dbdf1a89f44f402ba1287c","The Mutation++ library provides accurate and efficient computation of physicochemical properties associated with partially ionized gases in various degrees of thermal nonequilibrium. With v1.0.0, users can compute thermodynamic and transport properties, multiphase linearly-constrained equilibria, chemical production rates, energy transfer rates, and gas-surface interactions. The framework is based on an object-oriented design in C++, allowing users to plug-and-play various models, algorithms, and data as necessary. Mutation++ is available open-source under the GNU Lesser General Public License v3.0. © 2020 The Author(s)","Gas-surface interaction; Multiphase equilibrium; Partially ionized gases; Thermochemical nonequilibrium","Article","Scopus"
"Kahng A.B.; Wang L.; Xu B.","Kahng, Andrew B. (7005728278); Wang, Lutong (57111271200); Xu, Bangqi (57192205934)","7005728278; 57111271200; 57192205934","TritonRoute: The Open-Source Detailed Router","2021","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","10.1109/TCAD.2020.3003234","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087494704&doi=10.1109%2fTCAD.2020.3003234&partnerID=40&md5=bd06ce6cd5e61da0926360c145333498","Detailed routing is a dead-or-alive critical element in design automation tooling for advanced node enablement. However, very few works address detailed routing in the recent open literature, particularly in the context of modern industrial designs and a complete, end-to-end flow. The ISPD-2018 Initial Detailed Routing Contest addressed this gap for modern industrial designs, using a realistic design rules set. In this work, we present TritonRoute, a detailed router capable of delivering a DRC-clean routing solution. The key contributions of TritonRoute include an in-memory router database, along with an end-to-end detailed routing scheme that is capable of comprehending connectivity and design rule constraints, with every key detail revealed by a code release under a permissive open-source license. We evaluate our router using the official ISPD-2018 benchmark suite and show that TritonRoute achieves an unprecedented solution quality - improved wirelength and via count, and an extremely low level of design rule violations (DRCs). Compared to the known best detailed routing solutions from all published academic detailed routers, TritonRoute improves wirelength by up to 0.8% (avg. 0.4%), via count by up to 16.1% (avg. 9.3%), and DRCs by up to 100% (avg. 92.0%). © 1982-2012 IEEE.","Design automation; detailed routing; open source software; physical design; rip up and reroute; routing","Article","Scopus"
"Leightley D.; Puddephatt J.-A.; Goodwin L.; Rona R.; Fear N.T.","Leightley, Daniel (56028042600); Puddephatt, Jo-Anne (57202834094); Goodwin, Laura (7004562857); Rona, Roberto (35234810700); Fear, Nicola T. (6603924044)","56028042600; 57202834094; 7004562857; 35234810700; 6603924044","InDEx: Open source iOS and android software for self-reporting and monitoring of alcohol consumption","2018","Journal of Open Research Software","10.5334/jors.207","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049516278&doi=10.5334%2fjors.207&partnerID=40&md5=c371b7da0ef0c5378f52a2be38516014","InDEx is a software package for reporting and monitoring alcohol consumption via a smartphone application. Consumption of alcohol is self-reported by the user, and the app provides a visual representation of drinking behaviour and offers feedback on consumption levels compared to the general population. InDEx is intended as an exemplar app, operating as a standalone smartphone application and is highly customisable for a variety of research domains. InDEx is written in JavaScript, using IONIC framework which is cross-platform and is available under the liberal GNU General Public License (v3). The software is available from GitHub (https://github.com/DrDanL/index-app-public). © 2018 The Author(s).","Alcohol; Android; IONIC; IOS; Monitoring; Smartphone","Article","Scopus"
"Raczy C.; Petrovski R.; Saunders C.T.; Chorny I.; Kruglyak S.; Margulies E.H.; Chuang H.-Y.; Källberg M.; Kumar S.A.; Liao A.; Little K.M.; Strömberg M.P.; Tanner S.W.","Raczy, Come (25637638200); Petrovski, Roman (55808985400); Saunders, Christopher T. (55319018400); Chorny, Ilya (57643033700); Kruglyak, Semyon (6602350060); Margulies, Elliott H. (57192805473); Chuang, Han-Yu (55642184500); Källberg, Morten (57196860551); Kumar, Swathi A. (57197067697); Liao, Arnold (8367119000); Little, Kristina M. (36150895500); Strömberg, Michael P. (23482577900); Tanner, Stephen W. (9743863200)","25637638200; 55808985400; 55319018400; 57643033700; 6602350060; 57192805473; 55642184500; 57196860551; 57197067697; 8367119000; 36150895500; 23482577900; 9743863200","Isaac: Ultra-fast whole-genome secondary analysis on Illumina sequencing platforms","2013","Bioinformatics","10.1093/bioinformatics/btt314","210","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881018840&doi=10.1093%2fbioinformatics%2fbtt314&partnerID=40&md5=67c986278673d8b8a9ab7840b72b1406","An ultrafast DNA sequence aligner (Isaac Genome Alignment Software) that takes advantage of high-memory hardware (>48 GB) and variant caller (Isaac Variant Caller) have been developed. We demonstrate that our combined pipeline (Isaac) is four to five times faster than BWA + GATK on equivalent hardware, with comparable accuracy as measured by trio conflict rates and sensitivity. We further show that Isaac is effective in the detection of disease-causing variants and can easily/economically be run on commodity hardware.Availability: Isaac has an open source license and can be obtained at https://github.com/ sequencing.Contact: Supplementary information: Supplementary data are available at Bioinformatics online. © 2013 The Author 2013. Published by Oxford University Press.","","Article","Scopus"
"Muñoz-Quijada M.; Sanz L.; Guzman-Miranda H.","Muñoz-Quijada, Maria (57205300329); Sanz, Luis (57195454995); Guzman-Miranda, Hipolito (24586918500)","57205300329; 57195454995; 24586918500","A virtual device for simulation-based fault injection","2020","Electronics (Switzerland)","10.3390/electronics9121989","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096823565&doi=10.3390%2felectronics9121989&partnerID=40&md5=fa48fede11cbef9dd7ecca0ed4e1a4a6","This paper describes the design and implementation of a virtual device to perform simulation-based fault injection campaigns. The virtual device is fully compatible with the same user software that is already being used to perform fault injection campaigns in existing FPGA (Field Programmable Gate Array)-based hardware devices. Multiple instances of the virtual device can be launched in parallel in order to speed-up the fault injection campaigns, without any preexisting limitations on number, such as available license seats, since the virtual device can be compiled with the open-source simulator GHDL. This virtual device also allows one to find bugs in both software and firmware, and to reproduce in simulation, with total visibility of the internal states, corner cases that may have occurred in the real hardware. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Fault injection; Open source tools; Simulation; Single event effects; VHDL","Article","Scopus"
"Lundell B.; Lings B.; Lindqvist E.","Lundell, Björn (7004530817); Lings, Brian (6602251812); Lindqvist, Edvin (14819508600)","7004530817; 6602251812; 14819508600","Open source in Swedish companies: Where are we?","2010","Information Systems Journal","10.1111/j.1365-2575.2010.00348.x","35","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79953018230&doi=10.1111%2fj.1365-2575.2010.00348.x&partnerID=40&md5=1dc2e1027c077b408cbacd47881a9333","Open Source (OS) is a phenomenon of increasing significance for organizations, offering the prospect of effective alternative business solutions and new business opportunities. A number of surveys have been conducted in various countries with the purpose of understanding the state of practice with respect to OS in companies. In this paper we report on a study of the perceptions of OS and the uptake of OS products and development models in Swedish companies. The study used purposeful sampling of companies that have an expressed interest in OS, and the survey was conducted using a set of pre-prepared questions. Its goal was to investigate the extent to which OS has influenced business thinking, as seen from the standpoint of stakeholders. We found that uptake is much higher than reported in earlier studies, but as with previous studies, activity is still concentrated in small and medium-sized enterprises (SMEs). There is increased evidence of interest beyond the simple use of OS components at the infrastructure level. Further, a significant proportion of the companies studied are supporting the OS community as well as benefiting from it. Support includes participation in existing projects and the release of new software under OS licenses. © 2010 Blackwell Publishing Ltd.","Open source adoption; Open source in Swedish companies; Perceptions of open source; Qualitative survey","Article","Scopus"
"Gieseke F.; Oancea C.; Igel C.","Gieseke, Fabian (34874843900); Oancea, Cosmin (12140298600); Igel, Christian (6602116076)","34874843900; 12140298600; 6602116076","bufferkdtree: A Python library for massive nearest neighbor queries on multi-many-core devices","2017","Knowledge-Based Systems","10.1016/j.knosys.2017.01.002","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008472806&doi=10.1016%2fj.knosys.2017.01.002&partnerID=40&md5=82117cc08031dff3e92ed8acf037cd5b","The bufferkdtree package is an open-source software that provides an efficient implementation for processing huge amounts of nearest neighbor queries in Euclidean spaces of moderate dimensionality. Its underlying implementation resorts to a variant of the classical k-d tree data structure, called buffer k-d tree, which can be used to efficiently perform bulk nearest neighbor searches on modern many-core devices. The package, which is based on Python, C, and OpenCL, is made publicly available online at https://github.com/gieseke/bufferkdtree under the GPLv2 license. © 2017 Elsevier B.V.","GPUs; k-d trees; Nearest neighbor queries; OpenCL; Python","Article","Scopus"
"Shiozaki T.","Shiozaki, Toru (17435775100)","17435775100","BAGEL: Brilliantly Advanced General Electronic-structure Library","2018","Wiley Interdisciplinary Reviews: Computational Molecular Science","10.1002/wcms.1331","115","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041907309&doi=10.1002%2fwcms.1331&partnerID=40&md5=6b0ac5f5abf14ebb48c152d10640e0d7","On behalf of the development team, I review the capabilities of the Brilliantly Advanced General Electronic-structure Library (BAGEL) program package in this article. BAGEL is a newly developed full-fledged program package for electronic-structure computation in quantum chemistry, which is released under the GNU General Public License with many contributions from the developers. The unique features include analytical CASPT2 nuclear energy gradients and derivative couplings, relativistic multireference wave functions based on the Dirac equation, and implementations of novel electronic structure theories. All of the programs are efficiently parallelized using both threads and MPI processes. We also discuss the code generator SMITH3, which has been used to implement some of the programs in BAGEL. The developers’ contributions are listed at the end of the main text. WIREs Comput Mol Sci 2018, 8:e1331. doi: 10.1002/wcms.1331. This article is categorized under: Electronic Structure Theory > Ab Initio Electronic Structure Methods. © 2017 Wiley Periodicals, Inc.","","Article","Scopus"
"Botelho F.C.; Pagh R.; Ziviani N.","Botelho, Fabiano C. (8868733100); Pagh, Rasmus (6602880411); Ziviani, Nivio (6602184784)","8868733100; 6602880411; 6602184784","Practical perfect hashing in nearly optimal space","2013","Information Systems","10.1016/j.is.2012.06.002","31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869238649&doi=10.1016%2fj.is.2012.06.002&partnerID=40&md5=315c30090d23b1757956391f2c763ba6","A hash function is a mapping from a key universe U to a range of integers, i.e., h : U ← {0,1 m-1}, where m is the range's size. A perfect hash function for some set S ⊆ U is a hash function that is one-to-one on S, where m≥|S|. A minimal perfect hash function for some set S ⊆ U is a perfect hash function with a range of minimum size, i.e., m =|S|. This paper presents a construction for (minimal) perfect hash functions that combines theoretical analysis, practical performance, expected linear construction time and nearly optimal space consumption for the data structure. For n keys and m=n the space consumption ranges from 2.62n+o(n) to 3.3n+o(n) bits, and for m = 1.23n it ranges from 1.95n+o(n) to 2.7n + o(n) bits. This is within a small constant factor from the theoretical lower bounds of 1.44n bits for m = n and 0.89n bits for m = 1.23n. We combine several theoretical results into a practical solution that has turned perfect hashing into a very compact data structure to solve the membership problem when the key set S is static and known in advance. By taking into account the memory hierarchy we can construct (minimal) perfect hash functions for over a billion keys in 46 min using a commodity PC. An open source implementation of the algorithms is available at http://cmph.sf.net under the GNU Lesser General Public License (LGPL). © 2012 Elsevier Ltd. All rights reserved.","Large key sets; Perfect hash functions; Random graphs; Randomized algorithms","Article","Scopus"
"Heck N.; Schubotz M.","Heck, Nina (57194601243); Schubotz, Moritz (49864565600)","57194601243; 49864565600","DiViDu - An open source solution for dual task experiments with integrated divided visual field paradigm","2018","Journal of Open Research Software","10.5334/jors.199","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049511828&doi=10.5334%2fjors.199&partnerID=40&md5=a094a7ecdccad35d69ffbf8b98ad7a2c","We here present DiViDu, a research software, which we developed for a dual task experiment with an integrated divided visual field paradigm. The dual task experiment consists of a lexical decision task with different semantic verb categories, and a complex tapping task with either the left or right hand. The software allows researchers the replication of our experiment, as well as the reconfiguration for further dual task experiments with alternative tapping tasks and stimuli (e.g., word classes, semantic classes, task languages) as well as adjusted experimental settings. Furthermore, with only slight modifications to the source code, researchers can implement various new experimental setups including a large variety of language tasks (e.g., silent and aloud reading, naming, verbal fluency) and non-verbal tasks. The software DiViDu is implemented using the .NET framework and is available under the Apache 2 License on GitHub (https://github.com/dividu/dividu). © 2018 The Author(s).","Behavioural experiments; Divided visual field paradigm; Dual task paradigm; Lateralisation; Neuropsychology","Article","Scopus"
"Grotegerd D.; Redlich R.; Almeida J.R.C.; Riemenschneider M.; Kugel H.; Arolt V.; Dannlowski U.","Grotegerd, Dominik (37101507600); Redlich, Ronny (55248386800); Almeida, Jorge R. C. (35553255900); Riemenschneider, Mona (54389750500); Kugel, Harald (26643516600); Arolt, Volker (56247579900); Dannlowski, Udo (13806470600)","37101507600; 55248386800; 35553255900; 54389750500; 26643516600; 56247579900; 13806470600","MANIA - A pattern classification toolbox for neuroimaging data","2014","Neuroinformatics","10.1007/s12021-014-9223-8","19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904749680&doi=10.1007%2fs12021-014-9223-8&partnerID=40&md5=a65a463352bb2718712fded3166659b2","Conventional univariate statistics are common and widespread in neuroimaging research. However, functional and structural MRI data reveal a multivariate nature, since neighboring voxels are highly correlated and different localized brain regions activate interdependently. Multivariate pattern classification techniques are capable of overcoming shortcomings of univariate statistics. A rising interest in such approaches on neuroimaging data leads to an increasing demand of appropriate software and tools in this field. Here, we introduce and release MANIA - Machine learning Application for NeuroImaging Analyses. MANIA is a Matlab based software toolbox enabling easy pattern classification of neuroimaging data and offering a broad assortment of machine learning algorithms and feature selection methods. Between groups classifications are the main scope of this software, for instance the differentiation between patients and controls. A special emphasis was placed on an intuitive and easy to use graphical user interface allowing quick implementation and guidance also for clinically oriented researchers. MANIA is free and open source, published under GPL3 license. This work will give an overview regarding the functionality and the modular software architecture as well as a comparison between other software packages. © 2014 Springer Science+Business Media New York.","fMRI; Machine learning; MVPA; Neuroimaging software; Pattern classification","Article","Scopus"
"Thibodeau A.; Shin D.-G.","Thibodeau, Asa (57190285855); Shin, Dong-Guk (7403352651)","57190285855; 7403352651","TriPOINT: A software tool to prioritize important genes in pathways and their non-coding regulators","2019","Bioinformatics","10.1093/bioinformatics/bty998","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070708219&doi=10.1093%2fbioinformatics%2fbty998&partnerID=40&md5=ed5dcb3ff4654a9a8d9fb447afba6a4f","Summary: Current approaches for pathway analyses focus on representing gene expression levels on graph representations of pathways and conducting pathway enrichment among differentially expressed genes. However, gene expression levels by themselves do not reflect the overall picture as non-coding factors play an important role to regulate gene expression. To incorporate these non-coding factors into pathway analyses and to systematically prioritize genes in a pathway we introduce a new software: Triangulation of Perturbation Origins and Identification of Non-Coding Targets. Triangulation of Perturbation Origins and Identification of Non-Coding Targets is a pathway analysis tool, implemented in Java that identifies the significance of a gene under a condition (e.g. a disease phenotype) by studying graph representations of pathways, analyzing upstream and downstream gene interactions and integrating non-coding regions that may be regulating gene expression levels. Availability and implementation: The TriPOINT open source software is freely available at https://github.uconn.edu/ajt06004/TriPOINT under the GPL v3.0 license. Supplementary information: Supplementary data are available at Bioinformatics online. © 2018 The Author(s) 2018. Published by Oxford University Press.","","Article","Scopus"
"Woods J.O.; Christian J.A.","Woods, John O. (56330686900); Christian, John A. (23975296000)","56330686900; 23975296000","GLIDAR: An open GL-based, real-time, and open source 3d sensor simulator for testing computer vision algorithms","2016","Journal of Imaging","10.3390/jimaging2010005","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995591168&doi=10.3390%2fjimaging2010005&partnerID=40&md5=dac881777c7c969082030b0f1e8be42a","3D sensors such as LIDARs, stereo cameras, time-of-flight cameras, and the Microsoft Kinect are increasingly found in a wide range of applications, including gaming, personal robotics, and space exploration. In some cases, pattern recognition algorithms for processing depth images can be tested using actual sensors observing real-world objects. In many situations, however, it is common to test new algorithms using computer-generated synthetic images, as such simulations tend to be faster, more flexible, and less expensive than hardware tests. Computer generation of images is especially useful for Monte Carlo-type analyses or for situations where obtaining real sensor data for preliminary testing is difficult (e.g., space applications). We present GLIDAR, an OpenGL and GL Shading Language-based sensor simulator, capable of imaging nearly any static three-dimensional model. GLIDAR allows basic object manipulations, or may be connected to a physics simulator for more advanced behaviors. It permits publishing to a TCP socket at high frame-rates or can save to PCD (point cloud data) files. The software is written in C++, and is released under the open source BSD license. © 2016 by the authors; licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons by Attribution (CC-BY) license","3D sensors; Sensor simulators","Article","Scopus"
"Samourkasidis A.; Papoutsoglou E.; Athanasiadis I.N.","Samourkasidis, Argyrios (56426586500); Papoutsoglou, Evangelia (57196016941); Athanasiadis, Ioannis N. (57210555473)","56426586500; 57196016941; 57210555473","A template framework for environmental timeseries data acquisition","2019","Environmental Modelling and Software","10.1016/j.envsoft.2018.10.009","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063999990&doi=10.1016%2fj.envsoft.2018.10.009&partnerID=40&md5=8b788c50ceb05c84253ec33ab340aa28","Environmental timeseries data variety is exploding in the Internet of Things era, making data reuse a very demanding task. Data acquisition and integration remains a laborious step of the environmental data lifecycle. Environmental data heterogeneity is a persistent issue, as data are becoming available through different protocols and stored under diverse, custom formats. In this work, we deal with syntactic heterogeneity in environmental timeseries data. Our approach is based on describing different dataset syntaxes using abstract representations, called templates. We designed and implemented EDAM (Environmental Data Acquisition Module), a template framework that facilitates timeseries data acquisition and integration. EDAM templates are written using programming language-agnostic semantics, and can be reused both for input and output, thus enabling data reuse via transformations across different formats. We demonstrate EDAM generality in seven case studies, which involve scraping online data, extracting observations from a relational database, or aggregating historical timeseries stored in local files. Case studies span different environmental sciences domains, including meteorology, agriculture, urban air quality and hydrology. We also demonstrate EDAM for data dissemination, as instructed by output templates. We identified several syntactic interoperability challenges though the case studies, that include managing with differences in formatting observables, temporal and spatial references, and metadata documentation, and addressed them with EDAM. EDAM implementation has been released under an open-source license. © 2018 The Authors","Big data; Data acquisition; Environmental timeseries; Internet of things; Syntactic interoperability; Templates","Article","Scopus"
"Bourgey M.; Dali R.; Eveleigh R.; Chen K.C.; Letourneau L.; Fillon J.; Michaud M.; Caron M.; Sandoval J.; Lefebvre F.; Leveque G.; Mercier E.; Bujold D.; Marquis P.; Van Patrick T.; De Lima Morais D.A.; Tremblay J.; Shao X.; Henrion E.; Gonzalez E.; Quirion P.-O.; Caron B.; Bourque G.","Bourgey, Mathieu (57192309302); Dali, Rola (37018014100); Eveleigh, Robert (56840561500); Chen, Kuang Chung (57192096549); Letourneau, Louis (6603513783); Fillon, Joel (6603001144); Michaud, Marc (57209459632); Caron, Maxime (55908307600); Sandoval, Johanna (57196485679); Lefebvre, Francois (54886347100); Leveque, Gary (7004352624); Mercier, Eloi (57076084200); Bujold, David (57191989299); Marquis, Pascale (53868203800); Van Patrick, Tran (57209687304); De Lima Morais, David Anderson (22133913400); Tremblay, Julien (57211528413); Shao, Xiaojian (35280890300); Henrion, Edouard (36023668500); Gonzalez, Emmanuel (57199756139); Quirion, Pierre-Olivier (57219633468); Caron, Bryan (57192099701); Bourque, Guillaume (6603921571)","57192309302; 37018014100; 56840561500; 57192096549; 6603513783; 6603001144; 57209459632; 55908307600; 57196485679; 54886347100; 7004352624; 57076084200; 57191989299; 53868203800; 57209687304; 22133913400; 57211528413; 35280890300; 36023668500; 57199756139; 57219633468; 57192099701; 6603921571","GenPipes: An open-source framework for distributed and scalable genomic analyses","2019","GigaScience","10.1093/gigascience/giz037","59","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067822926&doi=10.1093%2fgigascience%2fgiz037&partnerID=40&md5=c2e7c7485ed2a2112eef978caefe68fc","Background: With the decreasing cost of sequencing and the rapid developments in genomics technologies and protocols, the need for validated bioinformatics software that enables efficient large-scale data processing is growing. Findings: Here we present GenPipes, a flexible Python-based framework that facilitates the development and deployment of multi-step workflows optimized for high-performance computing clusters and the cloud. GenPipes already implements 12 validated and scalable pipelines for various genomics applications, including RNA sequencing, chromatin immunoprecipitation sequencing, DNA sequencing, methylation sequencing, Hi-C, capture Hi-C, metagenomics, and Pacific Biosciences long-read assembly. The software is available under a GPLv3 open source license and is continuously updated to follow recent advances in genomics and bioinformatics. The framework has already been configured on several servers, and a Docker image is also available to facilitate additional installations. Conclusions: GenPipes offers genomics researchers a simple method to analyze different types of data, customizable to their needs and resources, as well as the flexibility to create their own workflows. © 2019 The Author(s).","Bioinformatics; Frameworks; Genomics; Pipeline; Workflow; Workflow management systems","Article","Scopus"
"Cavalcante M.A.; Pereira H.A.; Almeida R.C., Jr.","Cavalcante, Matheus A. (56544234100); Pereira, Helder A. (24484051400); Almeida, Raul C. (57226691692)","56544234100; 24484051400; 57226691692","SimEON: an open-source elastic optical network simulator for academic and industrial purposes","2017","Photonic Network Communications","10.1007/s11107-017-0697-9","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017119401&doi=10.1007%2fs11107-017-0697-9&partnerID=40&md5=a3e2095860b273fec00d52f954ef0b02","In comparison with wavelength division multiplexing optical networks, elastic optical networks are much more flexible, presenting an efficient alternative to use the frequency spectrum to establish call requests in a scenario with different transmission bit rates and modulation schemes. Due to the variety of optical devices, node architectures and physical topologies, it is difficult to implement optical network prototypes to analyze operational scenarios in terms of blocking probability of call requests, the impact of capital and operational expenditures and energy consumption, for example. To our knowledge, there is no available open-source simulation tool exclusively for elastic optical networks in the literature. There are a few simulation tools that were used to obtain results for optical networks but most of their source codes are unavailable. The state of the art of these simulators and our developed simulation tool called Simulator for Elastic Optical Networks (SimEON) are presented. SimEON is an open-source software. It is developed under the GNU Lesser General Public License and takes into account principles of software engineering. In this article, we present the characteristics of our simulator, its architecture and considered parameters, along with some examples of the simulations that can be executed on it. © 2017, Springer Science+Business Media New York.","Elastic optical networks; Modulation and spectrum assignment algorithm; Routing; Signal-to-noise ratio; Simulation tool","Article","Scopus"
"Bangerth W.; Burstedde C.; Heister T.; Kronbichler M.","Bangerth, Wolfgang (6508189083); Burstedde, Carsten (18834071900); Heister, Timo (35114920800); Kronbichler, Martin (56998515600)","6508189083; 18834071900; 35114920800; 56998515600","Algorithms and data structures for massively parallel generic adaptive finite element codes","2011","ACM Transactions on Mathematical Software","10.1145/2049673.2049678","136","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053101388&doi=10.1145%2f2049673.2049678&partnerID=40&md5=87cc561bce9df9299fd954832fb3f92f","Today's largest supercomputers have 100,000s of processor cores and offer the potential to solve partial differential equations discretized by billions of unknowns. However, the complexity of scaling to such large machines and problem sizes has so far prevented the emergence of generic software libraries that support such computations, although these would lower the threshold of entry and enable many more applications to benefit from large-scale computing. We are concerned with providing this functionality for mesh-adaptive finite element computations. We assume the existence of an ""oracle"" that implements the generation and modification of an adaptive mesh distributed across many processors, and that responds to queries about its structure. Based on querying the oracle, we develop scalable algorithms and data structures for generic finite element methods. Specifically, we consider the parallel distribution of mesh data, global enumeration of degrees of freedom, constraints, and postprocessing. Our algorithms remove the bottlenecks that typically limit large-scale adaptive finite element analyses. We demonstrate scalability of complete finite element workflows on up to 16,384 processors. An implementation of the proposed algorithms, based on the open source software p4est as mesh oracle, is provided under an open source license through the widely used deal.II finite element software library. © 2011 ACM 0098-3500/2011/12-ART10 $10.00.","Adaptive mesh refinement; Objectorientation; Parallel algorithms; Software design","Article","Scopus"
"Faouzi J.; Janati H.","Faouzi, Johann (57217236118); Janati, Hicham (57208924897)","57217236118; 57208924897","Pyts: A python package for time series classification","2020","Journal of Machine Learning Research","","39","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086867173&partnerID=40&md5=9a69b8a724752ae976a0536020d51086","Pyts is an open-source Python package for time series classification. This versatile toolbox provides implementations of many algorithms published in the literature, preprocessing functionalities, and data set loading utilities. pyts relies on the standard scientific Python packages numpy, scipy, scikit-learn, joblib, and numba, and is distributed under the BSD-3-Clause license. Documentation contains installation instructions, a detailed user guide, a full API description, and concrete self-contained examples. Source code and documentation can be downloaded from https://github.com/johannfaouzi/pyts. © 2020 Microtome Publishing. All rights reserved.","Classification; Machine learning; Python; Time series","Article","Scopus"
"Bližnák M.; Dulík T.; Vašek V.","Bližnák, Michal (34067456900); Dulík, Tomáš (25960789900); Vašek, Vladimír (35238743500)","34067456900; 25960789900; 35238743500","A persistent cross-platform class objects container for C++ and wxWidgets","2009","WSEAS Transactions on Computers","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-69449090024&partnerID=40&md5=8086714fd809cdef73a5e269afa4561f","This paper introduces a new open-source cross-platform software library written in C++ programming language which is able to serialize and deserialize hierarchically arranged class instances and their data members via XML files. The library provides easy and efficient way for processing, storing and managing complex object-oriented data with relationships between object instances. The library is based on mature cross-platform toolkit called wxWidgets and thus can be successfully used on many target platforms such as MS Windows, Linux or OS X. The library is published under open source licence and can be freely utilised in both open source and commercial projects. In this article, we describe the inner structure of the library, its key algorithms and principles and also demonstrate its usage on a set of simple examples.","C++; Class; Container; Data; List; Persistence; Serialization; Tree; wxWidgets; wxXmlSerializer; wxXS; XML","Article","Scopus"
"González-Beltrán A.; Neumann S.; Maguire E.; Sansone S.-A.; Rocca-Serra P.","González-Beltrán, Alejandra (23396745000); Neumann, Steffen (18038199000); Maguire, Eamonn (25932135100); Sansone, Susanna-Assunta (6603584690); Rocca-Serra, Philippe (6506036751)","23396745000; 18038199000; 25932135100; 6603584690; 6506036751","The Risa R/Bioconductor package: Integrativedata analysis from experimental metadata and back again","2014","BMC Bioinformatics","10.1186/1471-2105-15-S1-S11","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925870701&doi=10.1186%2f1471-2105-15-S1-S11&partnerID=40&md5=319dacd0d397ecb03d6aca166335eba9","Background.: The ISA-Tab format and software suite have been developed to break the silo effect induced by technology-specific formats for a variety of data types and to better support experimental metadata tracking. Experimentalists seldom use a single technique to monitor biological signals. Providing a multi-purpose, pragmatic and accessible format that abstracts away common constructs for describing Investigations, Studies and Assays, ISA is increasingly popular. To attract further interest towards the format and extend support to ensure reproducible research and reusable data, we present the Risa package, which delivers a central component to support the ISA format by enabling effortless integration with R, the popular, open source data crunching environment. Results.: The Risa package bridges the gap between the metadata collection and curation in an ISA-compliant way and the data analysis using the widely used statistical computing environment R. The package offers functionality for: i) parsing ISA-Tab datasets into R objects, ii) augmenting annotation with extra metadata not explicitly stated in the ISA syntax; iii) interfacing with domain specific R packages iv) suggesting potentially useful R packages available in Bioconductor for subsequent processing of the experimental data described in the ISA format; and finally v) saving back to ISA-Tab files augmented with analysis specific metadata from R. We demonstrate these features by presenting use cases for mass spectrometry data and DNA microarray data. Conclusions.: The Risa package is open source (with LGPL license) and freely available through Bioconductor. By making Risa available, we aim to facilitate the task of processing experimental data, encouraging a uniform representation of experimental information and results while delivering tools for ensuring traceability and provenance tracking. Software availability.: The Risa package is available since Bioconductor 2.11 (version 1.0.0) and version 1.2.1 appeared in Bioconductor 2.12, both along with documentation and examples. The latest version of the code is at the development branch in Bioconductor and can also be accessed from GitHub https://github.com/ISA-tools/Risa, where the issue tracker allows users to report bugs or feature requests. © 2014 González-Beltrán et al.; licensee BioMed Central Ltd.","","Article","Scopus"
"Sokol K.; Santos-Rodriguez R.; Flach P.","Sokol, Kacper (57195074647); Santos-Rodriguez, Raul (27968154800); Flach, Peter (7004057691)","57195074647; 27968154800; 7004057691","FAT Forensics: A Python toolbox for algorithmic fairness, accountability and transparency[Formula presented]","2022","Software Impacts","10.1016/j.simpa.2022.100406","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137276348&doi=10.1016%2fj.simpa.2022.100406&partnerID=40&md5=2251ab1b98cbbebb3c0edd1b62f7ba7f","Today, artificial intelligence systems driven by machine learning algorithms can be in a position to take important, and sometimes legally binding, decisions about our everyday lives. In many cases, however, these systems and their actions are neither regulated nor certified. To help counter the potential harm that such algorithms can cause we developed an open source toolbox that can analyse selected fairness, accountability and transparency aspects of the machine learning process: data (and their features), models and predictions, allowing to automatically and objectively report them to relevant stakeholders. In this paper we describe the design, scope, usage and impact of this Python package, which is published under the 3-Clause BSD open source licence. © 2022 The Author(s)","Accountability; Fairness; Python; Software; Toolbox; Transparency","Article","Scopus"
"Pintore S.; Quintiliani M.; Franceschi D.","Pintore, Stefano (8906614100); Quintiliani, Matteo (8906613900); Franceschi, Diego (53874843600)","8906614100; 8906613900; 53874843600","Teseo: A vectoriser of historical seismograms","2005","Computers and Geosciences","10.1016/j.cageo.2005.04.001","41","https://www.scopus.com/inward/record.uri?eid=2-s2.0-27244431615&doi=10.1016%2fj.cageo.2005.04.001&partnerID=40&md5=4535dc49966baba253befb2bacf91359","Historical seismograms contain a rich harvest of information useful for the study of past earthquakes. It is necessary to extract this information by digitising the analogue records if modern analysis is required. Teseo has been developed for quick and accurate digitisation of seismogram traces from raster files, introducing a vectorisation step based on piecewise cubic Bézier curves. The vectoriser can handle greyscale images stored in a suitable file format and it offers three concurrent vectorisation methods: manual, automatic by colour selection, and automatic by neural networks. The software that implements the methods described is distributed with open source license. © 2005 Published by Elsevier Ltd.","Digitisation; Historical seismogram; Vectorisation","Article","Scopus"
"Gong W.; Kim H.J.; Garry D.J.; Kwak I.-Y.","Gong, Wuming (55106311300); Kim, Hyunwoo J. (56336378000); Garry, Daniel J. (7006865345); Kwak, Il-Youp (37021669100)","55106311300; 56336378000; 7006865345; 37021669100","Single cell lineage reconstruction using distance-based algorithms and the R package, DCLEAR","2022","BMC Bioinformatics","10.1186/s12859-022-04633-x","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127023009&doi=10.1186%2fs12859-022-04633-x&partnerID=40&md5=a271c47764afee314cf9b03796e53af2","Background: DCLEAR is an R package used for single cell lineage reconstruction. The advances of CRISPR-based gene editing technologies have enabled the prediction of cell lineage trees based on observed edited barcodes from each cell. However, the performance of existing reconstruction methods of cell lineage trees was not accessed until recently. In response to this problem, the Allen Institute hosted the Cell Lineage Reconstruction Dream Challenge in 2020 to crowdsource relevant knowledge from across the world. Our team won sub-challenges 2 and 3 in the challenge competition. Results: The DCLEAR package contained the R codes, which was submitted in response to sub-challenges 2 and 3. Our method consists of two steps: (1) distance matrix estimation and (2) the tree reconstruction from the distance matrix. We proposed two novel methods for distance matrix estimation as outlined in the DCLEAR package. Using our method, we find that two of the more sophisticated distance methods display a substantially improved level of performance compared to the traditional Hamming distance method. DCLEAR is open source and freely available from R CRAN and from under the GNU General Public License, version 3. Conclusions: DCLEAR is a powerful resource for single cell lineage reconstruction. © 2022, The Author(s).","Cell lineage tracing; Lineage reconstruction; Machine learning; Simulation","Article","Scopus"
"Moldovan I.D.; Cismaşiu I.","Moldovan, Ionuţ Dragoş (26321771600); Cismaşiu, Ildi (8137032500)","26321771600; 8137032500","FreeHyTE: a hybrid-Trefftz finite element platform","2018","Advances in Engineering Software","10.1016/j.advengsoft.2018.03.014","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046435391&doi=10.1016%2fj.advengsoft.2018.03.014&partnerID=40&md5=4467fbbcd04a6763294b8c0001b308bd","FreeHyTE is a public, open-source and user-friendly software for the solution of initial boundary value problems using hybrid-Trefftz finite elements. FreeHyTE is designed to be straightforward to use, even by analysts unacquainted to the Trefftz elements, and amenable to expansion by researchers willing to test their new ideas without having to code common procedures from scratch. To support users, FreeHyTE features intuitive graphical interfaces, automatic mesh generators and adaptive p-refinement procedures. To support developers, FreeHyTE approaches Trefftz elements through a unifying perspective, applicable to hyperbolic, parabolic and elliptic boundary value problems alike. It provides standardized procedures in all phases of the algorithm, including data input, construction and manipulation of the solving system, and post-processing of the results. Moreover, the modular structure of FreeHyTE enables the integration of existing procedures into new modules with minimal coding effort. FreeHyTE's distribution is free under the terms of the GNU General Public License and supported by theory, installation, user's and developer's manuals to quickly get new users and developers started. © 2018 Elsevier Ltd","Boundary value problem; FreeHyTE; Hybrid-Trefftz finite elements; Open-source software; User-friendly interface","Article","Scopus"
"Dwivedi V.D.; Tripathi I.P.; Kaushik A.C.; Bharadwaj S.; Mishra S.K.","Dwivedi, Vivek Dhar (56342514200); Tripathi, Indra Prasad (6602321560); Kaushik, Aman Chandra (57201682415); Bharadwaj, Shiv (57217362041); Mishra, Sarad Kumar (57209527384)","56342514200; 6602321560; 57201682415; 57217362041; 57209527384","Biological Data Analysis Program (BDAP): a multitasking biological sequence analysis program","2018","Neural Computing and Applications","10.1007/s00521-016-2772-z","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006434586&doi=10.1007%2fs00521-016-2772-z&partnerID=40&md5=cb43f403637ca8ad7009e8d6a21d8732","Exploration of mysterious facts from the sequences and structures of biomolecules of an organism is the essential requirement for understanding their molecular and evolutionary processes. Sequence analysis approach is an exciting choice for exploring those mysterious facts from biological data at genomic, transcriptomic and proteomic level. Development of bioinformatics tools is the most challenging task for analyzing these biological data at above three levels. In this communication, an attempt has been made to develop a bioinformatics program “Biological Data Analysis Program (BDAP)” having the ability to analyze the DNA/RNA/protein sequence data at molecular level. It also includes the links of various online databases, tools, search engines and many of the prestigious journals. The coding of the program has been done in Perl language. BDAP is freely available at https://sites.google.com/site/dwivediplanet/bdap under the terms and conditions of GNU General Public License. © 2016, The Natural Computing Applications Forum.","Alignment; Biological data; Mutation; Sequence analysis","Article","Scopus"
"Labatut V.","Labatut, Vincent (36450788000)","36450788000","Continuous average Straightness in spatial graphs","2018","Journal of Complex Networks","10.1093/COMNET/CNX033","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052623352&doi=10.1093%2fCOMNET%2fCNX033&partnerID=40&md5=01c2831a0644e01f4982f54a86495c1f","The Straightness is a measure designed to characterize a pair of vertices in a spatial graph. It is defined as the ratio of the Euclidean distance to the graph distance between these vertices. It is often used as an average, for instance to describe the accessibility of a single vertex relatively to all the other vertices in the graph, or even to summarize the graph as a whole. In some cases, one needs to process the Straightness between not only vertices, but also any other points constituting the graph of interest. Suppose for instance that our graph represents a road network and we do not want to limit ourselves to crossroad-to-crossroad itineraries, but allow any street number to be a starting point or destination. In this situation, the standard approach consists in: (1) discretizing the graph edges, (2) processing the vertex-to-vertex Straightness considering the additional vertices resulting from this discretization and (3) performing the appropriate average on the obtained values. However, this discrete approximation can be computationally expensive on large graphs, and its precision has not been clearly assessed. In this article, we adopt a continuous approach to average the Straightness over the edges of spatial graphs. This allows us to derive five distinct measures able to characterize precisely the accessibility of the whole graph, as well as individual vertices and edges. Our method is generic and could be applied to other measures designed for spatial graphs. We perform an experimental evaluation of our continuous average Straightness measures, and show how they behave differently from the traditional vertex-to-vertex ones. Moreover, we also study their discrete approximations, and show that our approach is globally less demanding in terms of both processing time and memory usage. Our R source code is publicly available under an open source license. © The authors 2017. Published by Oxford University Press. All rights reserved.","Centrality measure; Graph characterization; Spatial graph; Straightness","Article","Scopus"
"Gaillard T.; Schwarz B.B.L.; Chebaro Y.; Stote R.H.; Dejaegere A.","Gaillard, Thomas (22934060800); Schwarz, Benjamin B. L. (55863365600); Chebaro, Yassmine (26321045700); Stote, Roland H. (7003909098); Dejaegere, Annick (56144660300)","22934060800; 55863365600; 26321045700; 7003909098; 56144660300","Protein structural statistics with PSS","2013","Journal of Chemical Information and Modeling","10.1021/ci400233j","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884544557&doi=10.1021%2fci400233j&partnerID=40&md5=14d035b06ee7dabc039148c66980bca1","Characterizing the variability within an ensemble of protein structures is a common requirement in structural biology and bioinformatics. With the increasing number of protein structures becoming available, there is a need for new tools capable of automating the structural comparison of large ensemble of structures. We present Protein Structural Statistics (PSS), a command-line program written in Perl for Unix-like environments, dedicated to the calculation of structural statistics for a set of proteins. PSS can perform multiple sequence alignments, structure superpositions, calculate Cartesian and dihedral coordinate statistics, and execute cluster analyses. An HTML report that contains a convenient summary of results with figures, tables, and hyperlinks can also be produced. PSS is a new tool providing an automated way to compare multiple structures. It integrates various types of structural analyses through an user-friendly and flexible interface, facilitating the access to powerful but more specialized programs. PSS is easy to modify and extend and is distributed under a free and open source license. The relevance of PSS is illustrated by examples of application to pertinent biological problems. © 2013 American Chemical Society.","","Article","Scopus"
"Rijnbeek M.; Steinbeck C.","Rijnbeek, Mark (22035973200); Steinbeck, Christoph (7003655166)","22035973200; 7003655166","OrChem - An open source chemistry search engine for Oracle®","2009","Journal of Cheminformatics","10.1186/1758-2946-1-17","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-74049141327&doi=10.1186%2f1758-2946-1-17&partnerID=40&md5=89e910a134d1a63f862c5459b8d4e82e","Background. Registration, indexing and searching of chemical structures in relational databases is one of the core areas of cheminformatics. However, little detail has been published on the inner workings of search engines and their development has been mostly closed-source. We decided to develop an open source chemistry extension for Oracle, the de facto database platform in the commercial world. Results. Here we present OrChem, an extension for the Oracle 11G database that adds registration and indexing of chemical structures to support fast substructure and similarity searching. The cheminformatics functionality is provided by the Chemistry Development Kit. OrChem provides similarity searching with response times in the order of seconds for databases with millions of compounds, depending on a given similarity cut-off. For substructure searching, it can make use of multiple processor cores on today's powerful database servers to provide fast response times in equally large data sets. Availability. OrChem is free software and can be redistributed and/or modified under the terms of the GNU Lesser General Public License as published by the Free Software Foundation. All software is available via http://orchem.sourceforge.net. © 2009 Rijnbeek and Steinbeck; licensee BioMed Central Ltd.","","Article","Scopus"
"Olson D.L.; Johansson B.; De Carvalho R.A.","Olson, David L. (35561732100); Johansson, Bjorn (57162010900); De Carvalho, Rogerio Atem (57105898300)","35561732100; 57162010900; 57105898300","Open source ERP business model framework","2018","Robotics and Computer-Integrated Manufacturing","10.1016/j.rcim.2015.09.007","23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057470110&doi=10.1016%2fj.rcim.2015.09.007&partnerID=40&md5=fca4b26dfc74ae1027d36ed4467f1bc2","ERP systems became popular with large organizations in the 1990s. In the 21st Century, these products were expanded by addition of supply chain management (SCM) and customer relationship management (CRM), as well as access through the Web, creating the ERP II concept. Efforts to increase the market led vendors to serve not only large organizations, but also focus more on small-to-medium sized enterprises (SMEs). Open source software has become a player in the field of enterprise resource planning (ERP) systems. While it is still unclear to what extent it has diffused among organizations, it is clear that opportunities exist. New ways of delivering ERP software, such as software as a service (SaaS) have appeared. Some smaller vendors utilized a free distribution system (Free/Open Source ERP, FOS-ERP) for their source code, relying on various business models for corporate success. There also have been attempts to generate FOS-ERP components found on sites such as SourceForge.com that are not only distributed freely, but also were developed through community participation much as Linux has been developed. Some ERP vendors use community developed components for various purposes to support their proprietorial software. Thus one dimension of ERP systems is based upon who directs the development process. Proprietorial ERP refers to systems with closely held intellectual property rights, such as the leading market products by SAP and Oracle as well as many smaller proprietorial competitors. FOS-ERP can be community based, or sponsored by some organization. In this paper we present a framework that aims at analyzing FOS-ERP business models. Goals include discussing the differences between FOS-ERP and their proprietary equivalents (P-ERP) in terms of business models, selection, customization, and evolution. We will discuss challenges and opportunities that they offer to adopters and vendors. © 2015 Elsevier Ltd","Business models; Enterprise resource planning (ERP); Evaluation; Open source","Article","Scopus"
"González Téllez A.","González Téllez, Alberto (24577955900)","24577955900","Authoring multimedia learning material using open standards and free software","2008","Interactive Technology and Smart Education","10.1108/17415650880001104","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992992452&doi=10.1108%2f17415650880001104&partnerID=40&md5=6f2730f34ae4f5e9cb061c0edebd1b6f","The purpose of this paper is to describe the case of synchronized multimedia presentations. The proposal is based on SMIL as composition language. Particularly, the paper reuses and customizes the SMIL template used by INRIA on their technical presentations. It also proposes a set of free tools to produce presentation content and design focusing on RealPlayer as delivery client. The integration in this e-learning platform of multimedia compositions developed following the proposed technique is also presented. Technological support to learning and teaching has become widespread due to computers and internet ubiquity. Particularly e-learning platforms permit the any-time-and-any-place distribution of interactive multimedia learning materials. There are commercial tools available to author this kind of content, usually based on proprietary formats. This option has some drawbacks like license cost and software company dependency. To use open data standards and free software is an alternative without these inconveniences but available authoring tools are commonly less productive. This shortcoming is certainly important to non-technical authors and it could be solved by open source collaboration. The paper presents multimedia learning material using open standards and free software. © 2007, Emerald Group Publishing Limited","Computer software; E-learning; Multimedia; Teaching aids","Article","Scopus"
"Birk W.; Castaño M.; Johansson A.","Birk, Wolfgang (6701517068); Castaño, Miguel (7006010756); Johansson, Andreas (25627620600)","6701517068; 7006010756; 25627620600","An application software for visualization and control configuration selection of interconnected processes","2014","Control Engineering Practice","10.1016/j.conengprac.2013.12.012","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897690252&doi=10.1016%2fj.conengprac.2013.12.012&partnerID=40&md5=04e868578224319948dec1ed4128c22a","This paper presents a new application software for control configuration selection of interconnected industrial processes, called ProMoVis. Moreover, ProMoVis is able to visualize process models and process layout at the physical level together with the control system dynamics. The software consists of a builder part where the visual representation of the interconnected process is created and an analyzer part where the process is analyzed using different control configuration selection tools.The conceptual idea of the software is presented and the subsequent design and implementation of ProMoVis are discussed. The implemented analysis methods are briefly described including their usage and implementation aspects. The use of ProMoVis is demonstrated by an application study on the stock preparation process at SCA Obbola AB, Sweden. The results of this study are compared with the currently used control strategy.The study indicates that ProMoVis introduces a systematic and comprehensive way to perform control configuration selection. ProMoVis has been released under the Apache Open Source license. © 2014 Elsevier Ltd.","Control configuration; Interaction measures; Interconnected systems; Process control; Pulp and paper industry; Visualization","Article","Scopus"
"Wójcikowski M.; Zielenkiewicz P.; Siedlecki P.","Wójcikowski, Maciej (56465860900); Zielenkiewicz, Piotr (7004305289); Siedlecki, Pawel (36875328100)","56465860900; 7004305289; 36875328100","Open Drug Discovery Toolkit (ODDT): A new open-source player in the drug discovery field","2015","Journal of Cheminformatics","10.1186/s13321-015-0078-2","84","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84932194253&doi=10.1186%2fs13321-015-0078-2&partnerID=40&md5=d1be666f064e0b8411b89598f3a03c95","Background: There has been huge progress in the open cheminformatics field in both methods and software development. Unfortunately, there has been little effort to unite those methods and software into one package. We here describe the Open Drug Discovery Toolkit (ODDT), which aims to fulfill the need for comprehensive and open source drug discovery software. Results: The Open Drug Discovery Toolkit was developed as a free and open source tool for both computer aided drug discovery (CADD) developers and researchers. ODDT reimplements many state-of-the-art methods, such as machine learning scoring functions (RF-Score and NNScore) and wraps other external software to ease the process of developing CADD pipelines. ODDT is an out-of-the-box solution designed to be easily customizable and extensible. Therefore, users are strongly encouraged to extend it and develop new methods. We here present three use cases for ODDT in common tasks in computer-aided drug discovery. Conclusion: Open Drug Discovery Toolkit is released on a permissive 3-clause BSD license for both academic and industrial use. ODDT's source code, additional examples and documentation are available on GitHub (https://github.com/oddt/oddt). © 2015 Wójcikowski et al.","Machine learning; Programming; Receptor-ligand interactions; Scoring function; Statistical methods; Toolkit; Virtual screening","Article","Scopus"
"Mesuere B.; Willems T.; Van Der Jeugt F.; Devreese B.; Vandamme P.; Dawyndt P.","Mesuere, Bart (55330353100); Willems, Toon (57189594176); Van Der Jeugt, Felix (57189602102); Devreese, Bart (35317162100); Vandamme, Peter (56211244100); Dawyndt, Peter (6603237419)","55330353100; 57189594176; 57189602102; 35317162100; 56211244100; 6603237419","Unipept web services for metaproteomics analysis","2016","Bioinformatics","10.1093/bioinformatics/btw039","37","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973293540&doi=10.1093%2fbioinformatics%2fbtw039&partnerID=40&md5=9cedea6b8d9467ac88d0d82f988d1b5f","Summary Unipept is an open source web application that is designed for metaproteomics analysis with a focus on interactive datavisualization. It is underpinned by a fast index built from UniProtKB and the NCBI taxonomy that enables quick retrieval of all UniProt entries in which a given tryptic peptide occurs. Unipept version 2.4 introduced web services that provide programmatic access to the metaproteomics analysis features. This enables integration of Unipept functionality in custom applications and data processing pipelines. Availability and implementation: The web services are freely available at http://api.unipept.ugent.be and are open sourced under the MIT license. Supplementary information: Supplementary data are available at Bioinformatics online. © 2016 The Author 2016. Published by Oxford University Press. All rights reserved.","","Article","Scopus"
"Voet T.; Devolder P.; Pynoo B.; Vercruysse J.; Duyck P.","Voet, T. (25622663900); Devolder, P. (22936583500); Pynoo, B. (16550544700); Vercruysse, J. (22939545900); Duyck, P. (13410480100)","25622663900; 22936583500; 16550544700; 22939545900; 13410480100","Design and implementation of an open source indexing solution for a large set of radiological reports and images","2007","Journal of Digital Imaging","10.1007/s10278-007-9055-2","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-35449007699&doi=10.1007%2fs10278-007-9055-2&partnerID=40&md5=0fb4ca5c4d7d1b7ee4d4717bcc5d5041","This paper hopes to share the insights we experienced during designing, building, and running an indexing solution for a large set of radiological reports and images in a production environment for more than 3 years. Several technical challenges were encountered and solved in the course of this project. One hundred four million words in 1.8 million radiological reports from 1989 to the present were indexed and became instantaneously searchable in a user-friendly fashion; the median query duration is only 31 ms. Currently, our highly tuned index holds 332,088 unique words in four languages. The indexing system is feature-rich and language-independent and allows for making complex queries. For research and training purposes it certainly is a valuable and convenient addition to our radiology informatics toolbox. Extended use of open-source technology dramatically reduced both implementation time and cost. All software we developed related to the indexing project has been made available to the open-source community covered by an unrestricted Berkeley Software Distribution-style license. © 2007 Society for Imaging Informatics in Medicine.","Document indexing; Medical informatics applications; Open source; PACS integration; Radiology information systems (RIS); Radiology reporting; Search engines","Article","Scopus"
"Santos C.; Kuk G.; Kon F.; Pearson J.","Santos, Carlos (36700519000); Kuk, George (6603024719); Kon, Fabio (6602156198); Pearson, John (56553331000)","36700519000; 6603024719; 6602156198; 56553331000","The attrsssaction of contributors in free and open source software projects","2013","Journal of Strategic Information Systems","10.1016/j.jsis.2012.07.004","62","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875273948&doi=10.1016%2fj.jsis.2012.07.004&partnerID=40&md5=66d038e580088dd12273b9c464e0a94d","As firms increasingly sanction an open sourcing strategy, the question of which open source project to undertake remains tentative. The lack of established metrics makes it difficult to formulate such strategy. While many projects have been formed and created, only a few managed to remain active. With the majority of these projects failing, firms need a reliable set of criteria to assess what makes a project appealing not only to developers but also to visitors, users and commercial sponsors. In this paper, we develop a theoretical model to explore the contextual and causal factors of project attractiveness in inducing activities such as source code contribution, software maintenance, and usage. We test our model with data derived from more than 4000 projects spanning 4 years. Our main findings include that projects' set of conditions such as license restrictiveness and their available resources provide the context that directly influence the amount of work activities observed in the projects. It was also found that indirect and unintended contributions such as recommending software, despite of being non-technical, cannot be ignored for project activeness, diffusion and sustainability. Finally, our analysis provide evidence that higher attractiveness leads to more code-related activities with the downside of slowing down responsiveness to address projects' tasks, such as the implementation of new features and bug fixes. Our model underscores the significance of the reinforcing effects of attractiveness and work activities in open source projects, giving us the opportunity to discuss strategies to manage common traps such as the liability of newness. We conclude by discussing the applicability of the research model to other user-led initiatives. © 2012 Elsevier B.V. All rights reserved.","Attractiveness; Contributions; Contributors; Free software; Open source; Preferential attachment; Software development","Article","Scopus"
"Padillo F.; Luna J.M.; Ventura S.","Padillo, Francisco (57188873275); Luna, Jose Maria (36170791300); Ventura, Sebastian (8846948400)","57188873275; 36170791300; 8846948400","LAC: Library for associative classification","2020","Knowledge-Based Systems","10.1016/j.knosys.2019.105432","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077386086&doi=10.1016%2fj.knosys.2019.105432&partnerID=40&md5=2342f848bdc5b69a58e422a3b76a186a","The goal of this paper is to introduce LAC, a new Java Library for Associative Classification. LAC is the first tool that covers the full taxonomy of this classification paradigm through 10 well-known proposals in the field. Furthermore, it includes several measures to quantify the quality of the solutions as well as different input/output data formats. Last but not least, the library also provides a framework to automate experimental studies, supporting both sequential and parallel executions. Thanks to the GPLv3 license, LAC is totally free, open-source and publicly available. © 2019 Elsevier B.V.","Association rule mining; Associative classification; Classification software; Java class library","Article","Scopus"
"Curtis D.S.; Phillips A.R.; Callister S.J.; Conlan S.; McCue L.A.","Curtis, Darren S. (23667072200); Phillips, Aaron R. (55842031600); Callister, Stephen J. (12241240600); Conlan, Sean (15758942600); McCue, Lee Ann (6603195245)","23667072200; 55842031600; 12241240600; 15758942600; 6603195245","SPOCS: Software for predicting and visualizing orthology/paralogy relationships among genomes","2013","Bioinformatics","10.1093/bioinformatics/btt454","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885635863&doi=10.1093%2fbioinformatics%2fbtt454&partnerID=40&md5=903f3f834dfdc34624b5cabe5d01413a","Summary: At the rate that prokaryotic genomes can now be generated, comparative genomics studies require a flexible method for quickly and accurately predicting orthologs among the rapidly changing set of genomes available. SPOCS implements a graph-based ortholog prediction method to generate a simple tab-delimited table of orthologs and in addition, html files that provide a visualization of the predicted ortholog/paralog relationships to which gene/protein expression metadata may be overlaid. Availability and Implementation: A SPOCS web application is freely available at http://cbb.pnnl.gov/portal/tools/spocs.html. Source code for Linux systems is also freely available under an open source license at http://cbb.pnnl.gov/ portal/software/spocs.html; the Boost C++ libraries and BLAST are required. Contact: leeann.mccue@pnnl.gov. © The Author 2013. Published by Oxford University Press.","","Article","Scopus"
"Ronan T.; Anastasio S.; Qi Z.; Sloutsky R.; Naegle K.M.; Vieira Tavares P.H.S.","Ronan, Tom (54781866800); Anastasio, Shawn (57203787301); Qi, Zhijie (57189707928); Sloutsky, Roman (6506542566); Naegle, Kristen M. (25922608900); Vieira Tavares, Pedro Henrique S. (57203788650)","54781866800; 57203787301; 57189707928; 6506542566; 25922608900; 57203788650","OpenEnSembles: A Python resource for ensemble clustering","2018","Journal of Machine Learning Research","","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052960053&partnerID=40&md5=4879caf9dfdb39c5d2f5106b59817cda","In this paper we introduce OpenEnsembles, a Python toolkit for performing and analyzing ensemble clustering. Ensemble clustering is the process of creating many clustering solutions for a given dataset and utilizing the relationships observed across the ensemble to identify final solutions, which are more robust, stable or better than the individual solutions within the ensemble. The OpenEnsembles library provides a unified interface for applying transformations to data, clustering data, visualizing individual clustering solutions, visualizing and finishing the ensemble, and calculating validation metrics for a clustering solution for any given partitioning of the data. We have documented examples of using OpenEnsembles to create, analyze, and visualize a number of different types of ensemble approaches on toy and example datasets. OpenEnsembles is released under the GNU General Public License version 3, can be installed via Conda or the Python Package Index (pip), and is available at https://github.com/NaegleLab/OpenEnsembles. © 2018 Tom Ronan, Shawn Anastasio, Zhijie Qi, Pedro Henrique S. Vieira Tavares, Roman Sloutsky, and Kristen M. Naegle.","Clustering; Ensemble Clustering; Ensembles; Finishing Techniques; Unsupervised Learning","Article","Scopus"
"Durrant J.D.; Lindert S.; Andrew McCammon J.","Durrant, Jacob D. (12239804300); Lindert, Steffen (26433593000); Andrew McCammon, J. (36050413200)","12239804300; 26433593000; 36050413200","AutoGrow 3.0: An improved algorithm for chemically tractable, semi-automated protein inhibitor design1","2013","Journal of Molecular Graphics and Modelling","10.1016/jjmgm.2013.05.006","40","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885121005&doi=10.1016%2fjjmgm.2013.05.006&partnerID=40&md5=23e1b7a6bd36822584ac71da68c42493","We here present an improved version of AutoGrow (version 3.0), an evolutionary algorithm that works in conjunction with existing open-source software to automatically optimize candidate ligands for predicted binding affinity and other druglike properties. Though no substitute for the medicinal chemist, AutoGrow 3.0, unlike its predecessors, attempts to introduce some chemical intuition into the automated optimization process. AutoGrow 3.0 uses the rules of click chemistry to guide optimization, greatly enhancing synthesizability. Additionally, the program discards any growing ligand whose physical and chemical properties are not druglike. By carefully crafting chemically feasible druglike molecules, we hope that AutoGrow 3.0 will help supplement the chemist's efforts. To demonstrate the utility of the program, we use AutoGrow 3.0 to generate predicted inhibitors of three important drug targets: Trypanosoma brucei RNA editing ligase 1, peroxisome proliferator-activated receptor 7, and dihydrofolate reductase. In all cases, AutoGrow generates druglike molecules with high predicted binding affinities. AutoGrow 3.0 is available free of charge (http://autogrow.ucsd.edu) under the terms of the GNU General Public License and has been tested on Linux and Mac OS X. ^ This is an open-access article distributed underthe terms of the Creative Commons Attribution-NonCommercial-No Derivative Works License, which permits non-commercial use, distribution, and reproduction in any medium, provided the original author and source are credited. © 2013 Elsevier Ltd. All rights reserved.","Autogrow; Click chemistry; Computational chemistry; Drug design","Article","Scopus"
"San Lucas F.A.; Sivakumar S.; Vattathil S.; Fowler J.; Vilar E.; Scheet P.","San Lucas, F. Anthony (57191541415); Sivakumar, Smruthy (57191488641); Vattathil, Selina (16240225500); Fowler, Jerry (56446229000); Vilar, Eduardo (8702260400); Scheet, Paul (7006450580)","57191541415; 57191488641; 16240225500; 56446229000; 8702260400; 7006450580","Rapid and powerful detection of subtle allelic imbalance from exome sequencing data with hapLOHseq","2016","Bioinformatics","10.1093/bioinformatics/btw340","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990889940&doi=10.1093%2fbioinformatics%2fbtw340&partnerID=40&md5=3a5a34322a8821780938b789daf96e37","Motivation: The detection of subtle genomic allelic imbalance events has many potential applications. For example, identifying cancer-associated allelic imbalanced regions in low tumor-cellularity samples or in low-proportion tumor subclones can be used for early cancer detection, prognostic assessment and therapeutic selection in cancer patients. We developed hapLOHseq for the detection of subtle allelic imbalance events from next-generation sequencing data. Results: Our method identified events of 10 megabases or greater occurring in as little as 16% of the sample in exome sequencing data (at 80×) and 4% in whole genome sequencing data (at 30×), far exceeding the capabilities of existing software. We also found hapLOHseq to be superior at detecting large chromosomal changes across a series of pancreatic samples from TCGA. Availability and Implementation: hapLOHseq is available at scheet.org/software, distributed under an open source MIT license. © 2016 The Author. Published by Oxford University Press.","","Article","Scopus"
"Hurley D.G.; Budden D.M.; Crampin E.J.","Hurley, Daniel G. (55169280400); Budden, David M. (55533505100); Crampin, Edmund J. (6603193453)","55169280400; 55533505100; 6603193453","Virtual reference environments: A simple way to make research reproducible","2014","Briefings in Bioinformatics","10.1093/bib/bbu043","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84935016522&doi=10.1093%2fbib%2fbbu043&partnerID=40&md5=1a90f01324858829a2bba197aaec521b","'Reproducible research' has received increasing attention over the past few years as bioinformatics and computational biology methodologies become more complex. Although reproducible research is progressing in several valuable ways, we suggest that recent increases in internet bandwidth and disk space, along with the availability of open-source and free-software licences for tools, enable another simple step to make research reproducible. In this article, we urge the creation of minimal virtual reference environments implementing all the tools necessary to reproduce a result, as a standard part of publication. We address potential problems with this approach, and show an example environment from our own work. © The Author 2014. Published by Oxford University Press.","Open source; Reproducible research; Virtual environments","Article","Scopus"
"Green H.; Durrant J.D.","Green, Harrison (57216357632); Durrant, Jacob D. (12239804300)","57216357632; 12239804300","DeepFrag: An Open-Source Browser App for Deep-Learning Lead Optimization","2021","Journal of Chemical Information and Modeling","10.1021/acs.jcim.1c00103","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108452365&doi=10.1021%2facs.jcim.1c00103&partnerID=40&md5=9d7955efe49918d8a850e8aa894c7597","Lead optimization, a critical step in early stage drug discovery, involves making chemical modifications to a small-molecule ligand to improve properties such as binding affinity. We recently developed DeepFrag, a deep-learning model capable of recommending such modifications. Though a powerful hypothesis-generating tool, DeepFrag is currently implemented in Python and so requires a certain degree of computational expertise. To encourage broader adoption, we have created the DeepFrag browser app, which provides a user-friendly graphical user interface that runs the DeepFrag model in users' web browsers. The browser app does not require users to upload their molecular structures to a third-party server, nor does it require the separate installation of any third-party software. We are hopeful that the app will be a useful tool for both researchers and students. It can be accessed free of charge, without registration, at http://durrantlab.com/deepfrag. The source code is also available at http://git.durrantlab.com/jdurrant/deepfrag-app, released under the terms of the open-source Apache License, Version 2.0.  © 2021 The Authors. Published by American Chemical Society.","","Article","Scopus"
"Pellerin J.; Botella A.; Bonneau F.; Mazuyer A.; Chauvin B.; Lévy B.; Caumon G.","Pellerin, Jeanne (37461847200); Botella, Arnaud (55920429500); Bonneau, François (55653877300); Mazuyer, Antoine (57186681600); Chauvin, Benjamin (57186456200); Lévy, Bruno (35264760300); Caumon, Guillaume (6507427599)","37461847200; 55920429500; 55653877300; 57186681600; 57186456200; 35264760300; 6507427599","RINGMesh: A programming library for developing mesh-based geomodeling applications","2017","Computers and Geosciences","10.1016/j.cageo.2017.03.005","31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015422772&doi=10.1016%2fj.cageo.2017.03.005&partnerID=40&md5=3a18833fd616cda92cfabc6d1c92c046","RINGMesh is a C++ open-source programming library for manipulating discretized geological models. It is designed to ease the development of applications and workflows that use discretized 3D models. It is neither a geomodeler, nor a meshing software. RINGMesh implements functionalities to read discretized surface-based or volumetric structural models and to check their validity. The models can be then exported in various file formats. RINGMesh provides data structures to represent geological structural models, either defined by their discretized boundary surfaces, and/or by discretized volumes. A programming interface allows to develop of new geomodeling methods, and to plug in external software. The goal of RINGMesh is to help researchers to focus on the implementation of their specific method rather than on tedious tasks common to many applications. The documented code is open-source and distributed under the modified BSD license. It is available at https://www.ring-team.org/index.php/software/ringmesh. © 2017 Elsevier Ltd","BRep; C++; Geology; Open-source; Structural model; Unstructured meshes","Article","Scopus"
"Boni A.A.","Boni, Arthur A. (15620249600)","15620249600","A business perspective on IP: Open innovation vs. open source in commercializing biomedical opportunities","2013","Journal of Commercial Biotechnology","10.5912/jcb.599","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879083673&doi=10.5912%2fjcb.599&partnerID=40&md5=ea3d2d56779a64e24cebe674e6dab175","In this article, we address the issues that are involved when developing a strategy for commercializing a discovery that is novel, useful, and non-obvious to someone skilled in the art. Patent(s) may be used as one means of providing a competitive advantage, and in addition this method is quite common as a means to monetize the intellectual asset. Alternatively, a more ""open- source"" method may be employed as is more typical in dealing with software products or services - thereby opening up the field to collaboration and widespread use. However, other means must then be developed to monetize the asset whether it involves a ""hardware"" component, software, or both. We argue that to answer these questions, one needs to be very strategic in framing the business model that would be most successful in commercializing the particular discovery keeping in mind that wide dissemination of the innovation is the objective. We focus on issues prevalent for innovation in biopharma, medtech, and medical IT, where high risk, long life cycle, capital-intensive investments are required for commercial introduction.","Business model; IP; Open innovation; Open source","Article","Scopus"
"Beebe N.L.; Stacy S.D.; Stuckey D.","Beebe, Nicole Lang (8632678600); Stacy, Sonia D. (32467463700); Stuckey, Dane (32467570300)","8632678600; 32467463700; 32467570300","Digital forensic implications of ZFS","2009","Digital Investigation","10.1016/j.diin.2009.06.006","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-68649086184&doi=10.1016%2fj.diin.2009.06.006&partnerID=40&md5=310dd2d3331b101c3369fb69e5b98d26","ZFS is a relatively new, open source file system designed and developed by Sun Microsystems.11As of the writing of this article, Sun Microsystems publicly acknowledged a plan for Oracle to acquire Sun. ZFS was released as open source software under a CDDL license. It is unknown what impact the not yet finalized acquisition will have on ZFS. The stated intent was to develop ""...a new kind of file system that provides simple administration, transactional semantics, end-to-end data integrity, and immense scalability"" (OpenSolaris community). Its functionality, architecture, and disk layout take a relatively radical departure from many commonly used file systems (e.g. FAT, NTFS, EXT2/3, UFS, HFS+, etc.). Since file systems play a very important role in how and where data are stored, as well as the likelihood of their retrieval during digital forensic investigations, it is important that forensics researchers and practitioners understand ZFS and its forensic implications. That is the goal of this article. We first provide the reader with a primer of sorts about ZFS, which lays the foundation for our discussion of ZFS forensics. We then present the results of our analysis of ZFS functionality, architecture, and disk layout - identifying and discussing several digital forensic artifacts and challenges unique to ZFS. © 2009 Digital Forensic Research Workshop.","Copy on write; Data recovery; File system; Forensics; ZFS","Article","Scopus"
"Lourenço J.; Wikramaratna P.S.; Gupta S.","Lourenço, José (36704151000); Wikramaratna, Paul S. (26644500000); Gupta, Sunetra (7407275054)","36704151000; 26644500000; 7407275054","MANTIS: An R package that simulates multilocus models of pathogen evolution","2015","BMC Bioinformatics","10.1186/s12859-015-0598-9","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938985571&doi=10.1186%2fs12859-015-0598-9&partnerID=40&md5=15935c824b9e2aa6ce2804ec7511de77","Background: In host-pathogen systems the development of immunity by the host places pressure on pathogens, by setting up competition between genetic variants due to the establishment of cross-protective responses. These pressures can lead to pathogen-specific, ubiquitous dynamic behaviours. Understanding the evolutionary forces that shape these patterns is one of the key goals of computationally simulated epidemiological models. Despite the contribution of such research methods in recent years to our current understanding of pathogen evolution, the availability of free software tools for the general public remains scarce. Results: We developed the Multilocus ANTIgenic Simulator (MANTIS) software package for the R statistical environment. MANTIS can simulate and analyse epidemiological time-series generated under the biological assumptions of the strain theory of host-pathogen systems by Gupta et al. Conclusions: MANTIS wraps a C/C++ ordinary-differential equations system and Runge-Kutta solver into a set of user-friendly R functions. These include routines to numerically simulate the system and others to analyse, visualize and export results. For this, the package offers its own set of time-series plotting and exportation functions. MANTIS's main goal is to serve as a free, ready-to-use academic software tool. Its open source nature further provides an opportunity for users with advanced programming skills to expand its capabilities. Here, we describe the background theory, implementation, basic functionality and usage of this package. MANTIS is freely available from http://www.eeid.ox.ac.uk/mantis under the GPL license. © 2015 Lourenço et al. licensee BioMed Central.","Evolution; Model; Multilocus; Pathogen; R package","Article","Scopus"
"Sherrouse B.C.; Semmens D.J.; Ancona Z.H.","Sherrouse, Benson C. (36449545700); Semmens, Darius J. (9234898400); Ancona, Zachary H. (57184401700)","36449545700; 9234898400; 57184401700","Social Values for Ecosystem Services (SolVES): Open-source spatial modeling of cultural services","2022","Environmental Modelling and Software","10.1016/j.envsoft.2021.105259","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120342776&doi=10.1016%2fj.envsoft.2021.105259&partnerID=40&md5=223aa0d61e04cd1e1c8028fee5ce1dbc","Social Values for Ecosystem Services (SolVES) version 4.0 is a fully open-source, GIS-based tool designed to aid in the creation of quantitative, spatially explicit models of the nonmonetary values attributed to cultural ecosystem services, such as aesthetics and recreation, specifically to facilitate their incorporation into larger ecosystem service assessments. Newly redeveloped for QGIS, SolVES can be applied in a wide variety of biophysical and social contexts including mountain, forest, coastal, riparian, agricultural, and urban settings worldwide. Redeveloping SolVES for an open-source platform was intended to expand its user base by eliminating the cost of proprietary GIS software licenses and to remove the impact of proprietary software changes on SolVES development. Providing additional options would enable users to delineate relevant stakeholder groups to better assess how differing preferences impact the intensity and spatial distribution of perceived social values. © 2021","Cultural ecosystem services; Nonmonetary valuation; Public participation GIS; Scenarios; Value transfer","Article","Scopus"
"Demir E.; Babur Ö.; Rodchenkov I.; Aksoy B.A.; Fukuda K.I.; Gross B.; Sümer O.S.; Bader G.D.; Sander C.","Demir, Emek (35309628300); Babur, Özgün (12238934400); Rodchenkov, Igor (6506281687); Aksoy, Bülent Arman (55359957600); Fukuda, Ken I. (56263252600); Gross, Benjamin (57190211000); Sümer, Onur Selçuk (55889226500); Bader, Gary D. (7102726136); Sander, Chris (55146122100)","35309628300; 12238934400; 6506281687; 55359957600; 56263252600; 57190211000; 55889226500; 7102726136; 55146122100","Using Biological Pathway Data with Paxtools","2013","PLoS Computational Biology","10.1371/journal.pcbi.1003194","44","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884679902&doi=10.1371%2fjournal.pcbi.1003194&partnerID=40&md5=5c2943383b3cd236a69638b77a65dbba","A rapidly growing corpus of formal, computable pathway information can be used to answer important biological questions including finding non-trivial connections between cellular processes, identifying significantly altered portions of the cellular network in a disease state and building predictive models that can be used for precision medicine. Due to its complexity and fragmented nature, however, working with pathway data is still difficult. We present Paxtools, a Java library that contains algorithms, software components and converters for biological pathways represented in the standard BioPAX language. Paxtools allows scientists to focus on their scientific problem by removing technical barriers to access and analyse pathway information. Paxtools can run on any platform that has a Java Runtime Environment and was tested on most modern operating systems. Paxtools is open source and is available under the Lesser GNU public license (LGPL), which allows users to freely use the code in their software systems with a requirement for attribution. Source code for the current release (4.2.0) can be found in Software S1. A detailed manual for obtaining and using Paxtools can be found in Protocol S1. The latest sources and release bundles can be obtained from biopax.org/paxtools. © 2013 Demir et al.","","Article","Scopus"
"Santillanes G.; Felder R.M.","Santillanes, Gary (55255420500); Felder, Ryan Marshall (56248192200)","55255420500; 56248192200","Software Piracy in Research: A Moral Analysis","2015","Science and Engineering Ethics","10.1007/s11948-014-9573-5","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903806043&doi=10.1007%2fs11948-014-9573-5&partnerID=40&md5=d8e4ed5629c0dab26893fe69c9cf21f6","Researchers in virtually every discipline rely on sophisticated proprietary software for their work. However, some researchers are unable to afford the licenses and instead procure the software illegally. We discuss the prohibition of software piracy by intellectual property laws, and argue that the moral basis for the copyright law offers the possibility of cases where software piracy may be morally justified. The ethics codes that scientific institutions abide by are informed by a rule-consequentialist logic: by preserving personal rights to authored works, people able to do so will be incentivized to create. By showing that the law has this rule-consequentialist grounding, we suggest that scientists who blindly adopt their institutional ethics codes will commit themselves to accepting that software piracy could be morally justified, in some cases. We hope that this conclusion will spark debate over important tensions between ethics codes, copyright law, and the underlying moral basis for these regulations. We conclude by offering practical solutions (other than piracy) for researchers. © 2014, Springer Science+Business Media Dordrecht.","Copyright; Crowdfunding; Fair use; Open source software; Rule consequentialism; Software piracy","Article","Scopus"
"Tiberti M.; Invernizzi G.; Lambrughi M.; Inbar Y.; Schreiber G.; Papaleo E.","Tiberti, Matteo (42462578900); Invernizzi, Gaetano (7005494696); Lambrughi, Matteo (55520006900); Inbar, Yuval (6602738851); Schreiber, Gideon (55861495100); Papaleo, Elena (11339375000)","42462578900; 7005494696; 55520006900; 6602738851; 55861495100; 11339375000","PyInteraph: A framework for the analysis of interaction networks in structural ensembles of proteins","2014","Journal of Chemical Information and Modeling","10.1021/ci400639r","68","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901593833&doi=10.1021%2fci400639r&partnerID=40&md5=5b325203990519ae42d2ac51e5ac4395","In the last years, a growing interest has been gathering around the ability of Molecular Dynamics (MD) to provide insight into the paths of long-range structural communication in biomolecules. The knowledge of the mechanisms related to structural communication helps in the rationalization in atomistic details of the effects induced by mutations, ligand binding, and the intrinsic dynamics of proteins. We here present PyInteraph, a tool for the analysis of structural ensembles inspired by graph theory. PyInteraph is a software suite designed to analyze MD and structural ensembles with attention to binary interactions between residues, such as hydrogen bonds, salt bridges, and hydrophobic interactions. PyInteraph also allows the different classes of intra- and intermolecular interactions to be represented, combined or alone, in the form of interaction graphs, along with performing network analysis on the resulting interaction graphs. The program also integrates the network description with a knowledge-based force field to estimate the interaction energies between side chains in the protein. It can be used alone or together with the recently developed xPyder PyMOL plugin through an xPyder-compatible format. The software capabilities and associated protocols are here illustrated by biologically relevant cases of study. The program is available free of charge as Open Source software via the GPL v3 license at http://linux.btbs.unimib.it/ pyinteraph/. © 2014 American Chemical Society.","","Article","Scopus"
"Geuna A.; Kataishi R.; Toselli M.; Guzmán E.; Lawson C.; Fernandez-Zubieta A.; Barros B.","Geuna, Aldo (6602070937); Kataishi, Rodrigo (55890862100); Toselli, Manuel (56526524900); Guzmán, Eduardo (8912783400); Lawson, Cornelia (55499145300); Fernandez-Zubieta, Ana (37561298300); Barros, Beatriz (6603564658)","6602070937; 55890862100; 56526524900; 8912783400; 55499145300; 37561298300; 6603564658","SiSOB data extraction and codification: A tool to analyze scientific careers","2015","Research Policy","10.1016/j.respol.2015.01.017","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952720032&doi=10.1016%2fj.respol.2015.01.017&partnerID=40&md5=ab3719b7bb690e23e583e62352cd3c7e","This paper describes the methodology and software tool used to build a database on the careers and productivity of academics, using public information available on the Internet, and provides a first analysis of the data collected for a sample of 360 US scientists funded by the National Institute of Health (NIH) and 291 UK scientists funded by the Biotechnology and Biological Sciences Research Council (BBSRC). The tool's structured outputs can be used for either econometric research or data representation for policy analysis. The methodology and software tool is validated for a sample of US and UK biomedical scientists, but can be applied to any countries where scientists' CVs are available in English. We provide an overview of the motivations for constructing the database, and the data crawling and data mining techniques used to transform webpage-based information and CV information into a relational database. We describe the database and the effectiveness of our algorithms and provide suggestions for further improvements. The software developed is released under free software GNU General Public License; the aim is for it to be available to the community of social scientists and economists interested in analyzing scientific production and scientific careers, who it is hoped will develop this tool further. © 2015 Elsevier B.V. All rights reserved.","Academic careers; Extraction and data integration; Information retrieval; Mobility of research scientists; Research productivity","Article","Scopus"
"Douglas J.; Zhang R.; Bouckaert R.","Douglas, Jordan (57189470741); Zhang, Rong (57216817699); Bouckaert, Remco (6603109318)","57189470741; 57216817699; 6603109318","Adaptive dating and fast proposals: Revisiting the phylogenetic relaxed clock model","2021","PLoS Computational Biology","10.1371/JOURNAL.PCBI.1008322","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101361381&doi=10.1371%2fJOURNAL.PCBI.1008322&partnerID=40&md5=2c68396ed99cf8eb78ee35fdb40a912e","Relaxed clock models enable estimation of molecular substitution rates across lineages and are widely used in phylogenetics for dating evolutionary divergence times. Under the (uncorrelated) relaxed clock model, tree branches are associated with molecular substitution rates which are independently and identically distributed. In this article we delved into the internal complexities of the relaxed clock model in order to develop efficient MCMC operators for Bayesian phylogenetic inference. We compared three substitution rate parameterisations, introduced an adaptive operator which learns the weights of other operators during MCMC, and we explored how relaxed clock model estimation can benefit from two cutting-edge proposal kernels: the AVMVN and Bactrian kernels. This work has produced an operator scheme that is up to 65 times more efficient at exploring continuous relaxed clock parameters compared with previous setups, depending on the dataset. Finally, we explored variants of the standard narrow exchange operator which are specifically designed for the relaxed clock model. In the most extreme case, this new operator traversed tree space 40% more efficiently than narrow exchange. The methodologies introduced are adaptive and highly effective on short as well as long alignments. The results are available via the open source optimised relaxed clock (ORC) package for BEAST 2 under a GNU licence (https://github.com/jordandouglas/ORC).  © 2021 Douglas et al.","","Article","Scopus"
"Sprouffske K.; Wagner A.","Sprouffske, Kathleen (23135862500); Wagner, Andreas (57203495887)","23135862500; 57203495887","Growthcurver: An R package for obtaining interpretable metrics from microbial growth curves","2016","BMC Bioinformatics","10.1186/s12859-016-1016-7","260","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007454025&doi=10.1186%2fs12859-016-1016-7&partnerID=40&md5=d4d7c032d39b85a8ee99929a8bf60f5c","Background: Plate readers can measure the growth curves of many microbial strains in a high-throughput fashion. The hundreds of absorbance readings collected simultaneously for hundreds of samples create technical hurdles for data analysis. Results: Growthcurver summarizes the growth characteristics of microbial growth curve experiments conducted in a plate reader. The data are fitted to a standard form of the logistic equation, and the parameters have clear interpretations on population-level characteristics, like doubling time, carrying capacity, and growth rate. Conclusions: Growthcurver is an easy-to-use R package available for installation from the Comprehensive R Archive Network (CRAN). The source code is available under the GNU General Public License and can be obtained from Github (Sprouffske K, Growthcurver sourcecode, 2016). � 2016 Sprouffske and Wagner.","Experimental evolution; Growth curve; Logistic","Article","Scopus"
"Fernández Navarro J.; Lundeberg J.; Ståhl P.L.","Fernández Navarro, José (57190048165); Lundeberg, Joakim (7004756744); Ståhl, Patrik L. (23013295900)","57190048165; 7004756744; 23013295900","ST viewer: A tool for analysis and visualization of spatial transcriptomics datasets","2019","Bioinformatics","10.1093/bioinformatics/bty714","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063013580&doi=10.1093%2fbioinformatics%2fbty714&partnerID=40&md5=cc6d297f268bbbcba53c7a3e8139e46d","Motivation Spatial Transcriptomics (ST) is a technique that combines high-resolution imaging with spatially resolved transcriptome-wide sequencing. This novel type of data opens up many possibilities for analysis and visualization, most of which are either not available with standard tools or too complex for normal users. Results Here, we present a tool, ST Viewer, which allows real-time interaction, analysis and visualization of Spatial Transcriptomics datasets through a seamless and smooth user interface. Availability and implementation The ST Viewer is open source under a MIT license and it is available at https://github.com/SpatialTranscriptomicsResearch/st-viewer. Supplementary informationSupplementary dataare available at Bioinformatics online. © 2018 The Author(s). Published by Oxford University Press. All rights reserved.","","Article","Scopus"
"Dalle J.-M.; Jullien N.","Dalle, Jean-Michel (16177066200); Jullien, Nicolas (54885990300)","16177066200; 54885990300","'Libre' software: Turning fads into institutions?","2003","Research Policy","10.1016/S0048-7333(02)00003-3","66","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037218149&doi=10.1016%2fS0048-7333%2802%2900003-3&partnerID=40&md5=52474f63249b600433ed23af9e3e85e2","The article presents an economic analysis of Libre software and of its sustainability as a new economic model for software. We underline the role of Libre software development communities and analyze incentives for both kernel and obscure developers. We emphasize the role of the so-called 'public' licenses to provide an appropriate institutional framework. We show that several features of Libre software also allow it to improve faster than proprietary software, and therefore to achieve strong market performance when competing against existing standards, even when proprietary software producers react. We illustrate our point using a simple local and global interaction model to study the technological competition between Linux and Windows on the server operating system (OS) market. We finally argue that if sufficient initial momentum could be created through public intervention Libre software could turn from a fad into an efficient economic institution to correct inefficiencies due to network externalities. © 2002 Published by Elsevier Science B.V.","Community; Incentives; Libre software; Linux; Network effects; Network externalities; Technological competition","Article","Scopus"
"Mehta C.; Karthi A.; Jetly V.; Chaudhury B.","Mehta, Chahak (57223163802); Karthi, Amarnath (57223169634); Jetly, Vishrut (57221411360); Chaudhury, Bhaskar (11240065600)","57223163802; 57223169634; 57221411360; 11240065600","Parallel Fast Multipole Method accelerated FFT on HPC clusters","2021","Parallel Computing","10.1016/j.parco.2021.102783","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105086761&doi=10.1016%2fj.parco.2021.102783&partnerID=40&md5=b769b5f3fd6a0d166917735ec1493545","With increasing sizes of distributed systems, there comes an increased risk of communication bottlenecks. In the past decade there has been a growing interest in communication-avoiding algorithms. The distributed memory Fast Fourier Transform is an important algorithm which suffers from major communication bottlenecks. In this work, we take a look at an existing communication-avoiding algorithm FMM-FFT, an alternative to FFT which utilizes the Fast Multipole Method (FMM) to reduce communications to a single all-to-all communication. We present a detailed implementation of FMM-FFT relying on modern libraries and demonstrate it on two distinct distributed memory architectures notably a traditional Intel Xeon based HPC cluster and then a Beowulf cluster. We show that while the FMM-FFT is significantly slower than FFT on the traditional HPC cluster, on the Beowulf cluster it outperforms standard FFT, consistently getting speedups of 1.5x or more against FFTW. We then proceed to show how the communication to computation cost metric is important and useful in explaining the performance results of FMM-FFT against standard FFT. The source code pertaining to this work is being made publicly available under a permissive open source licence at Github. © 2021 Elsevier B.V.","Beowulf cluster; Communication avoiding algorithms; Fast Fourier Transform; Fast Multipole Method; High performance computing; Parallel programming","Article","Scopus"
"Spinellis D.","Spinellis, Diomidis (35566637400)","35566637400","I spy","2007","IEEE Software","10.1109/MS.2007.43","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34047100490&doi=10.1109%2fMS.2007.43&partnerID=40&md5=14184b4a6cfa001a6893cbacf778eaae","Most tools can help solve a problem but they have a number of drawbacks. Sun's dynamic-tracing framework referred to as DTrace provides uniform mechanisms for spying comprehensively and unobtrusively on the operating system, application servers, runtime environments, libraries and application programs. The tool is open source under Sun's fairly liberal Common Development and Distribution License. In typical use, DTrace scripts range from one-liners to tens of lines containing multiple predicate-action pairs.","","Article","Scopus"
"Brehm M.; Kirchner B.","Brehm, Martin (38661083600); Kirchner, Barbara (7004315014)","38661083600; 7004315014","TRAVIS - A free analyzer and visualizer for monte carlo and molecular dynamics trajectories","2011","Journal of Chemical Information and Modeling","10.1021/ci200217w","746","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051994561&doi=10.1021%2fci200217w&partnerID=40&md5=212cb33c6eeb0c141205e4738c76d6e9","We present TRAVIS (""TRajectory Analyzer and VISualizer""), a free program package for analyzing and visualizing Monte Carlo and molecular dynamics trajectories. The aim of TRAVIS is to collect as many analyses as possible in one program, creating a powerful tool and making it unnecessary to use many different programs for evaluating simulations. This should greatly rationalize and simplify the workflow of analyzing trajectories. TRAVIS is written in C++, open-source freeware and licensed under the terms of the GNU General Public License (GPLv3). It is easy to install (platform independent, no external libraries) and easy to use. In this article, we present some of the algorithms that are implemented in TRAVIS - many of them widely known for a long time, but some of them also to appear in literature for the first time. All shown analyses only require a standard MD trajectory as input data. © 2011 American Chemical Society.","","Article","Scopus"
"Lafita A.; Bliven S.; Prlić A.; Guzenko D.; Rose P.W.; Bradley A.; Pavan P.; Myers-Turnbull D.; Valasatava Y.; Heuer M.; Larson M.; Burley S.K.; Duarte J.M.","Lafita, Aleix (57200724115); Bliven, Spencer (36629948800); Prlić, Andreas (8975983000); Guzenko, Dmytro (55857749200); Rose, Peter W. (7201669132); Bradley, Anthony (56394988200); Pavan, Paolo (34873050300); Myers-Turnbull, Douglas (56113483300); Valasatava, Yana (55942909900); Heuer, Michael (35848421600); Larson, Matt (57219241647); Burley, Stephen K. (16749310300); Duarte, Jose M. (35566119000)","57200724115; 36629948800; 8975983000; 55857749200; 7201669132; 56394988200; 34873050300; 56113483300; 55942909900; 35848421600; 57219241647; 16749310300; 35566119000","Biojava 5: A community driven open-source bioinformatics library","2019","PLoS Computational Biology","10.1371/journal.pcbi.1006791","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061966432&doi=10.1371%2fjournal.pcbi.1006791&partnerID=40&md5=c3a2ee6e808a2732dd79ce358bbd1702","BioJava is an open-source project that provides a Java library for processing biological data. The project aims to simplify bioinformatic analyses by implementing parsers, data structures, and algorithms for common tasks in genomics, structural biology, ontologies, phylogenetics, and more. Since 2012, we have released two major versions of the library (4 and 5) that include many new features to tackle challenges with increasingly complex macromolecular structure data. BioJava requires Java 8 or higher and is freely available under the LGPL 2.1 license. The project is hosted on GitHub at https://github.com/biojava/biojava. More information and documentation can be found online on the BioJava website (http:// www.biojava.org) and tutorial (https://github.com/biojava/biojava-tutorial). All inquiries should be directed to the GitHub page or the BioJava mailing list (http://lists.open-bio.org/ mailman/listinfo/biojava-l). © 2019 Lafita et al.","","Article","Scopus"
"Bisani M.; Ney H.","Bisani, Maximilian (13609786700); Ney, Hermann (7006360226)","13609786700; 7006360226","Joint-sequence models for grapheme-to-phoneme conversion","2008","Speech Communication","10.1016/j.specom.2008.01.002","492","https://www.scopus.com/inward/record.uri?eid=2-s2.0-41049105254&doi=10.1016%2fj.specom.2008.01.002&partnerID=40&md5=63e1d6b4163e1cdeeb5fef6319d68973","Grapheme-to-phoneme conversion is the task of finding the pronunciation of a word given its written form. It has important applications in text-to-speech and speech recognition. Joint-sequence models are a simple and theoretically stringent probabilistic framework that is applicable to this problem. This article provides a self-contained and detailed description of this method. We present a novel estimation algorithm and demonstrate high accuracy on a variety of databases. Moreover, we study the impact of the maximum approximation in training and transcription, the interaction of model size parameters, n-best list generation, confidence measures, and phoneme-to-grapheme conversion. Our software implementation of the method proposed in this work is available under an Open Source license. © 2008 Elsevier B.V. All rights reserved.","Grapheme-to-phoneme; Joint-sequence model; Letter-to-sound; Phonemic transcription; Pronunciation modeling","Article","Scopus"
"Distefano A.; Me G.","Distefano, Alessandro (24491757300); Me, Gianluigi (6603240003)","24491757300; 6603240003","An overall assessment of Mobile Internal Acquisition Tool","2008","Digital Investigation","10.1016/j.diin.2008.05.010","26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-48749091043&doi=10.1016%2fj.diin.2008.05.010&partnerID=40&md5=f5ce096f2020bb40efba3dc85b06666a","The smartphone market provides a great variety of manufacturers and models causing a strong (and mandatory) heterogeneity of the hardware tools adopted to retrieve smartphone contents in a forensically sound way. Thus, in order to lighten the burden for already overtaxed police operators, with possible increase of forensics productivity, we already identified, in a previous work, a new Mobile Equipment (ME) acquisition paradigm. In fact, it's possible to avoid the practical problems related to the USB/mobile phone plug heterogeneity, currently used by the mobile forensics tools, through the use of the MMC/SD slot, part of the hardware equipment of the target ME. This solution overcomes the problems related to the acquisition through the cables, simply relying on a piece of software installed stored into the SD/MMC. The contribution of this paper enriches the methodology already presented by the authors and presents some fundamental properties of the Mobile Internal Acquisition Tool (MIAT) in order to assess the performance with respect to the state of the art of the mobile forensics tools. The results of the assessment encourage the adoption of this tool, since integrity, performances and operational methodology mostly overall benefit from this approach, while, in the worst case, remain at the same level of the state of the art COTS. Finally, this tool, intended to be released under an Open Source license, proposes the paradigm where the acquisition source code is in the public domain, while the analysis and presentation are left to self-made/proprietary tools. © 2008 Digital Forensic Research Workshop.","API; Forensic acquisition; Memory card; Symbian; TAC","Article","Scopus"
"Silvestre-Ryan J.; Wang Y.; Sharma M.; Lin S.; Shen Y.; Dider S.; Holmes I.","Silvestre-Ryan, Jordi (47161530600); Wang, Yujie (57221325493); Sharma, Mehak (57221321271); Lin, Stephen (57222906108); Shen, Yolanda (57221324517); Dider, Shihab (57103807600); Holmes, Ian (32967474100)","47161530600; 57221325493; 57221321271; 57222906108; 57221324517; 57103807600; 32967474100","Machine Boss: rapid prototyping of bioinformatic automata","2021","Bioinformatics (Oxford, England)","10.1093/bioinformatics/btaa633","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097354036&doi=10.1093%2fbioinformatics%2fbtaa633&partnerID=40&md5=4bb2d97ac9d785d5afa57c3285754821","MOTIVATION: Many software libraries for using Hidden Markov Models in bioinformatics focus on inference tasks, such as likelihood calculation, parameter-fitting and alignment. However, construction of the state machines can be a laborious task, automation of which would be time-saving and less error-prone. RESULTS: We present Machine Boss, a software tool implementing not just inference and parameter-fitting algorithms, but also a set of operations for manipulating and combining automata. The aim is to make prototyping of bioinformatics HMMs as quick and easy as the construction of regular expressions, with one-line 'recipes' for many common applications. We report data from several illustrative examples involving protein-to-DNA alignment, DNA data storage and nanopore sequence analysis. AVAILABILITY AND IMPLEMENTATION: Machine Boss is released under the BSD-3 open source license and is available from http://machineboss.org/. SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online. © The Author(s) 2020. Published by Oxford University Press.","","Article","Scopus"
"Savelyev A.; Gorbet G.E.; Henrickson A.; Demeler B.","Savelyev, Alexey (15063357700); Gorbet, Gary E. (55827787000); Henrickson, Amy (57215127681); Demeler, Borries (7004087211)","15063357700; 55827787000; 57215127681; 7004087211","Moving analytical ultracentrifugation software to a good manufacturing practices (GMP) environment","2020","PLoS Computational Biology","10.1371/journal.pcbi.1007942","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087738501&doi=10.1371%2fjournal.pcbi.1007942&partnerID=40&md5=32351e0e7d173c2f57bb96718c90b7a1","Recent advances in instrumentation have moved analytical ultracentrifugation (AUC) closer to a possible validation in a Good Manufacturing Practices (GMP) environment. In order for AUC to be validated for a GMP environment, stringent requirements need to be satisfied; analysis procedures must be evaluated for consistency and reproducibility, and GMP capable data acquisition software needs to be developed and validated. These requirements extend to multiple regulatory aspects, covering documentation of instrument hardware functionality, data handling and software for data acquisition and data analysis, process control, audit trails and automation. Here we review the requirements for GMP validation of data acquisition software and illustrate software solutions based on UltraScan that address these requirements as far as they relate to the operation and data handling in conjunction with the latest analytical ultracentrifuge, the Optima AUC by Beckman Coulter. The software targets the needs of regulatory agencies, where AUC plays a critical role in the solutionbased characterization of biopolymers and macromolecular assemblies. Biopharmaceutical and regulatory agencies rely heavily on this technique for characterizations of pharmaceutical formulations, biosimilars, injectables, nanoparticles, and other soluble therapeutics. Because of its resolving power, AUC is a favorite application, despite the current lack of GMP validation. We believe that recent advances in standards, hardware, and software presented in this work manage to bridge this gap and allow AUC to be routinely used in a GMP environment. AUC has great potential to provide more detailed information, at higher resolution, and with greater confidence than other analytical techniques, and our software satisfies an urgent need for AUC operation in the GMP environment. The software, including documentation, are publicly available for free download from Github. The multi-platform software is licensed by the LGPL v.3 open source license and supports Windows, Mac and Linux platforms. Installation instructions and a mailing list are available from ultrascan.aucsolutions.com. Copyright: © 2020 Savelyev et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Article","Scopus"
"Nishizawa H.; Ishida W.; Sone Y.; Tanaka T.; Kuwabara S.; Inui T.; Sasai T.; Tomizawa M.","Nishizawa, Hideki (36811407400); Ishida, Wataru (57217459815); Sone, Yoshiaki (15129341500); Tanaka, Takafumi (55811690600); Kuwabara, Seiki (35883652200); Inui, Tetsuro (7203009180); Sasai, Takeo (57207908274); Tomizawa, Masahito (57080453200)","36811407400; 57217459815; 15129341500; 55811690600; 35883652200; 7203009180; 57207908274; 57080453200","Open whitebox architecture for smart integration of optical networking and data center technology [Invited]","2021","Journal of Optical Communications and Networking","10.1364/JOCN.403205","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097646843&doi=10.1364%2fJOCN.403205&partnerID=40&md5=584a7778b5c5b6ff20509a951bd374b3","In this paper, we identify challenges in developing future optical network infrastructure for new services based on technologies such as 5G, virtual reality, and artificial intelligence, and we suggest approaches to handling these challenges that include a business model, architecture, and diversity. Through activities in multiservice agreement and de facto standard organizations, we have shown how the hardware abstraction layer interfaces of optical transceivers are implemented for multivendor and heterogeneous environments, coherent digital signal processor interoperability, and optical transport whiteboxes. We have driven the effort to define the transponder abstraction interface with partners. The feasibility of such implementation was verified through demonstrations and trials. In addition, we are constructing an open-transport platform by combining existing open-source software and implementing software components that automate and enhance operations. An open architecture maintains a healthy ecosystem for industry and allows for a flexible, operator-driven network.  © 2009-2012 OSA.","","Article","Scopus"
"Machado D.J.","Machado, Denis Jacob (55958393200)","55958393200","YBYRÁ facilitates comparison of large phylogenetic trees","2015","BMC Bioinformatics","10.1186/s12859-015-0642-9","26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938998647&doi=10.1186%2fs12859-015-0642-9&partnerID=40&md5=891036eea5ac5064a99266dded249fb9","Background: The number and size of tree topologies that are being compared by phylogenetic systematists is increasing due to technological advancements in high-throughput DNA sequencing. However, we still lack tools to facilitate comparison among phylogenetic trees with a large number of terminals. Results: The ""YBYRÁ"" project integrates software solutions for data analysis in phylogenetics. It comprises tools for (1) topological distance calculation based on the number of shared splits or clades, (2) sensitivity analysis and automatic generation of sensitivity plots and (3) clade diagnoses based on different categories of synapomorphies. YBYRÁ also provides (4) an original framework to facilitate the search for potential rogue taxa based on how much they affect average matching split distances (using MSdist). Conclusions: YBYRÁ facilitates comparison of large phylogenetic trees and outperforms competing software in terms of usability and time efficiency, specially for large data sets. The programs that comprises this toolkit are written in Python, hence they do not require installation and have minimum dependencies. © 2015 Machado.","Diagnostic character states; Rogue taxa; Sensitivity analysis; Tree comparison","Article","Scopus"
"Galaz J.; Cienfuegos R.; Echeverría A.; Pereira S.; Bertín C.; Prato G.; Karich J.C.","Galaz, J. (57430159900); Cienfuegos, R. (14047837000); Echeverría, A. (57514425700); Pereira, S. (57220664358); Bertín, C. (57217258987); Prato, G. (57391784400); Karich, J.C. (57391526800)","57430159900; 14047837000; 57514425700; 57220664358; 57217258987; 57391784400; 57391526800","Integrating tsunami simulations in web applications using BROWNI, an open source client-side GPU-powered tsunami simulation library","2022","Computers and Geosciences","10.1016/j.cageo.2021.104976","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122030400&doi=10.1016%2fj.cageo.2021.104976&partnerID=40&md5=876ee2b24557074ad2e267c605e61f4c","Tsunami simulation software is a key component of state-of-the-art early warning systems but the inherent complexities in phases of installation, execution, pre and post-processing prevent their use in other areas of risk management such as communication and education. Recent advances in software and computational capacities such as the efficiency of GPU computing and the ubiquity of web browsers bring new opportunities to bridge the gap between expert and non-expert users. Here we present a Javascript library to enable a web browser to facilitate gathering and analyzing data from tsunami simulations, by means of interactive and efficient visualizations. At its core, the library uses WebGL, the browser's standard 3D graphics API, to run GPU accelerated computations of a tsunami model. A far-field tsunami model is implemented (linear shallow water equations discretized on spherical coordinates), and its implementation is validated against real tsunami observations, and benchmarked with two other tsunami software-packages. Two software platforms that use this library are presented to illustrate the powerful applications that can be developed for risk communication and education. These applications are characterized by their interactivity and fast computations, which enable users to focus on the understanding of the phenomena of tsunami propagation and iterate quickly to assess different scenarios and potential implications to tsunami risk management. Some limitations on this approach are discussed, in aspects such as scalability, performance, multi-threading and batch-processing, that can be relevant for other users. In our experience, the before mentioned benefits very well compensate the discussed limitations for this kind of applications. The library has an open source license, and is meant to be imported without modifying its source code to facilitate the creation of new applications as the ones herein presented. © 2021","GPU; Javascript; Simulation library; Tsunami; Visualization; Web","Article","Scopus"
"Rego N.; Koes D.","Rego, Nicholas (57200014444); Koes, David (6504625843)","57200014444; 6504625843","3Dmol.js: Molecular visualization with WebGL","2015","Bioinformatics","10.1093/bioinformatics/btu829","153","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927720583&doi=10.1093%2fbioinformatics%2fbtu829&partnerID=40&md5=ce7d5341b6f91717ce2404669d4324af","Summary: 3Dmol.js is a modern, object-oriented JavaScript library that uses the latest web technologies to provide interactive, hardware-accelerated three-dimensional representations of molecular data without the need to install browser plugins or Java. 3Dmol.js provides a full featured API for developers as well as a straightforward declarative interface that lets users easily share and embed molecular data in websites. Availability and implementation: 3Dmol.js is distributed under the permissive BSD open source license. Source code and documentation can be found at http://3Dmol.csb.pitt.edu © 2014 The Author.","","Article","Scopus"
"Stamate C.; Pons J.S.; Weston D.; Roussos G.","Stamate, Cosmin (57194415195); Pons, Joan Saez (35485399800); Weston, David (23981228700); Roussos, George (6602699769)","57194415195; 35485399800; 23981228700; 6602699769","PDKit: A data science toolkit for the digital assessment of Parkinson’s Disease","2021","PLoS Computational Biology","10.1371/journal.pcbi.1008833","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102618695&doi=10.1371%2fjournal.pcbi.1008833&partnerID=40&md5=c6182a58c82ccbb7435e75de7a4dd2e1","PDkit is an open source software toolkit supporting the collaborative development of novel methods of digital assessment for Parkinson’s Disease, using symptom measurements captured continuously by wearables (passive monitoring) or by high-use-frequency smartphone apps (active monitoring). The goal of the toolkit is to help address the current lack of algorithmic and model transparency in this area by facilitating open sharing of standardised methods that allow the comparison of results across multiple centres and hardware variations. PDkit adopts the information-processing pipeline abstraction incorporating stages for data ingestion, quality of information augmentation, feature extraction, biomarker estimation and finally, scoring using standard clinical scales. Additionally, a dataflow programming framework is provided to support high performance computations. The practical use of PDkit is demonstrated in the context of the CUSSP clinical trial in the UK. The toolkit is implemented in the python programming language, the de facto standard for modern data science applications, and is widely available under the MIT license. © 2021 Stamate et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Article","Scopus"
"Weninger F.; Bergmann J.; Schuller B.","Weninger, Felix (13610240900); Bergmann, Johannes (56673651200); Schuller, Björn (6603767415)","13610240900; 56673651200; 6603767415","Introducing CURRENNT: The Munich open-source CUDA RecurREnt neural network toolkit","2015","Journal of Machine Learning Research","","114","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930639546&partnerID=40&md5=64ce515863b57ea9a1d280c222adfee4","In this article, we introduce CURRENNT, an open-source parallel implementation of deep recurrent neural networks (RNNs) supporting graphics processing units (GPUs) through NVIDIA's Computed Unified Device Architecture (CUDA). CURRENNT supports uni- and bidirectional RNNs with Long Short-Term Memory (LSTM) memory cells which overcome the vanishing gradient problem. To our knowledge, CURRENNT is the first publicly available parallel implementation of deep LSTM-RNNs. Benchmarks are given on a noisy speech recognition task from the 2013 2nd CHiME Speech Separation and Recognition Challenge, where LSTM-RNNs have been shown to deliver best performance. In the result, double digit speedups in bidirectional LSTM training are achieved with respect to a reference single-threaded CPU implementation. CURRENNT is available under the GNU General Public License from http://sourceforge.net/p/currennt. ©2015 Felix Weninger, Johannes Bergmann and Björn Schuller.","Deep neural networks; Long short-term memory; Parallel computing; Recurrent neural networks","Article","Scopus"
"Clewley R.","Clewley, Robert (6508245638)","6508245638","Hybrid Models and Biological Model Reduction with PyDSTool","2012","PLoS Computational Biology","10.1371/journal.pcbi.1002628","52","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866119498&doi=10.1371%2fjournal.pcbi.1002628&partnerID=40&md5=510a1ddac99704feb973ba7a8fc82b41","The PyDSTool software environment is designed to develop, simulate, and analyze dynamical systems models, particularly for biological applications. Unlike the engineering application focus and graphical specification environments of most general purpose simulation tools, PyDSTool provides a programmatic environment well suited to exploratory data- and hypothesis-driven biological modeling problems. In this work, we show how the environment facilitates the application of hybrid dynamical modeling to the reverse engineering of complex biophysical dynamics; in this case, of an excitable membrane. The example demonstrates how the software provides novel tools that support the inference and validation of mechanistic hypotheses and the inclusion of data constraints in both quantitative and qualitative ways. The biophysical application is broadly relevant to models in the biosciences. The open source and platform-independent PyDSTool package is freely available under the BSD license from http://sourceforge.net/projects/pydstool/. The hosting service provides links to documentation and online forums for user support. © 2012 Robert Clewley.","","Article","Scopus"
"Kozlov K.; Samsonov A.M.; Samsonova M.","Kozlov, Konstantin (55408249000); Samsonov, Alexander M. (7005747479); Samsonova, Maria (7003974330)","55408249000; 7005747479; 7003974330","A software for parameter optimization with differential evolution entirely parallel method","2016","PeerJ Computer Science","10.7717/peerj-cs.74","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030182744&doi=10.7717%2fpeerj-cs.74&partnerID=40&md5=9cd5b89abedd7f6427186b9b3cce9737","Differential Evolution Entirely Parallel (DEEP) package is a software for finding unknown real and integer parameters in dynamical models of biological processes by minimizing one or even several objective functions that measure the deviation of model solution from data. Numerical solutions provided by the most efficient global optimization methods are often problem-specific and cannot be easily adapted to other tasks. In contrast, DEEP allows a user to describe both mathematical model and objective function in any programming language, such as R, Octave or Python and others. Being implemented in C, DEEP demonstrates as good performance as the top three methods from CEC-2014 (Competition on evolutionary computation) benchmark and was successfully applied to several biological problems. Availability. DEEP method is an open source and free software distributed under the terms of GPL licence version 3. The sources are available at http://deepmethod. sourceforge.net/ and binary packages for Fedora GNU/Linux are provided for RPM package manager at https://build.opensuse.org/project/repositories/home:mackoel: compbio. © 2016 Kozlov et al.","Bioinformatics; Differential Evolution; Mathematical modeling; Open source software; Parallelization; Parameter optimization","Article","Scopus"
"Greco J.F.","Greco, Joseph F. (57197652155)","57197652155","The commercialisation of bioinformatics and the threat of open-source software","2007","Journal of Commercial Biotechnology","10.1057/palgrave.jcb.3050051","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547896635&doi=10.1057%2fpalgrave.jcb.3050051&partnerID=40&md5=c9590b3176ab0cc75c27786c430c3b52","This study investigates the commercialisation process of a select group of bioinformatics companies and the impact of open-source software. Using the research-development-application translation model provides a framework for managers as an iterative mechanism. A Value Creation Pipeline is then introduced with five phases of the commercialisation process that provide specific financial benchmarks that can guide the firm through to successful commercialisation. Using trend and financial ratio analyses relative to returns, profitability and liquidity, the study finds that the surge in open-source licenses between 2003 and 2005 limited the sales for some firms. As for the claim that open-source software negatively impacts the success of bioinformatics commercialisation, there was little evidence to suggest a direct cause-and-effect relationship. Losses in returns, profitability and liquidity were just as common before the rise of open source as after its emergence. When firms report an overall record over a nine-year period of poor return on investment, assets and equity, there is little to attract potential investors. The lesson that can be drawn is that the innovation process and financial tracking must be integrated to ensure efficient and profitable use of investor funds.","","Article","Scopus"
"Dejanović I.; Vaderna R.; Milosavljević G.; Vuković Ž.","Dejanović, I. (56473610200); Vaderna, R. (57015596700); Milosavljević, G. (6508132948); Vuković, Ž. (57014929500)","56473610200; 57015596700; 6508132948; 57014929500","TextX: A Python tool for Domain-Specific Languages implementation","2017","Knowledge-Based Systems","10.1016/j.knosys.2016.10.023","27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006271509&doi=10.1016%2fj.knosys.2016.10.023&partnerID=40&md5=9a1541239a24bdf8f1c4fe27afaac49f","TextX is a meta-language and a tool for building Domain-Specific Languages in Python. It's built on top of the Arpeggio PEG parser and takes away the burden of converting parse trees to abstract representations from language designers. From a single grammar description, textX constructs Arpeggio parser and a meta-model in run-time. The meta-model contains all the information about the language and a set of Python classes inferred from grammar rules. The parser will parse programs/models written in the new language and construct Python object graph a.k.a. the model conforming to the meta-model. The textX tool has support for error reporting, debugging, and meta-model and model visualization. It is used in industrial environments and teaching Domain-Specific Languages course at the Faculty of Technical Sciences in Novi Sad. It is a free and open-source software available at GitHub under the MIT license. © 2016","Domain-Specific Language; Meta-model; Model; Model-Driven software development; Parser; Python","Article","Scopus"
"Noleto-Filho E.M.; Angelini R.; Steenbeek J.; Carvalho A.R.","Noleto-Filho, Eurico Mesquita (57193221125); Angelini, Ronaldo (56249804800); Steenbeek, Jeroen (26668052900); Carvalho, Adriana Rosa (7201882441)","57193221125; 56249804800; 26668052900; 7201882441","New, flexible and open-source fisheries self-reporting app: The Shiny4SelfReport","2021","SoftwareX","10.1016/j.softx.2021.100843","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118508508&doi=10.1016%2fj.softx.2021.100843&partnerID=40&md5=fc0930aca87e65cb2a10e1e2df3f5d83","Self-reporting applications are considered a promising solution for fisheries data monitoring. However, they are still failing in providing accurate information and engaging users. We introduce the Shiny4SelfReport, an application for self-reporting data in fisheries that aims to address these shortcomings. Instead of using expensive proprietary software, we demonstrate how common and affordable technologies can be used to fill gaps in fisheries management of developing nations. The tool, developed in R, works by gathering fishers’ inputs and storing them in the cloud. It was designed to be simple and adaptable. Our application improves the data assembly on small-scale fisheries, provides fishers’ engagement and data accuracy, and may integrate fisheries’ knowledge worldwide while filling the gaps on data-poor fisheries. The app is available at http://triatlas.shinyapps.io/Shiny4SelfReport under a General Public License (GPLv3). © 2021 The Authors","Fisheries; Monitoring; R software; Self-reporting; Shiny apps","Article","Scopus"
"Li P.; Merz K.M., Jr.","Li, Pengfei (55767751900); Merz, Kenneth M. (35512085100)","55767751900; 35512085100","MCPB.py: A Python Based Metal Center Parameter Builder","2016","Journal of Chemical Information and Modeling","10.1021/acs.jcim.5b00674","273","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969166500&doi=10.1021%2facs.jcim.5b00674&partnerID=40&md5=ecc21725cf28f868b8be1c324aad440a","MCPB.py, a python based metal center parameter builder, has been developed to build force fields for the simulation of metal complexes employing the bonded model approach. It has an optimized code structure, with far fewer required steps than the previous developed MCPB program. It supports various AMBER force fields and more than 80 metal ions. A series of parametrization schemes to derive force constants and charge parameters are available within the program. We give two examples (one metalloprotein example and one organometallic compound example), indicating the program's ability to build reliable force fields for different metal ion containing complexes. The original version was released with AmberTools15. It is provided via the GNU General Public License v3.0 (GNU-GPL-v3) agreement and is free to download and distribute. MCPB.py provides a bridge between quantum mechanical calculations and molecular dynamics simulation software packages thereby enabling the modeling of metal ion centers. It offers an entry into simulating metal ions in a number of situations by providing an efficient way for researchers to handle the vagaries and difficulties associated with metal ion modeling. © 2016 American Chemical Society.","","Article","Scopus"
"Pasi M.; Tiberti M.; Arrigoni A.; Papaleo E.","Pasi, Marco (56677605100); Tiberti, Matteo (42462578900); Arrigoni, Alberto (57518774300); Papaleo, Elena (11339375000)","56677605100; 42462578900; 57518774300; 11339375000","XPyder: A PyMOL plugin to analyze coupled residues and their networks in protein structures.","2012","Journal of Chemical Information and Modeling","10.1021/ci300213c","52","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864205788&doi=10.1021%2fci300213c&partnerID=40&md5=c360fc0dd4a6d7dbc41eea687a963f69","A versatile method to directly identify and analyze short- or long-range coupled or communicating residues in a protein conformational ensemble is of extreme relevance to achieve a complete understanding of protein dynamics and structural communication routes. Here, we present xPyder, an interface between one of the most employed molecular graphics systems, PyMOL, and the analysis of dynamical cross-correlation matrices (DCCM). The approach can also be extended, in principle, to matrices including other indexes of communication propensity or intensity between protein residues, as well as the persistence of intra- or intermolecular interactions, such as those underlying protein dynamics. The xPyder plugin for PyMOL 1.4 and 1.5 is offered as Open Source software via the GPL v2 license, and it can be found, along with the installation package, the user guide, and examples, at http://linux.btbs.unimib.it/xpyder/. © 2012 American Chemical Society.","","Article","Scopus"
"Olofsson J.; Hendeby G.; Lauknes T.R.; Johansen T.A.","Olofsson, Jonatan (57194638389); Hendeby, Gustaf (15925569800); Lauknes, Tom Rune (8406017300); Johansen, Tor Arne (55950927300)","57194638389; 15925569800; 8406017300; 55950927300","Multi-agent informed path planning using the probability hypothesis density","2020","Autonomous Robots","10.1007/s10514-020-09904-1","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079225270&doi=10.1007%2fs10514-020-09904-1&partnerID=40&md5=cf4c9199bd4bc6cbe8b82f1816838ab5","An Informed Path Planning algorithm for multiple agents is presented. It can be used to efficiently utilize available agents when surveying large areas, when total coverage is unattainable. Internally the algorithm has a Probability Hypothesis Density (PHD) representation, inspired by modern multi-target tracking methods, to represent unseen objects. Using the PHD, the expected number of observed objects is optimized. In a sequential manner, each agent maximizes the number of observed new targets, taking into account the probability of undetected objects due to previous agents’ actions and the probability of detection, which yields a scalable algorithm. Algorithm properties are evaluated in simulations, and shown to outperform a greedy base line method. The algorithm is also evaluated by applying it to a sea ice tracking problem, using two datasets collected in the Arctic, with reasonable results. An implementation is provided under an Open Source license. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","Multi-agent; Path planning; Probability hypothesis density (PHD); Target tracking","Article","Scopus"
"Langdale G.; Lemire D.","Langdale, Geoff (57211583695); Lemire, Daniel (10238969400)","57211583695; 10238969400","Parsing gigabytes of JSON per second","2019","VLDB Journal","10.1007/s00778-019-00578-5","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073900084&doi=10.1007%2fs00778-019-00578-5&partnerID=40&md5=1697562c973de3f58f17b7ebfcbf194d","JavaScript Object Notation or JSON is a ubiquitous data exchange format on the web. Ingesting JSON documents can become a performance bottleneck due to the sheer volume of data. We are thus motivated to make JSON parsing as fast as possible. Despite the maturity of the problem of JSON parsing, we show that substantial speedups are possible. We present the first standard-compliant JSON parser to process gigabytes of data per second on a single core, using commodity processors. We can use a quarter or fewer instructions than a state-of-the-art reference parser like RapidJSON. Unlike other validating parsers, our software (simdjson) makes extensive use of single instruction and multiple data instructions. To ensure reproducibility, simdjson is freely available as open-source software under a liberal license. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.","DFA; JSON parsing; SIMD; Software performance","Article","Scopus"
"Reis D.; Piedade B.; Correia F.F.; Dias J.P.; Aguiar A.","Reis, David (57393345300); Piedade, Bruno (57220076849); Correia, Filipe F. (35188659200); Dias, Joao Pedro (57194725990); Aguiar, Ademar (35753041400)","57393345300; 57220076849; 35188659200; 57194725990; 35753041400","Developing Docker and Docker-Compose Specifications: A Developers' Survey","2022","IEEE Access","10.1109/ACCESS.2021.3137671","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122096706&doi=10.1109%2fACCESS.2021.3137671&partnerID=40&md5=24d098c54985b3178e41ea56d1fe7709","Cloud computing and Infrastructure-as-Code (IaC), supported by technologies such as Docker, have shaped how many software systems are built and deployed. Previous research has identified typical issues for some types of IaC specification but not why they come to be, or they have delved into collaboration aspects but not into technical ones. This work aims to characterize the activities around two particular kinds of IaC specification - Dockerfiles and docker-compose.yml files. We seek to know how they can be better supported and therefore study also what approaches and tools practitioners employ. We used an online questionnaire to gather data. The first part of the study reached 68 graduate students from a study program on informatics engineering, and the second one 120 professional software developers. The results show that most of the activities of the process of developing a Dockerfile are perceived as time-consuming, especially when the respondents are beginners with this technology. We also found that solving issues using trial-and-error approaches is very common and that many developers do not use ancillary tools to support the development of Dockerfiles and docker-compose.yml files.  © 2013 IEEE.","cloud computing; Docker; docker-compose; orchestration; survey","Article","Scopus"
"Karpievitch Y.V.; Hill E.G.; Smolka A.J.; Morris J.S.; Coombes K.R.; Baggerly K.A.; Almeida J.S.","Karpievitch, Yuliya V. (12807479100); Hill, Elizabeth G. (8729605600); Smolka, Adam J. (7003675848); Morris, Jeffrey S. (7405897451); Coombes, Kevin R. (6701706213); Baggerly, Keith A. (6603944321); Almeida, Jonas S. (7203053525)","12807479100; 8729605600; 7003675848; 7405897451; 6701706213; 6603944321; 7203053525","PrepMS: TOF MS data graphical preprocessing tool","2007","Bioinformatics","10.1093/bioinformatics/btl583","35","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846690008&doi=10.1093%2fbioinformatics%2fbtl583&partnerID=40&md5=820613bba492fdf3ae0cebefbf4910d8","Summary: We introduce a simple-to-use graphical tool that enables researchers to easily prepare time-of-flight mass spectrometry data for analysis. For ease of use, the graphical executable provides default parameter settings, experimentally determined to work well in most situations. These values, if desired, can be changed by the user. PrepMS is a stand-alone application made freely available (open source), and is under the General Public License (GPL). Its graphical user interface, default parameter settings, and display plots allow PrepMS to be used effectively for data preprocessing, peak detection and visual data quality assessment. © 2007 Oxford University Press.","","Article","Scopus"
"Temelso B.; Mabey J.M.; Kubota T.; Appiah-Padi N.; Shields G.C.","Temelso, Berhane (8691916300); Mabey, Joel M. (57194503363); Kubota, Toshiro (57209814799); Appiah-Padi, Nana (57194502491); Shields, George C. (7005795386)","8691916300; 57194503363; 57209814799; 57194502491; 7005795386","ArbAlign: A Tool for Optimal Alignment of Arbitrarily Ordered Isomers Using the Kuhn-Munkres Algorithm","2017","Journal of Chemical Information and Modeling","10.1021/acs.jcim.6b00546","37","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020465795&doi=10.1021%2facs.jcim.6b00546&partnerID=40&md5=6f15f9a4e3f71ddf106862fe464fb987","When assessing the similarity between two isomers whose atoms are ordered identically, one typically translates and rotates their Cartesian coordinates for best alignment and computes the pairwise root-mean-square distance (RMSD). However, if the atoms are ordered differently or the molecular axes are switched, it is necessary to find the best ordering of the atoms and check for optimal axes before calculating a meaningful pairwise RMSD. The factorial scaling of finding the best ordering by looking at all permutations is too expensive for any system with more than ten atoms. We report use of the Kuhn-Munkres matching algorithm to reduce the cost of finding the best ordering from factorial to polynomial scaling. That allows the application of this scheme to any arbitrary system efficiently. Its performance is demonstrated for a range of molecular clusters as well as rigid systems. The largely standalone tool is freely available for download and distribution under the GNU General Public License v3.0 (GNU-GPL-v3) agreement. An online implementation is also provided via a web server (http://www.arbalign.org) for convenient use. © 2017 American Chemical Society.","","Article","Scopus"
"Yaniv Z.; Lowekamp B.C.; Johnson H.J.; Beare R.","Yaniv, Ziv (8555308800); Lowekamp, Bradley C. (14825420700); Johnson, Hans J. (57158367900); Beare, Richard (6603014849)","8555308800; 14825420700; 57158367900; 6603014849","SimpleITK Image-Analysis Notebooks: a Collaborative Environment for Education and Reproducible Research","2018","Journal of Digital Imaging","10.1007/s10278-017-0037-8","162","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035092406&doi=10.1007%2fs10278-017-0037-8&partnerID=40&md5=b765eb7dca7b05d95ed0bd97089b2c45","Modern scientific endeavors increasingly require team collaborations to construct and interpret complex computational workflows. This work describes an image-analysis environment that supports the use of computational tools that facilitate reproducible research and support scientists with varying levels of software development skills. The Jupyter notebook web application is the basis of an environment that enables flexible, well-documented, and reproducible workflows via literate programming. Image-analysis software development is made accessible to scientists with varying levels of programming experience via the use of the SimpleITK toolkit, a simplified interface to the Insight Segmentation and Registration Toolkit. Additional features of the development environment include user friendly data sharing using online data repositories and a testing framework that facilitates code maintenance. SimpleITK provides a large number of examples illustrating educational and research-oriented image analysis workflows for free download from GitHub under an Apache 2.0 license: github.com/InsightSoftwareConsortium/SimpleITK-Notebooks. © 2017, Society for Imaging Informatics in Medicine (outside the USA).","Image analysis; Open-source software; Python; R; Registration; Segmentation","Article","Scopus"
"Jung Y.G.; Kim H.-W.","Jung, Yong Gyu (55330336300); Kim, Hee-Wan (56981597700)","55330336300; 56981597700","Design and implementation of lightweight vehicle license plate recognition module utilizing open CV and Tesseract OCR library","2018","International Journal of Engineering and Technology(UAE)","10.14419/ijet.v7i1.1.9851","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082346661&doi=10.14419%2fijet.v7i1.1.9851&partnerID=40&md5=1560175e097b3b01c3c577b9533274d5","Background/Objectives: In order to recognize the license plates automatically, we design and implement a vehicle license plate recogni-tion module that extracts characters of license plate area using open source OpenCV and Terreract OCR library. Methods/Statistical analysis: The static image was binarized using OpenCV 's banalization function. After binarizing the image by ad-justing the pixel values between adjacent pixels, the candidate region judged a license plate was derived. The final candidate was derived according to the proposed algorithm in the candidate region. The extracted plate area was analyzed by using the Tesseract OCR library, and characters were extracted as a character string. Findings: The vehicle license plate recognition module relates to character recognition in the field of computer vision. In this paper, we designed and implemented a module that recognizes a license plate by using open source, applying a proposed algorithm to a moving object as a static image. The proposed module is a relatively lightweight software module and can be used in other applications. It is possible to install the camera at the entrance of the apartment and can read the license plate to identify whether it is a resident or not. When speeding and traffic violations occur on the highway, the vehicle numbers can be automatically stored and managed in the database. In addition, there is an advantage that it can be applied to various character recognition applications through modification of a slight algorithm in the module. Improvements/Applications: In addition to character recognition, the OpenCV library can be applied to various fields such as pattern recognition, object tracking, and motion recognition. Therefore, we will be able to create technologies corresponding to various services that are becoming automated and unmanned. © 2018 Yong Gyu Jung, Hee-Wan Kim.","Banalization; Open CV; Plate recognition; Static image; Terre Act OCR library","Article","Scopus"
"Rasmussen A.F.; Sandve T.H.; Bao K.; Lauser A.; Hove J.; Skaflestad B.; Klöfkorn R.; Blatt M.; Rustad A.B.; Sævareid O.; Lie K.-A.; Thune A.","Rasmussen, Atgeirr Flø (14045577800); Sandve, Tor Harald (54966700200); Bao, Kai (57214034777); Lauser, Andreas (39762011400); Hove, Joakim (56267985300); Skaflestad, Bård (14066739700); Klöfkorn, Robert (24474612500); Blatt, Markus (24474350300); Rustad, Alf Birger (6602687001); Sævareid, Ove (6508371970); Lie, Knut-Andreas (7101626220); Thune, Andreas (57217128953)","14045577800; 54966700200; 57214034777; 39762011400; 56267985300; 14066739700; 24474612500; 24474350300; 6602687001; 6508371970; 7101626220; 57217128953","The Open Porous Media Flow reservoir simulator","2021","Computers and Mathematics with Applications","10.1016/j.camwa.2020.05.014","35","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086359937&doi=10.1016%2fj.camwa.2020.05.014&partnerID=40&md5=12d90369b8a97f731ba3518e71c0cd3f","The Open Porous Media (OPM) initiative is a community effort that encourages open innovation and reproducible research for simulation of porous media processes. OPM coordinates collaborative software development, maintains and distributes open-source software and open data sets, and seeks to ensure that these are available under a free license in a long-term perspective. In this paper, we present OPM Flow, which is a reservoir simulator developed for industrial use, as well as some of the individual components used to make OPM Flow. The descriptions apply to the 2019.10 release of OPM. © 2020 The Author(s)","","Article","Scopus"
"Gonzalez S.; Clavijo B.; Rivarola M.; Moreno P.; Fernandez P.; Dopazo J.; Paniego N.","Gonzalez, Sergio (57213991152); Clavijo, Bernardo (56001198900); Rivarola, Máximo (23111365900); Moreno, Patricio (57143777500); Fernandez, Paula (8888232400); Dopazo, Joaquín (18133480200); Paniego, Norma (6602440209)","57213991152; 56001198900; 23111365900; 57143777500; 8888232400; 18133480200; 6602440209","ATGC transcriptomics: A web-based application to integrate, explore and analyze de novo transcriptomic data","2017","BMC Bioinformatics","10.1186/s12859-017-1494-2","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013403110&doi=10.1186%2fs12859-017-1494-2&partnerID=40&md5=459ed395d0d700fdeb6bd208a0c650a7","Background: In the last years, applications based on massively parallelized RNA sequencing (RNA-seq) have become valuable approaches for studying non-model species, e.g., without a fully sequenced genome. RNA-seq is a useful tool for detecting novel transcripts and genetic variations and for evaluating differential gene expression by digital measurements. The large and complex datasets resulting from functional genomic experiments represent a challenge in data processing, management, and analysis. This problem is especially significant for small research groups working with non-model species. Results: We developed a web-based application, called ATGC transcriptomics, with a flexible and adaptable interface that allows users to work with new generation sequencing (NGS) transcriptomic analysis results using an ontology-driven database. This new application simplifies data exploration, visualization, and integration for a better comprehension of the results. Conclusions: ATGC transcriptomics provides access to non-expert computer users and small research groups to a scalable storage option and simple data integration, including database administration and management. The software is freely available under the terms of GNU public license at http://atgcinta.sourceforge.net. © 2017 The Author(s).","Data integration; De novo transcriptomics; Ontology storage; Web application","Article","Scopus"
"Yang C.; Wu W.; Nie Y.; Wang Q.; Ren J.","Yang, Chunlan (24765736800); Wu, Wenxiao (57211757093); Nie, Yingnan (57196247503); Wang, Qun (57188574623); Ren, Jiechuan (56041037400)","24765736800; 57211757093; 57196247503; 57188574623; 56041037400","EasyMEG: An easy-to-use toolbox for MEG analysis","2020","Computer Methods and Programs in Biomedicine","10.1016/j.cmpb.2019.105199","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074911804&doi=10.1016%2fj.cmpb.2019.105199&partnerID=40&md5=69329d77a434ee763d13c770e44a5df1","Background and objective: Magnetoencephalography (MEG) is an advanced magnetic source imaging technology that measures the magnetic fields produced by neural activities. It has been extensively used in scientific research and clinical diagnosis due to its high temporal and spatial resolution. Considering the special nature of MEG data, it needs to perform a series of processes and analysis to obtain valuable information. Therefore, the identification of data processing is a key point of MEG studies. At present, the software for MEG analysis such as FieldTrip has no Graphic User Interface (GUI) and users must write their own script to perform concrete analysis. It brings the difficulties to researchers like the doctors without experience in programming or newcomers to MEG. Thus, an open-sourced software-EasyMEG was developed. It has friendly interface with highly functions-integration. Methods: The functions of EasyMEG are developed based on MATLAB language to ensure the consistency of the user interface under different operating systems. EasyMEG is a highly integrated software that contains a set of functions for preprocessing, time-lock analysis, time–frequency analysis, source analysis, and plotting. EasyMEG provides a friendly GUI and allows users to complete analyses through a simple and clean interface. Results: This toolbox has been released as an open-source software on GitHub under the GNU General Public License: https://tonywu2018.github.io/EasyMEG/. Conclusions: We hope to improve this toolbox by the power of community and wish to make EasyMEG a simple and powerful toolbox for further MEG studies. © 2019","Magnetoencephalography (MEG); Matlab toolbox; Open source software; Source analysis; Time-frequency analysis","Article","Scopus"
"Kessner D.; Chambers M.; Burke R.; Agus D.; Mallick P.","Kessner, Darren (25627662100); Chambers, Matt (16024179600); Burke, Robert (36799894900); Agus, David (57794227000); Mallick, Parag (7005810449)","25627662100; 16024179600; 36799894900; 57794227000; 7005810449","ProteoWizard: Open source software for rapid proteomics tools development","2008","Bioinformatics","10.1093/bioinformatics/btn323","1217","https://www.scopus.com/inward/record.uri?eid=2-s2.0-54949129419&doi=10.1093%2fbioinformatics%2fbtn323&partnerID=40&md5=fbda2ad8f7d1674d0406ef6585c7e594","The ProteoWizard software project provides a modular and extensible set of open-source, cross-platform tools and libraries. The tools perform proteomics data analyses; the libraries enable rapid tool creation by providing a robust, pluggable development framework that simplifies and unifies data file access, and performs standard proteomics and LCMS dataset computations. The library contains readers and writers of the mzML data format, which has been written using modern C++ techniques and design principles and supports a variety of platforms with native compilers. The software has been specifically released under the Apache v2 license to ensure it can be used in both academic and commercial projects. In addition to the library, we also introduce a rapidly growing set of companion tools whose implementation helps to illustrate the simplicity of developing applications on top of the ProteoWizard library. © 2008 The Author(s).","","Article","Scopus"
"Hughes J.","Hughes, Joseph (55738339200)","55738339200","TreeRipper web application: Towards a fully automated optical tree recognition software","2011","BMC Bioinformatics","10.1186/1471-2105-12-178","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79956225332&doi=10.1186%2f1471-2105-12-178&partnerID=40&md5=cffe57092243622a836b1217131730f5","Background: Relationships between species, genes and genomes have been printed as trees for over a century. Whilst this may have been the best format for exchanging and sharing phylogenetic hypotheses during the 20th century, the worldwide web now provides faster and automated ways of transferring and sharing phylogenetic knowledge. However, novel software is needed to defrost these published phylogenies for the 21st century.Results: TreeRipper is a simple website for the fully-automated recognition of multifurcating phylogenetic trees (http://linnaeus.zoology.gla.ac.uk/~jhughes/treeripper/). The program accepts a range of input image formats (PNG, JPG/JPEG or GIF). The underlying command line c++ program follows a number of cleaning steps to detect lines, remove node labels, patch-up broken lines and corners and detect line edges. The edge contour is then determined to detect the branch length, tip label positions and the topology of the tree. Optical Character Recognition (OCR) is used to convert the tip labels into text with the freely available tesseract-ocr software. 32% of images meeting the prerequisites for TreeRipper were successfully recognised, the largest tree had 115 leaves.Conclusions: Despite the diversity of ways phylogenies have been illustrated making the design of a fully automated tree recognition software difficult, TreeRipper is a step towards automating the digitization of past phylogenies. We also provide a dataset of 100 tree images and associated tree files for training and/or benchmarking future software. TreeRipper is an open source project licensed under the GNU General Public Licence v3. © 2011 Hughes; licensee BioMed Central Ltd.","","Article","Scopus"
"Ali M.; Hoyt C.T.; Domingo-Fernández D.; Lehmann J.; Jabeen H.","Ali, Mehdi (57211031203); Hoyt, Charles Tapley (56305849200); Domingo-Fernández, Daniel (57197746848); Lehmann, Jens (35229806900); Jabeen, Hajira (36005417500)","57211031203; 56305849200; 57197746848; 35229806900; 36005417500","BioKEEN: A library for learning and evaluating biological knowledge graph embeddings","2019","Bioinformatics","10.1093/bioinformatics/btz117","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072307229&doi=10.1093%2fbioinformatics%2fbtz117&partnerID=40&md5=bcbead8584f5028bfa75045e1350c5c1","Knowledge graph embeddings (KGEs) have received significant attention in other domains due to their ability to predict links and create dense representations for graphs' nodes and edges. However, the software ecosystem for their application to bioinformatics remains limited and inaccessible for users without expertise in programing and machine learning. Therefore, we developed BioKEEN (Biological KnowlEdge EmbeddiNgs) and PyKEEN (Python KnowlEdge EmbeddiNgs) to facilitate their easy use through an interactive command line interface. Finally, we present a case study in which we used a novel biological pathway mapping resource to predict links that represent pathway crosstalks and hierarchies. Availability and implementation: BioKEEN and PyKEEN are open source Python packages publicly available under the MIT License at https://github.com/SmartDataAnalytics/BioKEEN and https://github.com/SmartDataAnalytics/PyKEEN Supplementary information: Supplementary data are available at Bioinformatics online. © 2018 The Author(s) 2019. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com.","","Article","Scopus"
"Coronado E.; Khan S.N.; Riggio R.","Coronado, Estefanía (56996889100); Khan, Shah Nawaz (26646674100); Riggio, Roberto (23493444900)","56996889100; 26646674100; 23493444900","5G-EmPOWER: A software-defined networking platform for 5G radio access networks","2019","IEEE Transactions on Network and Service Management","10.1109/TNSM.2019.2908675","81","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071030620&doi=10.1109%2fTNSM.2019.2908675&partnerID=40&md5=b2835d5b6ec42725bbef1531798da732","Software-defined networking (SDN) is making their way into the fifth generation of mobile communications. For example, 3GPP is embracing the concept of control-user plane separation (a cornerstone concept in SDN) in the 5G core and the radio access network (RAN). In this paper, we introduce a flexible, programmable, and open-source SDN platform for heterogeneous 5G RANs. The platform builds on an open protocol that abstracts the technology-dependent aspects of the radio access elements, allowing network programmers to deploy complex management tasks as policies on top of a programmable logically centralized controller. We implement the proposed solution as an extension to the 5G-EmPOWER platform and release the software stack (including the southbound protocol) under a permissive APACHE 2.0 license. Finally, the effectiveness of the platform is assessed through three reference use cases: 1) active network slicing; 2) mobility management; and 3) load-balancing. © 2019 IEEE.","5G; Experimental evaluation; LTE; Network management; Network programmability; Open-source; SDN","Article","Scopus"
"Frank D.N.","Frank, Daniel N. (57203031220)","57203031220","BARCRAWL and BARTAB: Software tools for the design and implementation of barcoded primers for highly multiplexed DNA sequencing","2009","BMC Bioinformatics","10.1186/1471-2105-10-362","126","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70749085913&doi=10.1186%2f1471-2105-10-362&partnerID=40&md5=17a0f30566af18b0a38bbe6b173cc07c","Background: Advances in automated DNA sequencing technology have greatly increased the scale of genomic and metagenomic studies. An increasingly popular means of increasing project throughput is by multiplexing samples during the sequencing phase. This can be achieved by covalently linking short, unique ""barcode"" DNA segments to genomic DNA samples, for instance through incorporation of barcode sequences in PCR primers. Although several strategies have been described to insure that barcode sequences are unique and robust to sequencing errors, these have not been integrated into the overall primer design process, thus potentially introducing bias into PCR amplification and/or sequencing steps. Results: Barcrawl is a software program that facilitates the design of barcoded primers, for multiplexed high-throughput sequencing. The program bartab can be used to deconvolute DNA sequence datasets produced by the use of multiple barcoded primers. This paper describes the functions implemented by barcrawl and bartab and presents a proof-of-concept case study of both programs in which barcoded rRNA primers were designed and validated by high-throughput sequencing. Conclusion: Barcrawl and bartab can benefit researchers who are engaged in metagenomic projects that employ multiplexed specimen processing. The source code is released under the GNU general public license and can be accessed at http://www.phyloware.com. © 2009 Frank; licensee BioMed Central Ltd.","","Article","Scopus"
"Conway J.R.; Lex A.; Gehlenborg N.","Conway, Jake R. (57202548577); Lex, Alexander (35094166300); Gehlenborg, Nils (57208464039)","57202548577; 35094166300; 57208464039","UpSetR: An R package for the visualization of intersecting sets and their properties","2017","Bioinformatics","10.1093/bioinformatics/btx364","1053","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028383131&doi=10.1093%2fbioinformatics%2fbtx364&partnerID=40&md5=7ab96d21f46c93a518b79899b0436f20","Motivation: Venn and Euler diagrams are a popular yet inadequate solution for quantitative visualization of set intersections. A scalable alternative to Venn and Euler diagrams for visualizing intersecting sets and their properties is needed. Results: We developed UpSetR, an open source R package that employs a scalable matrix-based visualization to show intersections of sets, their size, and other properties. Availability and implementation: UpSetR is available at https://github.com/hms-dbmi/UpSetR/ and released under the MIT License. A Shiny app is available at https://gehlenborglab.shinyapps.io/ upsetr/. © 2017 The Author.","","Article","Scopus"
"McIver L.J.; Abu-Ali G.; Franzosa E.A.; Schwager R.; Morgan X.C.; Waldron L.; Segata N.; Huttenhower C.","McIver, Lauren J. (57205043672); Abu-Ali, Galeb (24449918900); Franzosa, Eric A. (25625992800); Schwager, Randall (57191277699); Morgan, Xochitl C. (8220519500); Waldron, Levi (8539323900); Segata, Nicola (14016713700); Huttenhower, Curtis (56776200000)","57205043672; 24449918900; 25625992800; 57191277699; 8220519500; 8539323900; 14016713700; 56776200000","BioBakery: A meta'omic analysis environment","2018","Bioinformatics","10.1093/bioinformatics/btx754","118","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045198464&doi=10.1093%2fbioinformatics%2fbtx754&partnerID=40&md5=6a380f1f8635fb3e9a75c101e3872c87","BioBakery is a meta'omic analysis environment and collection of individual software tools with the capacity to process raw shotgun sequencing data into actionable microbial community feature profiles, summary reports, and publication-ready figures. It includes a collection of pre-configured analysis modules also joined into workflows for reproducibility. Availability and implementation bioBakery (http://huttenhower.sph.harvard.edu/biobakery) is publicly available for local installation as individual modules and as a virtual machine image. Each individual module has been developed to perform a particular task (e.g. quantitative taxonomic profiling or statistical analysis), and they are provided with source code, tutorials, demonstration data, and validation results; the bioBakery virtual image includes the entire suite of modules and their dependencies pre-installed. Images are available for both Amazon EC2 and Google Compute Engine. All software is open source under the MIT license. bioBakery is actively maintained with a support group at biobakery-users@googlegroups.com and new tools being added upon their release. Contact chuttenh@hsph.harvard.edu Supplementary informationSupplementary dataare available at Bioinformatics online. © The Author 2017. Published by Oxford University Press.","","Article","Scopus"
"Mirams G.R.; Arthurs C.J.; Bernabeu M.O.; Bordas R.; Cooper J.; Corrias A.; Davit Y.; Dunn S.-J.; Fletcher A.G.; Harvey D.G.; Marsh M.E.; Osborne J.M.; Pathmanathan P.; Pitt-Francis J.; Southern J.; Zemzemi N.; Gavaghan D.J.","Mirams, Gary R. (26428367200); Arthurs, Christopher J. (55012360900); Bernabeu, Miguel O. (14053541200); Bordas, Rafel (26647464300); Cooper, Jonathan (55243567700); Corrias, Alberto (22733394800); Davit, Yohan (36105048900); Dunn, Sara-Jane (54895750800); Fletcher, Alexander G. (26767716900); Harvey, Daniel G. (55936335400); Marsh, Megan E. (55345314200); Osborne, James M. (26768162200); Pathmanathan, Pras (24484191400); Pitt-Francis, Joe (6506773089); Southern, James (24172076500); Zemzemi, Nejib (25423228600); Gavaghan, David J. (26643590100)","26428367200; 55012360900; 14053541200; 26647464300; 55243567700; 22733394800; 36105048900; 54895750800; 26767716900; 55936335400; 55345314200; 26768162200; 24484191400; 6506773089; 24172076500; 25423228600; 26643590100","Chaste: An Open Source C++ Library for Computational Physiology and Biology","2013","PLoS Computational Biology","10.1371/journal.pcbi.1002970","257","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875998970&doi=10.1371%2fjournal.pcbi.1002970&partnerID=40&md5=43ca5801892ae6fda1a6eea0ac507b54","Chaste - Cancer, Heart And Soft Tissue Environment - is an open source C++ library for the computational simulation of mathematical models developed for physiology and biology. Code development has been driven by two initial applications: cardiac electrophysiology and cancer development. A large number of cardiac electrophysiology studies have been enabled and performed, including high-performance computational investigations of defibrillation on realistic human cardiac geometries. New models for the initiation and growth of tumours have been developed. In particular, cell-based simulations have provided novel insight into the role of stem cells in the colorectal crypt. Chaste is constantly evolving and is now being applied to a far wider range of problems. The code provides modules for handling common scientific computing components, such as meshes and solvers for ordinary and partial differential equations (ODEs/PDEs). Re-use of these components avoids the need for researchers to 're-invent the wheel' with each new project, accelerating the rate of progress in new applications. Chaste is developed using industrially-derived techniques, in particular test-driven development, to ensure code quality, re-use and reliability. In this article we provide examples that illustrate the types of problems Chaste can be used to solve, which can be run on a desktop computer. We highlight some scientific studies that have used or are using Chaste, and the insights they have provided. The source code, both for specific releases and the development version, is available to download under an open source Berkeley Software Distribution (BSD) licence at http://www.cs.ox.ac.uk/chaste, together with details of a mailing list and links to documentation and tutorials. © 2013 Mirams et al.","","Article","Scopus"
"Calderone A.; Cesareni G.","Calderone, Alberto (55342285300); Cesareni, Gianni (7007018785)","55342285300; 7007018785","SPV: A JavaScript signaling pathway visualizer","2018","Bioinformatics","10.1093/bioinformatics/bty188","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055154301&doi=10.1093%2fbioinformatics%2fbty188&partnerID=40&md5=d77d8b24ae55cb6e5924f1fe00eee8c4","The visualization of molecular interactions annotated in web resources is useful to offer to users such information in a clear intuitive layout. These interactions are frequently represented as binary interactions that are laid out in free space where, different entities, cellular compartments and interaction types are hardly distinguishable. Signaling Pathway Visualizer is a free open source JavaScript library, which offers a series of pre-defined elements, compartments and interaction types meant to facilitate the representation of signaling pathways consisting of causal interactions without neglecting simple protein–protein interaction networks. Availability and implementation: Freely available under Apache version 2 license; Source code: https://github.com/Sinnefa/SPV_Signaling_Pathway_Visualizer_v1.0. Language: JavaScript; Web technology: Scalable Vector Graphics; Libraries: D3.js. © The Author(s) 2018. Published by Oxford University Press.","","Article","Scopus"
"Flint T.F.; Smith M.C.","Flint, T.F. (57193760876); Smith, M.C. (57212869280)","57193760876; 57212869280","HEDSATS: High energy density semi-analytical thermal solutions","2019","SoftwareX","10.1016/j.softx.2019.100243","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065120938&doi=10.1016%2fj.softx.2019.100243&partnerID=40&md5=f620e33a8cf3251b4932138151ba5752","HEDSATS is a mathematical simulation library designed for the modelling of the 3D transient heat equation due to the application of various distributed volumetric heat sources, representative of advanced manufacturing processes. The library constructs 3D solutions using one dimensional Green's functions, convoluted by the heat distribution in orthogonal domains. These solutions allow the thermal history to be computed, free from numerical discretisation errors, with representative boundary and initial conditions. Example applications calling various HEDSATS functions are provided that predict the transient temperature field in electron beam, arc and friction stir welding processes. HEDSATS is released under the GNU Lesser General Public License (LGPL v3.0), and its source code is available on github. © 2019 The Authors","3D solution; Analytical solution; Green's function analysis; Heat transfer","Article","Scopus"
"Mora M.; Gómez J.M.; O'Connor R.V.; Gelman O.","Mora, Manuel (25823339800); Gómez, Jorge Marx (7402100609); O'Connor, Rory V. (7202869241); Gelman, Ovsei (55989674800)","25823339800; 7402100609; 7202869241; 55989674800","An MADM risk-based evaluation-selection model of free-libre open source software tools","2016","International Journal of Technology, Policy and Management","10.1504/IJTPM.2016.081665","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010792416&doi=10.1504%2fIJTPM.2016.081665&partnerID=40&md5=87688e38ccdee8a53fe206af5fd12f67","Free-libre Open-source software (FLOSS) tools are free-cost licence highly attractive to be implemented by organisations. However, not of all the FLOSS tools are mature, and failed implementations can occur. Thus, FLOSS evaluation-selection frameworks and FLOSS success-failure implementation factors studies have been conducted. In this research, we advance on such studies through an integrated FLOSS evaluation-selection model with a riskbased decision-making approach. Our model was built upon the other two literatures, and it was structured as a multi-attribute decision-making (MADM) model which contains 12 variables grouped in four risk categories: financial, organisational, end user, and technical ones. We illustrated its utilisation in the domain of information technology service management (ITSM) FLOSS tools. Hence, our model contributes to the FLOSS literature with the inclusion of the risk management approach and to the FLOSS evaluation-selection praxis with the provision of an innovative and essential risk-based model. © 2016 Inderscience Enterprises Ltd.","FLOSS evaluation; FLOSS implementation; IT service management; MADM; Risk management; Value tree","Article","Scopus"
"Bonfield J.K.; Marshall J.; Danecek P.; Li H.; Ohan V.; Whitwham A.; Keane T.","Bonfield, James K (6602684116); Marshall, John (57220599288); Danecek, Petr (16642071000); Li, Heng (12777127000); Ohan, Valeriu (57190515987); Whitwham, Andrew (36134178000); Keane, Thomas (57208478692)","6602684116; 57220599288; 16642071000; 12777127000; 57190515987; 36134178000; 57208478692","HTSlib: C library for reading/writing high-Throughput sequencing data","2021","GigaScience","10.1093/gigascience/giab007","44","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101697771&doi=10.1093%2fgigascience%2fgiab007&partnerID=40&md5=9529b4e93e5fcc1a597157e48ab7b9ff","Background: Since the original publication of the VCF and SAM formats, an explosion of software tools have been created to process these data files. To facilitate this a library was produced out of the original SAMtools implementation, with a focus on performance and robustness. The file formats themselves have become international standards under the jurisdiction of the Global Alliance for Genomics and Health. Findings: We present a software library for providing programmatic access to sequencing alignment and variant formats. It was born out of the widely used SAMtools and BCFtools applications. Considerable improvements have been made to the original code plus many new features including newer access protocols, the addition of the CRAM file format, better indexing and iterators, and better use of threading. Conclusion: Since the original Samtools release, performance has been considerably improved, with a BAM read-write loop running 5 times faster and BAM to SAM conversion 13 times faster (both using 16 threads, compared to Samtools 0.1.19). Widespread adoption has seen HTSlib downloaded >1 million times from GitHub and conda. The C library has been used directly by an estimated 900 GitHub projects and has been incorporated into Perl, Python, Rust, and R, significantly expanding the number of uses via other languages. HTSlib is open source and is freely available from htslib.org under MIT/BSD license.  © 2021 The Author(s). Published by Oxford University Press GigaScience.","bcftools; data analysis; high-Throughput sequencing; next generation sequencing; samtools; variant calling","Article","Scopus"
"Carlsson L.; Spjuth O.; Adams S.; Glen R.C.; Boyer S.","Carlsson, Lars (35304642400); Spjuth, Ola (12808508000); Adams, Samuel (7402058533); Glen, Robert C. (7006542141); Boyer, Scott (55913555400)","35304642400; 12808508000; 7402058533; 7006542141; 55913555400","Use of historic metabolic biotransformation data as a means of anticipating metabolic sites using MetaPrint2D and Bioclipse","2010","BMC Bioinformatics","10.1186/1471-2105-11-362","64","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954048869&doi=10.1186%2f1471-2105-11-362&partnerID=40&md5=be41a70f7a71be9c46224ec1a2f6e39a","Background: Predicting metabolic sites is important in the drug discovery process to aid in rapid compound optimisation. No interactive tool exists and most of the useful tools are quite expensive.Results: Here a fast and reliable method to analyse ligands and visualise potential metabolic sites is presented which is based on annotated metabolic data, described by circular fingerprints. The method is available via the graphical workbench Bioclipse, which is equipped with advanced features in cheminformatics.Conclusions: Due to the speed of predictions (less than 50 ms per molecule), scientists can get real time decision support when editing chemical structures. Bioclipse is a rich client, which means that all calculations are performed on the local computer and do not require network connection. Bioclipse and MetaPrint2D are free for all users, released under open source licenses, and available from http://www.bioclipse.net. © 2010 Carlsson et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Juhl D.; Warme D.M.; Winter P.; Zachariasen M.","Juhl, Daniel (55890602400); Warme, David M. (6507885808); Winter, Pawel (7202002740); Zachariasen, Martin (6602194702)","55890602400; 6507885808; 7202002740; 6602194702","The GeoSteiner software package for computing Steiner trees in the plane: an updated computational study","2018","Mathematical Programming Computation","10.1007/s12532-018-0135-8","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054649553&doi=10.1007%2fs12532-018-0135-8&partnerID=40&md5=255f9610d5738a79d21e3b9cf660b26b","The GeoSteiner software package has for about 20 years been the fastest (publicly available) program for computing exact solutions to Steiner tree problems in the plane. The computational study by Warme, Winter and Zachariasen, published in 2000, documented the performance of the GeoSteiner approach—allowing the exact solution of Steiner tree problems with more than a thousand terminals. Since then, a number of algorithmic enhancements have improved the performance of the software package significantly. We describe these (previously unpublished) enhancements, and present a new computational study wherein we run the current code on the largest problem instances from the 2000-study, and on a number of larger problem instances. The computational study is performed using the commercial GeoSteiner 4.0 code base, and the performance is compared to the publicly available GeoSteiner 3.1 code base as well as the code base from the 2000-study. The software studied in the paper is being released as GeoSteiner 5.0 under an open source license. © 2018, Springer-Verlag GmbH Germany, part of Springer Nature and The Mathematical Programming Society.","Computational study; Euclidean Steiner tree problem; Exact algorithm; Fixed orientation Steiner tree problem; Rectilinear Steiner tree problem","Article","Scopus"
"Liagkou V.; Fragiadakis G.; Filiopoulou E.; Michalakelis C.; Kamalakis T.; Nikolaidou M.","Liagkou, Vasiliki (55890832700); Fragiadakis, George (57369758800); Filiopoulou, Evangelia (57189361336); Michalakelis, Christos (23501949400); Kamalakis, Thomas (6603137301); Nikolaidou, Mara (57194042339)","55890832700; 57369758800; 57189361336; 23501949400; 6603137301; 57194042339","A pricing model for Container-as-a-Service, based on hedonic indices","2022","Simulation Modelling Practice and Theory","10.1016/j.simpat.2021.102441","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120960017&doi=10.1016%2fj.simpat.2021.102441&partnerID=40&md5=1b36e7468e2eebbb5824fa64fbb24add","Container-as-a-service (CaaS) is a business model that facilitates software developers in organizing, running, managing, and deploying applications using container-based virtualization. The CaaS market is a fast-growing one, leading infrastructure-as-a-service (IaaS) providers into offering CaaS solutions built on top of their IaaS platforms. Given the increasing competition among providers, pricing strategies play a key role in determining the business prospects of CaaS. In this work we propose a methodology to analyze the pricing strategies of the providers, based on a hedonic regression. Following that, we also develop a hedonic price index, based on data collected from popular providers, by identifying a wide set of architectural requirements influencing the pricing strategy. We further analyze the correlations between these requirements and define the subset to be included in the regression analysis, interpreting the results in view of the underlying CaaS market characteristics. The model implementation and the data set are freely available on the web under an open-source license. © 2021 Elsevier B.V.","Container as a Service; Hedonic price index; Modeling; Pricing models","Article","Scopus"
"Chhatre V.E.; Emerson K.J.","Chhatre, Vikram E. (21733574500); Emerson, Kevin J. (15072561600)","21733574500; 15072561600","StrAuto: Automation and parallelization of STRUCTURE analysis","2017","BMC Bioinformatics","10.1186/s12859-017-1593-0","92","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016144681&doi=10.1186%2fs12859-017-1593-0&partnerID=40&md5=48f4f72dead9d4c897432722ff197431","Background: Population structure inference using the software STRUCTURE has become an integral part of population genetic studies covering a broad spectrum of taxa including humans. The ever-expanding size of genetic data sets poses computational challenges for this analysis. Although at least one tool currently implements parallel computing to reduce computational overload of this analysis, it does not fully automate the use of replicate STRUCTURE analysis runs required for downstream inference of optimal K. There is pressing need for a tool that can deploy population structure analysis on high performance computing clusters. Results: We present an updated version of the popular Python program StrAuto, to streamline population structure analysis using parallel computing. StrAuto implements a pipeline that combines STRUCTURE analysis with the Evanno δ K analysis and visualization of results using STRUCTURE HARVESTER. Using benchmarking tests, we demonstrate that StrAuto significantly reduces the computational time needed to perform iterative STRUCTURE analysis by distributing runs over two or more processors. Conclusion: StrAuto is the first tool to integrate STRUCTURE analysis with post-processing using a pipeline approach in addition to implementing parallel computation - a set up ideal for deployment on computing clusters. StrAuto is distributed under the GNU GPL (General Public License) and available to download from http://strauto.popgen.org. © 2017 The Author(s).","Parallelization; Population genomics; STRUCTURE analysis","Article","Scopus"
"Thomas R.","Thomas, R. (57195326543)","57195326543","SPARTAN: Maximizing the use of spectro-photometric observational data during template fitting","2021","Astronomy and Computing","10.1016/j.ascom.2020.100427","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095687720&doi=10.1016%2fj.ascom.2020.100427&partnerID=40&md5=9a0bad32589380ba6f046394626b5bab","SPARTAN [Spectroscopic And photometRic fitting Tool for Astronomical aNalysis] is a tool designed to perform the fitting of galaxy observations either using photometry and low resolution spectroscopy separately or simultaneously. Based on a grid search χ2 fitting method, SPARTAN was tailored to UV-to-NIR data and designed for well calibrated data. The first version of this tool allows the use of the low resolution models of Bruzual & Charlot (2003) and include the treatment of the intergalactic medium as a free parameter. It has been designed to be an user-friendly environment where people do not need to know how to code to perform the fit. SPARTAN includes everything needed to perform the fit, from the galaxy models creation, to the visualization of the results through the graphical interface. SPARTAN is a fully open source software made with Python 3. It is published under the GNU general public license (v3) and is available in a Github repository. It can be installed directly from the python official repository (pypi) and the documentation is available through a github repository. © 2020 Elsevier B.V.","Fitting; Galaxy; Observations; Photometry; Spectroscopy","Article","Scopus"
"Ditzler G.; Morrison J.C.; Lan Y.; Rosen G.L.","Ditzler, Gregory (36019949100); Morrison, J.Calvin (55990554600); Lan, Yemin (57193773276); Rosen, Gail L. (9335288900)","36019949100; 55990554600; 57193773276; 9335288900","Fizzy: Feature subset selection for metagenomics","2015","BMC Bioinformatics","10.1186/s12859-015-0793-8","34","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946416256&doi=10.1186%2fs12859-015-0793-8&partnerID=40&md5=6a8dce31da85464d0b7a9f06730b2127","Background: Some of the current software tools for comparative metagenomics provide ecologists with the ability to investigate and explore bacterial communities using aα- & β-diversity. Feature subset selection - a sub-field of machine learning - can also provide a unique insight into the differences between metagenomic or 16S phenotypes. In particular, feature subset selection methods can obtain the operational taxonomic units (OTUs), or functional features, that have a high-level of influence on the condition being studied. For example, in a previous study we have used information-theoretic feature selection to understand the differences between protein family abundances that best discriminate between age groups in the human gut microbiome. Results: We have developed a new Python command line tool, which is compatible with the widely adopted BIOM format, for microbial ecologists that implements information-theoretic subset selection methods for biological data formats. We demonstrate the software tools capabilities on publicly available datasets. Conclusions: We have made the software implementation of Fizzy available to the public under the GNU GPL license. The standalone implementation can be found at http://github.com/EESI/Fizzy. © 2015 Ditzler et al.","Comparative metagenomics; Feature subset selection; Open-source software","Article","Scopus"
"Murthy J.; Rahna P.T.; Sutaria F.; Safonova M.; Gudennavar S.B.; Bubbly S.G.","Murthy, J. (7102462509); Rahna, P.T. (57195281339); Sutaria, F. (6602157890); Safonova, M. (6602852259); Gudennavar, S.B. (57190039797); Bubbly, S.G. (23990204000)","7102462509; 57195281339; 6602157890; 6602852259; 57190039797; 23990204000","JUDE: An Ultraviolet Imaging Telescope pipeline","2017","Astronomy and Computing","10.1016/j.ascom.2017.07.001","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026775105&doi=10.1016%2fj.ascom.2017.07.001&partnerID=40&md5=60836e876133400b878c5bc5bc8aa5bd","The Ultraviolet Imaging Telescope (UVIT) was launched as part of the multi-wavelength Indian AstroSat mission on 28 September, 2015 into a low Earth orbit. A 6-month performance verification (PV) phase ended in March 2016, and the instrument is now in the general observing phase. UVIT operates in three channels: visible, near-ultraviolet (NUV) and far-ultraviolet (FUV), each with a choice of broad and narrow band filters, and has NUV and FUV gratings for low-resolution spectroscopy. We have written a software package (JUDE) to convert the Level 1 data from UVIT into scientifically useful photon lists and images. The routines are written in the GNU Data Language (GDL) and are compatible with the IDL software package. We use these programs in our own scientific work, and will continue to update the programs as we gain better understanding of the UVIT instrument and its performance. We have released JUDE under an Apache License. © 2017 Elsevier B.V.","Astronomical software; Data analysis; Ultraviolet; UVIT","Article","Scopus"
"Zhang W.-Z.; Xie H.-C.; Hsu C.-H.","Zhang, Wei-Zhe (35263372000); Xie, Hu-Cheng (57202354025); Hsu, Ching-Hsien (7404945944)","35263372000; 57202354025; 7404945944","Automatic Memory Control of Multiple Virtual Machines on a Consolidated Server","2017","IEEE Transactions on Cloud Computing","10.1109/TCC.2014.2378794","31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027716273&doi=10.1109%2fTCC.2014.2378794&partnerID=40&md5=a900ec55b4f02a1827c08e3fea1b2700","Through virtualization, multiple virtual machines (VMs) can coexist and operate on one physical machine. When virtual machines compete for memory, the performances of applications deteriorate, especially those of memory-intensive applications. In this study, we aim to optimize memory control techniques using a balloon driver for server consolidation. Our contribution is three-fold: (1) We design and implement an automatic control system for memory based on a Xen balloon driver. To avoid interference with VM monitor operation, our system works in user mode; therefore, the system is easily applied in practice. (2) We design an adaptive global-scheduling algorithm to regulate memory. This algorithm is based on a dynamic baseline, which can adjust memory allocation according to the memory used by the VMs. (3) We evaluate our optimized solution in a real environment with 10 VMs and well-known benchmarks ( DaCapo and Phoronix Test Suites). Experiments confirm that our system can improve the performance of memory-intensive and disk-intensive applications by up to 500 and 300 percent, respectively. This toolkit has been released for free download as a GNU General Public License v3 software. © 2013 IEEE.","global-scheduling; memory control; server consolidation; Virtual machine","Article","Scopus"
"Eghan E.E.; Alqahtani S.S.; Forbes C.; Rilling J.","Eghan, Ellis E. (57112509000); Alqahtani, Sultan S. (57111910900); Forbes, Christopher (43661102000); Rilling, Juergen (16242643400)","57112509000; 57111910900; 43661102000; 16242643400","API trustworthiness: an ontological approach for software library adoption","2019","Software Quality Journal","10.1007/s11219-018-9428-4","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061189262&doi=10.1007%2fs11219-018-9428-4&partnerID=40&md5=560e2258ab83d28738b0a7f44074f306","The globalization of the software industry has led to an emerging trend where software systems depend increasingly on the use of external open-source external libraries and application programming interfaces (APIs). While a significant body of research exists on identifying and recommending potentially reusable libraries to end users, very little is known on the potential direct and indirect impact of these external library recommendations on the quality and trustworthiness of a client’s project. In our research, we introduce a novel Ontological Trustworthiness Assessment Model (OntTAM), which supports (1) the automated analysis and assessment of quality attributes related to the trustworthiness of libraries and APIs in open-source systems and (2) provides developers with additional insights into the potential impact of reused libraries and APIs on the quality and trustworthiness of their project. We illustrate the applicability of our approach, by assessing the trustworthiness of libraries in terms of their API breaking changes, security vulnerabilities, and license violations and their potential impact on client projects. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.","API breaking changes; Code reuse; License violations; Software quality; Software security vulnerabilities; Trustworthiness","Article","Scopus"
"Martens L.; Monsieur G.; Ampe C.; Gevaert K.; Vandekerckhove J.","Martens, Lennart (15923262500); Monsieur, Geert (14054473600); Ampe, Christophe (7003949377); Gevaert, Kris (6603720214); Vandekerckhove, Joël (36038057000)","15923262500; 14054473600; 7003949377; 6603720214; 36038057000","Cell_motility: A cross-platform, open source application for the study of cell motion paths","2006","BMC Bioinformatics","10.1186/1471-2105-7-289","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33746630192&doi=10.1186%2f1471-2105-7-289&partnerID=40&md5=0d98a8c7ffbcbbf37f6a74b62e4f471f","Background: Migration is an important aspect of cellular behaviour and is therefore widely studied in cell biology. Numerous components are known to participate in this process in a highly dynamic manner. In order to obtain a better insight in cell migration, mutants or drugs are used and their motive phenotype is then linked with the disturbing factors. One of the typical approaches to study motion paths of individual cells relies on fitting mean square displacements to a persistent random walk function. Since the numerous calculations involved often rely on diverse commercial software packages, the analysis can be expensive, labour-intensive and error-prone work. Additionally, due to the nature of algorithms employed the calculations involved are not readily reproducible without access to the exact software package(s) used. Results: We here present the cell_motility software, an open source Java application under the GNU-GPL license that provides a clear and concise analysis workbench for large amounts of cell motion data. Apart from performing the necessary calculations, the software also visualizes the original motion paths as well as the results of the calculations to help the user interpret the data. The application features an intuitive graphical user interface as well as full user and developer documentation and both source and binary files can be freely downloaded from the project website at http://genesis.UGent.be/cell_motility. Conclusion: In providing a free, open source software solution for the automated processing of cell motion data, we aim to achieve two important goals: labs can greatly simplify their data analysis pipeline as switching between different computational software packages becomes obsolete (thus reducing the chances for human error during data manipulation and transfer) and secondly, to provide scientists in the field with a freely available common platform to perform their analyses, enabling more efficient data quality control through peer reviewing. © 2006 Martens et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Micieli D.; Minniti T.; Gorini G.","Micieli, Davide (57191909355); Minniti, Triestino (36546619000); Gorini, Giuseppe (24075688600)","57191909355; 36546619000; 24075688600","NeuTomPy toolbox, a Python package for tomographic data processing and reconstruction","2019","SoftwareX","10.1016/j.softx.2019.01.005","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062966359&doi=10.1016%2fj.softx.2019.01.005&partnerID=40&md5=91d2f08698b0b78852760c4bd8e89751","In this article we present the NeuTomPy Toolbox, a new Python package for tomographic data processing and reconstruction. The toolbox includes pre-processing algorithms, artifacts removal and a wide range of iterative reconstruction methods as well as the Filtered Back Projection algorithm. The NeuTomPy toolbox was conceived primarily for neutron tomography datasets and developed to support the need of users and researchers to compare state-of-the-art reconstruction methods and choose the optimal data processing workflow for their data. In fact, in several cases sparse-view datasets are acquired to reduce scan time during a neutron tomography experiment. Hence, there is great interest in improving quality of the reconstructed images by means of iterative methods and advanced image-processing algorithms. The toolbox has a modular design, multi-threading capabilities and it supports Windows, Linux and Mac OS operating systems. The NeuTomPy toolbox is open source and it is released under the GNU General Public License v3, encouraging researchers and developers to contribute. In this paper we present an overview of the main toolbox functionalities and finally we show a typical usage example. © 2019 The Authors","Neutron imaging; Tomographic reconstruction software; Tomography","Article","Scopus"
"Seibel H.; Goldenstein S.; Rocha A.","Seibel, Hilario (57147403300); Goldenstein, Siome (6602436600); Rocha, Anderson (16643616700)","57147403300; 6602436600; 16643616700","Eyes on the Target: Super-Resolution and License-Plate Recognition in Low-Quality Surveillance Videos","2017","IEEE Access","10.1109/ACCESS.2017.2737418","40","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028731406&doi=10.1109%2fACCESS.2017.2737418&partnerID=40&md5=d59f11b51b5613a9edbce73b0ddc5243","Low-quality surveillance cameras throughout the cities could provide important cues to identify a suspect, for example, in a crime scene. However, the license-plate recognition is especially difficult under poor image resolutions. In this vein, super-resolution (SR) can be an inexpensive solution, via software, to overcome this limitation. Consecutive frames in a video may contain different information that could be integrated into a single image, richer in details. In this paper, we design and develop a novel, free and open-source framework underpinned by SR and automatic license-plate recognition (ALPR) techniques to identify license-plate characters in low-quality real-world traffic videos, captured by cameras not designed specifically for the ALPR task, aiding forensic analysts in understanding an event of interest. The framework handles the necessary conditions to identify a target license plate, using a novel methodology to locate, track, align, super-resolve, and recognize its alphanumerics. The user receives as outputs the rectified and super-resolved license-plate, richer in detail, and also the sequence of license-plates characters that have been automatically recognized in the super-resolved image. Additionally, we also design and develop a novel SR method that projects the license-plates separately onto the rectified grid, and then fill in the missing pixels using inpainting techniques. We compare the different algorithms in the framework (five for tracking, three for registration, seven for reconstruction, two for post-processing, and two for the recognition step), and present discussions on the pros and cons of each choice. Our experiments show that SR can indeed increase the number of correctly recognized characters posing the framework as an important step toward providing forensic experts and practitioners with a solution for the license-plate recognition problem under difficult acquisition conditions. © 2017 IEEE.","license-plate; recognition; Super-resolution; tracking; video surveillance","Article","Scopus"
"Tomlinson J.E.; Arnott J.H.; Harou J.J.","Tomlinson, J.E. (57211028389); Arnott, J.H. (57214668865); Harou, J.J. (24329473000)","57211028389; 57214668865; 24329473000","A water resource simulator in Python","2020","Environmental Modelling and Software","10.1016/j.envsoft.2020.104635","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078936876&doi=10.1016%2fj.envsoft.2020.104635&partnerID=40&md5=e9d30afd8d8f8070712c0ae803cfd71f","A new generalised water resource network modelling Python library, Pywr, is presented. Given hydrological inflows, Pywr simulates customisable water allocation and operation rules throughout complex multi-purpose managed water systems at each user-defined time-step. The model uses a low-level interface to existing linear programming solvers for fast priority-based optimisation-driven simulation. The library uses an object based system for users to provide input data and record simulation outputs. A novel multi-scenario simulation method provides an almost 4-fold improvement in model run-times and supports calculating robustness metrics across scenarios. A flexible interface to specify multi-objective optimisation formulations as part of a model's input file is included. These features enable analysts to apply advanced water planning approaches, such as robust decision making and robust optimisation, to real systems. The library is available under the GPLv3 open source licence, includes several examples and a regression test suite. © 2020 The Authors","Decision making under deep uncertainty; Multi-reservoir operations; Network optimisation; Open source; Python; Water resource simulation","Article","Scopus"
"Nelson E.K.; Piehler B.; Eckels J.; Rauch A.; Bellew M.; Hussey P.; Ramsay S.; Nathe C.; Lum K.; Krouse K.; Stearns D.; Connolly B.; Skillman T.; Igra M.","Nelson, Elizabeth K. (37054544100); Piehler, Britt (37054387000); Eckels, Josh (37053561400); Rauch, Adam (12806951100); Bellew, Matthew (11439855100); Hussey, Peter (11440122800); Ramsay, Sarah (37054427100); Nathe, Cory (25652112100); Lum, Karl (37054095900); Krouse, Kevin (37054302900); Stearns, David (37054604200); Connolly, Brian (57198196869); Skillman, Tom (57101649600); Igra, Mark (11440397600)","37054544100; 37054387000; 37053561400; 12806951100; 11439855100; 11440122800; 37054427100; 25652112100; 37054095900; 37054302900; 37054604200; 57198196869; 57101649600; 11440397600","LabKey Server: An open source platform for scientific data integration, analysis and collaboration","2011","BMC Bioinformatics","10.1186/1471-2105-12-71","100","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952319218&doi=10.1186%2f1471-2105-12-71&partnerID=40&md5=e82a21904ffd31213d34206e23d7a2c0","Background: Broad-based collaborations are becoming increasingly common among disease researchers. For example, the Global HIV Enterprise has united cross-disciplinary consortia to speed progress towards HIV vaccines through coordinated research across the boundaries of institutions, continents and specialties. New, end-to-end software tools for data and specimen management are necessary to achieve the ambitious goals of such alliances. These tools must enable researchers to organize and integrate heterogeneous data early in the discovery process, standardize processes, gain new insights into pooled data and collaborate securely.Results: To meet these needs, we enhanced the LabKey Server platform, formerly known as CPAS. This freely available, open source software is maintained by professional engineers who use commercially proven practices for software development and maintenance. Recent enhancements support: (i) Submitting specimens requests across collaborating organizations (ii) Graphically defining new experimental data types, metadata and wizards for data collection (iii) Transitioning experimental results from a multiplicity of spreadsheets to custom tables in a shared database (iv) Securely organizing, integrating, analyzing, visualizing and sharing diverse data types, from clinical records to specimens to complex assays (v) Interacting dynamically with external data sources (vi) Tracking study participants and cohorts over time (vii) Developing custom interfaces using client libraries (viii) Authoring custom visualizations in a built-in R scripting environment.Diverse research organizations have adopted and adapted LabKey Server, including consortia within the Global HIV Enterprise. Atlas is an installation of LabKey Server that has been tailored to serve these consortia. It is in production use and demonstrates the core capabilities of LabKey Server. Atlas now has over 2,800 active user accounts originating from approximately 36 countries and 350 organizations. It tracks roughly 27,000 assay runs, 860,000 specimen vials and 1,300,000 vial transfers.Conclusions: Sharing data, analysis tools and infrastructure can speed the efforts of large research consortia by enhancing efficiency and enabling new insights. The Atlas installation of LabKey Server demonstrates the utility of the LabKey platform for collaborative research. Stable, supported builds of LabKey Server are freely available for download at http://www.labkey.org. Documentation and source code are available under the Apache License 2.0. © 2011 Nelson et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Pinter C.; Lasso A.; Choueib S.; Asselin M.; Fillion-Robin J.-C.; Vimort J.-B.; Martin K.; Jolley M.A.; Fichtinger G.","Pinter, Csaba (54385777900); Lasso, Andras (25030035000); Choueib, Saleh (57209851349); Asselin, Mark (57203139614); Fillion-Robin, Jean-Christophe (55279746000); Vimort, Jean-Baptiste (57194462629); Martin, Ken (22958067400); Jolley, Matthew A. (36883920500); Fichtinger, Gabor (6602161432)","54385777900; 25030035000; 57209851349; 57203139614; 55279746000; 57194462629; 22958067400; 36883920500; 6602161432","SlicerVR for Medical Intervention Training and Planning in Immersive Virtual Reality","2020","IEEE Transactions on Medical Robotics and Bionics","10.1109/TMRB.2020.2983199","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091488561&doi=10.1109%2fTMRB.2020.2983199&partnerID=40&md5=1dea50c206a556db676acef20b1df8af","Virtual reality (VR) provides immersive visualization that has proved to be useful in a variety of medical applications. Currently, however, no free open-source software platform exists that would provide comprehensive support for translational clinical researchers in prototyping experimental VR scenarios in training, planning or guiding medical interventions. By integrating VR functions in 3D Slicer, an established medical image analysis and visualization platform, SlicerVR enables virtual reality experience by a single click. It provides functions to navigate and manipulate the virtual scene, as well as various settings to abate the feeling of motion sickness. SlicerVR allows for shared collaborative VR experience both locally and remotely. We present illustrative scenarios created with SlicerVR in a wide spectrum of applications, including echocardiography, neurosurgery, spine surgery, brachytherapy, intervention training and personalized patient education. SlicerVR is freely available under BSD type license as an extension to 3D Slicer and it has been downloaded over 7,800 times at the time of writing this article. © 2018 IEEE.","Medical treatment; open source software; telemedicine; virtual reality","Article","Scopus"
"Watkins X.; Garcia L.J.; Pundir S.; Martin M.J.","Watkins, Xavier (23669649100); Garcia, Leyla J. (57216726687); Pundir, Sangya (55250584300); Martin, Maria J. (57417303200)","23669649100; 57216726687; 55250584300; 57417303200","ProtVista: Visualization of protein sequence annotations","2017","Bioinformatics","10.1093/bioinformatics/btx120","42","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021811644&doi=10.1093%2fbioinformatics%2fbtx120&partnerID=40&md5=5a26ff299dd3371e07c350a17915c83e","ProtVista is a comprehensive visualization tool for the graphical representation of protein sequence features in the UniProt Knowledgebase, experimental proteomics and variation public datasets. The complexity and relationships in this wealth of data pose a challenge in interpretation. Integrative visualization approaches such as provided by ProtVista are thus essential for researchers to understand the data and, for instance, discover patterns affecting function and disease associations. Availability and Implementation: ProtVista is a JavaScript component released as an open source project under the Apache 2 License. Documentation and source code are available at http://ebi-uni prot.github.io/ProtVista/. © 2017 The Author.","","Article","Scopus"
"Oliehoek F.A.; Spaan M.T.J.; Terwijn B.; Robbel P.; Messias J.V.","Oliehoek, Frans A. (15043050300); Spaan, Matthijs T. J. (8550631100); Terwijn, Bas (7801354071); Robbel, Philipp (35303584900); Messias, João V. (55208968600)","15043050300; 8550631100; 7801354071; 35303584900; 55208968600","The MADP toolbox: An open source library for planning and learning in (multi-)agent systems","2017","Journal of Machine Learning Research","","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030168139&partnerID=40&md5=2bfca295b227177817fff495a5075037","This article describes the Multiagent Decision Process (MADP) Toolbox, a software library to support planning and learning for intelligent agents and multiagent systems in uncertain environments. Key features are that it supports partially observable environments and stochastic transition models; has unified support for single- and multiagent systems; provides a large number of models for decision-theoretic decision making, including one-shot and sequential decision making under various assumptions of observability and cooperation, such as Dec-POMDPs and POSGs; provides tools and parsers to quickly prototype new problems; provides an extensive range of planning and learning algorithms for single- and multiagent systems; is released under the GNU GPL v3 license; and is written in C++ and designed to be extensible via the object-oriented paradigm. ©2017 Frans A. Oliehoek, Matthijs T. J. Spaan, Bas Terwijn, Philipp Robbel and João V. Messias.","Decision-theoretic planning; Multiagent systems; Reinforcement learning; Software","Article","Scopus"
"Solernou A.; Hanson B.S.; Richardson R.A.; Welch R.; Read D.J.; Harlen O.G.; Harris S.A.","Solernou, Albert (23028940200); Hanson, Benjamin S. (56663931700); Richardson, Robin A. (56493993600); Welch, Robert (57212518275); Read, Daniel J. (56679086700); Harlen, Oliver G. (6603789552); Harris, Sarah A. (7403484884)","23028940200; 56663931700; 56493993600; 57212518275; 56679086700; 6603789552; 7403484884","Fluctuating Finite Element Analysis (FFEA): A continuum mechanics software tool for mesoscale simulation of biomolecules","2018","PLoS Computational Biology","10.1371/journal.pcbi.1005897","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044772320&doi=10.1371%2fjournal.pcbi.1005897&partnerID=40&md5=954721cfa68857e7c2e069c3549ffb6a","Fluctuating Finite Element Analysis (FFEA) is a software package designed to perform continuum mechanics simulations of proteins and other globular macromolecules. It combines conventional finite element methods with stochastic thermal noise, and is appropriate for simulations of large proteins and protein complexes at the mesoscale (length-scales in the range of 5 nm to 1 μm), where there is currently a paucity of modelling tools. It requires 3D volumetric information as input, which can be low resolution structural information such as cryo-electron tomography (cryo-ET) maps or much higher resolution atomistic co-ordinates from which volumetric information can be extracted. In this article we introduce our open source software package for performing FFEA simulations which we have released under a GPLv3 license. The software package includes a C ++ implementation of FFEA, together with tools to assist the user to set up the system from Electron Microscopy Data Bank (EMDB) or Protein Data Bank (PDB) data files. We also provide a PyMOL plugin to perform basic visualisation and additional Python tools for the analysis of FFEA simulation trajectories. This manuscript provides a basic background to the FFEA method, describing the implementation of the core mechanical model and how intermolecular interactions and the solvent environment are included within this framework. We provide prospective FFEA users with a practical overview of how to set up an FFEA simulation with reference to our publicly available online tutorials and manuals that accompany this first release of the package. © 2018 Solernou et al.","","Article","Scopus"
"Halle M.; Demeusy V.; Kikinis R.","Halle, Michael (7006617404); Demeusy, Valentin (57194632251); Kikinis, Ron (7101859155)","7006617404; 57194632251; 7101859155","The open anatomy browser: A collaborative web-based viewer for interoperable anatomy atlases","2017","Frontiers in Neuroinformatics","10.3389/fninf.2017.00022","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021374923&doi=10.3389%2ffninf.2017.00022&partnerID=40&md5=df32a92e2366b42f6c4ff20c3e8d3dff","The Open Anatomy Browser (OABrowser) is an open source, web-based, zero-installation anatomy atlas viewer based on current web browser technologies and evolving anatomy atlas interoperability standards. OABrowser displays three-dimensional anatomical models, image cross-sections of labeled structures and source radiological imaging, and a text-based hierarchy of structures. The viewer includes novel collaborative tools: users can save bookmarks of atlas views for later access and exchange those bookmarks with other users, and dynamic shared views allow groups of users can participate in a collaborative interactive atlas viewing session. We have published several anatomy atlases (an MRI-derived brain atlas and atlases of other parts of the anatomy) to demonstrate OABrowser’s functionality. The atlas source data, processing tools, and the source for OABrowser are freely available through GitHub and are distributed under a liberal open source license. © 2017 Halle, Demeusy and Kikinis.","Anatomy atlases; Collaborative software; Format standardization; Open data; Open-source software; Visualization; WebGL","Article","Scopus"
"Hale M.L.; Thapa I.; Ghersi D.","Hale, Matthew L. (41561182300); Thapa, Ishwor (23398569100); Ghersi, Dario (8741047100)","41561182300; 23398569100; 8741047100","FunSet: An open-source software and web server for performing and displaying Gene Ontology enrichment analysis","2019","BMC Bioinformatics","10.1186/s12859-019-2960-9","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068263260&doi=10.1186%2fs12859-019-2960-9&partnerID=40&md5=cca0e59c331ad5f43f2c068b0aadf864","Background: Gene Ontology enrichment analysis provides an effective way to extract meaningful information from complex biological datasets. By identifying terms that are significantly overrepresented in a gene set, researchers can uncover biological features shared by genes. In addition to extracting enriched terms, it is also important to visualize the results in a way that is conducive to biological interpretation. Results: Here we present FunSet, a new web server to perform and visualize enrichment analysis. The web server identifies Gene Ontology terms that are statistically overrepresented in a target set with respect to a background set. The enriched terms are displayed in a 2D plot that captures the semantic similarity between terms, with the option to cluster terms via spectral clustering and identify a representative term for each cluster. FunSet can be used interactively or programmatically, and allows users to download the enrichment results both in tabular form and in graphical form as SVG files or in data format as JSON or csv. To enhance reproducibility of the analyses, users have access to historical data for the ontology and the annotations. The source code for the standalone program and the web server are made available with an open-source license. © 2019 The Author(s).","Functional Enrichment; Gene Ontology; Web Tools","Article","Scopus"
"Abi-Mansour A.","Abi-Mansour, Andrew (49060961300)","49060961300","PyGran: An object-oriented library for DEM simulation and analysis","2019","SoftwareX","10.1016/j.softx.2019.01.016","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061573748&doi=10.1016%2fj.softx.2019.01.016&partnerID=40&md5=08e77974ba292f516e70fcd389494403","PyGran is a simulation and analysis toolkit designed for particle systems with emphasis on discrete element method (DEM) simulation. PyGran enables DEM programmers to develop computational tools and perform interactive analysis of granular systems in Python. The toolkit provides an interface for running DEM simulations in parallel using the open-source LIGGGHTS-PUBLIC software, routines for performing structural and temporal analysis, and an intuitive way for building and manipulating granular systems. The object-oriented design of PyGran enables post-processing of coupled CFD–DEM simulation, and constructing coarse-grained representations of DEM systems. PyGran is released under the GNU General Public License (GPL v2.0), and its source code is available from github. © 2019","Discrete element method; Granular systems; LIGGGHTS; Python","Article","Scopus"
"Manohar K.; Jayan A.R.; Rajan R.","Manohar, Kavya (57219057165); Jayan, A.R. (24479268100); Rajan, Rajeev (57197984309)","57219057165; 24479268100; 57197984309","Mlphon: A Multifunctional Grapheme-Phoneme Conversion Tool Using Finite State Transducers","2022","IEEE Access","10.1109/ACCESS.2022.3204403","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137849393&doi=10.1109%2fACCESS.2022.3204403&partnerID=40&md5=0089e6eb46637cad9d83e1f343e8fd08","In this article we present the design and the development of a knowledge based computational linguistic tool, Mlphon for Malayalam language. Mlphon computationally models linguistic rules using finite state transducers and performs multiple functions including grapheme to phoneme (g2p) and phoneme to grapheme (p2g) conversions, syllabification, phonetic feature analysis and script grammar check. This open source software tool, released under MIT license, is developed as a one-stop solution to handle different speech related text processing tasks for automatic speech recognition, text to speech synthesis and non-speech natural language processing tasks including syllable subword based language modeling, phoneme diversity analysis and text sanity check. The tool is evaluated on a manually crafted gold standard lexicon. Mlphon performs orthographic syllabification with 99% accuracy with a syllable error rate of 0.62% on the gold standard lexicon. For grapheme to phoneme conversion task, overall phoneme recognition accuracy of 99% with a phoneme error rate of 0.55% is obtained on gold standard lexicon. Additionally an extrinsic evaluation of Mlphon is performed by employing the pronunciation lexicon created using Mlphon, in Malayalam automatic speech recognition (ASR) task. Performance analysis in terms of the computation time of lexicon creation process and the word error rate (WER) on ASR task are presented along with a comparison over other automated tools for lexicon creation. Pronunciation lexicons with more than 100k commonly used Malayalam words in phonemised and syllabified forms is created and they are published as open language resources along with this work. We also demonstrate the usage of Mlphon on different natural language processing applications - syllable subword ASR, assisted pronunciation learning, phoneme diversity analysis and text sanity check. Being a knowledge based solution with open source code, Mlphon can be adapted to other languages of similar script nature. © 2022 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","Computational Phonology; Low Resource Languages; Malayalam; Pronunciation Lexicon; Software Tool; Speech Recognition; Syllabification","Article","Scopus"
"Himanen L.; Rinke P.; Foster A.S.","Himanen, Lauri (56957148100); Rinke, Patrick (15081423900); Foster, Adam Stuart (7202034302)","56957148100; 15081423900; 7202034302","Materials structure genealogy and high-throughput topological classification of surfaces and 2D materials","2018","npj Computational Materials","10.1038/s41524-018-0107-6","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053256263&doi=10.1038%2fs41524-018-0107-6&partnerID=40&md5=80551f4b52bfbb0df66dbc9a7a12b57e","Automated and verifiable structural classification for atomistic structures is becoming necessary to cope with the vast amount of information stored in various computational materials databases. Here we present a general recursive scheme for the structural classification of atomistic systems and introduce a structural materials map that can be used to organize the materials structure genealogy. We also introduce our implementation for the automatic classification of two-dimensional structures, especially focusing on surfaces and 2D materials. This classification procedure can automatically determine the dimensionality of a structure, further categorize the structure as a surface or a 2D material, return the underlying unit cell and also identify the outlier atoms, such as adsorbates. The classification scheme does not require explicit search patterns and works even in the presence of defects and dislocations. The classification is tested on a wide variety of atomistic structures and provides a high-accuracy determination for all of the returned structural properties. A software implementation of the classification algorithm is freely available with an open-source license. © 2018, The Author(s).","","Article","Scopus"
"Carbonell P.; Carlsson L.; Faulon J.-L.","Carbonell, Pablo (36780066700); Carlsson, Lars (35304642400); Faulon, Jean-Loup (7004417884)","36780066700; 35304642400; 7004417884","Stereo signature molecular descriptor","2013","Journal of Chemical Information and Modeling","10.1021/ci300584r","42","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876554425&doi=10.1021%2fci300584r&partnerID=40&md5=6c70215f91b54bd424726191681cd853","We present an algorithm to compute molecular graph descriptors considering the stereochemistry of the molecular structure based on our previously introduced signature molecular descriptor. The algorithm can generate two types of descriptors, one which is compliant with the Cahn-Ingold-Prelog priority rules, including complex stereochemistry structures such as fullerenes, and a computationally efficient one based on our previous definition of a directed acyclic graph that is augmented to a chiral molecular graph. The performance of the algorithm in terms of speed as a canonicalizer as well as in modeling and predicting bioactivity is evaluated, showing an overall better performance than other molecular descriptors, which is particularly relevant in modeling stereoselective biochemical reactions. The complete source code of the stereo signature molecular descriptor is available for download under an open-source license at http://molsig.sourceforge.net. © 2013 American Chemical Society.","","Article","Scopus"
"Cerami E.G.; Bader G.D.; Gross B.E.; Sander C.","Cerami, Ethan G. (57205565604); Bader, Gary D. (7102726136); Gross, Benjamin E. (57190211000); Sander, Chris (55146122100)","57205565604; 7102726136; 57190211000; 55146122100","cPath: Open source software for collecting, storing, and querying biological pathways","2006","BMC Bioinformatics","10.1186/1471-2105-7-497","94","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33751435209&doi=10.1186%2f1471-2105-7-497&partnerID=40&md5=560da8da0f799a4e7963c84229a531c8","Background: Biological pathways, including metabolic pathways, protein interaction networks, signal transduction pathways, and gene regulatory networks, are currently represented in over 220 diverse databases. These data are crucial for the study of specific biological processes, including human diseases. Standard exchange formats for pathway information, such as BioPAX, CellML, SBML and PSI-MI, enable convenient collection of this data for biological research, but mechanisms for common storage and communication are required. Results: We have developed cPath, an open source database and web application for collecting, storing, and querying biological pathway data. cPath makes it easy to aggregate custom pathway data sets available in standard exchange formats from multiple databases, present pathway data to biologists via a customizable web interface, and export pathway data via a web service to third party software, such as Cytoscape, for visualization and analysis. cPath is software only, and does not include new pathway information. Key features include: a built-in identifier mapping service for linking identical interactors and linking to external resources; built-in support for PSI-MI and BioPAX standard pathway exchange formats; a web service interface for searching and retrieving pathway data sets; and thorough documentation. The cPath software is freely available under the LGPL open source license for academic and commercial use. Conclusion: cPath is a robust, scalable, modular, professional-grade software platform for collecting, storing, and querying biological pathways. It can serve as the core data handling component in information systems for pathway visualization, analysis and modeling. © 2006 Cerami et al; licensee BioMed Central Ltd.","","Article","Scopus"
"van Mourik T.; Snoek L.; Knapen T.; Norris D.G.","van Mourik, Tim (56519671700); Snoek, Lukas (57195229225); Knapen, Tomas (21234049800); Norris, David G. (7201567247)","56519671700; 57195229225; 21234049800; 7201567247","Porcupine: A visual pipeline tool for neuroimaging analysis","2018","PLoS Computational Biology","10.1371/journal.pcbi.1006064","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048178428&doi=10.1371%2fjournal.pcbi.1006064&partnerID=40&md5=9ad4b2143129e328a1cd34112512c915","The field of neuroimaging is rapidly adopting a more reproducible approach to data acquisition and analysis. Data structures and formats are being standardised and data analyses are getting more automated. However, as data analysis becomes more complicated, researchers often have to write longer analysis scripts, spanning different tools across multiple programming languages. This makes it more difficult to share or recreate code, reducing the reproducibility of the analysis. We present a tool, Porcupine, that constructs one’s analysis visually and automatically produces analysis code. The graphical representation improves understanding of the performed analysis, while retaining the flexibility of modifying the produced code manually to custom needs. Not only does Porcupine produce the analysis code, it also creates a shareable environment for running the code in the form of a Docker image. Together, this forms a reproducible way of constructing, visualising and sharing one’s analysis. Currently, Porcupine links to Nipype functionalities, which in turn accesses most standard neuroimaging analysis tools. Our goal is to release researchers from the constraints of specific implementation details, thereby freeing them to think about novel and creative ways to solve a given problem. Porcupine improves the overview researchers have of their processing pipelines, and facilitates both the development and communication of their work. This will reduce the threshold at which less expert users can generate reusable pipelines. With Porcupine, we bridge the gap between a conceptual and an implementational level of analysis and make it easier for researchers to create reproducible and shareable science. We provide a wide range of examples and documentation, as well as installer files for all platforms on our website: https://timvanmourik.github.io/Porcupine. Porcupine is free, open source, and released under the GNU General Public License v3.0. © 2018 van Mourik et al. http://creativecommons.org/licenses/by/4.0/","","Article","Scopus"
"Procacci P.","Procacci, Piero (7006445627)","7006445627","Hybrid MPI/OpenMP Implementation of the ORAC Molecular Dynamics Program for Generalized Ensemble and Fast Switching Alchemical Simulations","2016","Journal of Chemical Information and Modeling","10.1021/acs.jcim.6b00151","36","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976415946&doi=10.1021%2facs.jcim.6b00151&partnerID=40&md5=c6d16216021324b25434a84d2452eef9","We present a new release (6.0β) of the ORAC program [Marsili et al. J. Comput. Chem. 2010, 31, 1106-1116] with a hybrid OpenMP/MPI (open multiprocessing message passing interface) multilevel parallelism tailored for generalized ensemble (GE) and fast switching double annihilation (FS-DAM) nonequilibrium technology aimed at evaluating the binding free energy in drug-receptor system on high performance computing platforms. The production of the GE or FS-DAM trajectories is handled using a weak scaling parallel approach on the MPI level only, while a strong scaling force decomposition scheme is implemented for intranode computations with shared memory access at the OpenMP level. The efficiency, simplicity, and inherent parallel nature of the ORAC implementation of the FS-DAM algorithm, project the code as a possible effective tool for a second generation high throughput virtual screening in drug discovery and design. The code, along with documentation, testing, and ancillary tools, is distributed under the provisions of the General Public License and can be freely downloaded at www.chim.unifi.it/orac. © 2016 American Chemical Society.","","Article","Scopus"
"Brandt N.; Griem L.; Herrmann C.; Schoof E.; Tosato G.; Zhao Y.; Zschumme P.; Selzer M.","Brandt, Nico (57219502886); Griem, Lars (57221981907); Herrmann, Christoph (57219770733); Schoof, Ephraim (56422042200); Tosato, Giovanna (57221982210); Zhao, Yinghan (57219503490); Zschumme, Philipp (57221981540); Selzer, Michael (24503304900)","57219502886; 57221981907; 57219770733; 56422042200; 57221982210; 57219503490; 57221981540; 24503304900","Kadi4mat: A research data infrastructure for materials science","2021","Data Science Journal","10.5334/dsj-2021-008","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100864593&doi=10.5334%2fdsj-2021-008&partnerID=40&md5=0cb95d63e5f6358be961e9f7af2d58d5","The concepts and current developments of a research data infrastructure for materials science are presented, extending and combining the features of an electronic lab notebook and a repository. The objective of this infrastructure is to incorporate the possibility of structured data storage and data exchange with documented and reproducible data analysis and visualization, which finally leads to the publication of the data. This way, researchers can be supported throughout the entire research process. The software is being developed as a web-based and desktop-based system, offering both a graphical user interface and a programmatic interface. The focus of the development is on the integration of technologies and systems based on both established as well as new concepts. Due to the heterogeneous nature of materials science data, the current features are kept mostly generic, and the structuring of the data is largely left to the users. As a result, an extension of the research data infrastructure to other disciplines is possible in the future. The source code of the project is publicly available under a permissive Apache 2.0 license. © 2021 The Author(s).","Electronic lab notebook; Materials science; Open source; Repository; Research data management","Article","Scopus"
"Lee C.T.; Maragkakis M.","Lee, Christopher T. (57222311390); Maragkakis, Manolis (27967982300)","57222311390; 27967982300","SamQL: a structured query language and filtering tool for the SAM/BAM file format","2021","BMC Bioinformatics","10.1186/s12859-021-04390-3","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116353897&doi=10.1186%2fs12859-021-04390-3&partnerID=40&md5=b4ebe588c5c487d0366f7206c753cc0f","Background: The Sequence Alignment/Map Format Specification (SAM) is one of the most widely adopted file formats in bioinformatics and many researchers use it daily. Several tools, including most high-throughput sequencing read aligners, use it as their primary output and many more tools have been developed to process it. However, despite its flexibility, SAM encoded files can often be difficult to query and understand even for experienced bioinformaticians. As genomic data are rapidly growing, structured, and efficient queries on data that are encoded in SAM/BAM files are becoming increasingly important. Existing tools are very limited in their query capabilities or are not efficient. Critically, new tools that address these shortcomings, should not be able to support existing large datasets but should also do so without requiring massive data transformations and file infrastructure reorganizations. Results: Here we introduce SamQL, an SQL-like query language for the SAM format with intuitive syntax that supports complex and efficient queries on top of SAM/BAM files and that can replace commonly used Bash one-liners employed by many bioinformaticians. SamQL has high expressive power with no upper limit on query size and when parallelized, outperforms other substantially less expressive software. Conclusions: SamQL is a complete query language that we envision as a step to a structured database engine for genomics. SamQL is written in Go, and is freely available as standalone program and as an open-source library under an MIT license, https://github.com/maragkakislab/samql/. © 2021, The Author(s).","BAM; Big data; Genomics; SAM; SQL","Article","Scopus"
"Fonseca C.G.; Backhaus M.; Bluemke D.A.; Britten R.D.; Chung J.D.; Cowan B.R.; Dinov I.D.; Finn J.P.; Hunter P.J.; Kadish A.H.; Lee D.C.; Lima J.A.C.; Medrano-Gracia P.; Shivkumar K.; Suinesiaputra A.; Tao W.; Young A.A.","Fonseca, Carissa G. (36001997300); Backhaus, Michael (55862255800); Bluemke, David A. (7006047770); Britten, Randall D. (26647428000); Chung, Jae Do (36612865500); Cowan, Brett R. (7103199271); Dinov, Ivo D. (6603200380); Finn, J. Paul (7202432959); Hunter, Peter J. (7201422778); Kadish, Alan H. (7102750548); Lee, Daniel C. (13806507700); Lima, Joao A. C. (7202778154); Medrano-Gracia, Pau (23091453200); Shivkumar, Kalyanam (7003952173); Suinesiaputra, Avan (22434002000); Tao, Wenchao (8085833300); Young, Alistair A. (7403881255)","36001997300; 55862255800; 7006047770; 26647428000; 36612865500; 7103199271; 6603200380; 7202432959; 7201422778; 7102750548; 13806507700; 7202778154; 23091453200; 7003952173; 22434002000; 8085833300; 7403881255","The cardiac Atlas Project-an imaging database for computational modeling and statistical atlases of the heart","2011","Bioinformatics","10.1093/bioinformatics/btr360","202","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79961177806&doi=10.1093%2fbioinformatics%2fbtr360&partnerID=40&md5=b543929760dfbce557d0cf26093141a3","Motivation: Integrative mathematical and statistical models of cardiac anatomy and physiology can play a vital role in understanding cardiac disease phenotype and planning therapeutic strategies. However, the accuracy and predictive power of such models is dependent upon the breadth and depth of noninvasive imaging datasets. The Cardiac Atlas Project (CAP) has established a large-scale database of cardiac imaging examinations and associated clinical data in order to develop a shareable, webaccessible, structural and functional atlas of the normal and pathological heart for clinical, research and educational purposes. A goal of CAP is to facilitate collaborative statistical analysis of regional heart shape and wall motion and characterize cardiac function among and within population groups. Results: Three main open-source software components were developed: (i) a database with web-interface; (ii) a modeling client for 3D + time visualization and parametric description of shape and motion; and (iii) open data formats for semantic characterization of models and annotations. The database was implemented using a three-tier architecture utilizing MySQL, JBoss and Dcm4chee, in compliance with the DICOM standard to provide compatibility with existing clinical networks and devices. Parts of Dcm4chee were extended to access image specific attributes as search parameters. To date, approximately 3000 de-identified cardiac imaging examinations are available in the database. All software components developed by the CAP are open source and are freely available under the Mozilla Public License Version 1.1 (http://www.mozilla.org/MPL/MPL-1.1.txt). © The Author(s) 2011. Published by Oxford University Press.","","Article","Scopus"
"Arabas S.; Jarecka D.; Jaruga A.; Fijałkowski M.","Arabas, Sylwester (33067634600); Jarecka, Dorota (34869672600); Jaruga, Anna (56538577800); Fijałkowski, Maciej (35182786000)","33067634600; 34869672600; 56538577800; 35182786000","Formula translation in Blitz++, NumPy and modern Fortran: A case study of the language choice tradeoffs","2014","Scientific Programming","10.3233/SPR-140379","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927669822&doi=10.3233%2fSPR-140379&partnerID=40&md5=9f05abe48e159f2fbf806344cfcfea10","Three object-oriented implementations of a prototype solver of the advection equation are introduced. The presented programs are based on Blitz++ (C++), NumPy (Python) and Fortran's built-in array containers. The solvers constitute implementations of the Multidimensional Positive-Definite Advective Transport Algorithm (MPDATA). The introduced codes serve as examples for how the application of object-oriented programming (OOP) techniques and new language constructs from C++11 and Fortran 2008 allow to reproduce the mathematical notation used in the literature within the program code. A discussion on the tradeoffs of the programming language choice is presented. The main angles of comparison are code brevity and syntax clarity (and hence maintainability and auditability) as well as performance. All performance tests are carried out using free and open-source compilers. In the case of Python, a significant performance gain is observed when switching from the standard interpreter (CPython) to the PyPy implementation of Python. Entire source code of all three implementations is embedded in the text and is licensed under the terms of the GNU GPL license. © 2014 - IOS Press and the authors. All rights reserved.","advection equation; C++; Fortran; MPDATA; Object-oriented programming; Python","Article","Scopus"
"Sambo F.; Finotello F.; Lavezzo E.; Baruzzo G.; Masi G.; Peta E.; Falda M.; Toppo S.; Barzon L.; Di Camillo B.","Sambo, Francesco (36176302600); Finotello, Francesca (36522886900); Lavezzo, Enrico (24465431800); Baruzzo, Giacomo (57192312589); Masi, Giulia (8551687700); Peta, Elektra (52464360000); Falda, Marco (14015711300); Toppo, Stefano (6602694397); Barzon, Luisa (6603688122); Di Camillo, Barbara (12771391500)","36176302600; 36522886900; 24465431800; 57192312589; 8551687700; 52464360000; 14015711300; 6602694397; 6603688122; 12771391500","Optimizing PCR primers targeting the bacterial 16S ribosomal RNA gene","2018","BMC Bioinformatics","10.1186/s12859-018-2360-6","25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054085388&doi=10.1186%2fs12859-018-2360-6&partnerID=40&md5=ae1b4dc132d84bd7a3a7ae4ed13e2fa3","Background: Targeted amplicon sequencing of the 16S ribosomal RNA gene is one of the key tools for studying microbial diversity. The accuracy of this approach strongly depends on the choice of primer pairs and, in particular, on the balance between efficiency, specificity and sensitivity in the amplification of the different bacterial 16S sequences contained in a sample. There is thus the need for computational methods to design optimal bacterial 16S primers able to take into account the knowledge provided by the new sequencing technologies. Results: We propose here a computational method for optimizing the choice of primer sets, based on multi-objective optimization, which simultaneously: 1) maximizes efficiency and specificity of target amplification; 2) maximizes the number of different bacterial 16S sequences matched by at least one primer; 3) minimizes the differences in the number of primers matching each bacterial 16S sequence. Our algorithm can be applied to any desired amplicon length without affecting computational performance. The source code of the developed algorithm is released as the mopo16S software tool (Multi-Objective Primer Optimization for 16S experiments) under the GNU General Public License and is available at http://sysbiobig.dei.unipd.it/?q=Software#mopo16S. Conclusions: Results show that our strategy is able to find better primer pairs than the ones available in the literature according to all three optimization criteria. We also experimentally validated three of the primer pairs identified by our method on multiple bacterial species, belonging to different genera and phyla. Results confirm the predicted efficiency and the ability to maximize the number of different bacterial 16S sequences matched by primers. © 2018 The Author(s).","16S rRNA sequencing; Multi objective optimization; Primer design","Article","Scopus"
"Lima E.J., II; Souza Bomfim M.H.; De Miranda Mourão M.A.","Lima, Eduardo José (57226560523); Souza Bomfim, Marcelo Henrique (57194525558); De Miranda Mourão, Miguel Augusto (57200119510)","57226560523; 57194525558; 57200119510","POLIBOT – POwer Lines Inspection RoBOT","2018","Industrial Robot","10.1108/IR-08-2016-0217","24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038824961&doi=10.1108%2fIR-08-2016-0217&partnerID=40&md5=210aca61896b23f70ccde1f70ecad09c","Purpose – Several studies have aimed to develop robotic systems which move in transmission lines. Until this moment, all of them have a high weight and cost associated with the equipment and reduced battery autonomy time. In this context, this paper aims to propose the POLIBOT (POwer Lines Inspection roBOT) with low cost and weight, enabling the movement over the lines and an easier installation and remove. Design/methodology/approach – The designed robot uses the Profiles Manufacturing Methodology (PMM). The construction of the robot mechanical structure uses modularized aluminum parts built through square profiles. Thus, it's possible a drastic reduction in production time as well as cost reduction and weight when comparing this method with other manufacturing processes like foundry, for example. For hardware and software systems, the use of free and open source software causes a significant reduction in cost and project execution time. The benefits of using open source systems are immeasurable, both from academic and industrial applications. Findings – The POLIBOT platform is one solution to the problem of inspection in power lines. With this robot, more lines are maintained with lower time. In its constructive aspect, the robotic mechanism is designed using principles of bioengineering. The use of this principle was successful, considering that obstacle transposition is performed with stability and low energy consumption. Research limitations/implications – The suggestion for future researches is to replace the battery for solar energy and construction in polymeric material to avoid high magnetic fields. Practical implications – The commercial application is evident because manual inspections are inefficient, very expensive and dangerous. Thus, it is growing the number of researches that develop mechatronics systems for this kind of inspection. Social implications – The impact is the reduction of accidents because the present procedure requires precision of movements, where the pilot and electrical technician are close to high electrical and magnetic fields. In addition, for some tasks, the worker has to walk on the line to reach some important points. Thus, those tasks involve high risk of death. Originality/value – The PMM methodology represents an innovation to the state of the art because others robotic mechanisms proposed for inspection tasks present total structure mass between 50 and 100 kg and POLIBOT has only 9 kg. Other fact is its price for implementation as this robot used the robot operating system (ROS) framework, what dispense the use of licenses. Other important features are that the robot performs the tasks autonomously, which reduces errors introduced by the operator and its low manufacturing cost as compared with other projects. © Emerald Publishing Limited","Autonomous robots; Field robotics; Overhead transmission lines; Robot design","Article","Scopus"
"Latorre M.; Silva H.; Saba J.; Guziolowski C.; Vizoso P.; Martinez V.; Maldonado J.; Morales A.; Caroca R.; Cambiazo V.; Campos-Vargas R.; Gonzalez M.; Orellana A.; Retamales J.; Meisel L.A.","Latorre, Mariano (57224861604); Silva, Herman (55779365900); Saba, Juan (15124063800); Guziolowski, Carito (23097433600); Vizoso, Paula (15125114400); Martinez, Veronica (57200683803); Maldonado, Jonathan (15124361900); Morales, Andrea (23497697500); Caroca, Rodrigo (15123862400); Cambiazo, Veronica (6603336587); Campos-Vargas, Reinaldo (56065674900); Gonzalez, Mauricio (7404554511); Orellana, Ariel (7003725355); Retamales, Julio (8593635800); Meisel, Lee A. (8941652100)","57224861604; 55779365900; 15124063800; 23097433600; 15125114400; 57200683803; 15124361900; 23497697500; 15123862400; 6603336587; 56065674900; 7404554511; 7003725355; 8593635800; 8941652100","JUICE: A data management system that facilitates the analysis of large volumes of information in an EST project workflow","2006","BMC Bioinformatics","10.1186/1471-2105-7-513","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33845270203&doi=10.1186%2f1471-2105-7-513&partnerID=40&md5=4a74dae53034af99a351016019f3a496","Background: Expressed sequence tag (EST) analyses provide a rapid and economical means to identify candidate genes that may be involved in a particular biological process. These ESTs are useful in many Functional Genomics studies. However, the large quantity and complexity of the data generated during an EST sequencing project can make the analysis of this information a daunting task. Results: In an attempt to make this task friendlier, we have developed JUICE, an open source data management system (Apache + PHP + MySQL on Linux), which enables the user to easily upload, organize, visualize and search the different types of data generated in an EST project pipeline. In contrast to other systems, the JUICE data management system allows a branched pipeline to be established, modified and expanded, during the course of an EST project. The web interfaces and tools in JUICE enable the users to visualize the information in a graphical, user-friendly manner. The user may browse or search for sequences and/or sequence information within all the branches of the pipeline. The user can search using terms associated with the sequence name, annotation or other characteristics stored in JUICE and associated with sequences or sequence groups. Groups of sequences can be created by the user, stored in a clipboard and/or downloaded for further analyses. Different user profiles restrict the access of each user depending upon their role in the project. The user may have access exclusively to visualize sequence information, access to annotate sequences and sequence information, or administrative access. Conclusion: JUICE is an open source data management system that has been developed to aid users in organizing and analyzing the large amount of data generated in an EST Project workflow. JUICE has been used in one of the first functional genomics projects in Chile, entitled ""Functional Genomics in nectarines: Platform to potentiate the competitiveness of Chile in fruit exportation"". However, due to its ability to organize and visualize data from external pipelines, JUICE is a flexible data management system that should be useful for other EST/ Genome projects. The JUICE data management system is released under the Open Source GNU Lesser General Public License (LGPL). JUICE may be download from http://genoma.unab.cl/juice_system/ or http://www.genomavegetal.cl/juice_system/. © 2006 Latorre et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Pérez-Rodríguez G.; Glez-Peña D.; Azevedo N.F.; Pereira M.O.; Fdez-Riverola F.; Lourenço A.","Pérez-Rodríguez, Gael (57203126963); Glez-Peña, Daniel (23091104700); Azevedo, Nuno F. (8092231700); Pereira, Maria Olívia (7401842375); Fdez-Riverola, Florentino (35580091100); Lourenço, Anália (7005749859)","57203126963; 23091104700; 8092231700; 7401842375; 35580091100; 7005749859","Enabling systematic, harmonised and large-scale biofilms data computation: The biofilms experiment workbench","2015","Computer Methods and Programs in Biomedicine","10.1016/j.cmpb.2014.12.005","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923552052&doi=10.1016%2fj.cmpb.2014.12.005&partnerID=40&md5=a2a97c5c92885243c0d79d427a8ae179","Background and objective: Biofilms are receiving increasing attention from the biomedical community. Biofilm-like growth within human body is considered one of the key microbial strategies to augment resistance and persistence during infectious processes. The Biofilms Experiment Workbench is a novel software workbench for the operation and analysis of biofilms experimental data. The goal is to promote the interchange and comparison of data among laboratories, providing systematic, harmonised and large-scale data computation. Methods: The workbench was developed with AIBench, an open-source Java desktop application framework for scientific software development in the domain of translational biomedicine. Implementation favours free and open-source third-parties, such as the R statistical package, and reaches for the Web services of the BiofOmics database to enable public experiment deposition. Results: First, we summarise the novel, free, open, XML-based interchange format for encoding biofilms experimental data. Then, we describe the execution of common scenarios of operation with the new workbench, such as the creation of new experiments, the importation of data from Excel spreadsheets, the computation of analytical results, the on-demand and highly customised construction of Web publishable reports, and the comparison of results between laboratories. Conclusions: A considerable and varied amount of biofilms data is being generated, and there is a critical need to develop bioinformatics tools that expedite the interchange and comparison of microbiological and clinical results among laboratories. We propose a simple, open-source software infrastructure which is effective, extensible and easy to understand. The workbench is freely available for non-commercial use at http://sing.ei.uvigo.es/bew under LGPL license. © 2015 Elsevier Ireland Ltd.","Biofilms; Bioinformatics; Clinical microbiology; Experimental data workbench; Harmonised vocabulary; Interchange format","Article","Scopus"
"Suárez J.L.; García S.; Herrera F.","Suárez, Juan Luis (35202168700); García, Salvador (37103985200); Herrera, Francisco (57210774934)","35202168700; 37103985200; 57210774934","pyDML: A python library for distance metric learning","2020","Journal of Machine Learning Research","","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087330164&partnerID=40&md5=429425d6fc4cecd226cd747ab8537a8f","pyDML is an open-source python library that provides a wide range of distance metric learning algorithms. Distance metric learning can be useful to improve similarity learning algorithms, such as the nearest neighbors classifier, and also has other applications, like dimensionality reduction. The pyDML package currently provides more than 20 algorithms, which can be categorized, according to their purpose, in: dimensionality reduction algorithms, algorithms to improve nearest neighbors or nearest centroids classifiers, information theory based algorithms or kernel based algorithms, among others. In addition, the library also provides some utilities for the visualization of classifier regions, parameter tuning and a stats website with the performance of the implemented algorithms. The package relies on the scipy ecosystem, it is fully compatible with scikit-learn, and is distributed under GPLv3 license. Source code and documentation can be found at https://github.com/jlsuarezdiaz/pyDML. © 2020 Juan Luis Suárez, Salvador García, Francisco Herrera.","Classification; Dimensionality; Distance Metric Learning; Mahalanobis Distance; Python","Article","Scopus"
"Mussmann S.M.; Douglas M.R.; Chafin T.K.; Douglas M.E.","Mussmann, Steven M. (55624685600); Douglas, Marlis R. (57213634050); Chafin, Tyler K. (57203408380); Douglas, Michael E. (57220657646)","55624685600; 57213634050; 57203408380; 57220657646","AdmixPipe: population analyses in Admixture for non-model organisms","2020","BMC Bioinformatics","10.1186/s12859-020-03701-4","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088851282&doi=10.1186%2fs12859-020-03701-4&partnerID=40&md5=8963e7dd209d7cc1e330b41a408ea2e0","Background: Research on the molecular ecology of non-model organisms, while previously constrained, has now been greatly facilitated by the advent of reduced-representation sequencing protocols. However, tools that allow these large datasets to be efficiently parsed are often lacking, or if indeed available, then limited by the necessity of a comparable reference genome as an adjunct. This, of course, can be difficult when working with non-model organisms. Fortunately, pipelines are currently available that avoid this prerequisite, thus allowing data to be a priori parsed. An oft-used molecular ecology program (i.e., Structure), for example, is facilitated by such pipelines, yet they are surprisingly absent for a second program that is similarly popular and computationally more efficient (i.e., Admixture). The two programs differ in that Admixture employs a maximum-likelihood framework whereas Structure uses a Bayesian approach, yet both produce similar results. Given these issues, there is an overriding (and recognized) need among researchers in molecular ecology for bioinformatic software that will not only condense output from replicated Admixture runs, but also infer from these data the optimal number of population clusters (K). Results: Here we provide such a program (i.e., AdmixPipe) that (a) filters SNPs to allow the delineation of population structure in Admixture, then (b) parses the output for summarization and graphical representation via Clumpak. Our benchmarks effectively demonstrate how efficient the pipeline is for processing large, non-model datasets generated via double digest restriction-site associated DNA sequencing (ddRAD). Outputs not only parallel those from Structure, but also visualize the variation among individual Admixture runs, so as to facilitate selection of the most appropriate K-value. Conclusions: AdmixPipe successfully integrates Admixture analysis with popular variant call format (VCF) filtering software to yield file types readily analyzed by Clumpak. Large population genomic datasets derived from non-model organisms are efficiently analyzed via the parallel-processing capabilities of Admixture. AdmixPipe is distributed under the GNU Public License and freely available for Mac OSX and Linux platforms at: https://github.com/stevemussmann/admixturePipeline. © 2020 The Author(s).","Admixture analysis; Population genomics; Population structure; RADseq; SNP analysis","Article","Scopus"
"Hansen T.M.; Vu L.T.; Bach T.","Hansen, Thomas Mejer (35402645500); Vu, Le Thanh (57198288729); Bach, Torben (57192087193)","35402645500; 57198288729; 57192087193","MPSLIB: A C++ class for sequential simulation of multiple-point statistical models","2016","SoftwareX","10.1016/j.softx.2016.07.001","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996798860&doi=10.1016%2fj.softx.2016.07.001&partnerID=40&md5=d17c85fb0e400ba9e89bac397d98aa7e","Geostatistical simulation methods allow simulation of spatial structures and patterns based on a choice of statistical model. In the last few decades multiple-point statistics (MPS) has been developed that allows inferring the statistical model from a training image. This allows for a simpler quantification of the statistical model, and simulation of more realistic (Earth) structures. A number of different algorithms for MPS based simulation have been proposed, each associated with a unique set of pros or cons. MPSLIB is a C++ class that provides a framework for implementing most of the currently proposed multiple-point simulation methods based on sequential simulation. A number of the most widely used methods are provided as an example. The single normal equation simulation (SNESIM) method is implemented using both a tree and a list structure. A new generalized ENESIM (GENESIM) algorithm is proposed that can act as (in one extreme) the ENESIM algorithm, and (in another extreme) similar to the direct sampling algorithm. MPSLIB aims to be easy to compile on most platforms (standard C++11 is the only requirement) and is released under the Open Source LGPLv3 License to encourage reuse and further development. © 2016 The Author(s)","Geostatistics; Multiple-point statistics; Simulation","Article","Scopus"
"Klemm M.; Kirchner T.; Gröhl J.; Cheray D.; Nolden M.; Seitel A.; Hoppe H.; Maier-Hein L.; Franz A.M.","Klemm, Martin (36606358900); Kirchner, Thomas (7102358573); Gröhl, Janek (57191360550); Cheray, Dominique (57191358638); Nolden, Marco (55908659000); Seitel, Alexander (22635486300); Hoppe, Harald (57187834900); Maier-Hein, Lena (22634618600); Franz, Alfred M. (22633908400)","36606358900; 7102358573; 57191360550; 57191358638; 55908659000; 22635486300; 57187834900; 22634618600; 22633908400","MITK-OpenIGTLink for combining open-source toolkits in real-time computer-assisted interventions","2017","International Journal of Computer Assisted Radiology and Surgery","10.1007/s11548-016-1488-y","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989179758&doi=10.1007%2fs11548-016-1488-y&partnerID=40&md5=1dda3f923039f75d2d39679dfca0ddc2","Purpose: Due to rapid developments in the research areas of medical imaging, medical image processing and robotics, computer-assisted interventions (CAI) are becoming an integral part of modern patient care. From a software engineering point of view, these systems are highly complex and research can benefit greatly from reusing software components. This is supported by a number of open-source toolkits for medical imaging and CAI such as the medical imaging interaction toolkit (MITK), the public software library for ultrasound imaging research (PLUS) and 3D Slicer. An independent inter-toolkit communication such as the open image-guided therapy link (OpenIGTLink) can be used to combine the advantages of these toolkits and enable an easier realization of a clinical CAI workflow. Methods: MITK-OpenIGTLink is presented as a network interface within MITK that allows easy to use, asynchronous two-way messaging between MITK and clinical devices or other toolkits. Performance and interoperability tests with MITK-OpenIGTLink were carried out considering the whole CAI workflow from data acquisition over processing to visualization. Results: We present how MITK-OpenIGTLink can be applied in different usage scenarios. In performance tests, tracking data were transmitted with a frame rate of up to 1000 Hz and a latency of 2.81 ms. Transmission of images with typical ultrasound (US) and greyscale high-definition (HD) resolutions of 640 × 480 and 1920 × 1080 is possible at up to 512 and 128 Hz, respectively. Conclusion: With the integration of OpenIGTLink into MITK, this protocol is now supported by all established open-source toolkits in the field. This eases interoperability between MITK and toolkits such as PLUS or 3D Slicer and facilitates cross-toolkit research collaborations. MITK and its submodule MITK-OpenIGTLink are provided open source under a BSD-style licence (http://mitk.org). © 2016, CARS.","Computer-assisted interventions; Image-guided therapy; Interoperability; MITK; OpenIGTLink; Ultrasound","Article","Scopus"
"Fioravante de Siqueira A.; Ushizima D.M.; van der Walt S.J.","Fioravante de Siqueira, Alexandre (57440494400); Ushizima, Daniela M. (14827670900); van der Walt, Stéfan J. (15732291000)","57440494400; 14827670900; 15732291000","A reusable neural network pipeline for unidirectional fiber segmentation","2022","Scientific Data","10.1038/s41597-022-01119-6","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124057121&doi=10.1038%2fs41597-022-01119-6&partnerID=40&md5=3f2f9cfb37b86b3430fc04bdf54c9a06","Fiber-reinforced ceramic-matrix composites are advanced, temperature resistant materials with applications in aerospace engineering. Their analysis involves the detection and separation of fibers, embedded in a fiber bed, from an imaged sample. Currently, this is mostly done using semi-supervised techniques. Here, we present an open, automated computational pipeline to detect fibers from a tomographically reconstructed X-ray volume. We apply our pipeline to a non-trivial dataset by Larson et al. To separate the fibers in these samples, we tested four different architectures of convolutional neural networks. When comparing our neural network approach to a semi-supervised one, we obtained Dice and Matthews coefficients reaching up to 98%, showing that these automated approaches can match human-supervised methods, in some cases separating fibers that human-curated algorithms could not find. The software written for this project is open source, released under a permissive license, and can be freely adapted and re-used in other domains. © 2022, The Author(s).","","Article","Scopus"
"Fibich C.; Tauner S.; Rössler P.; Horauer M.; Matschnig M.; Taucher H.","Fibich, Christian (57195511572); Tauner, Stefan (56770106900); Rössler, Peter (22235447500); Horauer, Martin (8215581600); Matschnig, Martin (56732951400); Taucher, Herbert (56733058800)","57195511572; 56770106900; 22235447500; 8215581600; 56732951400; 56733058800","FIJI: Fault InJection Instrumenter","2019","Eurasip Journal on Embedded Systems","10.1186/s13639-019-0088-7","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062231864&doi=10.1186%2fs13639-019-0088-7&partnerID=40&md5=ae89b941b172ffc6eef854624985e3e9","FPGAs are increasingly used in safety-critical applications (e.g., in aerospace and automotive engineering). Safety standards stipulate that implemented countermeasures against run-time faults such as detection and isolation of affected components, automatic reconfiguration, and redundancy mechanisms must be adequately verified. To that end, fault injection tests by various means have been established as a suitable method. For such tests, faults can be provoked by radiation, simulation, or manipulating the design, for example, by inserting additional logic or manipulating the synthesis flow. This work briefly summarizes the various fault injection approaches with a focus on methods that are capable of stressing critical nets of a design running on actual hardware without requiring to re-synthesize. While the state-of-the-art tools can work with complex designs, they often lack controllability of the exact timing of the injection events (which is important to track the system’s response on faults in a logic simulation) and/or use a high amount of FPGA resources. To overcome these issues, we propose a resource-saving netlist-based fault injection framework Fault InJection Instrumenter (FIJI) that can target individual nets at test runtime. This paper presents FIJI’s work flow, implementation details, and an evaluation in terms of FPGA resources, timing impact, and performance during instrumentation and test execution. The FIJI framework has been made publicly available by the authors under an open-source license. © 2019, The Author(s).","Electronic design automation; Fault injection; FPGA; Safety-critical system; Verification","Article","Scopus"
"Bendarag A.; Bakkas J.; Hanine M.; Boutkhoum O.","Bendarag, Abdesadik (57822151500); Bakkas, Jamal (55752688400); Hanine, Mohamed (57219370936); Boutkhoum, Omar (55920067000)","57822151500; 55752688400; 57219370936; 55920067000","PyOPAsolver: A python based tool for ordinal priority approach operations and normalization","2022","SoftwareX","10.1016/j.softx.2022.101226","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140300606&doi=10.1016%2fj.softx.2022.101226&partnerID=40&md5=886558aa62e9b537fa8551ec3b20f64d","The Ordinal Priority Approach (OPA) is a new decision-making method that determines the best alternative among a set of solutions according to a set of attributes based on the experiences of one or more experts. OPA is frequently utilized in various studies, such as project portfolio selection, sustainable supplier selection, evaluation of the performance of the suppliers and sustainable construction, among other multi-criteria decision-making problems (MCDM). Despite the usefulness of this MCDM technique, there is no free open-source software for OPA with full analysis extensions. Thus, the current paper demonstrates a Python-based tool PyOPAsolver to allow researchers make operations on OPA method with the BSD -3-Clause license. This tool is designed mainly as a package to be integrated into Python programs that use the OPA method. The diversity and richness of its methods offer developers a very flexible exploitation. © 2022 The Author(s)","MCDM; OPA; PyOPASolver; Python","Article","Scopus"
"Kämpf C.; Specht M.; Scholz A.; Puppel S.-H.; Doose G.; Reiche K.; Schor J.; Hackermüller J.","Kämpf, Christoph (57203397081); Specht, Michael (57215342781); Scholz, Alexander (57215340348); Puppel, Sven-Holger (57204727977); Doose, Gero (55221827700); Reiche, Kristin (16246094500); Schor, Jana (57200659468); Hackermüller, Jörg (15925392700)","57203397081; 57215342781; 57215340348; 57204727977; 55221827700; 16246094500; 57200659468; 15925392700","Uap: Reproducible and robust HTS data analysis","2019","BMC Bioinformatics","10.1186/s12859-019-3219-1","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076462586&doi=10.1186%2fs12859-019-3219-1&partnerID=40&md5=942fef59041cb1ef092fee84bc1a78af","Background: A lack of reproducibility has been repeatedly criticized in computational research. High throughput sequencing (HTS) data analysis is a complex multi-step process. For most of the steps a range of bioinformatic tools is available and for most tools manifold parameters need to be set. Due to this complexity, HTS data analysis is particularly prone to reproducibility and consistency issues. We have defined four criteria that in our opinion ensure a minimal degree of reproducible research for HTS data analysis. A series of workflow management systems is available for assisting complex multi-step data analyses. However, to the best of our knowledge, none of the currently available work flow management systems satisfies all four criteria for reproducible HTS analysis. Results: Here we present uap, a workflow management system dedicated to robust, consistent, and reproducible HTS data analysis. uap is optimized for the application to omics data, but can be easily extended to other complex analyses. It is available under the GNU GPL v3 license at https://github.com/yigbt/uap. Conclusions: Uap is a freely available tool that enables researchers to easily adhere to reproducible research principles for HTS data analyses. © 2019 The Author(s).","Reproducible research; Sequencing data analysis; Work-flow management","Article","Scopus"
"Zhou Y.; Gallego G.; Shen S.","Zhou, Yi (57188826692); Gallego, Guillermo (36821159200); Shen, Shaojie (55325638900)","57188826692; 36821159200; 55325638900","Event-based stereo visual odometry","2021","IEEE Transactions on Robotics","10.1109/TRO.2021.3062252","38","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103302992&doi=10.1109%2fTRO.2021.3062252&partnerID=40&md5=286451a85a7f496690b90ac37a53be1c","Event-based cameras are bioinspired vision sensors whose pixels work independently from each other and respond asynchronously to brightness changes, with microsecond resolution. Their advantages make it possible to tackle challenging scenarios in robotics, such as high-speed and high dynamic range scenes. We present a solution to the problem of visual odometry from the data acquired by a stereo event-based camera rig. Our system follows a parallel tracking-and-mapping approach, where novel solutions to each subproblem (three-dimensional (3-D) reconstruction and camera pose estimation) are developed with two objectives in mind: being principled and efficient, for real-time operation with commodity hardware. To this end, we seek to maximize the spatio-temporal consistency of stereo event-based data while using a simple and efficient representation. Specifically, the mapping module builds a semidense 3-D map of the scene by fusing depth estimates from multiple viewpoints (obtained by spatio-temporal consistency) in a probabilistic fashion. The tracking module recovers the pose of the stereo rig by solving a registration problem that naturally arises due to the chosen map and event data representation. Experiments on publicly available datasets and on our own recordings demonstrate the versatility of the proposed method in natural scenes with general 6-DoF motion. The system successfully leverages the advantages of event-based cameras to perform visual odometry in challenging illumination conditions, such as low-light and high dynamic range, while running in real-time on a standard CPU. We release the software and dataset under an open source license to foster research in the emerging topic of event-based simultaneous localization and mapping. © 2021 IEEE.","Computer vision; Real-time systems; Robot vision systems; Simultaneous localization and mapping; Smart cameras; Stereo vision","Article","Scopus"
"Schumacher F.; Friederich W.","Schumacher, Florian (57126904100); Friederich, Wolfgang (6701431930)","57126904100; 6701431930","ASKI: A modular toolbox for scattering-integral-based seismic full waveform inversion and sensitivity analysis utilizing external forward codes","2016","SoftwareX","10.1016/j.softx.2016.10.005","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006482115&doi=10.1016%2fj.softx.2016.10.005&partnerID=40&md5=8bb884320a8c4139eca273995ad0426b","Due to increasing computational resources, the development of new numerically demanding methods and software for imaging Earth's interior remains of high interest in Earth sciences. Here, we give a description from a user's and programmer's perspective of the highly modular, flexible and extendable software package ASKI–Analysis of Sensitivity and Kernel Inversion–recently developed for iterative scattering-integral-based seismic full waveform inversion. In ASKI, the three fundamental steps of solving the seismic forward problem, computing waveform sensitivity kernels and deriving a model update are solved by independent software programs that interact via file output/input only. Furthermore, the spatial discretizations of the model space used for solving the seismic forward problem and for deriving model updates, respectively, are kept completely independent. For this reason, ASKI does not contain a specific forward solver but instead provides a general interface to established community wave propagation codes. Moreover, the third fundamental step of deriving a model update can be repeated at relatively low costs applying different kinds of model regularization or re-selecting/weighting the inverted dataset without need to re-solve the forward problem or re-compute the kernels. Additionally, ASKI offers the user sensitivity and resolution analysis tools based on the full sensitivity matrix and allows to compose customized workflows in a consistent computational environment. ASKI is written in modern Fortran and Python, it is well documented and freely available under terms of the GNU General Public License (http://www.rub.de/aski). © 2016 The Author(s)","ASKI; Object-oriented programming; Seismic full waveform inversion; Waveform sensitivity kernels","Article","Scopus"
"Benoit G.; Lemaitre C.; Lavenier D.; Drezen E.; Dayris T.; Uricaru R.; Rizk G.","Benoit, Gaëtan (56841247300); Lemaitre, Claire (36189617900); Lavenier, Dominique (6701814154); Drezen, Erwan (57505240700); Dayris, Thibault (56841676300); Uricaru, Raluca (36667545600); Rizk, Guillaume (32867961600)","56841247300; 36189617900; 6701814154; 57505240700; 56841676300; 36667545600; 32867961600","Reference-free compression of high throughput sequencing data with a probabilistic de Bruijn graph","2015","BMC Bioinformatics","10.1186/s12859-015-0709-7","56","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942190587&doi=10.1186%2fs12859-015-0709-7&partnerID=40&md5=8e81d688e13a5a770d0c6d6ad6234cae","Background: Data volumes generated by next-generation sequencing (NGS) technologies is now a major concern for both data storage and transmission. This triggered the need for more efficient methods than general purpose compression tools, such as the widely used gzip method. Results: We present a novel reference-free method meant to compress data issued from high throughput sequencing technologies. Our approach, implemented in the software Leon, employs techniques derived from existing assembly principles. The method is based on a reference probabilistic de Bruijn Graph, built de novo from the set of reads and stored in a Bloom filter. Each read is encoded as a path in this graph, by memorizing an anchoring kmer and a list of bifurcations. The same probabilistic de Bruijn Graph is used to perform a lossy transformation of the quality scores, which allows to obtain higher compression rates without losing pertinent information for downstream analyses. Conclusions: Leon was run on various real sequencing datasets (whole genome, exome, RNA-seq or metagenomics). In all cases, LEON showed higher overall compression ratios than state-of-the-art compression software. On a C. elegans whole genome sequencing dataset, LEON divided the original file size by more than 20. Leon is an open source software, distributed under GNU affero GPL License, available for download at http://gatb.inria.fr/software/leon/. © 2015 Benoit et al.","Bloom filter; Compression; de Bruijn Graph; NGS","Article","Scopus"
"Höck S.; Riedl R.","Höck, Stefan (57191900156); Riedl, Rainer (36999486300)","57191900156; 36999486300","CyBy2: A strongly typed, purely functional framework for chemical data management","2019","Journal of Cheminformatics","10.1186/s13321-019-0403-2","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077231948&doi=10.1186%2fs13321-019-0403-2&partnerID=40&md5=2255e0136066c8c044317f4ca754ca8b","We present the development of CyBy 2, a versatile framework for chemical data management written in purely functional style in Scala, a modern multi-paradigm programming language. Together with the core libraries we provide a fully functional example implementation of a HTTP server together with a single page web client with powerful querying and visualization capabilities, providing essential functionality for people working in the field of organic and medicinal chemistry. The main focus of CyBy 2 are the diverse needs of different research groups in the field and therefore the flexibility required from the underlying data model. Techniques for writing type level specifications giving strong guarantees about the correctness of the implementation are described, together with the resulting gain in confidence during refactoring. Finally we talk about the advantages of using a single code base from which the server, the client and the software's documentation pages are being generated. We conclude with a comparison with existing open source solutions. All code described in this article is published under version 3 of the GNU General Public License and available from GitHub including an example implementation of both backend and frontend together with documentation how to download and compile the software (available at https://github.com/stefan-hoeck/cyby2). © 2019 The Author(s).","Chemical data management; Functional programming; Lab inventory; Medicinal chemistry; Scala; Type driven development","Article","Scopus"
"Moore H.E., IV; Mignot E.","Moore, Hyatt E. (55795638100); Mignot, Emmanuel (55628584667)","55795638100; 55628584667","SEV – a software toolbox for large scale analysis and visualization of polysomnography data","2015","Computer Methods in Biomechanics and Biomedical Engineering: Imaging and Visualization","10.1080/21681163.2014.891076","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981360275&doi=10.1080%2f21681163.2014.891076&partnerID=40&md5=f3e100350d73909fda715c81467ad44c","SEV is a graphical toolbox designed in MATLAB for displaying polysomnography (PSG) signals recorded during sleep studies, prototyping signal-processing algorithms and automating sleep feature extraction methods across large collections or cohorts of such studies. Format imported are European Data Formats and event/hypnogram files. Time-series analysis can be performed using a suite of classifiers, filters and signal decomposition tools (e.g. wavelets) developed internally or implemented from validated methods published by others. Power spectral analysis can be performed using either periodogram averaging or multiple spectrum independent component analysis. The tool is highly configurable and provides a simple framework for classifier optimization and extensibility. MATLAB's parallel processing toolbox is utilized during batch processing. Output formats include MySQL database entry, tab-delimited text and MATLAB archive (.MAT). The tool is well suited for genetic or epidemiological sleep research questions requiring rigorous, robust and reproducible evaluation of a PSG-based sleep study cohort. Current built-in applications include modules to detect and quantify rapid eye movements and spindle activity (using existing algorithms), inter-channel electroencephalography coherence and a detector developed in house to quantify periodic leg movements during sleep. SEV is open source and freely available under a common creative license. © 2015, © 2014 Taylor & Francis.","automation; data visualization; pattern recognition; polysomnography; signal processing; sleep","Article","Scopus"
"Combrisson E.; Nest T.; Brovelli A.; Ince R.A.A.; Soto J.L.P.; Guillot A.; Jerbi K.","Combrisson, Etienne (56516980100); Nest, Timothy (57189030397); Brovelli, Andrea (23024383300); Ince, Robin A.A. (36852225800); Soto, Juan L.P. (35070368700); Guillot, Aymeric (7003423136); Jerbi, Karim (22334012100)","56516980100; 57189030397; 23024383300; 36852225800; 35070368700; 7003423136; 22334012100","Tensorpac: An open-source Python toolbox for tensor-based phase-amplitude coupling measurement in electrophysiological brain signals","2020","PLoS Computational Biology","10.1371/journal.pcbi.1008302","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095747987&doi=10.1371%2fjournal.pcbi.1008302&partnerID=40&md5=deb4b3c610fbf6e9d648d34d410bd6bb","Despite being the focus of a thriving field of research, the biological mechanisms that underlie information integration in the brain are not yet fully understood. A theory that has gained a lot of traction in recent years suggests that multi-scale integration is regulated by a hierarchy of mutually interacting neural oscillations. In particular, there is accumulating evidence that phase-amplitude coupling (PAC), a specific form of cross-frequency interaction, plays a key role in numerous cognitive processes. Current research in the field is not only hampered by the absence of a gold standard for PAC analysis, but also by the computational costs of running exhaustive computations on large and high-dimensional electrophysiological brain signals. In addition, various signal properties and analyses parameters can lead to spurious PAC. Here, we present Tensorpac, an open-source Python toolbox dedicated to PAC analysis of neurophysiological data. The advantages of Tensorpac include (1) higher computational efficiency thanks to software design that combines tensor computations and parallel computing, (2) the implementation of all most widely used PAC methods in one package, (3) the statistical analysis of PAC measures, and (4) extended PAC visualization capabilities. Tensorpac is distributed under a BSD-3-Clause license and can be launched on any operating system (Linux, OSX and Windows). It can be installed directly via pip or downloaded from Github (https://github.com/EtienneCmb/tensorpac). By making Tensorpac available, we aim to enhance the reproducibility and quality of PAC research, and provide open tools that will accelerate future method development in neuroscience. © 2020 Combrisson et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Article","Scopus"
"Marzolf B.; Deutsch E.W.; Moss P.; Campbell D.; Johnson M.H.; Galitski T.","Marzolf, Bruz (14056726000); Deutsch, Eric W. (35350950800); Moss, Patrick (57197016022); Campbell, David (57190293290); Johnson, Michael H. (56995412100); Galitski, Timothy (6602178062)","14056726000; 35350950800; 57197016022; 57190293290; 56995412100; 6602178062","SBEAMS-Microarray: Database software supporting genomic expression analyses for systems biology","2006","BMC Bioinformatics","10.1186/1471-2105-7-286","45","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33746704351&doi=10.1186%2f1471-2105-7-286&partnerID=40&md5=4380224b098d0beac942207fc7213c72","Background: The biological information in genomic expression data can be understood, and computationally extracted, in the context of systems of interacting molecules. The automation of this information extraction requires high throughput management and analysis of genomic expression data, and integration of these data with other data types. Results: SBEAMS-Microarray, a module of the open-source Systems Biology Experiment Analysis Management System (SBEAMS), enables MIAME-compliant storage, management, analysis, and integration of high-throughput genomic expression data. It is interoperable with the Cytoscape network integration, visualization, analysis, and modeling software platform. Conclusion: SBEAMS-Microarray provides end-to-end support for genomic expression analyses for network-based systems biology research. © 2006 Marzolf et al; license BioMed Central Ltd.","","Article","Scopus"
"Brehm M.; Thomas M.","Brehm, Martin (38661083600); Thomas, Martin (55141008200)","38661083600; 55141008200","An Efficient Lossless Compression Algorithm for Trajectories of Atom Positions and Volumetric Data","2018","Journal of Chemical Information and Modeling","10.1021/acs.jcim.8b00501","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054668185&doi=10.1021%2facs.jcim.8b00501&partnerID=40&md5=977671ea6a07b9e5b0bec45d1353e563","We present our newly developed and highly efficient lossless compression algorithm for trajectories of atom positions and volumetric data. The algorithm is designed as a two-step approach. In the first step, efficient polynomial extrapolation schemes reduce the information entropy of the data by exploiting both spatial and temporal continuity. The second step processes the data by a series of transformations (Burrows-Wheeler, move-to-front, run length encoding) and finally compresses the stream with multitable canonical Huffman coding. Our approach reaches a compression ratio of around 15:1 for typical position trajectories in the XYZ format. For volumetric data trajectories in Gaussian Cube format (such as electron density), even a compression ratio of around 35:1 is yielded, which is by far the smallest size of all formats compared here. At the same time, compression and decompression are still reasonably fast for everyday use. The precision of the data can be selected by the user. For storage of the compressed data, we introduce the BQB file format, which is very robust, flexible, and efficient. In contrast to most archiving formats, it allows fast random access to individual trajectory frames. Our method is implemented in C++ and provided as free software under the GNU LGPL license. It has been included in the TRAVIS program package but is also available as stand-alone tool and as a library (""libbqb"") for use in other projects. © 2018 American Chemical Society.","","Article","Scopus"
"Gamallo P.; Garcia M.","Gamallo, Pablo (56635186300); Garcia, Marcos (57198924640)","56635186300; 57198924640","Dependency parsing with finite state transducers and compression rules","2018","Information Processing and Management","10.1016/j.ipm.2018.05.003","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048572473&doi=10.1016%2fj.ipm.2018.05.003&partnerID=40&md5=589da713ae291dbb1773a9d3488b16fa","This article proposes a syntactic parsing strategy based on a dependency grammar containing formal rules and a compression technique that reduces the complexity of those rules. Compression parsing is mainly driven by the 'single-head’ constraint of Dependency Grammar, and can be seen as an alternative method to the well-known constructive strategy. The compression algorithm simplifies the input sentence by progressively removing from it the dependent tokens as soon as binary syntactic dependencies are recognized. This strategy is thus similar to that used in deterministic dependency parsing. A compression parser was implemented and released under General Public License, as well as a cross-lingual grammar with Universal Dependencies, containing only broad-coverage rules applied to Romance languages. The system is an almost delexicalized parser which does not need training data to analyze Romance languages. The rule-based cross-lingual parser was submitted to CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. The performance of our system was compared to the other supervised systems participating in the competition, paying special attention to the parsing of different treebanks of the same language. We also trained a supervised delexicalized parser for Romance languages in order to compare it to our rule-based system. The results show that the performance of our cross-lingual method does not change across related languages and across different treebanks, while most supervised methods turn out to be very dependent on the text domain used to train the system. © 2018 Elsevier Ltd","","Article","Scopus"
"Balazki P.; Lindauer K.; Einloft J.; Ackermann J.; Koch I.","Balazki, Pavel (56716557600); Lindauer, Klaus (15722127300); Einloft, Jens (55444498900); Ackermann, Jörg (57189026922); Koch, Ina (7006792171)","56716557600; 15722127300; 55444498900; 57189026922; 7006792171","MONALISA for stochastic simulations of Petri net models of biochemical systems","2015","BMC Bioinformatics","10.1186/s12859-015-0596-y","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019260780&doi=10.1186%2fs12859-015-0596-y&partnerID=40&md5=8d63f06e3721aa7304d5f231c958bb01","Background: The concept of Petri nets (PN) is widely used in systems biology and allows modeling of complex biochemical systems like metabolic systems, signal transduction pathways, and gene expression networks. In particular, PN allows the topological analysis based on structural properties, which is important and useful when quantitative (kinetic) data are incomplete or unknown. Knowing the kinetic parameters, the simulation of time evolution of such models can help to study the dynamic behavior of the underlying system. If the number of involved entities (molecules) is low, a stochastic simulation should be preferred against the classical deterministic approach of solving ordinary differential equations. The Stochastic Simulation Algorithm (SSA) is a common method for such simulations. The combination of the qualitative and semi-quantitative PN modeling and stochastic analysis techniques provides a valuable approach in the field of systems biology. Results: Here, we describe the implementation of stochastic analysis in a PN environment. We extended MonaLisa - an open-source software for creation, visualization and analysis of PN - by several stochastic simulation methods. The simulation module offers four simulation modes, among them the stochastic mode with constant firing rates and Gillespie's algorithm as exact and approximate versions. The simulator is operated by a user-friendly graphical interface and accepts input data such as concentrations and reaction rate constants that are common parameters in the biological context. The key features of the simulation module are visualization of simulation, interactive plotting, export of results into a text file, mathematical expressions for describing simulation parameters, and up to 500 parallel simulations of the same parameter sets. To illustrate the method we discuss a model for insulin receptor recycling as case study. Conclusions: We present a software that combines the modeling power of Petri nets with stochastic simulation of dynamic processes in a user-friendly environment supported by an intuitive graphical interface. The program offers a valuable alternative to modeling, using ordinary differential equations, especially when simulating single-cell experiments with low molecule counts. The ability to use mathematical expressions provides an additional flexibility in describing the simulation parameters. The open-source distribution allows further extensions by third-party developers. The software is cross-platform and is licensed under the Artistic License 2.0. © 2015 Balazki et al.","Gillespie's algorithm; Insulin receptor recycling; MonaLisa; Petri net; Stochastic simulation algorithm","Article","Scopus"
"Bozoky B.; Szekely L.; Ernberg I.; Savchenko A.","Bozoky, Benedek (55588685600); Szekely, Laszlo (7006491146); Ernberg, Ingemar (7006103048); Savchenko, Andrii (55851947968)","55588685600; 7006491146; 7006103048; 55851947968","AtlasGrabber: a software facilitating the high throughput analysis of the human protein atlas online database","2022","BMC Bioinformatics","10.1186/s12859-022-05097-9","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144170861&doi=10.1186%2fs12859-022-05097-9&partnerID=40&md5=fd7c5a07ca32a4f4ffaaac8063676ef4","Background: The human protein atlas (HPA) is an online database containing large sets of protein expression data in normal and cancerous tissues in image form from immunohistochemically (IHC) stained tissue microarrays. In these, the tissue architecture is preserved and thus provides information on the spatial distribution and localization of protein expression at the cellular and extracellular levels. The database is freely available online through the HPA website but currently without support for large-scale screening and analysis of the images in the database. Features like spatial information are typically lacking in gene expression datasets from homogenized tissues or single-cell analysis. To enable high throughput analysis of the HPA database, we developed the AtlasGrabber software. It is available freely under an open-source license. Based on a predefined gene list, the software fetches the images from the database and displays them for the user. Several filters for specific antibodies or images enable the user to customize her/his image analysis. Up to four images can be displayed simultaneously, which allows for the comparison of protein expression between different tissues and between normal and cancerous tissues. An additional feature is the XML parser that allows the extraction of a list of available antibodies, images, and genes for specific tissues or cancer types from the HPA’s database file. Results: Compared to existing software designed for a similar purpose, ours provide more functionality and is easier to use. To demonstrate the software’s usability, we identified six new markers of basal cells of the prostate. A comparison to prostate cancer showed that five of them are absent in prostate cancer. Conclusions: The HPA is a uniquely valuable database. By facilitating its usefulness with the AtlasGrabber, we enable researchers to exploit its full capacity. The loss of basal cell markers is diagnostic for prostate cancer and can help refine the histopathological diagnosis of prostate cancer. As proof of concept, with the AtlasGrabber we identified five new potential biomarkers specific for prostate basal cells which are lost in prostate cancer and thus can be used for prostate cancer diagnostics. © 2022, The Author(s).","AtlasGrabber; Basal cells; Biomarkers; Human protein atlas; Immunohistochemistry; Prostate cancer; Protein expression; Tissue microarray","Article","Scopus"
"Etherington G.J.; Maclean D.","Etherington, Graham J. (6603811384); Maclean, Daniel (23967105900)","6603811384; 23967105900","SVGenes: A library for rendering genomic features in scalable vector graphic format","2013","Bioinformatics","10.1093/bioinformatics/btt294","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880526453&doi=10.1093%2fbioinformatics%2fbtt294&partnerID=40&md5=bdfc15c5c5318d9f1753573387d76969","Motivation: Drawing genomic features in attractive and informative ways is a key task in visualization of genomics data. Scalable Vector Graphics (SVG) format is a modern and flexible open standard that provides advanced features including modular graphic design, advanced web interactivity and animation within a suitable client. SVGs do not suffer from loss of image quality on re-scaling and provide the ability to edit individual elements of a graphic on the whole object level independent of the whole image. These features make SVG a potentially useful format for the preparation of publication quality figures including genomic objects such as genes or sequencing coverage and for web applications that require rich user-interaction with the graphical elements.Results: SVGenes is a Ruby-language library that uses SVG primitives to render typical genomic glyphs through a simple and flexible Ruby interface. The library implements a simple Page object that spaces and contains horizontal Track objects that in turn style, colour and positions features within them. Tracks are the level at which visual information is supplied providing the full styling capability of the SVG standard. Genomic entities like genes, transcripts and histograms are modelled in Glyph objects that are attached to a track and take advantage of SVG primitives to render the genomic features in a track as any of a selection of defined glyphs. The feature model within SVGenes is simple but flexible and not dependent on particular existing gene feature formats meaning graphics for any existing datasets can easily be created without need for conversion.Availability: The library is provided as a Ruby Gem from https://rubygems.org/gems/bio-svgenes under the MIT license, and open source code is available at https://github.com/danmaclean/bioruby-svgenes also under the MIT License.Contact: © 2013 The Author 2013. Published by Oxford University Press.","","Article","Scopus"
"Tierny J.; Favelier G.; Levine J.A.; Gueunet C.; Michaux M.","Tierny, Julien (22954657500); Favelier, Guillaume (57195543711); Levine, Joshua A. (14919490600); Gueunet, Charles (57193870268); Michaux, Michael (57195552649)","22954657500; 57195543711; 14919490600; 57193870268; 57195552649","The Topology ToolKit","2018","IEEE Transactions on Visualization and Computer Graphics","10.1109/TVCG.2017.2743938","85","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028706951&doi=10.1109%2fTVCG.2017.2743938&partnerID=40&md5=8451bc270817b82bf2feebdc240350e2","This system paper presents the Topology ToolKit (TTK), a software platform designed for the topological analysis of scalar data in scientific visualization. While topological data analysis has gained in popularity over the last two decades, it has not yet been widely adopted as a standard data analysis tool for end users or developers. TTK aims at addressing this problem by providing a unified, generic, efficient, and robust implementation of key algorithms for the topological analysis of scalar data, including: critical points, integral lines, persistence diagrams, persistence curves, merge trees, contour trees, Morse-Smale complexes, fiber surfaces, continuous scatterplots, Jacobi sets, Reeb spaces, and more. TTK is easily accessible to end users due to a tight integration with ParaView. It is also easily accessible to developers through a variety of bindings (Python, VTK/C++) for fast prototyping or through direct, dependency-free, C++, to ease integration into pre-existing complex systems. While developing TTK, we faced several algorithmic and software engineering challenges, which we document in this paper. In particular, we present an algorithm for the construction of a discrete gradient that complies to the critical points extracted in the piecewise-linear setting. This algorithm guarantees a combinatorial consistency across the topological abstractions supported by TTK, and importantly, a unified implementation of topological data simplification for multi-scale exploration and analysis. We also present a cached triangulation data structure, that supports time efficient and generic traversals, which self-adjusts its memory usage on demand for input simplicial meshes and which implicitly emulates a triangulation for regular grids with no memory overhead. Finally, we describe an original software architecture, which guarantees memory efficient and direct accesses to TTK features, while still allowing for researchers powerful and easy bindings and extensions. TTK is open source (BSD license) and its code. online documentation and video tutorials are available on TTK's website [108]. © 1995-2012 IEEE.","bivariate data; data segmentation; feature extraction; scalar data; Topological data analysis; uncertain data","Article","Scopus"
"Chandra S.S.; Dowling J.A.; Engstrom C.; Xia Y.; Paproki A.; Neubert A.; Rivest-Hénault D.; Salvado O.; Crozier S.; Fripp J.","Chandra, Shekhar S. (15130876000); Dowling, Jason A. (57210097371); Engstrom, Craig (7005073295); Xia, Ying (54794656300); Paproki, Anthony (54986424700); Neubert, Aleš (7003774966); Rivest-Hénault, David (35199029200); Salvado, Olivier (6508030900); Crozier, Stuart (7005802852); Fripp, Jurgen (13605436500)","15130876000; 57210097371; 7005073295; 54794656300; 54986424700; 7003774966; 35199029200; 6508030900; 7005802852; 13605436500","A lightweight rapid application development framework for biomedical image analysis","2018","Computer Methods and Programs in Biomedicine","10.1016/j.cmpb.2018.07.011","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050975653&doi=10.1016%2fj.cmpb.2018.07.011&partnerID=40&md5=5d99a146843dce1d6b17e4411ca9d932","Biomedical imaging analysis typically comprises a variety of complex tasks requiring sophisticated algorithms and visualising high dimensional data. The successful integration and deployment of the enabling software to clinical (research) partners, for rigorous evaluation and testing, is a crucial step to facilitate adoption of research innovations within medical settings. In this paper, we introduce the Simple Medical Imaging Library Interface (SMILI), an object oriented open-source framework with a compact suite of objects geared for rapid biomedical imaging (cross-platform) application development and deployment. SMILI supports the development of both command-line (shell and Python scripting) and graphical applications utilising the same set of processing algorithms. It provides a substantial subset of features when compared to more complex packages, yet it is small enough to ship with clinical applications with limited overhead and has a license suitable for commercial use. After describing where SMILI fits within the existing biomedical imaging software ecosystem, by comparing it to other state-of-the-art offerings, we demonstrate its capabilities in creating a clinical application for manual measurement of cam-type lesions of the femoral head-neck region for the investigation of femoro-acetabular impingement (FAI) from three dimensional (3D) magnetic resonance (MR) images of the hip. This application for the investigation of FAI proved to be convenient for radiological analyses and resulted in high intra (ICC=0.97) and inter-observer (ICC=0.95) reliabilities for measurement of α-angles of the femoral head-neck region. We believe that SMILI is particularly well suited for prototyping biomedical imaging applications requiring user interaction and/or visualisation of 3D mesh, scalar, vector or tensor data. © 2018 Elsevier B.V.","Biomedical Software; Cam Lesions; FAI; Image Analysis; ITK; Scientific Visualization; SMILI; VTK","Article","Scopus"
"Rahmatallah Y.; Zybailov B.; Emmert-Streib F.; Glazko G.","Rahmatallah, Yasir (36162179100); Zybailov, Boris (6602166966); Emmert-Streib, Frank (15057742200); Glazko, Galina (55409419100)","36162179100; 6602166966; 15057742200; 55409419100","GSAR: Bioconductor package for Gene Set analysis in R","2017","BMC Bioinformatics","10.1186/s12859-017-1482-6","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010460642&doi=10.1186%2fs12859-017-1482-6&partnerID=40&md5=6a7e9f321bcd40e9d6b8a733e147cce1","Background: Gene set analysis (in a form of functionally related genes or pathways) has become the method of choice for analyzing omics data in general and gene expression data in particular. There are many statistical methods that either summarize gene-level statistics for a gene set or apply a multivariate statistic that accounts for intergene correlations. Most available methods detect complex departures from the null hypothesis but lack the ability to identify the specific alternative hypothesis that rejects the null. Results: GSAR (Gene Set Analysis in R) is an open-source R/Bioconductor software package for gene set analysis (GSA). It implements self-contained multivariate non-parametric statistical methods testing a complex null hypothesis against specific alternatives, such as differences in mean (shift), variance (scale), or net correlation structure. The package also provides a graphical visualization tool, based on the union of two minimum spanning trees, for correlation networks to examine the change in the correlation structures of a gene set between two conditions and highlight influential genes (hubs). Conclusions: Package GSAR provides a set of multivariate non-parametric statistical methods that test a complex null hypothesis against specific alternatives. The methods in package GSAR are applicable to any type of omics data that can be represented in a matrix format. The package, with detailed instructions and examples, is freely available under the GPL (> = 2) license from the Bioconductor web site. © 2017 The Author(s).","Gene set analysis; Kolmogorov-Smirnov; Minimum spanning tree; Non-parametric; Pathways; Wald Wolfowitz","Article","Scopus"
"Dumousseau M.; Rodriguez N.; Juty N.; Novère N.L.","Dumousseau, Marine (42061185000); Rodriguez, Nicolas (36794180200); Juty, Nick (35102303000); Novère, Nicolas L. (57193405552)","42061185000; 36794180200; 35102303000; 57193405552","MELTING, a flexible platform to predict the melting temperatures of nucleic acids","2012","BMC Bioinformatics","10.1186/1471-2105-13-101","29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861003597&doi=10.1186%2f1471-2105-13-101&partnerID=40&md5=2c68adeeca51e6cf01ba15df1c123e39","Background: Computing accurate nucleic acid melting temperatures has become a crucial step for the efficiency and the optimisation of numerous molecular biology techniques such as in situ hybridization, PCR, antigene targeting, and microarrays. MELTING is a free open source software which computes the enthalpy, entropy and melting temperature of nucleic acids. MELTING 4.2 was able to handle several types of hybridization such as DNA/DNA, RNA/RNA, DNA/RNA and provided corrections to melting temperatures due to the presence of sodium. The program can use either an approximative approach or a more accurate Nearest-Neighbor approach.Results: Two new versions of the MELTING software have been released. MELTING 4.3 is a direct update of version 4.2, integrating newly available thermodynamic parameters for inosine, a modified adenine base with an universal base capacity, and incorporates a correction for magnesium. MELTING 5 is a complete reimplementation which allows much greater flexibility and extensibility. It incorporates all the thermodynamic parameters and corrections provided in MELTING 4.x and introduces a large set of thermodynamic formulae and parameters, to facilitate the calculation of melting temperatures for perfectly matching sequences, mismatches, bulge loops, CNG repeats, dangling ends, inosines, locked nucleic acids, 2-hydroxyadenines and azobenzenes. It also includes temperature corrections for monovalent ions (sodium, potassium, Tris), magnesium ions and commonly used denaturing agents such as formamide and DMSO.Conclusions: MELTING is a useful and very flexible tool for predicting melting temperatures using approximative formulae or Nearest-Neighbor approaches, where one can select different sets of Nearest-Neighbor parameters, corrections and formulae. Both versions are freely available at http://sourceforge.net/projects/melting/and at http://www.ebi.ac.uk/compneur-srv/melting/under the terms of the GPL license. © 2012 Le Novère et al.; licensee BioMed Central Ltd.","","Article","Scopus"
"Vendelin M.; Laasmaa M.; Kalda M.; Branovets J.; Karro N.; Barsunova K.; Birkedal R.","Vendelin, Marko (6603536378); Laasmaa, Martin (54393330300); Kalda, Mari (37099881300); Branovets, Jelena (38361188500); Karro, Niina (57221384302); Barsunova, Karina (57216809328); Birkedal, Rikke (6506984956)","6603536378; 54393330300; 37099881300; 38361188500; 57221384302; 57216809328; 6506984956","IOCBIO Kinetics: An open-source software solution for analysis of data traces","2020","PLoS Computational Biology","10.1371/journal.pcbi.1008475","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098979711&doi=10.1371%2fjournal.pcbi.1008475&partnerID=40&md5=5e5f3120613c1139ffc20c34138f3509","Biological measurements frequently involve measuring parameters as a function of time, space, or frequency. Later, during the analysis phase of the study, the researcher splits the recorded data trace into smaller sections, analyzes each section separately by finding a mean or fitting against a specified function, and uses the analysis results in the study. Here, we present the software that allows to analyze these data traces in a manner that ensures repeatability of the analysis and simplifies the application of FAIR (findability, accessibility, interoperability, and reusability) principles in such studies. At the same time, it simplifies the routine data analysis pipeline and gives access to a fast overview of the analysis results. For that, the software supports reading the raw data, processing the data as specified in the protocol, and storing all intermediate results in the laboratory database. The software can be extended by study- or hardware-specific modules to provide the required data import and analysis facilities. To simplify the development of the data entry web interfaces, that can be used to enter data describing the experiments, we released a web framework with an example implementation of such a site. The software is covered by open-source license and is available through several online channels. © 2020 Vendelin et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Article","Scopus"
"Masuzzo P.; Hulstaert N.; Huyck L.; Ampe C.; Van Troys M.; Martens L.","Masuzzo, Paola (55885056000); Hulstaert, Niels (55123165700); Huyck, Lynn (24278417600); Ampe, Christophe (7003949377); Van Troys, Marleen (6602938212); Martens, Lennart (15923262500)","55885056000; 55123165700; 24278417600; 7003949377; 6602938212; 15923262500","CellMissy: A tool for management, storage and analysis of cell migration data produced in wound healing-like assays","2013","Bioinformatics","10.1093/bioinformatics/btt437","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885576496&doi=10.1093%2fbioinformatics%2fbtt437&partnerID=40&md5=1d4c25a5317c11afb80dbf5662dc65b9","Summary: Automated image processing has allowed cell migration research to evolve to a high-throughput research field. As a consequence, there is now an unmet need for data management in this domain. The absence of a generic management system for the quantitative data generated in cell migration assays results in each dataset being treated in isolation, making data comparison across experiments difficult. Moreover, by integrating quality control and analysis capabilities into such a data management system, the common practice of having to manually transfer data across different downstream analysis tools will be markedly sped up and made more robust. In addition, access to a data management solution creates gateways for data standardization, meta-analysis and structured public data dissemination. We here present CellMissy, a cross-platform data management system for cell migration data with a focus on wound healing data. CellMissy simplifies and automates data management, storage and analysis from the initial experimental set-up to data exploration. Availability and implementation: CellMissy is a cross-platform opensource software developed in Java. Source code and cross-platform binaries are freely available under the Apache2 open source license at http://cellmissy.googlecode. com. Contact: lennart.martens@ugent.be Supplementary Information: Supplementary data are available at Bioinformatics online. © The Author 2013. Published by Oxford University Press.","","Article","Scopus"
"Pinter C.; Lasso A.; Fichtinger G.","Pinter, Csaba (54385777900); Lasso, Andras (25030035000); Fichtinger, Gabor (6602161432)","54385777900; 25030035000; 6602161432","Polymorph segmentation representation for medical image computing","2019","Computer Methods and Programs in Biomedicine","10.1016/j.cmpb.2019.02.011","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061893372&doi=10.1016%2fj.cmpb.2019.02.011&partnerID=40&md5=4becaf5ef39cbce0fd1e0f66b879ac1b","Background and objective: Segmentation is a ubiquitous operation in medical image computing. Various data representations can describe segmentation results, such as labelmap volumes or surface models. Conversions between them are often required, which typically include complex data processing steps. We identified four challenges related to managing multiple representations: conversion method selection, data provenance, data consistency, and coherence of in-memory objects. Methods: A complex data container preserves identity and provenance of the contained representations and ensures data coherence. Conversions are executed automatically on-demand. A graph containing the implemented conversion algorithms determines each execution, ensuring consistency between various representations. The design and implementation of a software library are proposed, in order to provide a readily usable software tool to manage segmentation data in multiple data representations. A low-level core library called PolySeg implemented in the Visualization Toolkit (VTK) manages the data objects and conversions. It is used by a high-level application layer, which has been implemented in the medical image visualization and analysis platform 3D Slicer. The application layer provides advanced visualization, transformation, interoperability, and other functions. Results: The core conversion algorithms comprising the graph were validated. Several applications were implemented based on the library, demonstrating advantages in terms of usability and ease of software development in each case. The Segment Editor application provides fast, comprehensive, and easy-to-use manual and semi-automatic segmentation workflows. Clinical applications for gel dosimetry, external beam planning, and MRI-ultrasound image fusion in brachytherapy were rapidly prototyped resulting robust applications that are already in use in clinical research. The conversion algorithms were found to be accurate and reliable using these applications. Conclusions: A generic software library has been designed and developed for automatic management of multiple data formats in segmentation tasks. It enhances both user and developer experience, enabling fast and convenient manual workflows and quicker and more robust software prototyping. The software's BSD-style open-source license allows complete freedom of use of the library. © 2019 Elsevier B.V.","3D Slicer; DICOM; Open-source; Segmentation; Software library; Voxelization","Article","Scopus"
"Bach P.; Chernozhukov V.; Kurz M.S.; Spindler M.","Bach, Philipp (57201489781); Chernozhukov, Victor (6507847070); Kurz, Malte S. (57222072882); Spindler, Martin (55872916600)","57201489781; 6507847070; 57222072882; 55872916600","DoubleML - An Object-Oriented Implementation of Double Machine Learning in Python","2022","Journal of Machine Learning Research","","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124189919&partnerID=40&md5=96253133754248d504851d849c470c5b","DoubleML is an open-source Python library implementing the double machine learning framework of Chernozhukov et al. (2018) for a variety of causal models. It contains functionalities for valid statistical inference on causal parameters when the estimation of nuisance parameters is based on machine learning methods. The object-oriented implementation of DoubleML provides a high flexibility in terms of model specifications and makes it easily extendable. The package is distributed under the MIT license and relies on core libraries from the scientific Python ecosystem: scikit-learn, numpy, pandas, scipy, statsmodels and joblib. Source code, documentation and an extensive user guide can be found at https://github.com/DoubleML/doubleml-for-py and https://docs.doubleml.org. © 2022 Philipp Bach, Victor Chernozhukov, Malte S. Kurz and Martin Spindler.","Causal inference; Causal machine learning; Machine learning; Python","Article","Scopus"
"Rosen J.; Miguet L.; Pérez S.","Rosen, Jimmy (8317402300); Miguet, Laurence (55572302600); Pérez, Serge (57214464876)","8317402300; 55572302600; 57214464876","Shape: Automatic conformation prediction of carbohydrates using a genetic algorithm","2009","Journal of Cheminformatics","10.1186/1758-2946-1-16","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-74049121217&doi=10.1186%2f1758-2946-1-16&partnerID=40&md5=370b64166cfb38372af59b8f2758763c","Background. Detailed experimental three dimensional structures of carbohydrates are often difficult to acquire. Molecular modelling and computational conformation prediction are therefore commonly used tools for three dimensional structure studies. Modelling procedures generally require significant training and computing resources, which is often impractical for most experimental chemists and biologists. Shape has been developed to improve the availability of modelling in this field. Results. The Shape software package has been developed for simplicity of use and conformation prediction performance. A trivial user interface coupled to an efficient genetic algorithm conformation search makes it a powerful tool for automated modelling. Carbohydrates up to a few hundred atoms in size can be investigated on common computer hardware. It has been shown to perform well for the prediction of over four hundred bioactive oligosaccharides, as well as compare favourably with previously published studies on carbohydrate conformation prediction. Conclusion. The Shape fully automated conformation prediction can be used by scientists who lack significant modelling training, and performs well on computing hardware such as laptops and desktops. It can also be deployed on computer clusters for increased capacity. The prediction accuracy under the default settings is good, as it agrees well with experimental data and previously published conformation prediction studies. This software is available both as open source and under commercial licenses. © 2009 Rosen et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Page A.J.; Bastkowski S.; Yasir M.; Turner A.K.; Le Viet T.; Savva G.M.; Webber M.A.; Charles I.G.","Page, Andrew J. (9736752200); Bastkowski, Sarah (55750306500); Yasir, Muhammad (57205126940); Turner, A. Keith (7401820216); Le Viet, Thanh (57218346921); Savva, George M. (24399717300); Webber, Mark A. (7103355891); Charles, Ian G. (7005203643)","9736752200; 55750306500; 57205126940; 7401820216; 57218346921; 24399717300; 7103355891; 7005203643","AlbaTraDIS: Comparative analysis of large datasets from parallel transposon mutagenesis experiments","2020","PLoS Computational Biology","10.1371/journal.pcbi.1007980","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088879276&doi=10.1371%2fjournal.pcbi.1007980&partnerID=40&md5=b0c0a663329e90094865f8138ed9ed5e","Bacteria need to survive in a wide range of environments. Currently, there is an incomplete understanding of the genetic basis for mechanisms underpinning survival in stressful conditions, such as the presence of anti-microbials. Transposon directed insertion-site sequencing (TraDIS) is a powerful tool to identify genes and networks which are involved in survival and fitness under a given condition by simultaneously assaying the fitness of millions of mutants, thereby relating genotype to phenotype and contributing to an understanding of bacterial cell biology. A recent refinement of this approach allows the roles of essential genes in conditional stress survival to be inferred by altering their expression. These advancements combined with the rapidly falling costs of sequencing now allows comparisons between multiple experiments to identify commonalities in stress responses to different conditions. This capacity however poses a new challenge for analysis of multiple data sets in conjunction. To address this analysis need, we have developed 'AlbaTraDIS'; a software application for rapid large-scale comparative analysis of TraDIS experiments that predicts the impact of transposon insertions on nearby genes. AlbaTraDIS can identify genes which are up or down regulated, or inactivated, between multiple conditions, producing a filtered list of genes for further experimental validation as well as several accompanying data visualisations. We demonstrate the utility of our new approach by applying it to identify genes used by Escherichia coli to survive in a wide range of different concentrations of the biocide Triclosan. AlbaTraDIS identified all well characterised Triclosan resistance genes, including the primary target, fabI. A number of new loci were also implicated in Triclosan resistance and the predicted phenotypes for a selection of these were validated experimentally with results being consistent with predictions. AlbaTraDIS provides a simple and rapid method to analyse multiple transposon mutagenesis data sets allowing this technology to be used at large scale. To our knowledge this is the only tool currently available that can perform these tasks. AlbaTraDIS is written in Python 3 and is available under the open source licence GNU GPL 3 from https://github.com/quadram-institute-bioscience/albatradis. Copyright:  © 2020 Page et al.","","Article","Scopus"
"Pölsterl S.","Pölsterl, Sebastian (36103414600)","36103414600","Scikit-survival: A library for time-to-event analysis built on top of scikit-learn","2020","Journal of Machine Learning Research","","70","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094930446&partnerID=40&md5=3e864bafca91e59539a6992297df9132","scikit-survival is an open-source Python package for time-to-event analysis fully compatible with scikit-learn. It provides implementations of many popular machine learning techniques for time-to-event analysis, including penalized Cox model, Random Survival Forest, and Survival Support Vector Machine. In addition, the library includes tools to evaluate model performance on censored time-to-event data. The documentation contains installation instructions, interactive notebooks, and a full description of the API. scikit-survival is distributed under the GPL-3 license with the source code and detailed instructions available at https://github.com/sebp/scikit-survival. © 2020 Microtome Publishing. All rights reserved.","Censored Data; Python; Survival Analysis; Time-to-event Analysis","Article","Scopus"
"Vidal A.; Gauthier F.; Rodrigez W.; Guiglielmoni N.; Leroux D.; Chevrolier N.; Jasson S.; Tourrette E.; Martin O.C.; Falque M.","Vidal, Adrien (57217607796); Gauthier, Franck (35976025000); Rodrigez, Willy (57971820500); Guiglielmoni, Nadège (57201431418); Leroux, Damien (37023181700); Chevrolier, Nicolas (57972435800); Jasson, Sylvain (7801631803); Tourrette, Elise (57212177514); Martin, Olivier C. (7102395637); Falque, Matthieu (55857265600)","57217607796; 35976025000; 57971820500; 57201431418; 37023181700; 57972435800; 7801631803; 57212177514; 7102395637; 55857265600","SeSAM: software for automatic construction of order-robust linkage maps","2022","BMC Bioinformatics","10.1186/s12859-022-05045-7","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142225280&doi=10.1186%2fs12859-022-05045-7&partnerID=40&md5=297bbb173d83f434ffd7454fd744e529","Background: Genotyping and sequencing technologies produce increasingly large numbers of genetic markers with potentially high rates of missing or erroneous data. Therefore, the construction of linkage maps is more and more complex. Moreover, the size of segregating populations remains constrained by cost issues and is less and less commensurate with the numbers of SNPs available. Thus, guaranteeing a statistically robust marker order requires that maps include only a carefully selected subset of SNPs. Results: In this context, the SeSAM software allows automatic genetic map construction using seriation and placement approaches, to produce (1) a high-robustness framework map which includes as many markers as possible while keeping the order robustness beyond a given statistical threshold, and (2) a high-density total map including the framework plus almost all polymorphic markers. During this process, care is taken to limit the impact of genotyping errors and of missing data on mapping quality. SeSAM can be used with a wide range of biparental populations including from outcrossing species for which phases are inferred on-the-fly by maximum-likelihood during map elongation. The package also includes functions to simulate data sets, convert data formats, detect putative genotyping errors, visualize data and map quality (including graphical genotypes), and merge several maps into a consensus. SeSAM is also suitable for interactive map construction, by providing lower-level functions for 2-point and multipoint EM analyses. The software is implemented in a R package including functions in C++. Conclusions: SeSAM is a fully automatic linkage mapping software designed to (1) produce a framework map as robust as desired by optimizing the selection of a subset of markers, and (2) produce a high-density map including almost all polymorphic markers. The software can be used with a wide range of biparental mapping populations including cases from outcrossing. SeSAM is freely available under a GNU GPL v3 license and works on Linux, Windows, and macOS platforms. It can be downloaded together with its user-manual and quick-start tutorial from ForgeMIA (SeSAM project) at https://forgemia.inra.fr/gqe-acep/sesam/-/releases. © 2022, The Author(s).","Automated software; Genetic mapping; Linkage; Marker order robustness; Seriation","Article","Scopus"
"Padó S.; Noh T.-G.; Stern A.; Wang R.; Zanoli R.","Padó, Sebastian (10242453100); Noh, Tae-Gil (35912424000); Stern, Asher (55369493700); Wang, Rui (55880151000); Zanoli, Roberto (8379032800)","10242453100; 35912424000; 55369493700; 55880151000; 8379032800","Design and realization of a modular architecture for textual entailment","2015","Natural Language Engineering","10.1017/S1351324913000351","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925636275&doi=10.1017%2fS1351324913000351&partnerID=40&md5=3222bae9c46a9e43ee47dfbcd459be61","A key challenge at the core of many Natural Language Processing (NLP) tasks is the ability to determine which conclusions can be inferred from a given natural language text. This problem, called the Recognition of Textual Entailment (RTE), has initiated the development of a range of algorithms, methods, and technologies. Unfortunately, research on Textual Entailment (TE), like semantics research more generally, is fragmented into studies focussing on various aspects of semantics such as world knowledge, lexical and syntactic relations, or more specialized kinds of inference. This fragmentation has problematic practical consequences. Notably, interoperability among the existing RTE systems is poor, and reuse of resources and algorithms is mostly infeasible. This also makes systematic evaluations very difficult to carry out. Finally, textual entailment presents a wide array of approaches to potential end users with little guidance on which to pick. Our contribution to this situation is the novel EXCITEMENT architecture, which was developed to enable and encourage the consolidation of methods and resources in the textual entailment area. It decomposes RTE into components with strongly typed interfaces. We specify (a) a modular linguistic analysis pipeline and (b) a decomposition of the 'core' RTE methods into top-level algorithms and subcomponents. We identify four major subcomponent types, including knowledge bases and alignment methods. The architecture was developed with a focus on generality, supporting all major approaches to RTE and encouraging language independence. We illustrate the feasibility of the architecture by constructing mappings of major existing systems onto the architecture. The practical implementation of this architecture forms the EXCITEMENT open platform. It is a suite of textual entailment algorithms and components which contains the three systems named above, including linguistic-analysis pipelines for three languages (English, German, and Italian), and comprises a number of linguistic resources. By addressing the problems outlined above, the platform provides a comprehensive and flexible basis for research and experimentation in textual entailment and is available as open source software under the GNU General Public License. Copyright © Cambridge University Press 2013.","","Article","Scopus"
"Henning J.; Smith R.","Henning, Jessica (57204687661); Smith, Rob (57202910211)","57204687661; 57202910211","A web-based system for creating, viewing, and editing precursor mass spectrometry ground truth data","2020","BMC bioinformatics","10.1186/s12859-020-03752-7","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091617697&doi=10.1186%2fs12859-020-03752-7&partnerID=40&md5=f5be431369cbe7ce98d9b1d327dc052e","BACKGROUND: Mass spectrometry (MS) uses mass-to-charge ratios of measured particles to decode the identities and quantities of molecules in a sample. Interpretation of raw MS depends upon data processing algorithms that render it human-interpretable. Quantitative MS workflows are complex experimental chains and it is crucial to know the performance and bias of each data processing method as they impact accuracy, coverage, and statistical significance of the result. Creation of the ground truth necessary for quantitatively evaluating MS1-aware algorithms is difficult and tedious task, and better software for creating such datasets would facilitate more extensive evaluation and improvement of MS data processing algorithms. RESULTS: We present JS-MS 2.0, a software suite that provides a dependency-free, browser-based, one click, cross-platform solution for creating MS1 ground truth. The software retains the first version's capacity for loading, viewing, and navigating MS1 data in 2- and 3-D, and adds tools for capturing, editing, saving, and viewing isotopic envelope and extracted isotopic chromatogram features. The software can also be used to view and explore the results of feature finding algorithms. CONCLUSIONS: JS-MS 2.0 enables faster creation and inspection of MS1 ground truth data. It is publicly available with an MIT license at github.com/optimusmoose/jsms.","Mass spectrometry; Mass spectrometry viewer; MS1 feature finding; Open source mass spectrometry software","Article","Scopus"
"Procacci P.","Procacci, Piero (7006445627)","7006445627","PrimaDORAC: A Free Web Interface for the Assignment of Partial Charges, Chemical Topology, and Bonded Parameters in Organic or Drug Molecules","2017","Journal of Chemical Information and Modeling","10.1021/acs.jcim.7b00145","31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021301847&doi=10.1021%2facs.jcim.7b00145&partnerID=40&md5=2b43315c3311bfb503f3ca5ca1421e1b","We present PrimaDORAC, a simple and freely accessible web interface for generating the topology and the parameter files of organic or drug molecules to be used in molecular mechanics or molecular dynamics calculations. The interface relies on our in-house FORTRAN90 parser, working on the recently released Generalized Amber Force Field parameter set (GAFF2). AM1/BCC charges are computed using the Public Domain MOPAC7 program and the bond charge corrections (BCC) reported in Jakalian, A.; Jack, D. B.; Bayly, C. I.; J. Comp. Chem., 2002, 23, 1623-1641. The interface has been tested on about 52,000 compounds (identified with a CAS registry number) taken from the National Cancer Institute (NCI) Open Database. PrimaDORAC has been found to be very reliable, producing GAFF2 minimized structures bearing a mean root square displacement of about 0.01-0.02 nm with respect to the original CORINA-generated 3D NCI structures. As a demonstrative example, we release the full topology and parameter files, along with the AM1/BCC-GAFF2 computed in vacuo IR spectrum, for some recently discovered PARP/MCL1 inhibitors. The web interface and parser, including the sources, are part of the ORAC code (Procacci, P.; J. Chem. Inf. Model., 2016, 56, 1117-1121), distributed under the General Public License at www.chim.unifi.it/orac. © 2017 American Chemical Society.","","Article","Scopus"
"Sam Paul D.; Gautham N.","Sam Paul, D. (57203994993); Gautham, N. (56309975200)","57203994993; 56309975200","Protein–small molecule docking with receptor flexibility in iMOLSDOCK","2018","Journal of Computer-Aided Molecular Design","10.1007/s10822-018-0152-8","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053913078&doi=10.1007%2fs10822-018-0152-8&partnerID=40&md5=21e0332776fcce20238973e1f84b959d","We have earlier reported the iMOLSDOCK technique to perform ‘induced-fit’ peptide–protein docking. iMOLSDOCK uses the mutually orthogonal Latin squares (MOLSs) technique to sample the conformation and the docking pose of the small molecule ligand and also the flexible residues of the receptor protein, and arrive at the optimum pose and conformation. In this paper we report the extension carried out in iMOLSDOCK to dock nonpeptide small molecule ligands to receptor proteins. We have benchmarked and validated iMOLSDOCK with a dataset of 34 protein–ligand complexes as well as with Astex Diverse dataset, with nonpeptide small molecules as ligands. We have also compared iMOLSDOCK with other flexible receptor docking tools GOLD v5.2.1 and AutoDock Vina. The results obtained show that the method works better than these two algorithms, though it consumes more computer time. The source code and binary of MOLS 2.0 (under a GNU Lesser General Public License) are freely available for download at https://sourceforge.net/projects/mols2-0/files/. © 2018, Springer Nature Switzerland AG.","iMOLSDOCK; Induced-fit docking; Molecular docking; Mutually orthogonal Latin squares; Protein–ligand docking; Side-chain flexibility","Article","Scopus"
"Fernández-Álvarez P.; Rodríguez R.J.","Fernández-Álvarez, Pedro (57547808400); Rodríguez, Ricardo J. (56794828000)","57547808400; 56794828000","Extraction and analysis of retrievable memory artifacts from Windows Telegram Desktop application","2022","Forensic Science International: Digital Investigation","10.1016/j.fsidi.2022.301342","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127009310&doi=10.1016%2fj.fsidi.2022.301342&partnerID=40&md5=dc533264a848577d3d3146fa3d0bc1be","Instant messaging applications have become a very common way of communicating, and today there are many applications of this type. The forensic analysis of these applications can help provide essential clues to solve or clarify a possible crime. This type of applications generally store their data in a secure way or transmit it through encrypted channels and thus, the forensic analysis of memory takes on special relevance to analyze them. Following a three-phase forensic analysis methodology, this work has developed a forensic analysis environment for instant messaging applications composed of two tools. One of the tools is responsible for extracting the content of a process that runs on a Windows system, while the other focuses on studying the information present in the process memory of an instant messaging application. This second tool can be easily adapted and extended to provide analysis support for any instant messaging application. As a case study, we focus on the Telegram application for Windows systems called Telegram Desktop. Adapting these tools to this application, their joint use allows obtaining forensic artifacts of interest for an investigation, such as user contacts or the content of conversations that have taken place, among others, even when the application is blocked. Obtaining these data is of great help for a forensic analyst, since the analysis of these data can be vital to clarify the events that occurred in some type of criminal act. Both tools are open source under the GNU/GPLv3 license to promote their use and extensibility to applications of other instant messaging services. © 2022 The Authors","Digital forensics; Instant messaging; Memory forensics; Telegram Desktop; Windows","Article","Scopus"
"Rousseau F.; Oubel E.; Pontabry J.; Schweitzer M.; Studholme C.; Koob M.; Dietemann J.-L.","Rousseau, François (57188780886); Oubel, Estanislao (14016367100); Pontabry, Julien (53866932300); Schweitzer, Marc (55365353100); Studholme, Colin (7003668135); Koob, Mériam (16175473500); Dietemann, Jean-Louis (7101741272)","57188780886; 14016367100; 53866932300; 55365353100; 7003668135; 16175473500; 7101741272","BTK: An open-source toolkit for fetal brain MR image processing","2013","Computer Methods and Programs in Biomedicine","10.1016/j.cmpb.2012.08.007","43","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869873559&doi=10.1016%2fj.cmpb.2012.08.007&partnerID=40&md5=7623534128c501c4d759ddaf2ed92046","Studies about brain maturation aim at providing a better understanding of brain development and links between brain changes and cognitive development. Such studies are of great interest for diagnosis help and clinical course of development and treatment of illnesses. However, the processing of fetal brain MR images remains complicated which limits the translation from the research to the clinical domain. In this article, we describe an open-source image processing toolkit dedicated to these images. In this toolkit various tools are included such as: denoising, image reconstruction, super-resolution and tractography. The BTK resource program (distributed under CeCILL-B license) is developed in C++ and relies on common medical imaging libraries such as Insight Toolkit (ITK), Visualization Toolkit (VTK) and Open Multi-Processing (OpenMP). © 2012 Elsevier Ireland Ltd.","Fetal MRI; Image reconstruction; Open source software; Tractography","Article","Scopus"
"Vogt F.P.A.","Vogt, F.P.A. (36605423500)","36605423500","fcmaker: Automating the creation of ESO-compliant finding charts for Observing Blocks on p2","2018","Astronomy and Computing","10.1016/j.ascom.2018.08.007","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053412228&doi=10.1016%2fj.ascom.2018.08.007&partnerID=40&md5=11daf8ce7e073b9d678e87197075d5eb","FCMAKER is a PYTHON module that creates astronomical finding charts for Observing Blocks (OBs) on the p2 web server from the European Southern Observatory (ESO). It provides users with the ability to automate the creation of ESO-compliant finding charts for Service Mode and/or Visitor Mode OBs at the Very Large Telescope (VLT). The design of the FCMAKER finding charts, based on an intimate knowledge of VLT observing procedures, is fine-tuned to best support night time operations. As an automated tool, FCMAKER also provides observers with the means to independently check visually the observing sequence coded inside an OB. This includes, for example, the signs of telescope and position angle offsets. VLT instruments currently supported by FCMAKER include MUSE (WFM-AO, WFM-NOAO, NFM), HAWK-I (AO, NOAO), and X-shooter (full support). The FCMAKER code is published on a dedicated Github repository under the GNU General Public License, and is also available via PYPI. © 2018 Elsevier B.V.","Astroinformatics; Astronomical databases; Ground based astronomy; Very large telescope","Article","Scopus"
"Singh N.; Gunjan V.K.; Nasralla M.M.","Singh, Ninni (56621859400); Gunjan, Vinit Kumar (56034480700); Nasralla, Moustafa M. (55638677600)","56621859400; 56034480700; 55638677600","A Parametrized Comparative Analysis of Performance Between Proposed Adaptive and Personalized Tutoring System 'Seis Tutor' With Existing Online Tutoring System","2022","IEEE Access","10.1109/ACCESS.2022.3166261","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128303283&doi=10.1109%2fACCESS.2022.3166261&partnerID=40&md5=abbcd1ab922327a76051e8779582a7d2","Face-to-face tutoring offers a learning environment that best suits the learner's preferences (learning styles) and grasping levels (learning levels). This cognitive intelligence has been blended in our proposed intelligent tutoring system christened as 'Seis Tutor'. In this paper, we have detailed the architecture of Seis Tutor system and compared it with other existing traditional tutoring systems. Further, the performance of Seis Tutor has been evaluated in terms of personalization and adaptation through a comparison with some existing tutoring systems, i.e., My Moodle, Course-Builder, and Teachable.  © 2013 IEEE.","course builder; intelligent tutoring system; my moodle; personalization and adaptation; SeisTutor; teachable","Article","Scopus"
"Page A.J.; Cummins C.A.; Hunt M.; Wong V.K.; Reuter S.; Holden M.T.G.; Fookes M.; Falush D.; Keane J.A.; Parkhill J.","Page, Andrew J. (9736752200); Cummins, Carla A. (57190044241); Hunt, Martin (50061142000); Wong, Vanessa K. (35622677700); Reuter, Sandra (55368616400); Holden, Matthew T.G. (7102163449); Fookes, Maria (9733319600); Falush, Daniel (6602894490); Keane, Jacqueline A. (56388340500); Parkhill, Julian (57212237926)","9736752200; 57190044241; 50061142000; 35622677700; 55368616400; 7102163449; 9733319600; 6602894490; 56388340500; 57212237926","Roary: Rapid large-scale prokaryote pan genome analysis","2015","Bioinformatics","10.1093/bioinformatics/btv421","2179","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947793096&doi=10.1093%2fbioinformatics%2fbtv421&partnerID=40&md5=575adfd6016336fb6e2604b2fc677a02","Summary: A typical prokaryote population sequencing study can now consist of hundreds or thousands of isolates. Interrogating these datasets can provide detailed insights into the genetic structure of prokaryotic genomes. We introduce Roary, a tool that rapidly builds large-scale pan genomes, identifying the core and accessory genes. Roary makes construction of the pan genome of thousands of prokaryote samples possible on a standard desktop without compromising on the accuracy of results. Using a single CPU Roary can produce a pan genome consisting of 1000 isolates in 4.5 hours using 13 GB of RAM, with further speedups possible using multiple processors. Availability and implementation: Roary is implemented in Perl and is freely available under an open source GPLv3 license from http://sanger-pathogens.github.io/Roary. © The Author 2015. Published by Oxford University Press.","","Article","Scopus"
"Mendoza-Silva G.M.; Richter P.; Torres-Sospedra J.; Lohan E.S.; Huerta J.","Mendoza-Silva, Germán Martín (57190739716); Richter, Philipp (55917091500); Torres-Sospedra, Joaquín (6506831140); Lohan, Elena Simona (6602677794); Huerta, Joaquín (56260161000)","57190739716; 55917091500; 6506831140; 6602677794; 56260161000","Long-term WiFi fingerprinting dataset for research on robust indoor positioning","2018","Data","10.3390/data3010003","81","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046343832&doi=10.3390%2fdata3010003&partnerID=40&md5=ba1a0acc96560868ec8c848f0b0219b9","WiFi fingerprinting, one of the most popular methods employed in indoor positioning, currently faces two major problems: lack of robustness to short and long time signal changes and difficult reproducibility of new methods presented in the relevant literature. This paper presents a WiFi RSS (Received Signal Strength) database created to foster and ease research works that address the above-mentioned two problems. A trained professional took several consecutive fingerprints while standing at specific positions and facing specific directions. The consecutive fingerprints may enable the study of short-term signals variations. The data collection spanned over 15 months, and, for each month, one type of training datasets and five types of test datasets were collected. The measurements of a dataset type (training or test) were taken at the same positions and directions every month, in order to enable the analysis of long-term signal variations. The database is provided with supporting materials and software, which give more information about the collection environment and eases the database utilization, respectively. The WiFi measurements and the supporting materials are available at the Zenodo repository under the open-source MIT license. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Collection campaigns; Fingerprinting; Indoor positioning; Temporal signal variation; WiFi datasets","Article","Scopus"
"Kryukov K.; Ueda M.T.; Nakagawa S.; Imanishi T.","Kryukov, Kirill (25229093500); Ueda, Mahoko Takahashi (26325135800); Nakagawa, So (12143870400); Imanishi, Tadashi (7101939542)","25229093500; 26325135800; 12143870400; 7101939542","Nucleotide Archival Format (NAF) enables efficient lossless reference-free compression of DNA sequences","2019","Bioinformatics","10.1093/bioinformatics/btz144","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072705478&doi=10.1093%2fbioinformatics%2fbtz144&partnerID=40&md5=b934251f6b2d8793429be7dc8f445042","Summary: DNA sequence databases use compression such as gzip to reduce the required storage space and network transmission time. We describe Nucleotide Archival Format (NAF) - a new file format for lossless reference-free compression of FASTA and FASTQ-formatted nucleotide sequences. Nucleotide Archival Format compression ratio is comparable to the best DNA compressors, while providing dramatically faster decompression. We compared our format with DNA compressors: DELIMINATE and MFCompress, and with general purpose compressors: gzip, bzip2, xz, brotli and zstd. Availability and implementation: NAF compressor and decompressor, as well as format specification are available at https://github.com/KirillKryukov/naf. Format specification is in public domain. Compressor and decompressor are open source under the zlib/libpng license, free for nearly any use. Supplementary information: Supplementary data are available at Bioinformatics online. © 2019 The Author(s). Published by Oxford University Press.","","Article","Scopus"
"Wist J.","Wist, Julien (6506695325)","6506695325","HastaLaVista, a web-based user interface for NMR-based untargeted metabolic profiling analysis in biomedical sciences: Towards a new publication standard","2019","Journal of Cheminformatics","10.1186/s13321-019-0399-7","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076217212&doi=10.1186%2fs13321-019-0399-7&partnerID=40&md5=ca6b0c276e787196fc9bf7b25d9e58dc","Metabolic profiling has been shown to be useful to improve our understanding of complex metabolic processes. Shared data are key to the analysis and validation of metabolic profiling and untargeted spectral analysis and may increase the pace of new discovery. Improving the existing portfolio of open software may increase the fraction of shared data by decreasing the amount of effort required to publish them in a manner that is useful to others. However, a weakness of open software, when compared to commercial ones, is the lack of user-friendly graphical interface that may discourage inexperienced researchers. Here, a web-browser-oriented solution is presented and demonstrated for metabolic profiling analysis that combines the power of R for back-end statistical analyses and of JavaScript for front-end visualisations and user interactivity. This unique combination of statistical programming and web-browser visualisation brings enhanced data interoperability and interactivity into the open source realm. It is exemplified by characterizing the extent to which bariatric surgery perturbs the metabolisms of rats, showing the value of the approach in iterative analysis by the end-user to establish a deeper understanding of the system perturbation. HastaLaVista is available at: (https://github.com/jwist/hastaLaVista, https://doi.org/10.5281/zenodo.3544800) under MIT license. The approach described in this manuscript can be extended to connect the interface to other scripting languages such as Python, and to create interfaces for other types of data analysis. © 2019 The Author(s).","Data analysis; Graphical interface; GUI; Metabolic profiling; Metabolomics; Metabonomics; Untargeted analysis","Article","Scopus"
"Jing R.; Sun J.; Wang Y.; Li M.; Pu X.","Jing, Runyu (55261728200); Sun, Jing (57226172312); Wang, Yuelong (55796514500); Li, Menglong (35300166700); Pu, Xuemei (7006161028)","55261728200; 57226172312; 55796514500; 35300166700; 7006161028","PML: A parallel machine learning toolbox for data classification and regression","2014","Chemometrics and Intelligent Laboratory Systems","10.1016/j.chemolab.2014.07.005","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905261650&doi=10.1016%2fj.chemolab.2014.07.005&partnerID=40&md5=48993792888d8714dd367dd365283a95","Motivated by timesaving when dealing with the large-scale calculation for data modeling in parallel with multiple CPU cores or machines and result comparison, PML was designed in this study. PML has the ability to do dimension reduction and grid search in parallel, support both classification and regression, and could generate HTML pages as output for results comparison. Written in PERL, PML is compatible with Windows and Linux. This open source software is free available together with the code, manual, examples and license from http://cic.scu.edu.cn/pml or https://github.com/limlcic/PML. © 2014 Elsevier B.V.","Cross-platform; Data mining; Grid search; Modeling; Parallel; Toolbox","Article","Scopus"
"Garcia D.","Garcia, Damien (7202747971)","7202747971","SIMUS: An open-source simulator for medical ultrasound imaging. Part I: Theory & examples","2022","Computer Methods and Programs in Biomedicine","10.1016/j.cmpb.2022.106726","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126926274&doi=10.1016%2fj.cmpb.2022.106726&partnerID=40&md5=f9732a441f124ca79d03e2fdfed8cfac","Background and Objective: Computational ultrasound imaging has become a well-established methodology in the ultrasound community. Simulations of ultrasound sequences and images allow the study of innovative techniques in terms of emission strategy, beamforming, and probe design. There is a wide spectrum of software dedicated to ultrasound imaging, each having its specificities in its applications and the numerical method. Methods: We describe in this two-part paper a new ultrasound simulator (SIMUS) for MATLAB, which belongs to the MATLAB UltraSound Toolbox (MUST). The SIMUS software simulates acoustic pressure fields and radiofrequency RF signals for uniform linear or convex probes. SIMUS is an open-source software whose features are 1) ease of use, 2) time-harmonic analysis, 3) pedagogy. The main goal was to offer a comprehensive turnkey tool, along with a detailed theory for pedagogical and research purposes. Results: This article describes in detail the underlying linear theory of SIMUS and provides examples of simulated acoustic fields and ultrasound images. The accompanying article (part II) is devoted to the comparison of SIMUS with several software packages: Field II, k-Wave, FOCUS, and the Verasonics simulator. The MATLAB open codes for the simulator SIMUS are distributed under the terms of the GNU Lesser General Public License, and can be downloaded from https://www.biomecardio.com/MUST. Conclusions: The simulations described in this part and in the accompanying paper (Part II) show that SIMUS can be used for realistic simulations in medical ultrasound imaging. © 2022","Computer simulation; Open-source codes; Ultrasonic transducer arrays; Ultrasound imaging","Article","Scopus"
"Parton D.L.; Grinaway P.B.; Hanson S.M.; Beauchamp K.A.; Chodera J.D.","Parton, Daniel L. (54882662200); Grinaway, Patrick B. (56728781600); Hanson, Sonya M. (15769438600); Beauchamp, Kyle A. (35097126800); Chodera, John D. (6506773320)","54882662200; 56728781600; 15769438600; 35097126800; 6506773320","Ensembler: Enabling High-Throughput Molecular Simulations at the Superfamily Scale","2016","PLoS Computational Biology","10.1371/journal.pcbi.1004728","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978900622&doi=10.1371%2fjournal.pcbi.1004728&partnerID=40&md5=93e79e9e65e22bb474884f2a8f6610e8","The rapidly expanding body of available genomic and protein structural data provides a rich resource for understanding protein dynamics with biomolecular simulation. While computational infrastructure has grown rapidly, simulations on an omics scale are not yet widespread, primarily because software infrastructure to enable simulations at this scale has not kept pace. It should now be possible to study protein dynamics across entire (super)families, exploiting both available structural biology data and conformational similarities across homologous proteins. Here, we present a new tool for enabling high-throughput simulation in the genomics era. Ensembler takes any set of sequences—from a single sequence to an entire superfamily—and shepherds them through various stages of modeling and refinement to produce simulation-ready structures. This includes comparative modeling to all relevant PDB structures (which may span multiple conformational states of interest), reconstruction of missing loops, addition of missing atoms, culling of nearly identical structures, assignment of appropriate protonation states, solvation in explicit solvent, and refinement and filtering with molecular simulation to ensure stable simulation. The output of this pipeline is an ensemble of structures ready for subsequent molecular simulations using computer clusters, supercomputers, or distributed computing projects like Folding@home. Ensembler thus automates much of the time-consuming process of preparing protein models suitable for simulation, while allowing scalability up to entire superfamilies. A particular advantage of this approach can be found in the construction of kinetic models of conformational dynamics—such as Markov state models (MSMs)—which benefit from a diverse array of initial configurations that span the accessible conformational states to aid sampling. We demonstrate the power of this approach by constructing models for all catalytic domains in the human tyrosine kinase family, using all available kinase catalytic domain structures from any organism as structural templates. Ensembler is free and open source software licensed under the GNU General Public License (GPL) v2. It is compatible with Linux and OS X. The latest release can be installed via the conda package manager, and the latest source can be downloaded from https://github.com/choderalab/ensembler. © 2016 Parton et al.","","Article","Scopus"
"Guo M.; Wang H.; Potter S.S.; Whitsett J.A.; Xu Y.","Guo, Minzhe (35113278100); Wang, Hui (56590779600); Potter, S. Steven (7102952269); Whitsett, Jeffrey A. (57204642359); Xu, Yan (57203023722)","35113278100; 56590779600; 7102952269; 57204642359; 57203023722","SINCERA: A Pipeline for Single-Cell RNA-Seq Profiling Analysis","2015","PLoS Computational Biology","10.1371/journal.pcbi.1004575","205","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949293695&doi=10.1371%2fjournal.pcbi.1004575&partnerID=40&md5=cf64ea79cfd17bde657140ddf63fabed","A major challenge in developmental biology is to understand the genetic and cellular processes/programs driving organ formation and differentiation of the diverse cell types that comprise the embryo. While recent studies using single cell transcriptome analysis illustrate the power to measure and understand cellular heterogeneity in complex biological systems, processing large amounts of RNA-seq data from heterogeneous cell populations creates the need for readily accessible tools for the analysis of single-cell RNA-seq (scRNA-seq) profiles. The present study presents a generally applicable analytic pipeline (SINCERA: a computational pipeline for SINgle CEll RNA-seq profiling Analysis) for processing scRNA-seq data from a whole organ or sorted cells. The pipeline supports the analysis for: 1) the distinction and identification of major cell types; 2) the identification of cell type specific gene signatures; and 3) the determination of driving forces of given cell types. We applied this pipeline to the RNA-seq analysis of single cells isolated from embryonic mouse lung at E16.5. Through the pipeline analysis, we distinguished major cell types of fetal mouse lung, including epithelial, endothelial, smooth muscle, pericyte, and fibroblast-like cell types, and identified cell type specific gene signatures, bioprocesses, and key regulators. SINCERA is implemented in R, licensed under the GNU General Public License v3, and freely available from CCHMC PBGE website, https://research.cchmc.org/pbge/sincera.html. © 2015 Guo et al.","","Article","Scopus"
"Brosgol B.M.","Brosgol, Benjamin M. (6602641192)","6602641192","How to succeed in the software business while giving away the source code: The adacore experience","2020","Ada User Journal","10.1109/MS.2019.2934044","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108967844&doi=10.1109%2fMS.2019.2934044&partnerID=40&md5=a52334b15a82e1ec3a19715fb8473d68","Open-source software, or, more accurately, Freely Licensed Open-Source Software (“FLOSS”), at first appears to present a dilemma when adopted as part of a business model. If users are allowed to access, modify and/or redistribute the source code, how does a software producer protect its intellectual property and sell something that can be easily and legally reproduced? AdaCore has faced this issue since the company’s inception in 1994. Its major commercial product, GNAT Pro Ada, is an Ada development environment based on the GNU Compiler Collection (GCC) from the Free Software Foundation (FSF). AdaCore has implemented an Ada compiler front end and comp-anion run-time libraries and tools and has con-tributed these components to the FSF. In turn, the GNAT Pro Ada compiler incorporates the GCC back end for a variety of target architectures. By lever-aging the GCC back end, AdaCore has made Ada available on a wide range of platforms, both native and embedded, at a significantly reduced effort – indeed, that was the technical rationale for choosing GCC and a design goal of GCC itself. But the challenge of this approach is how to generate a sustained and profitable business. AdaCore's 25 years of FLOSS experience offers an explanation and “lessons learned”. © 2020, Ada-Europe. All rights reserved.","","Article","Scopus"
"Johansson M.; Veryazov V.","Johansson, Marcus (57193152495); Veryazov, Valera (6602838163)","57193152495; 6602838163","Automatic procedure for generating symmetry adapted wavefunctions","2017","Journal of Cheminformatics","10.1186/s13321-017-0193-3","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011310403&doi=10.1186%2fs13321-017-0193-3&partnerID=40&md5=8173ea09f6f6064dde776a88af9f7ecf","Automatic detection of point groups as well as symmetrisation of molecular geometry and wavefunctions are useful tools in computational quantum chemistry. Algorithms for developing these tools as well as an implementation are presented. The symmetry detection algorithm is a clustering algorithm for symmetry invariant properties, combined with logical deduction of possible symmetry elements using the geometry of sets of symmetrically equivalent atoms. An algorithm for determining the symmetry adapted linear combinations (SALCs) of atomic orbitals is also presented. The SALCs are constructed with the use of projection operators for the irreducible representations, as well as subgroups for determining splitting fields for a canonical basis. The character tables for the point groups are auto generated, and the algorithm is described. Symmetrisation of molecules use a projection into the totally symmetric space, whereas for wavefunctions projection as well and partner function determination and averaging is used. The software has been released as a stand-alone, open source library under the MIT license and integrated into both computational and molecular modelling software. Graphical abstract. © 2017 The Author(s).","Molecular symmetry; Point group; Symmetry adapted; Wavefunction","Article","Scopus"
"Burton R.J.; Ahmed R.; Cuff S.M.; Baker S.; Artemiou A.; Eberl M.","Burton, Ross J. (57210806782); Ahmed, Raya (56939908400); Cuff, Simone M. (8744135100); Baker, Sarah (57211459242); Artemiou, Andreas (35263550700); Eberl, Matthias (7004514483)","57210806782; 56939908400; 8744135100; 57211459242; 35263550700; 7004514483","CytoPy: An autonomous cytometry analysis framework","2021","PLoS Computational Biology","10.1371/journal.pcbi.1009071","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108018615&doi=10.1371%2fjournal.pcbi.1009071&partnerID=40&md5=d8cf2421556b7de96d2ddd92cbc61847","Cytometry analysis has seen a considerable expansion in recent years in the maximum number of parameters that can be acquired in a single experiment. In response to this technological advance there has been an increased effort to develop new computational methodologies for handling high-dimensional single cell data acquired by flow or mass cytometry. Despite the success of numerous algorithms and published packages to replicate and outperform traditional manual analysis, widespread adoption of these techniques has yet to be realised in the field of immunology. Here we present CytoPy, a Python framework for automated analysis of cytometry data that integrates a document-based database for a data-centric and iterative analytical environment. In addition, our algorithm agnostic design provides a platform for open-source cytometry bioinformatics in the Python ecosystem. We demonstrate the ability of CytoPy to phenotype T cell subsets in whole blood samples even in the presence of significant batch effects due to technical and user variation. The complete analytical pipeline was then used to immunophenotype the local inflammatory infiltrate in individuals with and without acute bacterial infection. CytoPy is open-source and licensed under the MIT license. CytoPy is open source and available at https://github.com/burtonrj/CytoPy, with notebooks accompanying this manuscript (https://github.com/burtonrj/ CytoPyManuscript) and software documentation at https://cytopy.readthedocs.io/. Copyright: © 2021 Burton et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Article","Scopus"
"Seal A.; Wild D.J.","Seal, Abhik (55262929400); Wild, David J. (13102874300)","55262929400; 13102874300","Netpredictor: R and Shiny package to perform drug-target network analysis and prediction of missing links","2018","BMC Bioinformatics","10.1186/s12859-018-2254-7","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050148760&doi=10.1186%2fs12859-018-2254-7&partnerID=40&md5=f45ff786daa4c055d0b566055acf8838","Background: Netpredictor is an R package for prediction of missing links in any given unipartite or bipartite network. The package provides utilities to compute missing links in a bipartite and well as unipartite networks using Random Walk with Restart and Network inference algorithm and a combination of both. The package also allows computation of Bipartite network properties, visualization of communities for two different sets of nodes, and calculation of significant interactions between two sets of nodes using permutation based testing. The application can also be used to search for top-K shortest paths between interactome and use enrichment analysis for disease, pathway and ontology. The R standalone package (including detailed introductory vignettes) and associated R Shiny web application is available under the GPL-2 Open Source license and is freely available to download. Results: We compared different algorithms performance in different small datasets and found random walk supersedes rest of the algorithms. The package is developed to perform network based prediction of unipartite and bipartite networks and use the results to understand the functionality of proteins in an interactome using enrichment analysis. Conclusion: The rapid application development envrionment like shiny, helps non programmers to develop fast rich visualization apps and we beleieve it would continue to grow in future with further enhancements. We plan to update our algorithms in the package in near future and help scientist to analyse data in a much streamlined fashion. © 2018 The Author(s).","Drug-target; Enrichment analysis; Prediction; R shiny; Shortest-path","Article","Scopus"
"McGeachie M.J.; Chang H.-H.; Weiss S.T.","McGeachie, Michael J. (6506020083); Chang, Hsun-Hsien (8349766000); Weiss, Scott T. (36040917900)","6506020083; 8349766000; 36040917900","CGBayesNets: Conditional Gaussian Bayesian Network Learning and Inference with Mixed Discrete and Continuous Data","2014","PLoS Computational Biology","10.1371/journal.pcbi.1003676","56","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903398929&doi=10.1371%2fjournal.pcbi.1003676&partnerID=40&md5=3c24eb09b257ecd9ea5040fcc6432a1b","Bayesian Networks (BN) have been a popular predictive modeling formalism in bioinformatics, but their application in modern genomics has been slowed by an inability to cleanly handle domains with mixed discrete and continuous variables. Existing free BN software packages either discretize continuous variables, which can lead to information loss, or do not include inference routines, which makes prediction with the BN impossible. We present CGBayesNets, a BN package focused around prediction of a clinical phenotype from mixed discrete and continuous variables, which fills these gaps. CGBayesNets implements Bayesian likelihood and inference algorithms for the conditional Gaussian Bayesian network (CGBNs) formalism, one appropriate for predicting an outcome of interest from, e.g., multimodal genomic data. We provide four different network learning algorithms, each making a different tradeoff between computational cost and network likelihood. CGBayesNets provides a full suite of functions for model exploration and verification, including cross validation, bootstrapping, and AUC manipulation. We highlight several results obtained previously with CGBayesNets, including predictive models of wood properties from tree genomics, leukemia subtype classification from mixed genomic data, and robust prediction of intensive care unit mortality outcomes from metabolomic profiles. We also provide detailed example analysis on public metabolomic and gene expression datasets. CGBayesNets is implemented in MATLAB and available as MATLAB source code, under an Open Source license and anonymous download at http://www.cgbayesnets.com. © 2014 McGeachie et al.","","Article","Scopus"
"Leonori S.; Martino A.; Luzi M.; Frattale Mascioli F.M.; Rizzi A.","Leonori, Stefano (57192819093); Martino, Alessio (57194493625); Luzi, Massimiliano (57192820888); Frattale Mascioli, Fabio Massimo (57218539509); Rizzi, Antonello (7101771404)","57192819093; 57194493625; 57192820888; 57218539509; 7101771404","A generalized framework for ANFIS synthesis procedures by clustering techniques","2020","Applied Soft Computing Journal","10.1016/j.asoc.2020.106622","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089431806&doi=10.1016%2fj.asoc.2020.106622&partnerID=40&md5=8bc661e85f67d4af06883ef39cce0749","The application of machine learning and soft computing techniques for function approximation is a widely explored topic in literature. Neural networks, evolutionary algorithms and support vector machines proved to be very effective, although these models suffer from very low level of interpretability by human operators. Conversely, Adaptive Neuro Fuzzy Inference Systems (ANFISs) demonstrated to be very accurate models featured by a considerable degree of interpretability. In this paper, a general framework for ANFIS training by clustering is proposed and investigated. In particular, different derivative-free ANFIS synthesis procedures are considered for performance evaluation, by taking into account different clustering algorithms, dissimilarity measures and by including an additional neuro-fuzzy classifier downstream the clustering phase targeted to rule base refinement. The resulting ANFISs have been compared, in terms of effectiveness and efficiency, on several benchmark datasets against three suitable competitors, namely a Support Vector Regression, MultiLayer Perceptron and a K-Nearest Neighbour decision rule. Computational results show that the proposed techniques tend to outperform competing strategies while, at same time, featuring models with lower structural complexity. A complete software suite implementing the proposed framework is freely available under an open-source licence. © 2020 Elsevier B.V.","ANFIS; Clustering; Function approximation; Machine learning; Neuro-fuzzy classifiers","Article","Scopus"
"Kollias S.; Vlachos V.; Papanikolaou A.; Chatzimisios P.; Ilioudis C.; Metaxiotis K.","Kollias, Spyridon (36634316500); Vlachos, Vasileios (13411549800); Papanikolaou, Alexandros (26422447700); Chatzimisios, Periklis (57193396103); Ilioudis, Christos (6602906000); Metaxiotis, Kostas (6701910640)","36634316500; 13411549800; 26422447700; 57193396103; 6602906000; 6701910640","A global-local approach for estimating the internet's threat level","2014","Journal of Communications and Networks","10.1109/JCN.2014.000070","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907188077&doi=10.1109%2fJCN.2014.000070&partnerID=40&md5=b27021d2cbbf2e007bd0f41cbdac6281","The Internet is a highly distributed and complex system consisting of billion devices and has become the field of various kinds of conflicts during the last two decades. As a matter of fact, various actors utilise the Internet for illicit purposes, such as for performing distributed denial of service attacks (DDoS) and for spreading various types of aggressive malware. Despite the fact that numerous services provide information regarding the threat level of the Internet, they are mostly based on information acquired by their sensors or on offline statistical sampling of various security applications (antivirus software, intrusion detection systems, etc.). This paper introduces proactive threat observatory system (PROTOS), an open-source early warning system that does not require a commercial license and is capable of estimating the threat level across the Internet. The proposed system utilises both a global and a local approach, and is thus able to determine whether a specific host is under an imminent threat, as well as to provide an estimation of the malicious activity across the Internet. Apart from these obvious advantages, PROTOS supports a large-scale installation and can be extended even further to improve the effectiveness by incorporating prediction and forecasting techniques. © 2014 KICS.","Computer virus; Forecasting; Intrusion detection; Security; Time series","Article","Scopus"
"Lucas B.C.; Bogovic J.A.; Carass A.; Bazin P.-L.; Prince J.L.; Pham D.L.; Landman B.A.","Lucas, Blake C. (35292936200); Bogovic, John A. (24766195800); Carass, Aaron (15061054500); Bazin, Pierre-Louis (8439138300); Prince, Jerry L. (56600943200); Pham, Dzung L. (7203009692); Landman, Bennett A. (16679175200)","35292936200; 24766195800; 15061054500; 8439138300; 56600943200; 7203009692; 16679175200","The Java Image Science Toolkit (JIST) for rapid prototyping and publishing of neuroimaging software","2010","Neuroinformatics","10.1007/s12021-009-9061-2","99","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953102950&doi=10.1007%2fs12021-009-9061-2&partnerID=40&md5=fae8e5a63c8835565c82a977d6a1505b","Non-invasive neuroimaging techniques enable extraordinarily sensitive and specific in vivo study of the structure, functional response and connectivity of biological mechanisms. With these advanced methods comes a heavy reliance on computer-based processing, analysis and interpretation. While the neuroimaging community has produced many excellent academic and commercial tool packages, new tools are often required to interpret new modalities and paradigms. Developing custom tools and ensuring interoperability with existing tools is a significant hurdle. To address these limitations, we present a new framework for algorithm development, that implicitly ensures tool interoperability, generates graphical user interfaces, provides advanced batch processing tools, and, most importantly, requires minimal additional programming or computational overhead. Javabased rapid prototyping with this system is an efficient and practical approach to evaluate new algorithms since the proposed system ensures that rapidly constructed prototypes are actually fully-functional processing modules with support for multiple GUI's, a broad range of file formats, and distributed computation. Herein, we demonstrate MRI image processing with the proposed system for cortical surface extraction in large cross-sectional cohorts, provide a system for fully automated diffusion tensor image analysis, and illustrate how the system can be used as a simulation framework for the development of a new image analysis method. Hie system is released as open source under the Lesser GNU Public License (LGPL) through the Neuroimaging Infoimatics Tools and Resources Clearinghouse (NITRC). © Springer Science+Business Media, LLC 2010.","Image processing; MRI; Parallel processing; Pipeline; Rapid prototyping","Article","Scopus"
"Huth J.; Masquelier T.; Arleo A.","Huth, Jacob (57201196148); Masquelier, Timothée (16022351100); Arleo, Angelo (6602727179)","57201196148; 16022351100; 6602727179","Convis: A toolbox to fit and simulate filter-based models of early visual processing","2018","Frontiers in Neuroinformatics","10.3389/fninf.2018.00009","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043776079&doi=10.3389%2ffninf.2018.00009&partnerID=40&md5=a57b89cd9bfec239600890fce2757d63","We developed Convis, a Python simulation toolbox for large scale neural populations which offers arbitrary receptive fields by 3D convolutions executed on a graphics card. The resulting software proves to be flexible and easily extensible in Python, while building on the PyTorch library (The Pytorch Project, 2017), which was previously used successfully in deep learning applications, for just-in-time optimization and compilation of the model onto CPU or GPU architectures. An alternative implementation based on Theano (Theano Development Team, 2016) is also available, although not fully supported. Through automatic differentiation, any parameter of a specified model can be optimized to approach a desired output which is a significant improvement over e.g., Monte Carlo or particle optimizations without gradients. We show that a number of models including even complex non-linearities such as contrast gain control and spiking mechanisms can be implemented easily. We show in this paper that we can in particular recreate the simulation results of a popular retina simulation software VirtualRetina (Wohrer and Kornprobst, 2009), with the added benefit of providing (1) arbitrary linear filters instead of the product of Gaussian and exponential filters and (2) optimization routines utilizing the gradients of the model. We demonstrate the utility of 3d convolution filters with a simple direction selective filter. Also we showthat it is possible to optimize the input for a certain goal, rather than the parameters, which can aid the design of experiments as well as closed-loop online stimulus generation. Yet, Convis is more than a retina simulator. For instance it can also predict the response of V1 orientation selective cells. Convis is open source under the GPL-3.0 license and available from https://github.com/jahuth/convis/ with documentation at https://jahuth.github.io/convis/. © 2018 Huth, Masquelier and Arleo.","GPU; Primary visual cortex model; Python; PyTorch; Retina model; Theano; Vision model toolbox","Article","Scopus"
"Leweke S.; von Lieres E.","Leweke, Samuel (56896179200); von Lieres, Eric (12753882200)","56896179200; 12753882200","Chromatography Analysis and Design Toolkit (CADET)","2018","Computers and Chemical Engineering","10.1016/j.compchemeng.2018.02.025","41","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044726620&doi=10.1016%2fj.compchemeng.2018.02.025&partnerID=40&md5=118472852716fb8a724f53a21f7a5b43","CADET is an open source modeling and simulation framework for column liquid chromatography. The software is freely distributed to both academia and industry under the GPL license (http://github.com/modsim/cadet). CADET is based on a core simulator that is written in object oriented C++ and applies modern mathematical algorithms for efficiently solving a variety of customary chromatography models. This simulation engine is interfaced to a suite of MATLAB tools for setting up and executing the most common scientific workflows, e.g., model calibration, process design, robustness analysis, statistical analysis, and experimental design. The model library and numerical methods are continuously extended and improved. For instance, binding models with multiple bound states, pH and/or temperature dependence of binding parameters, surface diffusion, and arbitrary spacing of the radial discretization have been recently added. Moreover, numerical accuracy and computational speed of the code are comprehensively benchmarked using high precision reference solutions and realistic model problems. Versatility of the CADET modeling platform is demonstrated with several examples that are also published as open source code and can be freely adapted to specific use cases. In one of several case studies, sequential and simultaneous optimization of elution gradient shape and cut times are compared for a three component separation. This process is designed to achieve Pareto optimal purity and yield of the central fraction. Moreover, the robustness of these designs with respect to typical process variations is systematically studied. The last case study illustrates the optimal design of experiments for estimating model parameters with maximal accuracy. © 2018 Elsevier Ltd","Column liquid chromatography; Experimental design; General rate model; Model calibration; Modeling and simulation platform; Process analysis and design; Statistical analysis","Article","Scopus"
"Ghaffarizadeh A.; Heiland R.; Friedman S.H.; Mumenthaler S.M.; Macklin P.","Ghaffarizadeh, Ahmadreza (34871959000); Heiland, Randy (8721479900); Friedman, Samuel H. (57189240677); Mumenthaler, Shannon M. (23485755100); Macklin, Paul (57203054046)","34871959000; 8721479900; 57189240677; 23485755100; 57203054046","PhysiCell: An open source physics-based cell simulator for 3-D multicellular systems","2018","PLoS Computational Biology","10.1371/journal.pcbi.1005991","156","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042731473&doi=10.1371%2fjournal.pcbi.1005991&partnerID=40&md5=67b9ea9aea3c76d6985d045858f88741","Many multicellular systems problems can only be understood by studying how cells move, grow, divide, interact, and die. Tissue-scale dynamics emerge from systems of many interacting cells as they respond to and influence their microenvironment. The ideal “virtual laboratory” for such multicellular systems simulates both the biochemical microenvironment (the “stage”) and many mechanically and biochemically interacting cells (the “players” upon the stage). PhysiCell—physics-based multicellular simulator—is an open source agent-based simulator that provides both the stage and the players for studying many interacting cells in dynamic tissue microenvironments. It builds upon a multi-substrate biotransport solver to link cell phenotype to multiple diffusing substrates and signaling factors. It includes biologically-driven sub-models for cell cycling, apoptosis, necrosis, solid and fluid volume changes, mechanics, and motility “out of the box.” The C++ code has minimal dependencies, making it simple to maintain and deploy across platforms. PhysiCell has been parallelized with OpenMP, and its performance scales linearly with the number of cells. Simulations up to 105-106cells are feasible on quad-core desktop workstations; larger simulations are attainable on single HPC compute nodes. We demonstrate PhysiCell by simulating the impact of necrotic core biomechanics, 3-D geometry, and stochasticity on the dynamics of hanging drop tumor spheroids and ductal carcinoma in situ (DCIS) of the breast. We demonstrate stochastic motility, chemical and contact-based interaction of multiple cell types, and the extensibility of PhysiCell with examples in synthetic multicellular systems (a “cellular cargo delivery” system, with application to anti-cancer treatments), cancer heterogeneity, and cancer immunology. PhysiCell is a powerful multicellular systems simulator that will be continually improved with new capabilities and performance improvements. It also represents a significant independent code base for replicating results from other simulation platforms. The PhysiCell source code, examples, documentation, and support are available under the BSD license at http://PhysiCell.MathCancer.org and http://PhysiCell.sf.net. © 2018 Ghaffarizadeh et al.","","Article","Scopus"
"Gysi D.M.; Voigt A.; Fragoso T.M.; Almaas E.; Nowick K.","Gysi, Deisy Morselli (56607225500); Voigt, Andre (57195958769); Fragoso, Tiago de Miranda (57225246077); Almaas, Eivind (6602858032); Nowick, Katja (8845731900)","56607225500; 57195958769; 57225246077; 6602858032; 8845731900","wTO: An R package for computing weighted topological overlap and a consensus network with integrated visualization tool","2018","BMC Bioinformatics","10.1186/s12859-018-2351-7","26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055544235&doi=10.1186%2fs12859-018-2351-7&partnerID=40&md5=29672644a02d4e652f92870f2d94bdeb","Background: Network analyses, such as of gene co-expression networks, metabolic networks and ecological networks have become a central approach for the systems-level study of biological data. Several software packages exist for generating and analyzing such networks, either from correlation scores or the absolute value of a transformed score called weighted topological overlap (wTO). However, since gene regulatory processes can up- or down-regulate genes, it is of great interest to explicitly consider both positive and negative correlations when constructing a gene co-expression network. Results: Here, we present an R package for calculating the weighted topological overlap (wTO), that, in contrast to existing packages, explicitly addresses the sign of the wTO values, and is thus especially valuable for the analysis of gene regulatory networks. The package includes the calculation of p-values (raw and adjusted) for each pairwise gene score. Our package also allows the calculation of networks from time series (without replicates). Since networks from independent datasets (biological repeats or related studies) are not the same due to technical and biological noise in the data, we additionally, incorporated a novel method for calculating a consensus network (CN) from two or more networks into our R package. To graphically inspect the resulting networks, the R package contains a visualization tool, which allows for the direct network manipulation and access of node and link information. When testing the package on a standard laptop computer, we can conduct all calculations for systems of more than 20,000 genes in under two hours. We compare our new wTO package to state of art packages and demonstrate the application of the wTO and CN functions using 3 independently derived datasets from healthy human pre-frontal cortex samples. To showcase an example for the time series application we utilized a metagenomics data set. Conclusion: In this work, we developed a software package that allows the computation of wTO networks, CNs and a visualization tool in the R statistical environment. It is publicly available on CRAN repositories under the GPL -2 Open Source License (https://cran.r-project.org/web/packages/wTO/). © 2018 The Author(s).","Co-expression network; Co-occurrence network; Consensus Network; Expression; Meta analysis; Metagenomics; Network; R package; Software; WTO","Article","Scopus"
"Schmied C.; Steinbach P.; Pietzsch T.; Preibisch S.; Tomancak P.","Schmied, Christopher (55674584300); Steinbach, Peter (57225401399); Pietzsch, Tobias (25653472100); Preibisch, Stephan (8935131900); Tomancak, Pavel (6508156550)","55674584300; 57225401399; 25653472100; 8935131900; 6508156550","An automated workflow for parallel processing of large multiview SPIM recordings","2016","Bioinformatics","10.1093/bioinformatics/btv706","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964497666&doi=10.1093%2fbioinformatics%2fbtv706&partnerID=40&md5=e6b13518cae3ce3a562d3f85980e210a","Summary: Selective Plane Illumination Microscopy (SPIM) allows to image developing organisms in 3D at unprecedented temporal resolution over long periods of time. The resulting massive amounts of raw image data requires extensive processing interactively via dedicated graphical user interface (GUI) applications. The consecutive processing steps can be easily automated and the individual time points can be processed independently, which lends itself to trivial parallelization on a high performance computing (HPC) cluster. Here, we introduce an automated workflow for processing large multiview, multichannel, multiillumination time-lapse SPIM data on a single workstation or in parallel on a HPC cluster. The pipeline relies on snakemake to resolve dependencies among consecutive processing steps and can be easily adapted to any cluster environment for processing SPIM data in a fraction of the time required to collect it. Availability and implementation: The code is distributed free and open source under the MIT license http://opensource.org/licenses/MIT. The source code can be downloaded from github: https://github.com/mpicbg-scicomp/snakemake-workflows. Documentation can be found here: http://fiji.sc/Automated-workflow-for-parallel-Multiview-Reconstruction. © 2015 The Author 2015. Published by Oxford University Press.","","Article","Scopus"
"Dixon P.C.; Loh J.J.; Michaud-Paquette Y.; Pearsall D.J.","Dixon, Philippe C. (35784144900); Loh, Jonathan J. (36762506300); Michaud-Paquette, Yannick (26530669700); Pearsall, David J. (7003649347)","35784144900; 36762506300; 26530669700; 7003649347","biomechZoo: An open-source toolbox for the processing, analysis, and visualization of biomechanical movement data","2017","Computer Methods and Programs in Biomedicine","10.1016/j.cmpb.2016.11.007","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84999663783&doi=10.1016%2fj.cmpb.2016.11.007&partnerID=40&md5=bfa1ea647c451a3c70a63c59c9ef4ea9","It is common for biomechanics data sets to contain numerous dependent variables recorded over time, for many subjects, groups, and/or conditions. These data often require standard sorting, processing, and analysis operations to be performed in order to answer research questions. Visualization of these data is also crucial. This manuscript presents biomechZoo, an open-source toolbox that provides tools and graphical user interfaces to help users achieve these goals. The aims of this manuscript are to (1) introduce the main features of the toolbox, including a virtual three-dimensional environment to animate motion data (Director), a data plotting suite (Ensembler), and functions for the computation of three-dimensional lower-limb joint angles, moments, and power and (2) compare these computations to those of an existing validated system. To these ends, the steps required to process and analyze a sample data set via the toolbox are outlined. The data set comprises three-dimensional marker, ground reaction force (GRF), joint kinematic, and joint kinetic data of subjects performing straight walking and 90° turning manoeuvres. Joint kinematics and kinetics processed within the toolbox were found to be similar to outputs from a commercial system. The biomechZoo toolbox represents the work of several years and multiple contributors to provide a flexible platform to examine time-series data sets typical in the movement sciences. The toolbox has previously been used to process and analyse walking, running, and ice hockey data sets, and can integrate existing routines, such as the KineMat toolbox, for additional analyses. The toolbox can help researchers and clinicians new to programming or biomechanics to process and analyze their data through a customizable workflow, while advanced users are encouraged to contribute additional functionality to the project. Students may benefit from using biomechZoo as a learning and research tool. It is hoped that the toolbox can play a role in advancing research in the movement sciences. The biomechZoo m-files, sample data, and help repositories are available online (http://www.biomechzoo.com) under the Apache 2.0 License. The toolbox is supported for Matlab (r2014b or newer, The Mathworks Inc., Natick, USA) for Windows (Microsoft Corp., Redmond, USA) and Mac OS (Apple Inc., Cupertino, USA). © 2016 Elsevier Ireland Ltd","Analysis; Biomechanics; Gait; Kinematics; Kinetics; Processing; Programming; Visualization","Article","Scopus"
"Gao J.; Prlić A.; Bi C.; Bluhm W.F.; DImitropoulos D.; Xu D.; Bourne P.E.; Rose P.W.","Gao, Jianjiong (55370612000); Prlić, Andreas (8975983000); Bi, Chunxiao (36011530400); Bluhm, Wolfgang F. (6602674245); DImitropoulos, DImitris (36832491200); Xu, Dong (7404074295); Bourne, Philip E. (35458582500); Rose, Peter W. (7201669132)","55370612000; 8975983000; 36011530400; 6602674245; 36832491200; 7404074295; 35458582500; 7201669132","BioJava-ModFinder: Identification of protein modifications in 3D structures from the Protein Data Bank","2017","Bioinformatics","10.1093/bioinformatics/btx101","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021838724&doi=10.1093%2fbioinformatics%2fbtx101&partnerID=40&md5=b6ba35d8a6981632d0e3b7ed9e692d47","We developed a new software tool, BioJava-ModFinder, for identifying protein modifications observed in 3D structures archived in the Protein Data Bank (PDB). Information on more than 400 types of protein modifications were collected and curated from annotations in PDB, RESID, and PSI-MOD. We divided these modifications into three categories: Modified residues, attachment modifications, and cross-links. We have developed a systematic method to identify these modifications in 3D protein structures.We have integrated this package with the RCSB PDB web application and added protein modification annotations to the sequence diagram and structure display. By scanning all 3D structures in the PDB using BioJava-ModFinder, we identified more than 30 000 structures with proteinmodifications, which can be searched, browsed, and visualized on the RCSB PDB website. Availability and Implementation: BioJava-ModFinder is available as open source (LGPL license) at (https://github.com/biojava/biojava/tree/master/biojava-modfinder). The RCSB PDB can be accessed at http://www.rcsb.org. © 2017 The Author.","","Article","Scopus"
"Niklasson M.; Ahlner A.; Andresen C.; Marsh J.A.; Lundström P.","Niklasson, Markus (56503427600); Ahlner, Alexandra (55510151600); Andresen, Cecilia (8561632200); Marsh, Joseph A. (15081439000); Lundström, Patrik (7004664885)","56503427600; 55510151600; 8561632200; 15081439000; 7004664885","Fast and Accurate Resonance Assignment of Small-to-Large Proteins by Combining Automated and Manual Approaches","2015","PLoS Computational Biology","10.1371/journal.pcbi.1004022","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922230982&doi=10.1371%2fjournal.pcbi.1004022&partnerID=40&md5=3f72e4cc14c7161fa944cf6d167058a1","The process of resonance assignment is fundamental to most NMR studies of protein structure and dynamics. Unfortunately, the manual assignment of residues is tedious and time-consuming, and can represent a significant bottleneck for further characterization. Furthermore, while automated approaches have been developed, they are often limited in their accuracy, particularly for larger proteins. Here, we address this by introducing the software COMPASS, which, by combining automated resonance assignment with manual intervention, is able to achieve accuracy approaching that from manual assignments at greatly accelerated speeds. Moreover, by including the option to compensate for isotope shift effects in deuterated proteins, COMPASS is far more accurate for larger proteins than existing automated methods. COMPASS is an open-source project licensed under GNU General Public License and is available for download from. Source code and binaries for Linux, Mac OS X and Microsoft Windows are available. © 2015 Niklasson et al.","","Article","Scopus"
"Jao J.; Ciernia A.V.","Jao, Justin (57226333051); Ciernia, Annie Vogel (55491054000)","57226333051; 55491054000","MGEnrichment: A web application for microglia gene list enrichment analysis","2021","PLoS Computational Biology","10.1371/journal.pcbi.1009160","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119928320&doi=10.1371%2fjournal.pcbi.1009160&partnerID=40&md5=fc98fb5441d12e088247a4bee804781e","Gene expression analysis is becoming increasingly utilized in neuro-immunology research, and there is a growing need for non-programming scientists to be able to analyze their own genomic data. MGEnrichment is a web application developed both to disseminate to the community our curated database of microglia-relevant gene lists, and to allow non-programming scientists to easily conduct statistical enrichment analysis on their gene expression data. Users can upload their own gene IDs to assess the relevance of their expression data against gene lists from other studies. We include example datasets of differentially expressed genes (DEGs) from human postmortem brain samples from Autism Spectrum Disorder (ASD) and matched controls. We demonstrate how MGEnrichment can be used to expand the interpretations of these DEG lists in terms of regulation of microglial gene expression and provide novel insights into how ASD DEGs may be implicated specifically in microglial development, microbiome responses and relationships to other neuropsychiatric disorders. This tool will be particularly useful for those working in microglia, autism spectrum disorders, and neuro-immune activation research. MGEnrichment is available at https:// ciernialab.shinyapps.io/MGEnrichmentApp/ and further online documentation and datasets can be found at https://github.com/ciernialab/MGEnrichmentApp. The app is released under the GNU GPLv3 open source license.  © 2021 Jao, Ciernia. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Article","Scopus"
"Mosaliganti K.R.; Noche R.R.; Xiong F.; Swinburne I.A.; Megason S.G.","Mosaliganti, Kishore R. (14016148900); Noche, Ramil R. (6506906400); Xiong, Fengzhu (55088033100); Swinburne, Ian A. (14029406000); Megason, Sean G. (6506248083)","14016148900; 6506906400; 55088033100; 14029406000; 6506248083","ACME: Automated Cell Morphology Extractor for Comprehensive Reconstruction of Cell Membranes","2012","PLoS Computational Biology","10.1371/journal.pcbi.1002780","84","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872027943&doi=10.1371%2fjournal.pcbi.1002780&partnerID=40&md5=e1d382fd9dbb97796314b9ab4e935a4d","The quantification of cell shape, cell migration, and cell rearrangements is important for addressing classical questions in developmental biology such as patterning and tissue morphogenesis. Time-lapse microscopic imaging of transgenic embryos expressing fluorescent reporters is the method of choice for tracking morphogenetic changes and establishing cell lineages and fate maps in vivo. However, the manual steps involved in curating thousands of putative cell segmentations have been a major bottleneck in the application of these technologies especially for cell membranes. Segmentation of cell membranes while more difficult than nuclear segmentation is necessary for quantifying the relations between changes in cell morphology and morphogenesis. We present a novel and fully automated method to first reconstruct membrane signals and then segment out cells from 3D membrane images even in dense tissues. The approach has three stages: 1) detection of local membrane planes, 2) voting to fill structural gaps, and 3) region segmentation. We demonstrate the superior performance of the algorithms quantitatively on time-lapse confocal and two-photon images of zebrafish neuroectoderm and paraxial mesoderm by comparing its results with those derived from human inspection. We also compared with synthetic microscopic images generated by simulating the process of imaging with fluorescent reporters under varying conditions of noise. Both the over-segmentation and under-segmentation percentages of our method are around 5%. The volume overlap of individual cells, compared to expert manual segmentation, is consistently over 84%. By using our software (ACME) to study somite formation, we were able to segment touching cells with high accuracy and reliably quantify changes in morphogenetic parameters such as cell shape and size, and the arrangement of epithelial and mesenchymal cells. Our software has been developed and tested on Windows, Mac, and Linux platforms and is available publicly under an open source BSD license. © 2012 Mosaliganti et al.","","Article","Scopus"
"Prosperi M.; Marini S.; Boucher C.","Prosperi, Mattia (22036230400); Marini, Simone (53981812300); Boucher, Christina (36843507800)","22036230400; 53981812300; 36843507800","Fast and exact quantification of motif occurrences in biological sequences","2021","BMC Bioinformatics","10.1186/s12859-021-04355-6","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115129188&doi=10.1186%2fs12859-021-04355-6&partnerID=40&md5=d80dfbbd11b2b32257fd57f2e0f465a5","Background: Identification of motifs and quantification of their occurrences are important for the study of genetic diseases, gene evolution, transcription sites, and other biological mechanisms. Exact formulae for estimating count distributions of motifs under Markovian assumptions have high computational complexity and are impractical to be used on large motif sets. Approximated formulae, e.g. based on compound Poisson, are faster, but reliable p value calculation remains challenging. Here, we introduce ‘motif_prob’, a fast implementation of an exact formula for motif count distribution through progressive approximation with arbitrary precision. Our implementation speeds up the exact calculation, usually impractical, making it feasible and posit to substitute currently employed heuristics. Results: We implement motif_prob in both Perl and C+ + languages, using an efficient error-bound iterative process for the exact formula, providing comparison with state-of-the-art tools (e.g. MoSDi) in terms of precision, run time benchmarks, along with a real-world use case on bacterial motif characterization. Our software is able to process a million of motifs (13–31 bases) over genome lengths of 5 million bases within the minute on a regular laptop, and the run times for both the Perl and C+ + code are several orders of magnitude smaller (50–1000× faster) than MoSDi, even when using their fast compound Poisson approximation (60–120× faster). In the real-world use cases, we first show the consistency of motif_prob with MoSDi, and then how the p-value quantification is crucial for enrichment quantification when bacteria have different GC content, using motifs found in antimicrobial resistance genes. The software and the code sources are available under the MIT license at https://github.com/DataIntellSystLab/motif_prob. Conclusions: The motif_prob software is a multi-platform and efficient open source solution for calculating exact frequency distributions of motifs. It can be integrated with motif discovery/characterization tools for quantifying enrichment and deviation from expected frequency ranges with exact p values, without loss in data processing efficiency. © 2021, The Author(s).","Bioinformatics; Markov model; Motifs; Probability distribution","Article","Scopus"
"Myrseth V.; Perez-Valdes G.A.; Bakker S.J.; Midthun K.T.; Torsæter M.","Myrseth, Velaug (9337844800); Perez-Valdes, Gerardo A. (35213744700); Bakker, Steffen J. (57190223116); Midthun, Kjetil T. (36051923100); Torsæter, Malin (35367131900)","9337844800; 35213744700; 57190223116; 36051923100; 35367131900","Development of a norwegian open-source plug-and-abandonment database with applications","2017","SPE Economics and Management","10.2118/180027-pa","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032930386&doi=10.2118%2f180027-pa&partnerID=40&md5=29527567378590d62728b1af28da4bbb","An estimated 3,000 oil wells need to be plugged and abandoned on the Norwegian Continental Shelf (NCS), with approximately 150 new wells being drilled each year. The petroleum industry estimates the total plugging costs to be almost 900 billion Norwegian kroner (NOK), and that the work will take up to 40 years to complete. Because of the current tax regulations in Norway, the state indirectly pays 78% of the costs (approximately 700 billion NOK). It is therefore vital to reduce expenses by targeted research and development (R&D) of new technology, and to ensure better planning of plug-and-abandonment (P&A) operations in and between licenses. The current study aims to gather available data relevant for Norwegian P&A operations in an open-source database, and to develop and use a P&A planning software that serves as a decisionsupport tool for various problems operators face. The software can be used to generate planning schedules, identify bottlenecks in P&A operations, and analyze potential efficiency gains from technology improvements and cooperative plugging campaigns. We will use a cross-disciplinary approach that combines the fields of operations research with technological expertise. In this paper, we present the outline of the database and the current status of available data for P&A operations on the NCS, as well as a short literature review. Available data are categorized according to the different choices that need to be made within a single P&A operation, with regard to both technological aspects and the existing regulatory framework. We also discuss the type of analysis the P&A planning software is envisioned to perform. Industry, government, and ordinary tax payers will all benefit from knowledge sharing, optimized planning, and more targeted R&D efforts on this topic. The results from this study will be used to identify important cost drivers and to draw up a roadmap for future P&A-related R&D. © 2017 Society of Petroleum Engineers.","","Article","Scopus"
"Fan Y.; Song Y.-Q.","Fan, Yanhui (37461378000); Song, You-Qiang (55812396800)","37461378000; 55812396800","PyHLA: Tests for the association between HLA alleles and diseases","2017","BMC Bioinformatics","10.1186/s12859-017-1496-0","19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011661226&doi=10.1186%2fs12859-017-1496-0&partnerID=40&md5=614d3093008a4612debcfd925df0d53c","Background: Recently, several tools have been designed for human leukocyte antigen (HLA) typing using single nucleotide polymorphism (SNP) array and next-generation sequencing (NGS) data. These tools provide high-throughput and cost-effective approaches for identifying HLA types. Therefore, tools for downstream association analysis are highly desirable. Although several tools have been designed for multi-allelic marker association analysis, they were designed only for microsatellite markers and do not scale well with increasing data volumes, or they were designed for large-scale data but provided a limited number of tests. Results: We have developed a Python package called PyHLA, which implements several methods for HLA association analysis, to fill the gap. PyHLA is a tailor-made, easy to use, and flexible tool designed specifically for the association analysis of the HLA types imputed from genome-wide genotyping and NGS data. PyHLA provides functions for association analysis, zygosity tests, and interaction tests between HLA alleles and diseases. Monte Carlo permutation and several methods for multiple testing corrections have also been implemented. Conclusions: PyHLA provides a convenient and powerful tool for HLA analysis. Existing methods have been integrated and desired methods have been added in PyHLA. Furthermore, PyHLA is applicable to small and large sample sizes and can finish the analysis in a timely manner on a personal computer with different platforms. PyHLA is implemented in Python. PyHLA is a free, open source software distributed under the GPLv2 license. The source code, tutorial, and examples are available at https://github.com/felixfan/PyHLA. © 2017 The Author(s).","Association; HLA; Interaction; Multi-allelic","Article","Scopus"
"Mate S.; Bürkle T.; Kapsner L.A.; Toddenroth D.; Kampf M.O.; Sedlmayr M.; Castellanos I.; Prokosch H.-U.; Kraus S.","Mate, Sebastian (54581374100); Bürkle, Thomas (55923777000); Kapsner, Lorenz A. (57206905177); Toddenroth, Dennis (36599445900); Kampf, Marvin O. (57208243901); Sedlmayr, Martin (56043034300); Castellanos, Ixchel (35228773800); Prokosch, Hans-Ulrich (6701859198); Kraus, Stefan (36004109900)","54581374100; 55923777000; 57206905177; 36599445900; 57208243901; 56043034300; 35228773800; 6701859198; 36004109900","A method for the graphical modeling of relative temporal constraints","2019","Journal of Biomedical Informatics","10.1016/j.jbi.2019.103314","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074554772&doi=10.1016%2fj.jbi.2019.103314&partnerID=40&md5=08d064d1506041b98321bd7b5a1db362","Searching for patient cohorts in electronic patient data often requires the definition of temporal constraints between the selection criteria. However, beyond a certain degree of temporal complexity, the non-graphical, form-based approaches implemented in current translational research platforms may be limited when modeling such constraints. In our opinion, there is a need for an easily accessible and implementable, fully graphical method for creating temporal queries. We aim to respond to this challenge with a new graphical notation. Based on Allen's time interval algebra, it allows for modeling temporal queries by arranging simple horizontal bars depicting symbolic time intervals. To make our approach applicable to complex temporal patterns, we apply two extensions: with duration intervals, we enable the inference about relative temporal distances between patient events, and with time interval modifiers, we support counting and excluding patient events, as well as constraining numeric values. We describe how to generate database queries from this notation. We provide a prototypical implementation, consisting of a temporal query modeling frontend and an experimental backend that connects to an i2b2 system. We evaluate our modeling approach on the MIMIC-III database to demonstrate that it can be used for modeling typical temporal phenotyping queries. Data availability statement The source code (licensed under the GNU General Public License v3.0) is available on GitHub (https://github.com/sebmate/AllenGUI and https://github.com/sebmate/AllenSPARQL). Also supplied are the development i2b2 dataset (with the 13 artificial patients) and the SQL scripts to populate the i2b2 system with the MIMIC-III data. Please note that the software is of prototypical character and provided “as is”, without any warranties. © 2019 Elsevier Inc.","Data integration; Data retrieval; Patient cohort identification; Phenotyping; Phenotyping algorithms; Temporal queries","Article","Scopus"
"Benson S.J.; Ye Y.","Benson, Steven J. (7202652309); Ye, Yinyu (7401627522)","7202652309; 7401627522","Algorithm 875: DSDP5-software for semidefinite programming","2008","ACM Transactions on Mathematical Software","10.1145/1356052.1356057","26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-44249088324&doi=10.1145%2f1356052.1356057&partnerID=40&md5=33ee148166cdd141feb21d94c1d64aa4","DSDP implements the dual-scaling algorithm for semidefinite programming. The source code for this interior-point algorithm, written entirely in ANSI C, is freely available under an open source license. The solver can be used as a subroutine library, as a function within the Matlab environment, or as an executable that reads and writes to data files. Initiated in 1997, DSDP has developed into an efficient and robust general-purpose solver for semidefinite programming. Its features include a convergence proof with polynomially bounded worst-case complexity, primal and dual feasible solutions when they exist, certificates of infeasibility when solutions do not exist, initial points that can be feasible or infeasible, relatively low memory requirements for an interior-point method, sparse and low-rank data structures, extensibility that allows applications to customize the solver and improve its performance, a subroutine library that enables it to be linked to larger applications, scalable performance for large problems on parallel architectures, and a well-documented interface and examples of its use. The package has been used in many applications and tested for efficiency, robustness, and ease of use. © 2008 ACM.","Conic programming; Dual-scaling algorithm; Interior-point methods; Linear matrix inequalities; Semidefinite programming","Article","Scopus"
"Cipriano B.P.; Fachada N.; Alves P.","Cipriano, Bruno Pereira (57669691700); Fachada, Nuno (35194003700); Alves, Pedro (57206259056)","57669691700; 35194003700; 57206259056","Drop Project: An automatic assessment tool for programming assignments","2022","SoftwareX","10.1016/j.softx.2022.101079","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129535807&doi=10.1016%2fj.softx.2022.101079&partnerID=40&md5=b10c0f7dd2c37ff4e2ef4e9ae9992b16","Automated assessment tools (AATs) are software systems used in teaching environments to automate the evaluation of computer programs implemented by students. These tools can be used to stimulate the interest of computer science students in programming courses by providing quick feedback on their work and highlighting their mistakes. Despite the abundance of such tools, most of them are developed for a specific course and are not production-ready. Others lack advanced features that are required for certain pedagogical goals (e.g. Git integration) and/or are not flexible enough to be used with students having different computer literacy levels, such as first year and second year students. In this paper we present Drop Project (DP), an automated assessment tool built on top of the Maven build automation software. We have been using DP in our teaching activity since 2018, having received more than fifty thousand submissions between projects, classroom exercises, tests and homework assignments. The tool's automated feedback has allowed us to raise the difficulty level of the course's projects, while the grading process has become more efficient and consistent between different teachers. DP is an extensively tested, production-ready tool. The software's code and documentation are available in GitHub under an open-source software license. © 2022 The Author(s)","Automated assessment; Computer science education; Programming education; Unit testing","Article","Scopus"
"Yu S.-H.; Vogel J.; Förstner K.U.","Yu, Sung-Huan (16426378400); Vogel, Jörg (15074184800); Förstner, Konrad U. (14032724100)","16426378400; 15074184800; 14032724100","ANNOgesic: a Swiss army knife for the RNA-seq based annotation of bacterial/archaeal genomes","2018","GigaScience","10.1093/gigascience/giy096","28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055914111&doi=10.1093%2fgigascience%2fgiy096&partnerID=40&md5=c1c1d2752eee34d0fc2679e85f077062","To understand the gene regulation of an organism of interest, a comprehensive genome annotation is essential. While some features, such as coding sequences, can be computationally predicted with high accuracy based purely on the genomic sequence, others, such as promoter elements or noncoding RNAs, are harder to detect. RNA sequencing (RNA-seq) has proven to be an efficient method to identify these genomic features and to improve genome annotations. However, processing and integrating RNA-seq data in order to generate high-resolution annotations is challenging, time consuming, and requires numerous steps. We have constructed a powerful and modular tool called ANNOgesic that provides the required analyses and simplifies RNA-seq-based bacterial and archaeal genome annotation. It can integrate data from conventional RNA-seq and differential RNA-seq and predicts and annotates numerous features, including small noncoding RNAs, with high precision. The software is available under an open source license (ISCL) at https://pypi.org/project/ANNOgesic/.","","Article","Scopus"
"Ruiz-Carmona S.; Alvarez-Garcia D.; Foloppe N.; Garmendia-Doval A.B.; Juhos S.; Schmidtke P.; Barril X.; Hubbard R.E.; Morley S.D.","Ruiz-Carmona, Sergio (56178317900); Alvarez-Garcia, Daniel (56177508200); Foloppe, Nicolas (34975052500); Garmendia-Doval, A. Beatriz (55344856300); Juhos, Szilveszter (6602624427); Schmidtke, Peter (36764104900); Barril, Xavier (6602104920); Hubbard, Roderick E. (7202298710); Morley, S. David (57198275346)","56178317900; 56177508200; 34975052500; 55344856300; 6602624427; 36764104900; 6602104920; 7202298710; 57198275346","rDock: A Fast, Versatile and Open Source Program for Docking Ligands to Proteins and Nucleic Acids","2014","PLoS Computational Biology","10.1371/journal.pcbi.1003571","281","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901363730&doi=10.1371%2fjournal.pcbi.1003571&partnerID=40&md5=1ec87e090e24aed5183cf1c29cb423c2","Identification of chemical compounds with specific biological activities is an important step in both chemical biology and drug discovery. When the structure of the intended target is available, one approach is to use molecular docking programs to assess the chemical complementarity of small molecules with the target; such calculations provide a qualitative measure of affinity that can be used in virtual screening (VS) to rank order a list of compounds according to their potential to be active. rDock is a molecular docking program developed at Vernalis for high-throughput VS (HTVS) applications. Evolved from RiboDock, the program can be used against proteins and nucleic acids, is designed to be computationally very efficient and allows the user to incorporate additional constraints and information as a bias to guide docking. This article provides an overview of the program structure and features and compares rDock to two reference programs, AutoDock Vina (open source) and Schrödinger's Glide (commercial). In terms of computational speed for VS, rDock is faster than Vina and comparable to Glide. For binding mode prediction, rDock and Vina are superior to Glide. The VS performance of rDock is significantly better than Vina, but inferior to Glide for most systems unless pharmacophore constraints are used; in that case rDock and Glide are of equal performance. The program is released under the Lesser General Public License and is freely available for download, together with the manuals, example files and the complete test sets, at http://www.w3.org/1999/xlink. © 2014 Ruiz-Carmona et al.","","Article","Scopus"
"Babur Ö.; Aksoy B.A.; Rodchenkov I.; Sümer S.O.; Sander C.; Demir E.","Babur, Özgün (12238934400); Aksoy, Bülent Arman (55359957600); Rodchenkov, Igor (6506281687); Sümer, Selçuk Onur (57196395059); Sander, Chris (55146122100); Demir, Emek (35309628300)","12238934400; 55359957600; 6506281687; 57196395059; 55146122100; 35309628300","Pattern search in biopax models","2014","Bioinformatics","10.1093/bioinformatics/btt539","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891354802&doi=10.1093%2fbioinformatics%2fbtt539&partnerID=40&md5=34515fea67d88dfd31c6cf96b413af2e","Motivation: BioPAX is a standard language for representing complex cellular processes, including metabolic networks, signal transduction and gene regulation. Owing to the inherent complexity of a BioPAX model, searching for a specific type of subnetwork can be non-trivial and difficult.Results: We developed an open source and extensible framework for defining and searching graph patterns in BioPAX models. We demonstrate its use with a sample pattern that captures directed signaling relations between proteins. We provide search results for the pattern obtained from the Pathway Commons database and compare these results with the current data in signaling databases SPIKE and SignaLink. Results show that a pattern search in public pathway data can identify a substantial amount of signaling relations that do not exist in signaling databases.Availability: BioPAX-pattern software was developed in Java. Source code and documentation is freely available at http://code.google.com/p/biopax- pattern under Lesser GNU Public License.Contact: Supplementary information: Supplementary data are available at Bioinformatics online. © 2013 The Author .","","Article","Scopus"
"Steffens S.; Fu X.; He F.; Li Y.; Babarinde I.A.; Hutchins A.P.","Steffens, Simon (57215717426); Fu, Xiuling (57194006681); He, Fangfang (57194008067); Li, Yuhao (57194004664); Babarinde, Isaac A. (56005108200); Hutchins, Andrew P. (7003743014)","57215717426; 57194006681; 57194008067; 57194004664; 56005108200; 7003743014","DPre: Computational identification of differentiation bias and genes underlying cell type conversions","2020","Bioinformatics","10.1093/bioinformatics/btz789","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081731957&doi=10.1093%2fbioinformatics%2fbtz789&partnerID=40&md5=45353d82152692550bd9505ae7c5fdec","Summary: Cells are generally resistant to cell type conversions, but can be converted by the application of growth factors, chemical inhibitors and ectopic expression of genes. However, it remains difficult to accurately identify the destination cell type or differentiation bias when these techniques are used to alter cell type. Consequently, there is demand for computational techniques that can help researchers understand both the cell type and differentiation bias. While advanced tools identifying cell types exist for single cell data and the deconvolution of mixed cell populations, the problem of exploring partially differentiated cells of indeterminate transcriptional identity has not been addressed. To fill this gap, we developed driver-predictor, which relies on scoring per gene transcriptional similarity between RNA-Seq datasets to reveal directional bias of differentiation. By comparing against large cell type transcriptome libraries or a desired target expression profile, the tool enables the user to visualize both the changes in transcriptional identity as well as the genes accounting for the cell type changes. This software will be a powerful tool for researchers to explore in vitro experiments that involve cell type conversions. Availability and implementation: Source code is open source under the MIT license and is freely available on https://github.com/LoaloaF/DPre. © The Author(s) 2019. Published by Oxford University Press. All rights reserved.","","Article","Scopus"
"Barbosa I.B.; Cristani M.; Caputo B.; Rognhaugen A.; Theoharis T.","Barbosa, Igor Barros (55420664800); Cristani, Marco (8244336900); Caputo, Barbara (6701493146); Rognhaugen, Aleksander (57200040329); Theoharis, Theoharis (6602076896)","55420664800; 8244336900; 6701493146; 57200040329; 6602076896","Looking beyond appearances: Synthetic training data for deep CNNs in re-identification","2018","Computer Vision and Image Understanding","10.1016/j.cviu.2017.12.002","88","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038901677&doi=10.1016%2fj.cviu.2017.12.002&partnerID=40&md5=b3bc57da930271e0acf513585d70ea37","Re-identification is generally carried out by encoding the appearance of a subject in terms of outfit, suggesting scenarios where people do not change their attire. In this paper we overcome this restriction, by proposing a framework based on a deep convolutional neural network, SOMAnet, that additionally models other discriminative aspects, namely, structural attributes of the human figure (e.g. height, obesity, gender). Our method is unique in many respects. First, SOMAnet is based on the Inception architecture, departing from the usual siamese framework. This spares expensive data preparation (pairing images across cameras) and allows the understanding of what the network learned. Second, and most notably, the training data consists of a synthetic 100K instance dataset, SOMAset, created by photorealistic human body generation software. SOMAset will be released with a open source license to enable further developments in re-identification. Synthetic data represents a cost-effective way of acquiring semi-realistic imagery (full realism is usually not required in re-identification since surveillance cameras capture low-resolution silhouettes), while at the same time providing complete control of the samples in terms of ground truth. Thus it is relatively easy to customize the data w.r.t. the surveillance scenario at-hand, e.g. ethnicity. SOMAnet, trained on SOMAset and fine-tuned on recent re-identification benchmarks, matches subjects even with different apparel. © 2017 Elsevier Inc.","Automated training dataset generation; Deep learning; Re-identification; Re-identification photorealistic dataset; Training set","Article","Scopus"
"Lencse G.; Bakai D.","Lencse, Gábor (6508061114); Bakai, Dániel (57194429168)","6508061114; 57194429168","Design and implementation of a test program for benchmarking DNS64 servers","2017","IEICE Transactions on Communications","10.1587/transcom.2016EBN0007","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020081351&doi=10.1587%2ftranscom.2016EBN0007&partnerID=40&md5=c9c5a076d93da225441a54c3e0e84593","A new Internet Draft on benchmarking methodologies for IPv6 transition technologies including DNS64 was adopted by the Bench- marking Working Group of IETF. The aim of our effort is to design and implement a test program that complies with the draft and thus to create the world's first standard DNS64 benchmarking tool. In this paper, we disclose our design considerations and high-level implementation decisions. The precision of our special timing method is tested and found to be excellent. Due to the prudent design, the performance of our test program is also excellent: it can send more than 200,000 AAAA record requests using a single core of a desktop computer with a 3.2 GHz Intel Core i5-4570 CPU. Its operation comprises all the functionalities required by the draft includ- ing checking the timeliness and validity of the answers of the tested DNS64 server. Our DNS64 benchmarking program, dns64perf++, is distributed as free software under GNU GPL v2 license for the benefit of the research, benchmarking and networking communities. © 2017 The Institute of Electronics, Information and Communication Engineers.","Benchmarking; DNS64; IPv6 transition technology; Perfor- mance analysis","Article","Scopus"
"Oosterhof N.N.; Connolly A.C.; Haxby J.V.","Oosterhof, Nikolaas N. (24367429900); Connolly, Andrew C. (55015541800); Haxby, James V. (7004857212)","24367429900; 55015541800; 7004857212","CoSMoMVPA: Multi-modal multivariate pattern analysis of neuroimaging data in matlab/GNU octave","2016","Frontiers in Neuroinformatics","10.3389/fninf.2016.00027","250","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989851801&doi=10.3389%2ffninf.2016.00027&partnerID=40&md5=a072c21133597da128cf1e73b28ee822","Recent years have seen an increase in the popularity of multivariate pattern (MVP) analysis of functional magnetic resonance (fMRI) data, and, to a much lesser extent, magneto- and electro-encephalography (M/EEG) data. We present CoSMoMVPA, a lightweight MVPA (MVP analysis) toolbox implemented in the intersection of the Matlab and GNU Octave languages, that treats both fMRI and M/EEG data as first-class citizens. CoSMoMVPA supports all state-of-the-art MVP analysis techniques, including searchlight analyses, classification, correlations, representational similarity analysis, and the time generalization method. These can be used to address both data-driven and hypothesis-driven questions about neural organization and representations, both within and across: space, time, frequency bands, neuroimaging modalities, individuals, and species. It uses a uniform data representation of fMRI data in the volume or on the surface, and of M/EEG data at the sensor and source level. Through various external toolboxes, it directly supports reading and writing a variety of fMRI and M/EEG neuroimaging formats, and, where applicable, can convert between them. As a result, it can be integrated readily in existing pipelines and used with existing preprocessed datasets. CoSMoMVPA overloads the traditional volumetric searchlight concept to support neighborhoods for M/EEG and surface-based fMRI data, which supports localization of multivariate effects of interest across space, time, and frequency dimensions. CoSMoMVPA also provides a generalized approach to multiple comparison correction across these dimensions using Threshold-Free Cluster Enhancement with state-of-the-art clustering and permutation techniques. CoSMoMVPA is highly modular and uses abstractions to provide a uniform interface for a variety of MVP measures. Typical analyses require a few lines of code, making it accessible to beginner users. At the same time, expert programmers can easily extend its functionality. CoSMoMVPA comes with extensive documentation, including a variety of runnable demonstration scripts and analysis exercises (with example data and solutions). It uses best software engineering practices including version control, distributed development, an automated test suite, and continuous integration testing. It can be used with the proprietary Matlab and the free GNU Octave software, and it complies with open source distribution platforms such as NeuroDebian. CoSMoMVPA is Free/Open Source Software under the permissive MIT license. Website: http://cosmomvpa.org Sourcecode:https://github.com/CoSMoMVPA/CoSMoMVPA. © 2016 Oosterhof, Connolly and Haxby.","Cognitive neuroscience; Electroencephalography; Functional magnetic resonance imaging; Magnetoencephalography; Multi-variate pattern analysis; Open source; Software","Article","Scopus"
"Knight J.M.; Ivanov I.; Dougherty E.R.","Knight, Jason M. (26423016500); Ivanov, Ivan (57208266927); Dougherty, Edward R. (57203104116)","26423016500; 57208266927; 57203104116","MCMC implementation of the optimal Bayesian classifier for non-Gaussian models: Model-based RNA-Seq classification","2014","BMC Bioinformatics","10.1186/s12859-014-0401-3","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923930030&doi=10.1186%2fs12859-014-0401-3&partnerID=40&md5=9c921cda14a8bd412bad69092160ba34","Background: Sequencing datasets consist of a finite number of reads which map to specific regions of a reference genome. Most effort in modeling these datasets focuses on the detection of univariate differentially expressed genes. However, for classification, we must consider multiple genes and their interactions. Results: Thus, we introduce a hierarchical multivariate Poisson model (MP) and the associated optimal Bayesian classifier (OBC) for classifying samples using sequencing data. Lacking closed-form solutions, we employ a Monte Carlo Markov Chain (MCMC) approach to perform classification. We demonstrate superior or equivalent classification performance compared to typical classifiers for two synthetic datasets and over a range of classification problem difficulties. We also introduce the Bayesian minimum mean squared error (MMSE) conditional error estimator and demonstrate its computation over the feature space. In addition, we demonstrate superior or leading class performance over an RNA-Seq dataset containing two lung cancer tumor types from The Cancer Genome Atlas (TCGA). Conclusions: Through model-based, optimal Bayesian classification, we demonstrate superior classification performance for both synthetic and real RNA-Seq datasets. A tutorial video and Python source code is available under an open source license at. © Knight et al.; licensee BioMed Central Ltd.","Bayesian; Classification; Model-based; RNA-Seq","Article","Scopus"
"López-Fernández H.; Graña-Castro O.; Nogueira-Rodríguez A.; Reboiro-Jato M.; Glez-Peña D.","López-Fernández, Hugo (45061084000); Graña-Castro, Osvaldo (6506124355); Nogueira-Rodríguez, Alba (57213741518); Reboiro-Jato, Miguel (36088045500); Glez-Peña, Daniel (23091104700)","45061084000; 6506124355; 57213741518; 36088045500; 23091104700","Compi: A framework for portable and reproducible pipelines","2021","PeerJ Computer Science","10.7717/PEERJ-CS.593","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109459891&doi=10.7717%2fPEERJ-CS.593&partnerID=40&md5=59ac35278ba4609870e4c7c3299e8f7c","Compi is an application framework to develop end-user, pipeline-based applications with a primary emphasis on: (i) user interface generation, by automatically generating a command-line interface based on the pipeline specific parameter definitions; (ii) application packaging, with compi-dk, which is a version-control-friendly tool to package the pipeline application and its dependencies into a Docker image; and (iii) application distribution provided through a public repository of Compi pipelines, named Compi Hub, which allows users to discover, browse and reuse them easily. By addressing these three aspects, Compi goes beyond traditional workflow engines, having been specially designed for researchers who want to take advantage of common workflow engine features (such as automatic job scheduling or logging, among others) while keeping the simplicity and readability of shell scripts without the need to learn a new programming language. Here we discuss the design of various pipelines developed with Compi to describe its main functionalities, as well as to highlight the similarities and differences with similar tools that are available. An open-source distribution under the Apache 2.0 License is available from GitHub (available at https://github.com/sing-group/compi). Documentation and installers are available from Available at https://www.sing-group.org/compi. A specific repository for Compi pipelines is available from Compi Hub (available at https://www.sing-group.org/compihub. © Copyright 2021 López-Fernández et al. Distributed under Creative Commons CC-BY 4.0","Application development framework; Computational pipelines; Workflow management systems","Article","Scopus"
"Garrison E.; Guarracino A.","Garrison, Erik (39361398800); Guarracino, Andrea (57221350829)","39361398800; 57221350829","Unbiased pangenome graphs","2023","Bioinformatics (Oxford, England)","10.1093/bioinformatics/btac743","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145425638&doi=10.1093%2fbioinformatics%2fbtac743&partnerID=40&md5=59a1ea28e8b07b151e1dd89fd836fee3","MOTIVATION: Pangenome variation graphs model the mutual alignment of collections of DNA sequences. A set of pairwise alignments implies a variation graph, but there are no scalable methods to generate such a graph from these alignments. Existing related approaches depend on a single reference, a specific ordering of genomes or a de Bruijn model based on a fixed k-mer length. A scalable, self-contained method to build pangenome graphs without such limitations would be a key step in pangenome construction and manipulation pipelines. RESULTS: We design the seqwish algorithm, which builds a variation graph from a set of sequences and alignments between them. We first transform the alignment set into an implicit interval tree. To build up the variation graph, we query this tree-based representation of the alignments to reduce transitive matches into single DNA segments in a sequence graph. By recording the mapping from input sequence to output graph, we can trace the original paths through this graph, yielding a pangenome variation graph. We present an implementation that operates in external memory, using disk-backed data structures and lock-free parallel methods to drive the core graph induction step. We demonstrate that our method scales to very large graph induction problems by applying it to build pangenome graphs for several species. AVAILABILITY AND IMPLEMENTATION: seqwish is published as free software under the MIT open source license. Source code and documentation are available at https://github.com/ekg/seqwish. seqwish can be installed via Bioconda https://bioconda.github.io/recipes/seqwish/README.html or GNU Guix https://github.com/ekg/guix-genomics/blob/master/seqwish.scm. © The Author(s) 2022. Published by Oxford University Press.","","Article","Scopus"
"Vanfretti L.; Rabuzin T.; Baudette M.; Murad M.","Vanfretti, L. (23029592800); Rabuzin, T. (57189497416); Baudette, M. (55960804300); Murad, M. (57016314400)","23029592800; 57189497416; 55960804300; 57016314400","iTesla Power Systems Library (iPSL): A Modelica library for phasor time-domain simulations","2016","SoftwareX","10.1016/j.softx.2016.05.001","42","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971435087&doi=10.1016%2fj.softx.2016.05.001&partnerID=40&md5=32364d445d9025b40f994a4f3cb716b8","The iTesla Power Systems Library (iPSL) is a Modelica package providing a set of power system components for phasor time-domain modeling and simulation. The Modelica language provides a systematic approach to develop models using a formal mathematical description, that uniquely specifies the physical behavior of a component or the entire system. Furthermore, the standardized specification of the Modelica language (Modelica Association [1]) enables unambiguous model exchange by allowing any Modelica-compliant tool to utilize the models for simulation and their analyses without the need of a specific model transformation tool. As the Modelica language is being developed with open specifications, any tool that implements these requirements can be utilized. This gives users the freedom of choosing an Integrated Development Environment (IDE) of their choice. Furthermore, any integration solver can be implemented within a Modelica tool to simulate Modelica models. Additionally, Modelica is an object-oriented language, enabling code factorization and model re-use to improve the readability of a library by structuring it with object-oriented hierarchy. The developed library is released under an open source license to enable a wider distribution and let the user customize it to their specific needs. This paper describes the iPSL and provides illustrative application examples. © 2016 The Author(s)","Modelica; Power system; Simulation","Article","Scopus"
"Zych K.; Gort G.; Maliepaard C.A.; Jansen R.C.; Voorrips R.E.","Zych, Konrad (55991636400); Gort, Gerrit (6603413990); Maliepaard, Chris A. (6602403259); Jansen, Ritsert C. (7201964208); Voorrips, Roeland E. (6603582794)","55991636400; 6603413990; 6602403259; 7201964208; 6603582794","FitTetra 2.0 - Improved genotype calling for tetraploids with multiple population and parental data support","2019","BMC Bioinformatics","10.1186/s12859-019-2703-y","19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063222502&doi=10.1186%2fs12859-019-2703-y&partnerID=40&md5=5ed443526054b46385bad938e1969b94","Background: Genetic studies in tetraploids are lagging behind in comparison with studies of diploids as the complex genetics of tetraploids require much more elaborated computational methodologies. Recent advancements in development of molecular techniques and computational tools facilitate new methods for automated, high-throughput genotype calling in tetraploid species. We report on the upgrade of the widely-used fitTetra software aiming to improve its accuracy, which to date is hampered by technical artefacts in the data. Results: Our upgrade of the fitTetra package is designed for a more accurate modelling of complex collections of samples. The package fits a mixture model where some parameters of the model are estimated separately for each sub-collection. When a full-sib family is analyzed, we use parental genotypes to predict the expected segregation in terms of allele dosages in the offspring. More accurate modelling and use of parental data increases the accuracy of dosage calling. We tested the package on data obtained with an Affymetrix Axiom 60 k array and compared its performance with the original version and the recently published ClusterCall tool, showing that at least 20% more SNPs could be called with our updated. Conclusion: Our updated software package shows clearly improved performance in genotype calling accuracy. Estimation of mixing proportions of the underlying dosage distributions is separated for full-sib families (where mixture proportions can be estimated from the parental dosages and inheritance model) and unstructured populations (where they are based on the assumption of Hardy-Weinberg equilibrium). Additionally, as the distributions of signal ratios of the dosage classes can be assumed to be the same for all populations, including parental data for some subpopulations helps to improve fitting other populations as well. The R package fitTetra 2.0 is freely available under the GNU Public License as Additional file with this article. © 2019 The Author(s).","Autotetraploids; fitPoly; Genomics; Genotype calling; Genotyping; Polyploids","Article","Scopus"
"Steininger T.; Greiner M.; Beaujean F.; Enßlin T.","Steininger, Theo (57193436918); Greiner, Maksim (56379766000); Beaujean, Frederik (36918010400); Enßlin, Torsten (7004428302)","57193436918; 56379766000; 36918010400; 7004428302","d2o: a distributed data object for parallel high-performance computing in Python","2016","Journal of Big Data","10.1186/s40537-016-0052-5","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013925990&doi=10.1186%2fs40537-016-0052-5&partnerID=40&md5=d2907bc720641ef64f67fc4aadbd247c","We introduce d2o, a Python module for cluster-distributed multi-dimensional numerical arrays. It acts as a layer of abstraction between the algorithm code and the data-distribution logic. The main goal is to achieve usability without losing numerical performance and scalability. d2o’s global interface is similar to the one of a numpy.ndarray, whereas the cluster node’s local data is directly accessible for use in customized high-performance modules. d2o is written in pure Python which makes it portable and easy to use and modify. Expensive operations are carried out by dedicated external libraries like numpy and mpi4py. The performance of d2o is on a par with numpy for serial applications and scales well when moving to an MPI cluster. d2o is open-source software available under the GNU General Public License v3 (GPL-3) at https://gitlab.mpcdf.mpg.de/ift/D2O. © 2016, The Author(s).","MPI; Numerics; Numpy; Open source; Parallelization; Python","Article","Scopus"
"Rybiński M.; Möller S.; Sunnåker M.; Lormeau C.; Stelling J.","Rybiński, Mikołaj (55169766800); Möller, Simon (57201648841); Sunnåker, Mikael (36092195200); Lormeau, Claude (8222356500); Stelling, Jörg (57205546137)","55169766800; 57201648841; 36092195200; 8222356500; 57205546137","Topofilter: A matlab package for mechanistic model identification in systems biology","2020","BMC Bioinformatics","10.1186/s12859-020-3343-y","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078689466&doi=10.1186%2fs12859-020-3343-y&partnerID=40&md5=1e8cd4c18d1dc3688e20f58899db148d","Background: To develop mechanistic dynamic models in systems biology, one often needs to identify all (or minimal) representations of the biological processes that are consistent with experimental data, out of a potentially large set of hypothetical mechanisms. However, a simple enumeration of all alternatives becomes quickly intractable when the number of model parameters grows. Selecting appropriate dynamic models out of a large ensemble of models, taking the uncertainty in our biological knowledge and in the experimental data into account, is therefore a key current problem in systems biology. Results: The TopoFilter package addresses this problem in a heuristic and automated fashion by implementing the previously described topological filtering method for Bayesian model selection. It includes a core heuristic for searching the space of submodels of a parametrized model, coupled with a sampling-based exploration of the parameter space. Recent developments of the method allow to balance exhaustiveness and speed of the model space search, to efficiently re-sample parameters, to parallelize the search, and to use custom scoring functions. We use a theoretical example to motivate these features and then demonstrate TopoFilter's applicability for a yeast signaling network with more than 250'000 possible model structures. Conclusions: TopoFilter is a flexible software framework that makes Bayesian model selection and reduction efficient and scalable to network models of a complexity that represents contemporary problems in, for example, cell signaling. TopoFilter is open-source, available under the GPL-3.0 license at https://gitlab.com/csb.ethz/TopoFilter. It includes installation instructions, a quickstart guide, a description of all package options, and multiple examples. © 2020 The Author(s).","Bayesian model selection; Ensemble modeling; Signal transduction; Topological filtering","Article","Scopus"
"Liu X.; Truppe S.; Meijer G.; Pérez-Ríos J.","Liu, Xiangyue (57216877650); Truppe, Stefan (35173716900); Meijer, Gerard (57217803728); Pérez-Ríos, Jesús (35180307400)","57216877650; 35173716900; 57217803728; 35180307400","The diatomic molecular spectroscopy database","2020","Journal of Cheminformatics","10.1186/s13321-020-00433-8","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085095793&doi=10.1186%2fs13321-020-00433-8&partnerID=40&md5=9257b173a7e82cc6bbdb666ce13c92a6","Motivation: The spectroscopy of diatomic molecules is an important research area in chemical physics due to its relevance in astrochemistry, combustion chemistry, and ultracold physics. However, there is currently no database where the user can easily retrieve, in a useful format, the spectroscopic constants of a given molecule. A similar situation appears concerning the vibrational Franck-Condon factors for diatomic molecules, a crucial parameter to infer laser cooling prospects for molecules. To address this problem, and inspired by the idea that data should be open and freely accessible, we have developed a user-friendly website (https://rios.mp.fhi.mpg.de) where the user can retrieve spectroscopic constants and Franck-Condon factors in useful formats. Implementation: In this database, the spectroscopic constants of the ground states and first excited states of the diatomic molecules are accessible from the website and can be retrieved in readable formats. The website is implemented within the LAMP web service stacks. In particular, using Linux as the operative system, Apache as the HTTP Server, MySQL as the database management system, and PHP as the programming language for the web. Furthermore, the user can register and upload new data. This project is licensed under the Free-Libre/Open Source Software (FLOSS) license Apache License 2.0 which allows free and open access to the codes as well as efficient collaboration in the maintenance of the software. Conclusions and impact: The present data-driven website presents essential information in a user-friendly manner and may help the chemical physics community to identify molecules that should be explored through spectroscopic techniques. © 2020 The Author(s).","Franck-Condon factors; Laser cooling; Molecular spectroscopic constants; Open database","Article","Scopus"
"Kim M.; Vo D.D.; Kumagai M.E.; Jops C.T.; Gandal M.J.","Kim, Minsoo (57205057714); Vo, Daniel D. (57885162200); Kumagai, Michi E. (58047197500); Jops, Connor T. (57349247400); Gandal, Michael J. (25222786000)","57205057714; 57885162200; 58047197500; 57349247400; 25222786000","GeneticsMakie.jl: a versatile and scalable toolkit for visualizing locus-level genetic and genomic data","2023","Bioinformatics (Oxford, England)","10.1093/bioinformatics/btac786","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145954623&doi=10.1093%2fbioinformatics%2fbtac786&partnerID=40&md5=ae26f5ba5ce0ad740d1bbcf2d1746805","SUMMARY: With the continued deluge of results from genome-wide association and functional genomic studies, it has become increasingly imperative to quickly combine and visualize different layers of genetic and genomic data within a given locus to facilitate exploratory and integrative data analyses. While several tools have been developed to visualize locus-level genetic results, the limited speed, scalability and flexibility of current approaches remain a significant bottleneck. Here, we present a Julia package for high-performance genetics and genomics-related data visualization that enables fast, simultaneous plotting of hundreds of association results along with multiple relevant genomic annotations. Leveraging the powerful plotting and layout utilities from Makie.jl facilitates the customization and extensibility of every component of a plot, enabling generation of publication-ready figures. AVAILABILITY AND IMPLEMENTATION: The GeneticsMakie.jl package is open source and distributed under the MIT license via GitHub (https://github.com/mmkim1210/GeneticsMakie.jl). The GitHub repository contains installation instructions as well as examples and documentation for built-in functions. SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online. © The Author(s) 2022. Published by Oxford University Press.","","Article","Scopus"
"Rodchenkov I.; Demir E.; Sander C.; Bader G.D.","Rodchenkov, Igor (6506281687); Demir, Emek (35309628300); Sander, Chris (55146122100); Bader, Gary D. (7102726136)","6506281687; 35309628300; 55146122100; 7102726136","The BioPAX validator","2013","Bioinformatics","10.1093/bioinformatics/btt452","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885593464&doi=10.1093%2fbioinformatics%2fbtt452&partnerID=40&md5=0d23fdaabfcd9b43a0efa5aa40f8e66b","Summary: BioPAX is a community-developed standard language for biological pathway data. A key functionality required for efficient BioPAX data exchange is validation-detecting errors and inconsistencies in BioPAX documents. The BioPAX Validator is a commandline tool, Java library and online web service for BioPAX that performs 4100 classes of consistency checks. Availability and implementation: The validator recognizes common syntactic errors and semantic inconsistencies and reports them in a customizable human readable format. It can also automatically fix some errors and normalize BioPAX data. Since its release, the validator has become a critical tool for the pathway informatics community, detecting thousands of errors and helping substantially increase the conformity and uniformity of BioPAX-formatted data. The BioPAX Validator is open source and released under LGPL v3 license. All sources, binaries and documentation can be found at sf.net/p/ biopax, and the latest stable version of the web application is available at biopax.org/validator. Contact: igor.rodchenkov@utoronto.ca or gary.bader@utoronto.ca. © The Author 2013. Published by Oxford University Press.","","Article","Scopus"
"Weigand M.; Kemna A.","Weigand, M. (56911966100); Kemna, A. (6601948771)","56911966100; 6601948771","Debye decomposition of time-lapse spectral induced polarisation data","2016","Computers and Geosciences","10.1016/j.cageo.2015.09.021","35","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944704056&doi=10.1016%2fj.cageo.2015.09.021&partnerID=40&md5=7539b27963915308f441ccc1ad765617","Spectral induced polarisation (SIP) measurements capture the low-frequency electrical properties of soils and rocks and provide a non-invasive means to access lithological, hydrogeological, and geochemical properties of the subsurface. The Debye decomposition (DD) approach is now increasingly being used to analyse SIP signatures in terms of relaxation time distributions due to its flexibility regarding the shape of the spectra. Imaging and time-lapse (monitoring) SIP measurements, capturing SIP variations in space and time, respectively, are now more and more conducted and lead to a drastic increase in the number of spectra considered, which prompts the need for robust and reliable DD tools to extract quantitative parameters from such data. We here present an implementation of the DD method for the analysis of a series of SIP data sets which are expected to only smoothly change in terms of spectral behaviour, such as encountered in many time-lapse applications where measurement geometry does not change. The routine is based on a non-linear least-squares inversion scheme with smoothness constraints on the spectral variation and in addition from one spectrum of the series to the next to deal with the inherent ill-posedness and non-uniqueness of the problem. By means of synthetic examples with typical SIP characteristics we elucidate the influence of the number and range of considered relaxation times on the inversion results. The source code of the presented routines is provided under an open source licence as a basis for further applications and developments. © 2015 The Authors.","Debye decomposition; Spectral induced polarisation; Time-lapse inversion","Article","Scopus"
"Basu M.K.; Selengut J.D.; Haft D.H.","Basu, Malay K. (8979787900); Selengut, Jeremy D. (6602750204); Haft, Daniel H. (57204866117)","8979787900; 6602750204; 57204866117","ProPhylo: Partial phylogenetic profiling to guide protein family construction and assignment of biological process","2011","BMC Bioinformatics","10.1186/1471-2105-12-434","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80655139177&doi=10.1186%2f1471-2105-12-434&partnerID=40&md5=9309cf7702a7737974fa03cd291e5b32","Background: Phylogenetic profiling is a technique of scoring co-occurrence between a protein family and some other trait, usually another protein family, across a set of taxonomic groups. In spite of several refinements in recent years, the technique still invites significant improvement. To be its most effective, a phylogenetic profiling algorithm must be able to examine co-occurrences among protein families whose boundaries are uncertain within large homologous protein superfamilies.Results: Partial Phylogenetic Profiling (PPP) is an iterative algorithm that scores a given taxonomic profile against the taxonomic distribution of families for all proteins in a genome. The method works through optimizing the boundary of each protein family, rather than by relying on prebuilt protein families or fixed sequence similarity thresholds. Double Partial Phylogenetic Profiling (DPPP) is a related procedure that begins with a single sequence and searches for optimal granularities for its surrounding protein family in order to generate the best query profiles for PPP. We present ProPhylo, a high-performance software package for phylogenetic profiling studies through creating individually optimized protein family boundaries. ProPhylo provides precomputed databases for immediate use and tools for manipulating the taxonomic profiles used as queries.Conclusion: ProPhylo results show universal markers of methanogenesis, a new DNA phosphorothioation-dependent restriction enzyme, and efficacy in guiding protein family construction. The software and the associated databases are freely available under the open source Perl Artistic License from ftp://ftp.jcvi.org/pub/data/ppp/. © 2011 Basu et al; licensee BioMed Central Ltd.","","Article","Scopus"
"De Jay N.; Papillon-Cavanagh S.; Olsen C.; El-Hachem N.; Bontempi G.; Haibe-Kains B.","De Jay, Nicolas (55832446600); Papillon-Cavanagh, Simon (44261435500); Olsen, Catharina (57196924824); El-Hachem, Nehme (36930289700); Bontempi, Gianluca (6603615974); Haibe-Kains, Benjamin (23667678400)","55832446600; 44261435500; 57196924824; 36930289700; 6603615974; 23667678400","MRMRe: An R package for parallelized mRMR ensemble feature selection","2013","Bioinformatics","10.1093/bioinformatics/btt383","137","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883483361&doi=10.1093%2fbioinformatics%2fbtt383&partnerID=40&md5=0376171e8afb6a093cbcf6f1c67967ea","Motivation: Feature selection is one of the main challenges in analyzing high-throughput genomic data. Minimum redundancy maximum relevance (mRMR) is a particularly fast feature selection method for finding a set of both relevant and complementary features. Here we describe the mRMRe R package, in which the mRMR technique is extended by using an ensemble approach to better explore the feature space and build more robust predictors. To deal with the computational complexity of the ensemble approach, the main functions of the package are implemented and parallelized in C using the openMP Application Programming Interface.Results: Our ensemble mRMR implementations outperform the classical mRMR approach in terms of prediction accuracy. They identify genes more relevant to the biological context and may lead to richer biological interpretations. The parallelized functions included in the package show significant gains in terms of run-time speed when compared with previously released packages.Availability: The R package mRMRe is available on Comprehensive R Archive Network and is provided open source under the Artistic-2.0 License. The code used to generate all the results reported in this application note is available from Supplementary File 1. © The Author 2013.","","Article","Scopus"
"Lisitsyn S.; Widme C.; Garcia F.J.I.","Lisitsyn, Sergey (55292796000); Widme, Christian (24482810000); Garcia, Fernando J. Iglesias (55884135700)","55292796000; 24482810000; 55884135700","Tapkee: An efficient dimension reduction library","2013","Journal of Machine Learning Research","","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885642698&partnerID=40&md5=8dae9bd6673842a63e903a705eb48060","We present Tapkee, a C++ template library that provides efficient implementations of more than 20 widely used dimensionality reduction techniques ranging from Locally Linear Embedding (Roweis and Saul, 2000) and Isomap (de Silva and Tenenbaum, 2002) to the recently introduced Barnes-Hut-SNE (van der Maaten, 2013). Our library was designed with a focus on performance and flexibility. For performance, we combine efficient multi-core algorithms, modern data structures and state-of-the-art low-level libraries. To achieve flexibility, we designed a clean interface for applying methods to user data and provide a callback API that facilitates integration with the library. The library is freely available as open-source software and is distributed under the permissive BSD 3-clause license. We encourage the integration of Tapkee into other open-source toolboxes and libraries. For example, Tapkee has been integrated into the codebase of the Shogun toolbox (Sonnenburg et al., 2010), giving us access to a rich set of kernels, distance measures and bindings to common programming languages including Python, Octave, Matlab, R, Java, C#, Ruby, Perl and Lua. Source code, examples and documentation are available at http://tapkee.lisitsyn.me. © 2013 Sergey Lisitsyn, Christian Widmer and Fernando J. Iglesias Garcia.","C++; Dimensionality reduction; Machine learning; Open source software","Article","Scopus"
"Matthey T.; Cickovski T.; Hampton S.; Ko A.; Ma Q.; Nyerges M.; Raeder T.; Slabach T.; Izaguirre J.A.","Matthey, Thierry (6603411597); Cickovski, Trevor (6507498504); Hampton, Scott (7005791887); Ko, Alice (7007018352); Ma, Qun (26660624200); Nyerges, Matthew (7004547387); Raeder, Troy (6507846496); Slabach, Thomas (6508253520); Izaguirre, Jesús A. (6603905955)","6603411597; 6507498504; 7005791887; 7007018352; 26660624200; 7004547387; 6507846496; 6508253520; 6603905955","ProtoMol, an object-oriented framework for prototyping novel algorithms for molecular dynamics","2004","ACM Transactions on Mathematical Software","10.1145/1024074.1024075","64","https://www.scopus.com/inward/record.uri?eid=2-s2.0-8344261362&doi=10.1145%2f1024074.1024075&partnerID=40&md5=0aab79a2ee746289e44ae2977f6777a2","PROTOMOL is a high-performance framework in C++ for rapid prototyping of novel algorithms for molecular dynamics and related applications. Its flexibility is achieved primarily through the use of inheritance and design patterns (object-oriented programming). Performance is obtained by using templates that enable generation of efficient code for sections critical to performance (generic programming). The framework encapsulates important optimizations that can be used by developers, such as parallelism in the force computation. Its design is based on domain analysis of numerical integrators for molecular dynamics (MD) and of fast solvers for the force computation, particularly due to electrostatic interactions. Several new and efficient algorithms are implemented in PROTOMOL. Finally, it is shown that PROTOMOL'S sequential performance is excellent when compared to a leading MD program, and that it scales well for moderate number of processors. Binaries and source codes for Windows, Linux, Solaris, IRIX, HP-UX, and AIX platforms are available under open source license at http://protomol.sourceforge.net.","Fast electrostatic methods; Incremental parallelism; Molecular dynamics; Multigrid; Multiple time-stepping integration; Object-oriented framework","Article","Scopus"
"Griss J.; Gerner C.","Griss, Johannes (26632798400); Gerner, Christopher (7003781554)","26632798400; 7003781554","GPDE: A biological view on PRIDE","2009","Journal of Proteomics and Bioinformatics","10.4172/jpb.1000074","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-68549105828&doi=10.4172%2fjpb.1000074&partnerID=40&md5=ac2517bb77ff61c8b290c71475eba2dc","Clinical proteomics are unthinkable without the extensive use of meta-analysis. By the development of the Proteomics Identification Database Engine (PRIDE) extensive markup language (XML) data format in 2005 a standardized data format for proteomics data publishing was created. Here we present the Griss Proteomics Database Engine (GPDE, http://www.griss.co.at/?GPDE): an open source web-based bioinformatic tool that uses the possibilities of this standardized data format to create biologically-based meta-analysis over an unlimited number of proteomics experiments. Its aims are (1) to be fully compatible with the PRIDE XML data schema, (2) to integrate the data of different experiments or projects based on specially defined ""cell types"" thus dissolving the ""borders"" between different experiments and (3) to provide an intuitive web interface to access data otherwise only accessible via complex queries. The GPDE is free software and available for download under the terms of the Affero General Public License (AGPL, http://www.fsf.org/licensing/licenses/agpl-3.0.html). The GPDE is currently used by the Clinical Proteomics Laboratories at the Medical University of Vienna (CPL/MUW) (available at http://www.meduniwien.ac.at/proteomics/database). There the GPDE is used in three different ways: 1) as an in silico alternative to multiple Western analyses; 2) to provide easy access to cellular proteome reference maps and 3) to reliably support the assessment of the specificity of biomarker candidates. © 2009 Griss J, et al.","Biomarker discovery; Database; GPDE; Meta-analysis; Pride; Proteomics","Article","Scopus"
"Rodrigues M.R.; Magalhães W.C.S.; Machado M.; Tarazona-Santos E.","Rodrigues, Maíra R. (42062368800); Magalhães, Wagner C.S. (24168827800); Machado, Moara (37661875300); Tarazona-Santos, Eduardo (6602570139)","42062368800; 24168827800; 37661875300; 6602570139","A graph-based approach for designing extensible pipelines","2012","BMC Bioinformatics","10.1186/1471-2105-13-163","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863674803&doi=10.1186%2f1471-2105-13-163&partnerID=40&md5=6196f70103cf4774d5af1f2c543bcff2","Background: In bioinformatics, it is important to build extensible and low-maintenance systems that are able to deal with the new tools and data formats that are constantly being developed. The traditional and simplest implementation of pipelines involves hardcoding the execution steps into programs or scripts. This approach can lead to problems when a pipeline is expanding because the incorporation of new tools is often error prone and time consuming. Current approaches to pipeline development such as workflow management systems focus on analysis tasks that are systematically repeated without significant changes in their course of execution, such as genome annotation. However, more dynamism on the pipeline composition is necessary when each execution requires a different combination of steps.Results: We propose a graph-based approach to implement extensible and low-maintenance pipelines that is suitable for pipeline applications with multiple functionalities that require different combinations of steps in each execution. Here pipelines are composed automatically by compiling a specialised set of tools on demand, depending on the functionality required, instead of specifying every sequence of tools in advance. We represent the connectivity of pipeline components with a directed graph in which components are the graph edges, their inputs and outputs are the graph nodes, and the paths through the graph are pipelines. To that end, we developed special data structures and a pipeline system algorithm. We demonstrate the applicability of our approach by implementing a format conversion pipeline for the fields of population genetics and genetic epidemiology, but our approach is also helpful in other fields where the use of multiple software is necessary to perform comprehensive analyses, such as gene expression and proteomics analyses. The project code, documentation and the Java executables are available under an open source license at http://code.google.com/p/dynamic-pipeline. The system has been tested on Linux and Windows platforms.Conclusions: Our graph-based approach enables the automatic creation of pipelines by compiling a specialised set of tools on demand, depending on the functionality required. It also allows the implementation of extensible and low-maintenance pipelines and contributes towards consolidating openness and collaboration in bioinformatics systems. It is targeted at pipeline developers and is suited for implementing applications with sequential execution steps and combined functionalities. In the format conversion application, the automatic combination of conversion tools increased both the number of possible conversions available to the user and the extensibility of the system to allow for future updates with new file formats. © 2012 Rodrigues et al.; licensee BioMed Central Ltd.","","Article","Scopus"
"Sojer M.; Alexy O.; Kleinknecht S.; Henkel J.","Sojer, Manuel (15021403000); Alexy, Oliver (36439193000); Kleinknecht, Sven (56769760800); Henkel, Joachim (15822422700)","15021403000; 36439193000; 56769760800; 15822422700","Understanding the Drivers of Unethical Programming Behavior: The Inappropriate Reuse of Internet-Accessible Code","2014","Journal of Management Information Systems","10.1080/07421222.2014.995563","26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938873635&doi=10.1080%2f07421222.2014.995563&partnerID=40&md5=da88798003406785e7b5371901a8c745","Programming is riddled with ethical issues. Although extant literature explains why individuals in IT would act unethically in many situations, we know surprisingly little about what causes them to do so during the creative act of programming. To address this issue, we look at the reuse of Internet-accessible code: software source code legally available for gratis download from the Internet. Specifically, we scrutinize the reasons why individuals would unethically reuse such code by not checking or purposefully violating its accompanying license obligations, thus risking harm for their employer. By integrating teleological and deontological ethical judgments into a theory of planned behavior model - using elements of expected utility, deterrence, and ethical work climate theory - we construct an original theoretical framework to capture individuals' decision-making process leading to the unethical reuse of Internet-accessible code. We test this framework with a unique survey of 869 professional software developers. Our findings advance the theoretical and practical understanding of ethical behavior in information systems. We show that programmers use consequentialist ethical judgments when carrying out creative tasks and that ethical work climates influence programmers indirectly through their peers' judgment of what is appropriate behavior. For practice, where code reuse promises substantial efficiency and quality gains, our results highlight that firms can prevent unethical code reuse by informing developers of its negative consequences, building a work climate that fosters compliance with laws and professional codes, and making sure that excessive time pressure is avoided. Copyright © Taylor & Francis Group, LLC.","code reuse; ethical behavior; information systems ethics; Internet-accessible code; open source software; partial least squares; programming ethics; theory of planned behavior","Article","Scopus"
"Mamagiannou E.; Pitenis E.; Natsiopoulos D.A.; Vergos G.S.; Tziavos I.N.","Mamagiannou, Elisavet (57782118600); Pitenis, Eleftherios (57780803900); Natsiopoulos, Dimitrios A. (57190972128); Vergos, Georgios S. (8407418700); Tziavos, Ilias N. (6601969866)","57782118600; 57780803900; 57190972128; 8407418700; 6601969866","GeoGravGOCE: A standalone MATLAB GUI for processing GOCE satellite gradient data","2022","Computers and Geosciences","10.1016/j.cageo.2022.105184","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133478204&doi=10.1016%2fj.cageo.2022.105184&partnerID=40&md5=667e4d35fd2c655d11dc5494ecc45d1f","The exploitation of data from the Global Ocean Circulation Explorer (GOCE) mission still offers unique insights in Earth system processes despite the fact that the mission has been completed more than eight years ago. The use of GOCE data requires tedious and cumbersome processing in order to extract them from their original format, process them in the various reference frames and filter them to derive final products at the orbital altitude. GeoGravGOCE is an open-source software, developed in MATLAB, which aims to provide a friendly Graphical User Interface (GUI) to process the original GOCE gradiometric observations, i.e., second-order derivatives of the gravitational potential as provided by the European Space Agency. It is composed of four main tabs, which first allows the GOCE gradient pre-processing and the transformation of gradients from a geopotential models to the gradiometric reference frame. Then, the spectral filtering and the mutual transformations of gravity gradients between the four reference systems used in satellite gravimetry can be carried out. Three main filtering methods are implemented within the software, referring to: Finite Impulse Response (FIR), Infinite Impulse Response (IIR), and Wavelet Multi-Resolution Analysis (WL-MRA) filters. The user is free to select the desired degree of filtering and evaluate the derived results in terms of both the power spectral density of the filtered signals and their spatial distribution. The present work gives an analytical outline of the program, along with its various functionalities, while results derived from the processing of original GOCE data are presented as well. GeoGravGOCE is a free software under the GNU license and can be freely accessed via the project webpage http://olimpia.topo.auth.gr/GeoGravGOCE/. © 2022 The Authors","FIR; GOCE mission; Gravity gradients; IIR; MATLAB GUI; Reference frame transformation; Wavelet filtering","Article","Scopus"
"Miolane N.; Guigui N.; Le Brigant A.; Mathe J.; Hou B.; Thanwerdas Y.; Heyder S.; Peltre O.; Koep N.; Zaatiti H.; Hajri H.; Cabanes Y.; Gerald T.; Chauchat P.; Shewmake C.; Brooks D.; Kainz B.; Donnat C.; Holmes S.; Pennec X.","Miolane, Nina (56667563400); Guigui, Nicolas (57212571697); Le Brigant, Alice (57190735929); Mathe, Johan (57219522686); Hou, Benjamin (57193190944); Thanwerdas, Yann (57212576297); Heyder, Stefan (57219694418); Peltre, Olivier (57212574627); Koep, Niklas (56941001000); Zaatiti, Hadi (57188762577); Hajri, Hatem (51461201600); Cabanes, Yann (57210210830); Gerald, Thomas (57197832064); Chauchat, Paul (57217959303); Shewmake, Christian (57219685375); Brooks, Daniel (57203928409); Kainz, Bernhard (25937325100); Donnat, Claire (57203205066); Holmes, Susan (7203030601); Pennec, Xavier (7003505762)","56667563400; 57212571697; 57190735929; 57219522686; 57193190944; 57212576297; 57219694418; 57212574627; 56941001000; 57188762577; 51461201600; 57210210830; 57197832064; 57217959303; 57219685375; 57203928409; 25937325100; 57203205066; 7203030601; 7003505762","Geomstats: A python package for riemannian geometry in machine learning","2020","Journal of Machine Learning Research","","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098458681&partnerID=40&md5=70c95d61425be6704496ef75e07e4dce","We introduce Geomstats, an open-source Python package for computations and statistics on nonlinear manifolds such as hyperbolic spaces, spaces of symmetric positive definite matrices, Lie groups of transformations, and many more. We provide object-oriented and extensively unit-tested implementations. Manifolds come equipped with families of Riemannian metrics with associated exponential and logarithmic maps, geodesics, and parallel transport. Statistics and learning algorithms provide methods for estimation, clustering, and dimension reduction on manifolds. All associated operations are vectorized for batch computation and provide support for different execution backends-namely NumPy, PyTorch, and TensorFlow. This paper presents the package, compares it with related libraries, and provides relevant code examples. We show that Geomstats provides reliable building blocks to both foster research in differential geometry and statistics and democratize the use of Riemannian geometry in machine learning applications. The source code is freely available under the MIT license at geomstats.ai. © 2020 Nina Miolane, Nicolas Guigui, Alice Le Brigant, Johan Mathe, Benjamin Hou, Yann Thanwerdas, Stefan Heyder, Olivier Peltre, Niklas Koep, Hadi Zaatiti, Hatem Hajri, Yann Cabanes, Thomas Gerald, Paul Chauchat, Christian Shewmake, Daniel Brooks, Bernhard Kainz, Claire Donnat, Susan Holmes and Xavier Pennec. License: CC-BY 4.0, see https://creativecommons.org/licenses/by/4.0/. Attribution requirements are provided at http://jmlr.org/papers/v21/19-027.html.","Differential geometry; Machine learning; Manifold; Riemannian geometry; Statistics","Article","Scopus"
"Wu Y.; Wang S.; Bezemer C.-P.; Inoue K.","Wu, Yuhao (57095239500); Wang, Shaowei (54685504200); Bezemer, Cor-Paul (35742992600); Inoue, Katsuro (7601540520)","57095239500; 54685504200; 35742992600; 7601540520","How do developers utilize source code from stack overflow?","2019","Empirical Software Engineering","10.1007/s10664-018-9634-5","48","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049571873&doi=10.1007%2fs10664-018-9634-5&partnerID=40&md5=0d9dc751b467f3d48c59d37e06855209","Technical question and answer Q&A platforms, such as Stack Overflow, provide a platform for users to ask and answer questions about a wide variety of programming topics. These platforms accumulate a large amount of knowledge, including hundreds of thousands lines of source code. Developers can benefit from the source code that is attached to the questions and answers on Q&A platforms by copying or learning from (parts of) it. By understanding how developers utilize source code from Q&A platforms, we can provide insights for researchers which can be used to improve next-generation Q&A platforms to help developers reuse source code fast and easily. In this paper, we first conduct an exploratory study on 289 files from 182 open-source projects, which contain source code that has an explicit reference to a Stack Overflow post. Our goal is to understand how developers utilize code from Q&A platforms and to reveal barriers that may make code reuse more difficult. In 31.5% of the studied files, developers needed to modify source code from Stack Overflow to make it work in their own projects. The degree of required modification varied from simply renaming variables to rewriting the whole algorithm. Developers sometimes chose to implement an algorithm from scratch based on the descriptions from Stack Overflow answers, even if there was an implementation readily available in the post. In 35.5% of the studied files, developers used Stack Overflow posts as an information source for later reference. To further understand the barriers of reusing code and to obtain suggestions for improving the code reuse process on Q&A platforms, we conducted a survey with 453 open-source developers who are also on Stack Overflow. We found that the top 3 barriers that make it difficult for developers to reuse code from Stack Overflow are: (1) too much code modification required to fit in their projects, (2) incomprehensive code, and (3) low code quality. We summarized and analyzed all survey responses and we identified that developers suggest improvements for future Q&A platforms along the following dimensions: code quality, information enhancement & management, data organization, license, and the human factor. For instance, developers suggest to improve the code quality by adding an integrated validator that can test source code online, and an outdated code detection mechanism. Our findings can be used as a roadmap for researchers and developers to improve code reuse. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","","Article","Scopus"
"Glicksberg B.S.; Oskotsky B.; Thangaraj P.M.; Giangreco N.; Badgeley M.A.; Johnson K.W.; Datta D.; Rudrapatna V.A.; Rappoport N.; Shervey M.M.; Miotto R.; Goldstein T.C.; Rutenberg E.; Frazier R.; Lee N.; Israni S.; Larsen R.; Percha B.; Li L.; Dudley J.T.; Tatonetti N.P.; Butte A.J.; Wren J.","Glicksberg, Benjamin S. (55845627200); Oskotsky, Boris (57196193993); Thangaraj, Phyllis M. (57203848211); Giangreco, Nicholas (57195370965); Badgeley, Marcus A. (55262062500); Johnson, Kipp W. (55522229700); Datta, Debajyoti (57211526806); Rudrapatna, Vivek A. (57193290890); Rappoport, Nadav (36673704500); Shervey, Mark M. (57202109467); Miotto, Riccardo (57202034402); Goldstein, Theodore C. (57208459316); Rutenberg, Eugenia (57211527573); Frazier, Remi (57211527179); Lee, Nelson (57201072023); Israni, Sharat (57197752356); Larsen, Rick (57211526133); Percha, Bethany (9841093300); Li, Li (56370080000); Dudley, Joel T. (18633685600); Tatonetti, Nicholas P. (35604787200); Butte, Atul J. (7003333396); Wren, Jonathan (7005385633)","55845627200; 57196193993; 57203848211; 57195370965; 55262062500; 55522229700; 57211526806; 57193290890; 36673704500; 57202109467; 57202034402; 57208459316; 57211527573; 57211527179; 57201072023; 57197752356; 57211526133; 9841093300; 56370080000; 18633685600; 35604787200; 7003333396; 7005385633","PatientExploreR: An extensible application for dynamic visualization of patient clinical history from electronic health records in the OMOP common data model","2019","Bioinformatics","10.1093/bioinformatics/btz409","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074306462&doi=10.1093%2fbioinformatics%2fbtz409&partnerID=40&md5=1b2d1544c27f3e9bbf88af18a5caec2f","Motivation: Electronic health records (EHRs) are quickly becoming omnipresent in healthcare, but interoperability issues and technical demands limit their use for biomedical and clinical research. Interactive and flexible software that interfaces directly with EHR data structured around a common data model (CDM) could accelerate more EHR-based research by making the data more accessible to researchers who lack computational expertise and/or domain knowledge. Results: We present PatientExploreR, an extensible application built on the R/Shiny framework that interfaces with a relational database of EHR data in the Observational Medical Outcomes Partnership CDM format. PatientExploreR produces patient-level interactive and dynamic reports and facilitates visualization of clinical data without any programming required. It allows researchers to easily construct and export patient cohorts from the EHR for analysis with other software. This application could enable easier exploration of patient-level data for physicians and researchers. PatientExploreR can incorporate EHR data from any institution that employs the CDM for users with approved access. The software code is free and open source under the MIT license, enabling institutions to install and users to expand and modify the application for their own purposes. Availability and implementation: PatientExploreR can be freely obtained from GitHub: https://github.com/BenGlicksberg/PatientExploreR. We provide instructions for how researchers with approved access to their institutional EHR can use this package. We also release an open sandbox server of synthesized patient data for users without EHR access to explore: http://patientexplorer.ucsf.edu. Supplementary information: Supplementary data are available at Bioinformatics online. © 2019 The Author(s) 2019. Published by Oxford University Press.","","Article","Scopus"
"Shah S.P.; He D.Y.M.; Sawkins J.N.; Druce J.C.; Quon G.; Lett D.; Zheng G.X.Y.; Xu T.; Ouellette B.F.F.","Shah, Sohrab P. (7403888751); He, David Y.M. (55885766800); Sawkins, Jessica N. (6602853809); Druce, Jeffrey C. (55885667400); Quon, Gerald (6507836772); Lett, Drew (6602217172); Zheng, Grace X.Y. (35075509200); Xu, Tao (56612145300); Ouellette, B.F. Francis (6603899294)","7403888751; 55885766800; 6602853809; 55885667400; 6507836772; 6602217172; 35075509200; 56612145300; 6603899294","Pegasys: Software for executing and integrating analyses of biological sequences","2004","BMC Bioinformatics","10.1186/1471-2105-5-40","67","https://www.scopus.com/inward/record.uri?eid=2-s2.0-2942544409&doi=10.1186%2f1471-2105-5-40&partnerID=40&md5=95a5124652b59df8d41e739a1e3f594d","Background: We present Pegasys - a flexible, modular and customizable software system that facilitates the execution and data integration from heterogeneous biological sequence analysis tools. Results: The Pegasys system includes numerous tools for pair-wise and multiple sequence alignment, ab initio gene prediction, RNA gene detection, masking repetitive sequences in genomic DNA as well as filters for database formatting and processing raw output from various analysis tools. We introduce a novel data structure for creating workflows of sequence analyses and a unified data model to store its results. The software allows users to dynamically create analysis workflows at run-time by manipulating a graphical user interface. All non-serial dependent analyses are executed in parallel on a compute cluster for efficiency of data generation. The uniform data model and backend relational database management system of Pegasys allow for results of heterogeneous programs included in the workflow to be integrated and exported into General Feature Format for further analyses in GFF-dependent tools, or GAME XML for import into the Apollo genome editor. The modularity of the design allows for new tools to be added to the system with little programmer overhead. The database application programming interface allows programmatic access to the data stored in the backend through SQL queries. Conclusions: The Pegasys system enables biologists and bioinformaticians to create and manage sequence analysis workflows. The software is released under the Open Source GNU General Public License. © 2004 Shah et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Broeksema B.; Calusinska M.; McGee F.; Winter K.; Bongiovanni F.; Goux X.; Wilmes P.; Delfosse P.; Ghoniem M.","Broeksema, Bertjan (54405503400); Calusinska, Magdalena (35723912400); McGee, Fintan (9040105500); Winter, Klaas (57194111008); Bongiovanni, Francesco (57226735524); Goux, Xavier (55266549500); Wilmes, Paul (57207607143); Delfosse, Philippe (6701446316); Ghoniem, Mohammad (8261997800)","54405503400; 35723912400; 9040105500; 57194111008; 57226735524; 55266549500; 57207607143; 6701446316; 8261997800","ICoVeR - an interactive visualization tool for verification and refinement of metagenomic bins","2017","BMC Bioinformatics","10.1186/s12859-017-1653-5","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018746504&doi=10.1186%2fs12859-017-1653-5&partnerID=40&md5=ca7eb382564aa7385715d38a12cc7ac3","Background: Recent advances in high-throughput sequencing allow for much deeper exploitation of natural and engineered microbial communities, and to unravel so-called ""microbial dark matter"" (microbes that until now have evaded cultivation). Metagenomic analyses result in a large number of genomic fragments (contigs) that need to be grouped (binned) in order to reconstruct draft microbial genomes. While several contig binning algorithms have been developed in the past 2 years, they often lack consensus. Furthermore, these software tools typically lack a provision for the visualization of data and bin characteristics. Results: We present ICoVeR, the Interactive Contig-bin Verification and Refinement tool, which allows the visualization of genome bins. More specifically, ICoVeR allows curation of bin assignments based on multiple binning algorithms. Its visualization window is composed of two connected and interactive main views, including a parallel coordinates view and a dimensionality reduction plot. To demonstrate ICoVeR's utility, we used it to refine disparate genome bins automatically generated using MetaBAT, CONCOCT and MyCC for an anaerobic digestion metagenomic (AD microbiome) dataset. Out of 31 refined genome bins, 23 were characterized with higher completeness and lower contamination in comparison to their respective, automatically generated, genome bins. Additionally, to benchmark ICoVeR against a previously validated dataset, we used Sharon's dataset representing an infant gut metagenome. Conclusions: ICoVeR is an open source software package that allows curation of disparate genome bins generated with automatic binning algorithms. It is freely available under the GPLv3 license at https://git.list.lu/eScience/ICoVeR. The data management and analytical functions of ICoVeR are implemented in R, therefore the software can be easily installed on any system for which R is available. Installation and usage guide together with the example files ready to be visualized are also provided via the project wiki. ICoVeR running instance preloaded with AD microbiome and Sharon's datasets can be accessed via the website. © 2017 The Author(s).","Contig bin visualization; Genome reconstruction; Metagenomics; Software","Article","Scopus"
"Kochev N.; Avramova S.; Jeliazkova N.","Kochev, Nikolay (7801569368); Avramova, Svetlana (57203511295); Jeliazkova, Nina (8378341000)","7801569368; 57203511295; 8378341000","Ambit-SMIRKS: a software module for reaction representation, reaction search and structure transformation","2018","Journal of Cheminformatics","10.1186/s13321-018-0295-6","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051957228&doi=10.1186%2fs13321-018-0295-6&partnerID=40&md5=74c0c1aa2d6ae88af36ebfb8c4f19a2e","Ambit-SMIRKS is an open source software, enabling structure transformation via the SMIRKS language and implemented as an extension of Ambit-SMARTS. As part of the Ambit project it builds on top of The Chemistry Development Kit (The CDK). Ambit-SMIRKS provides the following functionalities: parsing of SMIRKS linear notations into internal reaction (transformation) representations based on The CDK objects, application of the stored reactions against target (reactant) molecules for actual transformation of the target chemical objects, reaction searching, stereo information handling, product post-processing, etc. The transformations can be applied on various sites of the reactant molecule in several modes: single, non-overlapping, non-identical, non-homomorphic or externally specified list of sites utilizing efficient substructure searching algorithm. Ambit-SMIRKS handles the molecules stereo information and supports basic chemical stereo elements implemented in The CDK library. The full SMARTS logical expressions syntax for reactions specification is supported, including recursive SMARTS expressions as well as additional syntax extensions. Since its initial development for the purpose of metabolite generation within Toxtree, the Ambit-SMIRKS module was used in various chemoinformatics projects, both developed by the authors of the package and by external teams. We show several use cases of the Ambit-SMIRKS software including standardization of large chemical databases and pathway transformation database and prediction. Ambit-SMIRKS is distributed as a Java library under LGPL license. More information on use cases and applications, including download links is available at http://ambit.sourceforge.net/smirks. © 2018, The Author(s).","Linear notation; Reaction presentation; SMIRKS; Software library; Structure transformation","Article","Scopus"
"Greenfield P.; Miller T.","Greenfield, P. (43961164600); Miller, T. (57198615493)","43961164600; 57198615493","The Calibration Reference Data System","2016","Astronomy and Computing","10.1016/j.ascom.2016.04.001","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966372696&doi=10.1016%2fj.ascom.2016.04.001&partnerID=40&md5=16b87660c76a5fc316cf6f8cf835ca7d","We describe a software architecture and implementation for using rules to determine which calibration files are appropriate for calibrating a given observation. This new system, the Calibration Reference Data System (CRDS), replaces what had been previously used for the Hubble Space Telescope (HST) calibration pipelines, the Calibration Database System (CDBS). CRDS will be used for the James Webb Space Telescope (JWST) calibration pipelines, and is currently being used for HST calibration pipelines. CRDS can be easily generalized for use in similar applications that need a rules-based system for selecting the appropriate item for a given dataset; we give some examples of such generalizations that will likely be used for JWST. The core functionality of the Calibration Reference Data System is available under an Open Source license. CRDS is briefly contrasted with a sampling of other similar systems used at other observatories. © 2016 Published by Elsevier B.V.","Calibration; Pipelines","Article","Scopus"
"Zhang W.; Cheng A.M.K.; Subhlok J.","Zhang, Weizhe (35263372000); Cheng, Albert M.K. (7402075079); Subhlok, Jaspal (6701413086)","35263372000; 7402075079; 6701413086","DwarfCode: A performance prediction tool for parallel applications","2016","IEEE Transactions on Computers","10.1109/TC.2015.2417526","19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962053261&doi=10.1109%2fTC.2015.2417526&partnerID=40&md5=284893c3c985072d2fd8632301c29d49","We present DwarfCode, a performance prediction tool for MPI applications on diverse computing platforms. The goal is to accurately predict the running time of applications for task scheduling and job migration. First, DwarfCode collects the execution traces to record the computing and communication events. Then, it merges the traces from different processes into a single trace. After that, DwarfCode identifies and compresses the repeating patterns in the final trace to shrink the size of the events. Finally, a dwarf code is generated to mimic the original program behavior. This smaller running benchmark is replayed in the target platform to predict the performance of the original application. In order to generate such a benchmark, two major challenges are to reduce the time complexity of trace merging and repeat compression algorithms. We propose an O(mpn) trace merging algorithm to combine the traces generated by separate MPI processes, where m denotes the upper bound of tracing distance, p denotes the number of processes, and n denotes the maximum of event numbers of all the traces. More importantly, we put forward a novel repeat compression algorithm, whose time complexity is O(nlogn). Experimental results show that DwarfCode can accurately predict the running time of MPI applications. The error rate is below 10 percent for compute and communication intensive applications. This toolkit has been released for free download as a GNU General Public License v3 software. © 1968-2012 IEEE.","DwarfCode; MPI application; Performance prediction; trace compressing; trace merging","Article","Scopus"
"Huang H.-D.; Lee C.-S.; Wang M.-H.; Kao H.-Y.","Huang, Hsien-De (55557406800); Lee, Chang-Shing (26435840500); Wang, Mei-Hui (36244824800); Kao, Hung-Yu (35292548600)","55557406800; 26435840500; 36244824800; 35292548600","IT2FS-based ontology with soft-computing mechanism for malware behavior analysis","2014","Soft Computing","10.1007/s00500-013-1056-0","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892669628&doi=10.1007%2fs00500-013-1056-0&partnerID=40&md5=d983e8b3f172855d8948fab3b84abeb8","Antimalware application is one of the most important research issues in the area of cyber security threat. Nowadays, because hackers continuously develop novel techniques to intrude into computer systems for various reasons, many security researchers should analyze and track new malicious program to protect sensitive and valuable information in the organization. In this paper, we propose a novel soft-computing mechanism based on the ontology model for malware behavioral analysis: Malware Analysis Network in Taiwan (MAN in Taiwan, MiT). The core techniques of MiT contain two parts listed as follows: (1) collect the logs of network connection, registry, and memory from the operation system on the physical-virtual hybrid analysis environment to get and extract more unknown malicious behavior information. The important information is then extracted to construct the ontology model by using the Web Ontology Language and Fuzzy Markup Language. Additionally, MiT is also able to automatically provide and share samples and reports via the cloud storage mechanism; (2) apply the techniques of Interval Type-2 Fuzzy Set to construct the malware analysis domain knowledge, namely the Interval Type-2 Fuzzy Malware Ontology (IT2FMO), for malware behavior analysis. Simulation results show that the proposed approach can effectively execute the malware behavior analysis, and the constructed system has also released under GNU General Public License version 3. In the future, the system is expected to largely collect and analyze malware samples for providing industries or universities to do related applications via the established IT2FMO. © 2013 Springer-Verlag Berlin Heidelberg.","Fuzzy markup language; Malware behavioral analysis; Ontology; Soft computing; Type-2 fuzzy set","Article","Scopus"
"Sahadevan S.; Sekaran T.; Ashaf N.; Fritz M.; Hentze M.W.; Huber W.; Schwarzl T.","Sahadevan, Sudeep (55433693500); Sekaran, Thileepan (56091644200); Ashaf, Nadia (58047145900); Fritz, Marko (58047258700); Hentze, Matthias W. (7007053212); Huber, Wolfgang (57548428500); Schwarzl, Thomas (56636900300)","55433693500; 56091644200; 58047145900; 58047258700; 7007053212; 57548428500; 56636900300","htseq-clip: a toolset for the preprocessing of eCLIP/iCLIP datasets","2023","Bioinformatics (Oxford, England)","10.1093/bioinformatics/btac747","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145955312&doi=10.1093%2fbioinformatics%2fbtac747&partnerID=40&md5=5fcc56fb11ef291d1a64f0778f367cc5","SUMMARY: Transcriptome-wide detection of binding sites of RNA-binding proteins is achieved using Individual-nucleotide crosslinking and immunoprecipitation (iCLIP) and its derivative enhanced CLIP (eCLIP) sequencing methods. Here, we introduce htseq-clip, a python package developed for preprocessing, extracting and summarizing crosslink site counts from i/eCLIP experimental data. The package delivers crosslink site count matrices along with other metrics, which can be directly used for filtering and downstream analyses such as the identification of differential binding sites. AVAILABILITY AND IMPLEMENTATION: The Python package htseq-clip is available via pypi (python package index), bioconda and the Galaxy Tool Shed under the open source MIT License. The code is hosted at https://github.com/EMBL-Hentze-group/htseq-clip and documentation is available under https://htseq-clip.readthedocs.io/en/latest. © The Author(s) 2022. Published by Oxford University Press.","","Article","Scopus"
"Arias-Carrasco R.; Vásquez-Morán Y.; Nakaya H.I.; Maracaja-Coutinho V.","Arias-Carrasco, Raúl (57200334302); Vásquez-Morán, Yessenia (57200677567); Nakaya, Helder I. (36843586800); Maracaja-Coutinho, Vinicius (29068002000)","57200334302; 57200677567; 36843586800; 29068002000","StructRNAfinder: An automated pipeline and web server for RNA families prediction","2018","BMC Bioinformatics","10.1186/s12859-018-2052-2","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042154072&doi=10.1186%2fs12859-018-2052-2&partnerID=40&md5=551345fc14a72f8e8fc50e224f6e7745","Background: The function of many noncoding RNAs (ncRNAs) depend upon their secondary structures. Over the last decades, several methodologies have been developed to predict such structures or to use them to functionally annotate RNAs into RNA families. However, to fully perform this analysis, researchers should utilize multiple tools, which require the constant parsing and processing of several intermediate files. This makes the large-scale prediction and annotation of RNAs a daunting task even to researchers with good computational or bioinformatics skills. Results: We present an automated pipeline named StructRNAfinder that predicts and annotates RNA families in transcript or genome sequences. This single tool not only displays the sequence/structural consensus alignments for each RNA family, according to Rfam database but also provides a taxonomic overview for each assigned functional RNA. Moreover, we implemented a user-friendly web service that allows researchers to upload their own nucleotide sequences in order to perform the whole analysis. Finally, we provided a stand-alone version of StructRNAfinder to be used in large-scale projects. The tool was developed under GNU General Public License (GPLv3) and is freely available at http://structrnafinder.integrativebioinformatics.me. Conclusions: The main advantage of StructRNAfinder relies on the large-scale processing and integrating the data obtained by each tool and database employed along the workflow, of which several files are generated and displayed in user-friendly reports, useful for downstream analyses and data exploration. © 2018 The Author(s).","Covariance models; Noncoding RNAs; Pipeline; RNA family; RNA structure; Tool; Web server","Article","Scopus"
"Saito T.L.; Yoshimura J.; Sasaki S.; Ahsan B.; Sasaki A.; Kuroshu R.; Morishita S.","Saito, Taro L. (35337582800); Yoshimura, Jun (27968234100); Sasaki, Shin (55743012500); Ahsan, Budrul (16443962200); Sasaki, Atsushi (35338081600); Kuroshu, Reginaldo (35337279700); Morishita, Shinichi (7102349168)","35337582800; 27968234100; 55743012500; 16443962200; 35338081600; 35337279700; 7102349168","UTGB toolkit for personalized genome browsers","2009","Bioinformatics","10.1093/bioinformatics/btp350","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-67650760507&doi=10.1093%2fbioinformatics%2fbtp350&partnerID=40&md5=e8a1975f712026d895147b956af1e504","The advent of high-throughput DNA sequencers has increased the pace of collecting enormous amounts of genomic information, yielding billions of nucleotides on a weekly basis. This advance represents an improvement of two orders of magnitude over traditional Sanger sequencers in terms of the number of nucleotides per unit time, allowing even small groups of researchers to obtain huge volumes of genomic data over fairly short period. Consequently, a pressing need exists for the development of personalized genome browsers for analyzing these immense amounts of locally stored data. The UTGB (University of Tokyo Genome Browser) Toolkit is designed to meet three major requirements for personalization of genome browsers: easy installation of the system with minimum efforts, browsing locally stored data and rapid interactive design of web interfaces tailored to individual needs. The UTGB Toolkit is licensed under an open source license. © 2009 The Author(s).","","Article","Scopus"
"Cui J.; Xu L.; Bressler S.L.; Ding M.; Liang H.","Cui, Jie (57199384316); Xu, Lei (57219036433); Bressler, Steven L. (55403619000); Ding, Mingzhou (57199665712); Liang, Hualou (7402853981)","57199384316; 57219036433; 55403619000; 57199665712; 7402853981","BSMART: A Matlab/C toolbox for analysis of multichannel neural time series","2008","Neural Networks","10.1016/j.neunet.2008.05.007","151","https://www.scopus.com/inward/record.uri?eid=2-s2.0-53249113374&doi=10.1016%2fj.neunet.2008.05.007&partnerID=40&md5=1ec60d5eae910a01ab1ef5b0e339d6b3","We have developed a Matlab/C toolbox, Brain-SMART (System for Multivariate AutoRegressive Time series, or BSMART), for spectral analysis of continuous neural time series data recorded simultaneously from multiple sensors. Available functions include time series data importing/exporting, preprocessing (normalization and trend removal), AutoRegressive (AR) modeling (multivariate/bivariate model estimation and validation), spectral quantity estimation (auto power, coherence and Granger causality spectra), network analysis (including coherence and causality networks) and visualization (including data, power, coherence and causality views). The tools for investigating causal network structures in respect of frequency bands are unique functions provided by this toolbox. All functionality has been integrated into a simple and user-friendly graphical user interface (GUI) environment designed for easy accessibility. Although we have tested the toolbox only on Windows and Linux operating systems, BSMART itself is system independent. This toolbox is freely available (http://www.brain-smart.org) under the GNU public license for open source development. © 2008 Elsevier Ltd. All rights reserved.","Granger causality spectrum; Multivariate signal analysis; Network analysis; Neural time series; Open source toolbox","Article","Scopus"
"Hoppe A.; Hoffmann S.; Gerasch A.; Gille C.; Holzhütter H.","Hoppe, Andreas (57198201821); Hoffmann, Sabrina (56214767900); Gerasch, Andreas (23008473800); Gille, Christoph (6603564177); Holzhütter, Hermann-Georg (7006041587)","57198201821; 56214767900; 23008473800; 6603564177; 7006041587","FASIMU: Flexible software for flux-balance computation series in large metabolic networks","2011","BMC Bioinformatics","10.1186/1471-2105-12-28","48","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651553577&doi=10.1186%2f1471-2105-12-28&partnerID=40&md5=7c26f2dcd38bbe5711250f358d8d8de8","Background: Flux-balance analysis based on linear optimization is widely used to compute metabolic fluxes in large metabolic networks and gains increasingly importance in network curation and structural analysis. Thus, a computational tool flexible enough to realize a wide variety of FBA algorithms and able to handle batch series of flux-balance optimizations is of great benefit.Results: We present FASIMU, a command line oriented software for the computation of flux distributions using a variety of the most common FBA algorithms, including the first available implementation of (i) weighted flux minimization, (ii) fitness maximization for partially inhibited enzymes, and (iii) of the concentration-based thermodynamic feasibility constraint. It allows batch computation with varying objectives and constraints suited for network pruning, leak analysis, flux-variability analysis, and systematic probing of metabolic objectives for network curation. Input and output supports SBML. FASIMU can work with free (lp_solve and GLPK) or commercial solvers (CPLEX, LINDO). A new plugin (faBiNA) for BiNA allows to conveniently visualize calculated flux distributions. The platform-independent program is an open-source project, freely available under GNU public license at http://www.bioinformatics.org/fasimu including manual, tutorial, and plugins.Conclusions: We present a flux-balance optimization program whose main merits are the implementation of thermodynamics as a constraint, batch series of computations, free availability of sources, choice on various external solvers, and the flexibility on metabolic objectives and constraints. © 2011 Hoppe et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Carillo M.; Cordasco G.; Serrapica F.; Scarano V.; Spagnuolo C.; Szufel P.","Carillo, Michele (57189299189); Cordasco, Gennaro (57193482076); Serrapica, Flavio (55421395000); Scarano, Vittorio (7004638056); Spagnuolo, Carmine (55757507300); Szufel, Przemysław (36988254100)","57189299189; 57193482076; 55421395000; 7004638056; 55757507300; 36988254100","Distributed simulation optimization and parameter exploration framework for the cloud","2018","Simulation Modelling Practice and Theory","10.1016/j.simpat.2017.12.005","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039448974&doi=10.1016%2fj.simpat.2017.12.005&partnerID=40&md5=4c973bd636f16a60e4cae1198d244b2b","Simulation models are becoming an increasingly popular tool for the analysis and optimization of complex real systems in different fields. Finding an optimal system design requires performing a large sweep over the parameter space in an organized way. Hence, the model optimization process is extremely demanding from a computational point of view, as it requires careful, time-consuming, complex orchestration of coordinated executions. In this paper, we present the design of SOF (Simulation Optimization and exploration Framework in the cloud), a framework which exploits the computing power of a cloud computational environment in order to carry out effective and efficient simulation optimization strategies. SOF offers several attractive features. Firstly, SOF requires “zero configuration” as it does not require any additional software installed on the remote node; only standard Apache Hadoop and SSH access are sufficient. Secondly, SOF is transparent to the user, since the user is totally unaware that the system operates on a distributed environment. Finally, SOF is highly customizable and programmable, since it enables the running of different simulation optimization scenarios using diverse programming languages – provided that the hosting platform supports them – and different simulation toolkits, as developed by the modeler. The tool has been fully developed and is available on a public repository1 under the terms of the open source Apache License. It has been tested and validated on several private platforms, such as a dedicated cluster of workstations, as well as on public platforms, including the Hortonworks Data Platform and Amazon Web Services Elastic MapReduce solution. © 2017 Elsevier B.V.","Agent-based simulation; Cloud computing; Distributed computing; Model exploration; Parallel computing; Simulation optimization","Article","Scopus"
"Craig I.R.; Pfleger C.; Gohlke H.; Essex J.W.; Spiegel K.","Craig, Ian R. (36018536700); Pfleger, Christopher (37059516100); Gohlke, Holger (7006624651); Essex, Jonathan W. (7003710935); Spiegel, Katrin (12783341900)","36018536700; 37059516100; 7006624651; 7003710935; 12783341900","Pocket-space maps to identify novel binding-site conformations in proteins","2011","Journal of Chemical Information and Modeling","10.1021/ci200168b","36","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80054928519&doi=10.1021%2fci200168b&partnerID=40&md5=2baea41f4a8ba5a972e5f0f5af1adf3c","The identification of novel binding-site conformations can greatly assist the progress of structure-based ligand design projects. Diverse pocket shapes drive medicinal chemistry to explore a broader chemical space and thus present additional opportunities to overcome key drug discovery issues such as potency, selectivity, toxicity, and pharmacokinetics. We report a new automated approach to diverse pocket selection, PocketAnalyzerPCA, which applies principal component analysis and clustering to the output of a grid-based pocket detection algorithm. Since the approach works directly with pocket shape descriptors, it is free from some of the problems hampering methods that are based on proxy shape descriptors, e.g. a set of atomic positional coordinates. The approach is technically straightforward and allows simultaneous analysis of mutants, isoforms, and protein structures derived from multiple sources with different residue numbering schemes. The PocketAnalyzerPCA approach is illustrated by the compilation of diverse sets of pocket shapes for aldose reductase and viral neuraminidase. In both cases this allows identification of novel computationally derived binding-site conformations that are yet to be observed crystallographically. Indeed, known inhibitors capable of exploiting these novel binding-site conformations are subsequently identified, thereby demonstrating the utility of PocketAnalyzerPCA for rationalizing and improving the understanding of the molecular basis of protein-ligand interaction and bioactivity. A Python program implementing the PocketAnalyzerPCA approach is available for download under an open-source license (http://sourceforge.net/projects/papca/ or http://cpclab.uni-duesseldorf.de/ downloads). © 2011 American Chemical Society.","","Article","Scopus"
"Bitard-Feildel T.; Kemena C.; Greenwood J.M.; Bornberg-Bauer E.","Bitard-Feildel, Tristan (56566652900); Kemena, Carsten (35336690500); Greenwood, Jenny M. (24174017900); Bornberg-Bauer, Erich (6603818279)","56566652900; 35336690500; 24174017900; 6603818279","Domain similarity based orthology detection","2015","BMC Bioinformatics","10.1186/s12859-015-0570-8","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930206938&doi=10.1186%2fs12859-015-0570-8&partnerID=40&md5=25a5c866b0b6c521e165e177a5ea85da","Background: Orthologous protein detection software mostly uses pairwise comparisons of amino-acid sequences to assert whether two proteins are orthologous or not. Accordingly, when the number of sequences for comparison increases, the number of comparisons to compute grows in a quadratic order. A current challenge of bioinformatic research, especially when taking into account the increasing number of sequenced organisms available, is to make this ever-growing number of comparisons computationally feasible in a reasonable amount of time. We propose to speed up the detection of orthologous proteins by using strings of domains to characterize the proteins. Results: We present two new protein similarity measures, a cosine and a maximal weight matching score based on domain content similarity, and new software, named porthoDom. The qualities of the cosine and the maximal weight matching similarity measures are compared against curated datasets. The measures show that domain content similarities are able to correctly group proteins into their families. Accordingly, the cosine similarity measure is used inside porthoDom, the wrapper developed for proteinortho. porthoDom makes use of domain content similarity measures to group proteins together before searching for orthologs. By using domains instead of amino acid sequences, the reduction of the search space decreases the computational complexity of an all-against-all sequence comparison. Conclusion: We demonstrate that representing and comparing proteins as strings of discrete domains, i.e. as a concatenation of their unique identifiers, allows a drastic simplification of search space. porthoDom has the advantage of speeding up orthology detection while maintaining a degree of accuracy similar to proteinortho. The implementation of porthoDom is released using python and C++ languages and is available under the GNU GPL licence 3 at http://www.bornberglab.org/pages/porthoda. © Bitard-Feildelet al.; licensee BioMed Central.","Domain; Domain similarity; Orthology; Similarity","Article","Scopus"
"Vandenbroucke B.; De Rijcke S.","Vandenbroucke, B. (55772958500); De Rijcke, S. (6701487611)","55772958500; 6701487611","The moving mesh code Shadowfax","2016","Astronomy and Computing","10.1016/j.ascom.2016.05.001","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971222155&doi=10.1016%2fj.ascom.2016.05.001&partnerID=40&md5=e32408329a3edd09415a7e5ac2c55104","We introduce the moving mesh code Shadowfax, which can be used to evolve a mixture of gas, subject to the laws of hydrodynamics and gravity, and any collisionless fluid only subject to gravity, such as cold dark matter or stars. The code is written in C++ and its source code is made available to the scientific community under the GNU Affero General Public Licence. We outline the algorithm and the design of our implementation, and demonstrate its validity through the results of a set of basic test problems, which are also part of the public version. We also compare Shadowfax with a number of other publicly available codes using different hydrodynamical integration schemes, illustrating the advantages and disadvantages of the moving mesh technique. © 2016 Elsevier B.V.","Hydrodynamics; Methods: numerical","Article","Scopus"
"Oster J.; Llinares R.; Payne S.; Tse Z.T.H.; Schmidt E.J.; Clifford G.D.","Oster, Julien (24822561400); Llinares, Raul (14031679200); Payne, Stephen (35729165200); Tse, Zion Tsz Ho (23468110400); Schmidt, Ehud Jeruham (7402694084); Clifford, Gari D. (7004468844)","24822561400; 14031679200; 35729165200; 23468110400; 7402694084; 7004468844","Comparison of three artificial models of the magnetohydrodynamic effect on the electrocardiogram","2015","Computer Methods in Biomechanics and Biomedical Engineering","10.1080/10255842.2014.909090","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920591781&doi=10.1080%2f10255842.2014.909090&partnerID=40&md5=1303e8111b1ad7967d489df13b99140e","The electrocardiogram (ECG) is often acquired during magnetic resonance imaging (MRI), but its analysis is restricted by the presence of a strong artefact, called magnetohydrodynamic (MHD) effect. MHD effect is induced by the flow of electrically charged particles in the blood perpendicular to the static magnetic field, which creates a potential of the order of magnitude of the ECG and temporally coincident with the repolarisation period. In this study, a new MHD model is proposed by using MRI-based 4D blood flow measurements made across the aortic arch. The model is extended to several cardiac cycles to allow the simulation of a realistic ECG acquisition during MRI examination and the quality assessment of MHD suppression techniques. A comparison of two existing models, based, respectively, on an analytical solution and on a numerical method-based solution of the fluids dynamics problem, is made with the proposed model and with an estimate of the MHD voltage observed during a real MRI scan. Results indicate a moderate agreement between the proposed model and the estimated MHD model for most leads, with an average correlation factor of 0.47. However, the results demonstrate that the proposed model provides a closer approximation to the observed MHD effects and a better depiction of the complexity of the MHD effect compared with the previously published models, with an improved correlation ((Formula presented.)), coefficient of determination ((Formula presented.)) and fraction of energy ((Formula presented.)) compared with the best previous model. The source code will be made freely available under an open source licence to facilitate collaboration and allow more rapid development of more accurate models of the MHD effect. © 2014, © 2014 Taylor & Francis.","electrocardiogram; magnetic resonance imaging; magnetohydrodynamic effect; modelling","Article","Scopus"
"Hanghøj K.; Moltke I.; Andersen P.A.; Manica A.; Korneliussen T.S.","Hanghøj, Kristian (57023826500); Moltke, Ida (24437405900); Andersen, Philip Alstrup (57208669195); Manica, Andrea (57219105897); Korneliussen, Thorfinn Sand (26639439000)","57023826500; 24437405900; 57208669195; 57219105897; 26639439000","Fast and accurate relatedness estimation from high-throughput sequencing data in the presence of inbreeding","2019","GigaScience","10.1093/gigascience/giz034","43","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065493331&doi=10.1093%2fgigascience%2fgiz034&partnerID=40&md5=15cb3afcc24dcd72bdeaf22997cbf954","Background: The estimation of relatedness between pairs of possibly inbred individuals from high-throughput sequencing (HTS) data has previously not been possible for samples where we cannot obtain reliable genotype calls, as in the case of low-coverage data. Results: We introduce ngsRelateV2, a major revision of ngsRelateV1, a program that originally allowed for estimation of relatedness from HTS data among non-inbred individuals only. The new revised version takes into account the possibility of individuals being inbred by estimating the 9 condensed Jacquard coefficients along with various other relatedness statistics. The program is threaded and scales linearly with the number of cores allocated to the process. Conclusion: The program is available as an open source C/C++ program under the GPL license and hosted at https://github.com/ANGSD/ngsRelate. To facilitate easy analysis, the program is able to work directly on the most commonly used container formats for raw sequence (BAM/CRAM) and summary data (VCF/BCF). © The Author(s) 2019. Published by Oxford University Press. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.","Genotype likelihood; High-throughput sequencing data; Inbreeding; Jacquard coefficients; Next-generation sequencing; Population genetics; Relatedness estimation; Threading","Article","Scopus"
"Sud M.; Fahy E.; Subramaniam S.","Sud, Manish (36724768000); Fahy, Eoin (7007102355); Subramaniam, Shankar (7102872096)","36724768000; 7007102355; 7102872096","Template-based combinatorial enumeration of virtual compound libraries for lipids","2012","Journal of Cheminformatics","10.1186/1758-2946-4-23","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872469846&doi=10.1186%2f1758-2946-4-23&partnerID=40&md5=35f55186e5c6c01bf954d22d2c5afcbe","A variety of software packages are available for the combinatorial enumeration of virtual libraries for small molecules, starting from specifications of core scaffolds with attachments points and lists of R-groups as SMILES or SD files. Although SD files include atomic coordinates for core scaffolds and R-groups, it is not possible to control 2-dimensional (2D) layout of the enumerated structures generated for virtual compound libraries because different packages generate different 2D representations for the same structure. We have developed a software package called LipidMapsTools for the template-based combinatorial enumeration of virtual compound libraries for lipids. Virtual libraries are enumerated for the specified lipid abbreviations using matching lists of pre-defined templates and chain abbreviations, instead of core scaffolds and lists of R-groups provided by the user. 2D structures of the enumerated lipids are drawn in a specific and consistent fashion adhering to the framework for representing lipid structures proposed by the LIPID MAPS consortium. LipidMapsTools is lightweight, relatively fast and contains no external dependencies. It is an open source package and freely available under the terms of the modified BSD license.","","Article","Scopus"
"Zappia L.; Phipson B.; Oshlack A.","Zappia, Luke (57194271070); Phipson, Belinda (35079432100); Oshlack, Alicia (55882468700)","57194271070; 35079432100; 55882468700","Exploring the single-cell RNA-seq analysis landscape with the scRNA-tools database","2018","PLoS Computational Biology","10.1371/journal.pcbi.1006245","124","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049372156&doi=10.1371%2fjournal.pcbi.1006245&partnerID=40&md5=5cc9d1f9afca61cbee1ad6b8b087413a","As single-cell RNA-sequencing (scRNA-seq) datasets have become more widespread the number of tools designed to analyse these data has dramatically increased. Navigating the vast sea of tools now available is becoming increasingly challenging for researchers. In order to better facilitate selection of appropriate analysis tools we have created the scRNA-tools database (www.scRNA-tools.org) to catalogue and curate analysis tools as they become available. Our database collects a range of information on each scRNA-seq analysis tool and categorises them according to the analysis tasks they perform. Exploration of this database gives insights into the areas of rapid development of analysis methods for scRNA-seq data. We see that many tools perform tasks specific to scRNA-seq analysis, particularly clustering and ordering of cells. We also find that the scRNA-seq community embraces an open-source and open-science approach, with most tools available under open-source licenses and preprints being extensively used as a means to describe methods. The scRNA-tools database provides a valuable resource for researchers embarking on scRNA-seq analysis and records the growth of the field over time. © 2018 Zappia et al. http://creativecommons.org/licenses/by/4.0/","","Article","Scopus"
"Lemaître G.; Nogueira F.; Aridas C.K.","Lemaître, Guillaume (57201562636); Nogueira, Fernando (57193751320); Aridas, Christos K. (57188727398)","57201562636; 57193751320; 57188727398","Imbalanced-learn: A python toolbox to tackle the curse of imbalanced datasets in machine learning","2017","Journal of Machine Learning Research","","1045","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016274615&partnerID=40&md5=dd32549cc0b9c2cd01c342fff0468b7b","Imbalanced-learn is an open-source python toolbox aiming at providing a wide range of methods to cope with the problem of imbalanced dataset frequently encountered in machine learning and pattern recognition. The implemented state-of-the-art methods can be categorized into 4 groups: (i) under-sampling, (ii) over-sampling, (iii) combination of overand under-sampling, and (iv) ensemble learning methods. The proposed toolbox depends only on numpy, scipy, and scikit-learn and is distributed under MIT license. Furthermore, it is fully compatible with scikit-learn and is part of the scikit-learn-contrib supported project. Documentation, unit tests as well as integration tests are provided to ease usage and contribution. Source code, binaries, and documentation can be downloaded from https://github.com/scikit-learn-contrib/imbalanced-learn.","Ensemble learning; Imbalanced dataset; Machine learning; Over-sampling; Python; Under-sampling","Article","Scopus"
"Field M.J.","Field, Martin J. (7201475778)","7201475778","PDynamo3 Molecular Modeling and Simulation Program","2022","Journal of Chemical Information and Modeling","10.1021/acs.jcim.2c01239","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143382285&doi=10.1021%2facs.jcim.2c01239&partnerID=40&md5=90c96d56ce0072cb06729af5d4810985","pDynamo3 is the first formal version of the Dynamo molecular modeling and simulation library that is written in Python 3. It follows from the previous pDynamo versions written in Python 2, the first of which was released in 2007. Both pDynamo and its predecessor, fDynamo, were designed with the aim of providing easy-to-use and flexible frameworks for performing molecular simulations at an atomistic level with a special emphasis on those employing hybrid quantum chemical and molecular mechanical potential methods. Although the use of pDynamo3 is quite similar to that of pDynamo2, it has added significant new capability and also undergone extensive restructuring that will make it much easier to extend with new functionality. The pDynamo3 code is issued under the GNU general public license at https://github.com/pdynamo/pDynamo3 with additional information on the pDynamo website https:www.pdynamo.org. © 2022 American Chemical Society. All rights reserved.","","Article","Scopus"
"Schröder C.; Rahmann S.","Schröder, Christopher (56663936500); Rahmann, Sven (55917419100)","56663936500; 55917419100","A hybrid parameter estimation algorithm for beta mixtures and applications to methylation state classification","2017","Algorithms for Molecular Biology","10.1186/s13015-017-0112-1","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027698874&doi=10.1186%2fs13015-017-0112-1&partnerID=40&md5=8396d7b9f3be927071bb785802fea59a","Background: Mixtures of beta distributions are a flexible tool for modeling data with values on the unit interval, such as methylation levels. However, maximum likelihood parameter estimation with beta distributions suffers from problems because of singularities in the log-likelihood function if some observations take the values0 or1. Methods: While ad-hoc corrections have been proposed to mitigate this problem, we propose a different approach to parameter estimation for beta mixtures where such problems do not arise in the first place. Our algorithm combines latent variables with the method of moments instead of maximum likelihood, which has computational advantages over the popular EM algorithm. Results: As an application, we demonstrate that methylation state classification is more accurate when using adaptive thresholds from beta mixtures than non-adaptive thresholds on observed methylation levels. We also demonstrate that we can accurately infer the number of mixture components. Conclusions: The hybrid algorithm between likelihood-based component un-mixing and moment-based parameter estimation is a robust and efficient method for beta mixture estimation. We provide an implementation of the method (""betamix"") as open source software under the MIT license. © 2017 The Author(s).","Beta distribution; Classification; Differential methylation; EM algorithm; Maximum likelihood; Method of moments; Mixture model","Article","Scopus"
"Schumacher A.; Pireddu L.; Niemenmaa M.; Kallio A.; Korpelainen E.; Zanetti G.; Heljanko K.","Schumacher, André (23475500400); Pireddu, Luca (57203183373); Niemenmaa, Matti (55149821300); Kallio, Aleksi (25027891500); Korpelainen, Eija (56507076400); Zanetti, Gianluigi (57197321160); Heljanko, Keijo (55876711000)","23475500400; 57203183373; 55149821300; 25027891500; 56507076400; 57197321160; 55876711000","SeqPig: Simple and scalable scripting for large sequencing data sets in hadoop","2014","Bioinformatics","10.1093/bioinformatics/btt601","74","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891355779&doi=10.1093%2fbioinformatics%2fbtt601&partnerID=40&md5=dc3e4c5158343adec1fee73c967e15ce","Summary: Hadoop MapReduce-based approaches have become increasingly popular due to their scalability in processing large sequencing datasets. However, as these methods typically require in-depth expertise in Hadoop and Java, they are still out of reach of many bioinformaticians. To solve this problem, we have created SeqPig, a library and a collection of tools to manipulate, analyze and query sequencing datasets in a scalable and simple manner. SeqPigscripts use the Hadoop-based distributed scripting engine Apache Pig, which automatically parallelizes and distributes data processing tasks. We demonstrate SeqPig's scalability over many computing nodes and illustrate its use with example scripts.Availability and Implementation: Available under the open source MIT license at http://sourceforge.net/projects/seqpig/Contact: Supplementary information: Supplementary data are available at Bioinformatics online. © 2013 The Author .","","Article","Scopus"
"de Alencar L.F.; Cuconato B.; Rademaker A.","de Alencar, Leonel Figueiredo (56404545000); Cuconato, Bruno (57199408265); Rademaker, Alexandre (24528977800)","56404545000; 57199408265; 24528977800","Morphobr: An open source large-coverage full-form lexicon for morphological analysis of Portuguese","2018","Texto Livre","10.17851/1983-3652.11.3.1-25","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067542548&doi=10.17851%2f1983-3652.11.3.1-25&partnerID=40&md5=438d129ebdf4e44ccd4de5a106bdaa5d","One of the prerequisites for many natural language processing technologies is the availability of large lexical resources. This paper reports on MorphoBr, an ongoing project aiming at building a comprehensive full-form lexicon for morphological analysis of Portuguese. A first version of the resource is already freely available online under an open source, free software license. MorphoBr combines analogous free resources, correcting several thousand errors and gaps, and systematically adding new entries. In comparison to the integrated resources, lexical entries in MorphoBr follow a more user-friendly format, which can be straightforwardly compiled into finite-state transducers for morphological analysis, e.g. in the context of syntactic parsing with a grammar in the LFG formalism using the XLE system. MorphoBr results from a combination of computational techniques. Errors and the more obvious gaps in the integrated resources were automatically corrected with scripts. However, MorphoBr's main contribution is the expansion in the inventory of nouns and adjectives. This was carried out by systematically modeling diminutive formation in the paradigm of finite-state morphology. This allowed MorphoBr to significantly outperform analogous resources in the coverage of diminutives. The first evaluation results show MorphoBr to be a promising initiative which will directly contribute to the development of more robust natural language processing tools and applications which depend on wide-coverage morphological analysis. © 2018 Universidade Federal de Minas Gerais. All rights reserved.","Computational linguistics; Diminutive formation; Full-form lexicon; Morphological analysis; Natural language processing","Article","Scopus"
"Wiewiórka M.S.; Messina A.; Pacholewska A.; Maffioletti S.; Gawrysiak P.; Okoniewski M.J.","Wiewiórka, Marek S. (56373558600); Messina, Antonio (56222369800); Pacholewska, Alicja (55964827200); Maffioletti, Sergio (24922034300); Gawrysiak, Piotr (24337898500); Okoniewski, Michal J. (14049023900)","56373558600; 56222369800; 55964827200; 24922034300; 24337898500; 14049023900","SparkSeq: Fast, scalable and cloud-ready tool for the interactive genomic data analysis with nucleotide precision","2014","Bioinformatics","10.1093/bioinformatics/btu343","86","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907494876&doi=10.1093%2fbioinformatics%2fbtu343&partnerID=40&md5=dfec110461ff3363461202bb43066a26","Many time-consuming analyses of next-generation sequencing data can be addressed with modern cloud computing. The Apache Hadoop-based solutions have become popular in genomics because of their scalability in a cloud infrastructure. So far, most of these tools have been used for batch data processing rather than interactive data querying. The SparkSeq software has been created to take advantage of a new MapReduce framework, Apache Spark, for next-generation sequencing data. SparkSeq is a general-purpose, flexible and easily extendable library for genomic cloud computing. It can be used to build genomic analysis pipelines in Scala and run them in an interactive way. SparkSeq opens up the possibility of customized ad hoc secondary analyses and iterative machine learning algorithms. This article demonstrates its scalability and overall fast performance by running the analyses of sequencing datasets. Tests of SparkSeq also prove that the use of cache and HDFS block size can be tuned for the optimal performance on multiple worker nodes.; Availability and implementation: Available under open source Apache 2.0 license: https://bitbucket.org/mwiewiorka/sparkseq/. © 2014 The Author.","","Article","Scopus"
"Pageaud Y.; Plass C.; Assenov Y.","Pageaud, Yoann (57202078167); Plass, Christoph (7006412289); Assenov, Yassen (15756807500)","57202078167; 7006412289; 15756807500","Enrichment analysis with EpiAnnotator","2018","Bioinformatics","10.1093/bioinformatics/bty007","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047081757&doi=10.1093%2fbioinformatics%2fbty007&partnerID=40&md5=cc04639867f860df15c5069764a7e4c2","Motivation Deciphering relevant biological insights from epigenomic data can be a challenging task. One commonly used approach is to perform enrichment analysis. However, finding, downloading and using the publicly available functional annotations require time, programming skills and IT infrastructure. Here we describe the online tool EpiAnnotator for performing enrichment analyses on epigenomic data in a fast and user-friendly way. Results EpiAnnotator is an R Package accompanied by a web interface. It contains regularly updated annotations from 4 public databases: Blueprint, RoadMap, GENCODE and the UCSC Genome Browser. Annotations are hosted locally or in a server environment and automatically updated by scripts of our own design. Thousands of tracks are available, reflecting data on a variety of tissues, cell types and cell lines from the human and mouse genomes. Users need to upload sets of selected and background regions. Results are displayed in customizable and easily interpretable figures. Availability and implementation The R package and Shiny app are open source and available under the GPL v3 license. EpiAnnotator's web interface is accessible at http://computational-epigenomics.com/en/epiannotator. © The Author(s) 2018. Published by Oxford University Press.","","Article","Scopus"
"Lelli J.; Scordino C.; Abeni L.; Faggioli D.","Lelli, Juri (55257414400); Scordino, Claudio (9044210900); Abeni, Luca (55922066400); Faggioli, Dario (29767601400)","55257414400; 9044210900; 55922066400; 29767601400","Deadline scheduling in the Linux kernel","2016","Software - Practice and Experience","10.1002/spe.2335","58","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930887960&doi=10.1002%2fspe.2335&partnerID=40&md5=510d2e11d041e1379d532a572219457b","During the last decade, there has been a considerable interest in using Linux in real-time systems, especially for industrial control. The simple and elegant design of Linux guarantees reliability and very good performance, while its open-source license allows to modify and change the source code according to the user needs. However, Linux has been designed to be a general-purpose operating system. Therefore, it presents some issues like unpredictable latencies and limited support for real-time scheduling. In this paper, we present our experience in the design and implementation of the real-time scheduler that has been recently included in the Linux kernel. The scheduler is based on the Resource Reservation paradigm, which allows to enforce temporal isolation between the running tasks. We describe the genesis of the project, the challenges we have encountered, the implementation details and the API offered to the programmers. Then, we show the experimental results measured on a real hardware. Copyright © 2015 John Wiley & Sons, Ltd.","Linux; operating system; real-time; resource-reservation; scheduling","Article","Scopus"
"Fitzpatrick P.; Metta G.; Natale L.","Fitzpatrick, Paul (7202727613); Metta, Giorgio (6602884280); Natale, Lorenzo (9737895100)","7202727613; 6602884280; 9737895100","Towards long-lived robot genes","2008","Robotics and Autonomous Systems","10.1016/j.robot.2007.09.014","141","https://www.scopus.com/inward/record.uri?eid=2-s2.0-41749120800&doi=10.1016%2fj.robot.2007.09.014&partnerID=40&md5=1d24f6853b69d0af2e2f5d3357328bb2","Robot projects are often evolutionary dead ends, with the software and hardware they produce disappearing without trace afterwards. In humanoid robotics, a small field with an avid appetite for novel devices, we experience a great deal of ""churn"" of this nature. In this paper, we explore how best to make our projects stable and long-lasting, without compromising our ability to constantly change our sensors, actuators, processors and networks. We also look at how to encourage the propagation and evolution of hardware designs, so that we can start to build up a ""gene-pool"" of material to draw upon for new projects. We advance on two fronts, software and hardware. For some time, we have been developing and using the YARP robot software architecture [Giorgio Metta, Paul Fitzpatrick, Lorenzo Natale, YARP: Yet another robot platform, International Journal on Advanced Robotics Systems 3 (2006) 43-48], which helps organize communication between sensors, processors, and actuators so that loose coupling is encouraged, making gradual system evolution much easier. YARP includes a model of communication that is transport-neutral, so that data flow is decoupled from the details of the underlying networks and protocols in use. Importantly for the long term, YARP is designed to play well with other architectures. Device drivers written for YARP can be ripped out and used without any ""middleware"". On the network, basic interoperation is possible with a few lines of code in any language with a socket library, and maximally efficient interoperation can be achieved by following documented protocols. These features are not normally the first things that end-users look for when starting a project, but they are crucial for longevity. We emphasize the strategic utility of the Free Software social contract [B. Perens, The open source definition, in: Chris DiBona, Sam Ockman, Mark Stone (Eds.), Open Sources: Voices from the Open Source Revolution, O'Reilly and Associates, Cambridge, MA, 1999] to software development for small communities with idiosyncratic requirements. We also work to expand our community by releasing the design of our ICub humanoid [N.G. Tsagarakis, G. Metta, G. Sandini, D. Vernon, R. Beira, F. Becchi, L. Righetti, J. Santos-Victor, A.J. Ijspeert, M.C. Carrozza, D.G. Caldwell, iCub - The design and realization of an open humanoid platform for cognitive and neuroscience research, Journal of Advanced Robotics 21 (10) (2007) 1151-1175] under a free and open licence, and funding development using this platform. © 2007 Elsevier Ltd. All rights reserved.","Device drivers; Free software; Humanoid robotics; ICub humanoid; YARP","Article","Scopus"
"Pau G.; Fuchs F.; Sklyar O.; Boutros M.; Huber W.","Pau, Grégoire (36009965800); Fuchs, Florian (14038878300); Sklyar, Oleg (9334083200); Boutros, Michael (7003540355); Huber, Wolfgang (22135017800)","36009965800; 14038878300; 9334083200; 7003540355; 22135017800","EBImage-an R package for image processing with applications to cellular phenotypes","2010","Bioinformatics","10.1093/bioinformatics/btq046","408","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951959633&doi=10.1093%2fbioinformatics%2fbtq046&partnerID=40&md5=ecbbf1be95a85161b1a73e4981a6b68f","Summary: EBImage provides general purpose functionality for reading, writing, processing and analysis of images. Furthermore, in the context of microscopy-based cellular assays, EBImage offers tools to segment cells and extract quantitative cellular descriptors. This allows the automation of such tasks using the R programming language and use of existing tools in the R environment for signal processing, statistical modeling, machine learning and data visualization. Availability: EBImage is free and open source, released under the LGPL license and available from the Bioconductor project (http://www.bioconductor.org/packages/release/bioc/html/EBImage.html). Contact: gregoire.pau@ebi.ac.uk. © The Author(s) 2010. Published by Oxford University Press.","","Article","Scopus"
"Burns D.M.; Whyne C.M.","Burns, David M. (57191851161); Whyne, Cari M. (56219445800)","57191851161; 56219445800","Seglearn: A python package for learning sequences and time series","2018","Journal of Machine Learning Research","","19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060520681&partnerID=40&md5=ce775563c7bc2b655371ab1e4b6fea68","seglearn is an open-source Python package for performing machine learning on time series or sequences. The implementation provides a flexible pipeline for tackling classification, regression, and forecasting problems with multivariate sequence and contextual data. Sequences and series may be learned directly with deep learning models or via feature representation with classical machine learning estimators. This package is compatible with scikit-learn and is listed under scikit-learn”Related Projects”. The package depends on numpy, scipy, and scikit-learn. seglearn is distributed under the BSD 3-Clause License. Documentation includes a detailed API description, user guide, and examples. Unit tests provide a high degree of code coverage. Source code and documentation can be downloaded from https://github.com/dmbee/seglearn. © 2018 David M. Burns and Cari M. Whyne.","Machine-Learning; Python; Sequences; Time-Series","Article","Scopus"
"Hankeln W.; Buttigieg P.L.; Fink D.; Kottmann R.; Yilmaz P.; Glöckner F.O.","Hankeln, Wolfgang (35344929000); Buttigieg, Pier L. (35344346700); Fink, Dennis (51763491600); Kottmann, Renzo (23090953800); Yilmaz, Pelin (35346201600); Glöckner, Frank O. (7003727520)","35344929000; 35344346700; 51763491600; 23090953800; 35346201600; 7003727520","MetaBar - a tool for consistent contextual data acquisition and standards compliant submission","2010","BMC Bioinformatics","10.1186/1471-2105-11-358","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954055630&doi=10.1186%2f1471-2105-11-358&partnerID=40&md5=032fae4c2eb5ccf90a6b3d0c61851105","Background: Environmental sequence datasets are increasing at an exponential rate; however, the vast majority of them lack appropriate descriptors like sampling location, time and depth/altitude: generally referred to as metadata or contextual data. The consistent capture and structured submission of these data is crucial for integrated data analysis and ecosystems modeling. The application MetaBar has been developed, to support consistent contextual data acquisition.Results: MetaBar is a spreadsheet and web-based software tool designed to assist users in the consistent acquisition, electronic storage, and submission of contextual data associated to their samples. A preconfigured Microsoft® Excel® spreadsheet is used to initiate structured contextual data storage in the field or laboratory. Each sample is given a unique identifier and at any stage the sheets can be uploaded to the MetaBar database server. To label samples, identifiers can be printed as barcodes. An intuitive web interface provides quick access to the contextual data in the MetaBar database as well as user and project management capabilities. Export functions facilitate contextual and sequence data submission to the International Nucleotide Sequence Database Collaboration (INSDC), comprising of the DNA DataBase of Japan (DDBJ), the European Molecular Biology Laboratory database (EMBL) and GenBank. MetaBar requests and stores contextual data in compliance to the Genomic Standards Consortium specifications. The MetaBar open source code base for local installation is available under the GNU General Public License version 3 (GNU GPL3).Conclusion: The MetaBar software supports the typical workflow from data acquisition and field-sampling to contextual data enriched sequence submission to an INSDC database. The integration with the megx.net marine Ecological Genomics database and portal facilitates georeferenced data integration and metadata-based comparisons of sampling sites as well as interactive data visualization. The ample export functionalities and the INSDC submission support enable exchange of data across disciplines and safeguarding contextual data. © 2010 Hankeln et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Vallon-Christersson J.; Nordborg N.; Svensson M.; Häkkinen J.","Vallon-Christersson, Johan (6505982835); Nordborg, Nicklas (35176493400); Svensson, Martin (57213441122); Häkkinen, Jari (7007052235)","6505982835; 35176493400; 57213441122; 7007052235","BASE - 2nd generation software for microarray data management and analysis","2009","BMC Bioinformatics","10.1186/1471-2105-10-330","42","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70449732423&doi=10.1186%2f1471-2105-10-330&partnerID=40&md5=d0143d0ae4ea1693a46281a69c7b77f9","Background: Microarray experiments are increasing in size and samples are collected asynchronously over long time. Available data are re-analysed as more samples are hybridized. Systematic use of collected data requires tracking of biomaterials, array information, raw data, and assembly of annotations. To meet the information tracking and data analysis challenges in microarray experiments we reimplemented and improved BASE version 1.2. Results: The new BASE presented in this report is a comprehensive annotable local microarray data repository and analysis application providing researchers with an efficient information management and analysis tool. The information management system tracks all material from biosource, via sample and through extraction and labelling to raw data and analysis. All items in BASE can be annotated and the annotations can be used as experimental factors in downstream analysis. BASE stores all microarray experiment related data regardless if analysis tools for specific techniques or data formats are readily available. The BASE team is committed to continue improving and extending BASE to make it usable for even more experimental setups and techniques, and we encourage other groups to target their specific needs leveraging on the infrastructure provided by BASE. Conclusion: BASE is a comprehensive management application for information, data, and analysis of microarray experiments, available as free open source software at http://base.thep.lu.se under the terms of the GPLv3 license. © 2009 Vallon-Christersson et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Hinselmann G.; Rosenbaum L.; Jahn A.; Fechner N.; Zell A.","Hinselmann, Georg (26648370100); Rosenbaum, Lars (36704071300); Jahn, Andreas (26648198000); Fechner, Nikolas (26648282000); Zell, Andreas (7003785870)","26648370100; 36704071300; 26648198000; 26648282000; 7003785870","JCompoundMapper: An open source Java library and command-line tool for chemical fingerprints","2011","Journal of Cheminformatics","10.1186/1758-2946-3-3","56","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951482239&doi=10.1186%2f1758-2946-3-3&partnerID=40&md5=810817e546dab3fa94bf5e6ba6f05275","Background: The decomposition of a chemical graph is a convenient approach to encode information of the corresponding organic compound. While several commercial toolkits exist to encode molecules as so-called fingerprints, only a few open source implementations are available. The aim of this work is to introduce a library for exactly defined molecular decompositions, with a strong focus on the application of these features in machine learning and data mining. It provides several options such as search depth, distance cut-offs, atom- and pharmacophore typing. Furthermore, it provides the functionality to combine, to compare, or to export the fingerprints into several formats. Results: We provide a Java 1.6 library for the decomposition of chemical graphs based on the open source Chemistry Development Kit toolkit. We reimplemented popular fingerprinting algorithms such as depth-first search fingerprints, extended connectivity fingerprints, autocorrelation fingerprints (e.g. CATS2D), radial fingerprints (e.g. Molprint2D), geometrical Molprint, atom pairs, and pharmacophore fingerprints. We also implemented custom fingerprints such as the all-shortest path fingerprint that only includes the subset of shortest paths from the full set of paths of the depth-first search fingerprint. As an application of jCompoundMapper, we provide a command-line executable binary. We measured the conversion speed and number of features for each encoding and described the composition of the features in detail. The quality of the encodings was tested using the default parametrizations in combination with a support vector machine on the Sutherland QSAR data sets. Additionally, we benchmarked the fingerprint encodings on the large-scale Ames toxicity benchmark using a large-scale linear support vector machine. The results were promising and could often compete with literature results. On the large Ames benchmark, for example, we obtained an AUC ROC performance of 0.87 with a reimplementation of the extended connectivity fingerprint. This result is comparable to the performance achieved by a non-linear support vector machine using state-of-the-art descriptors. On the Sutherland QSAR data set, the best fingerprint encodings showed a comparable or better performance on 5 of the 8 benchmarks when compared against the results of the best descriptors published in the paper of Sutherland et al. Conclusions: jCompoundMapper is a library for chemical graph fingerprints with several tweaking possibilities and exporting options for open source data mining toolkits. The quality of the data mining results, the conversion speed, the LPGL software license, the command-line interface, and the exporters should be useful for many applications in cheminformatics like benchmarks against literature methods, comparison of data mining algorithms, similarity searching, and similarity-based data mining. © 2011 Hinselmann et al; licensee Chemistry Central Ltd.","","Article","Scopus"
"Brinson M.E.; Kuznetsov V.","Brinson, M.E. (7004061648); Kuznetsov, V. (56912758200)","7004061648; 56912758200","A new approach to compact semiconductor device modelling with Qucs Verilog-A analogue module synthesis","2016","International Journal of Numerical Modelling: Electronic Networks, Devices and Fields","10.1002/jnm.2166","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963536401&doi=10.1002%2fjnm.2166&partnerID=40&md5=cc1d0add5d05c653e975f9d7bf04f9e6","Since the introduction of SPICE non-linear controlled voltage and current sources, they have become a central feature in the interactive development of behavioural device models and circuit macromodels. The current generation of SPICE-based open source general public license circuit simulators, including Qucs, Ngspice and Xyce©, implements a range of mathematical operators and functions for modelling physical phenomena and system performance. The Qucs equation-defined device is an extension of the SPICE style non-linear B type controlled source which adds dynamic charge properties to behavioural sources, allowing for example, voltage and current dependent capacitance to be easily modelled. Following, the standardization of Verilog-A, it has become a preferred hardware description language where analogue models are written in a netlist format combined with more general computer programming features for sequencing and controlling model operation. In traditional circuit simulation, the generation of a Verilog-A model from a schematic, with embedded non-linear behavioural sources, is not automatic but is normally undertaken manually. This paper introduces a new approach to the generation of Verilog-A compact device models from Qucs circuit schematics using a purpose built analogue module synthesizer. To illustrate the properties and use of the Qucs Verilog-A module synthesiser, the text includes a number of semiconductor device modelling examples and in some cases compares their simulation performance with conventional behavioural device models. Copyright © 2016 John Wiley & Sons, Ltd. Copyright © 2016 John Wiley & Sons, Ltd.","circuit simulation; compact device modelling; equation-defined devices (EDD); Qucs; Verilog-A analogue module synthesis","Article","Scopus"
"DeJesus M.A.; Ambadipudi C.; Baker R.; Sassetti C.; Ioerger T.R.","DeJesus, Michael A. (53867747700); Ambadipudi, Chaitra (56940865600); Baker, Richard (57208417888); Sassetti, Christopher (6602478124); Ioerger, Thomas R. (7003840251)","53867747700; 56940865600; 57208417888; 6602478124; 7003840251","TRANSIT - A Software Tool for Himar1 TnSeq Analysis","2015","PLoS Computational Biology","10.1371/journal.pcbi.1004401","87","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946090107&doi=10.1371%2fjournal.pcbi.1004401&partnerID=40&md5=4d1176176b3da7b7370124d504faa6f3","TnSeq has become a popular technique for determining the essentiality of genomic regions in bacterial organisms. Several methods have been developed to analyze the wealth of data that has been obtained through TnSeq experiments. We developed a tool for analyzing Himar1 TnSeq data called TRANSIT. TRANSIT provides a graphical interface to three different statistical methods for analyzing TnSeq data. These methods cover a variety of approaches capable of identifying essential genes in individual datasets as well as comparative analysis between conditions. We demonstrate the utility of this software by analyzing TnSeq datasets of M. tuberculosis grown on glycerol and cholesterol. We show that TRANSIT can be used to discover genes which have been previously implicated for growth on these carbon sources. TRANSIT is written in Python, and thus can be run on Windows, OSX and Linux platforms. The source code is distributed under the GNU GPL v3 license and can be obtained from the following GitHub repository: https://github.com/mad-lab/transit © 2015 DeJesus et al.","","Article","Scopus"
"Syed T.A.; Siddique M.S.; Nadeem A.; Alzahrani A.; Jan S.; Khattak M.A.K.","Syed, Toqeer Ali (55204929000); Siddique, Muhammad Shoaib (57217480328); Nadeem, Adnan (35183741600); Alzahrani, Ali (57197006041); Jan, Salman (56825229400); Khattak, Muazzam A. Khan (57202773102)","55204929000; 57217480328; 35183741600; 57197006041; 56825229400; 57202773102","A Novel Blockchain-Based Framework for Vehicle Life Cycle Tracking: An End-to-End Solution","2020","IEEE Access","10.1109/ACCESS.2020.3002170","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087280432&doi=10.1109%2fACCESS.2020.3002170&partnerID=40&md5=ecb0f3e9208185d8d17cc882d0176a34","Transactions related to vehicles include manufacturing, buying, selling, paying insurance(takaful), obtaining regular inspection, leasing a vehicle from banks, getting in an accident, engaging in a traffic violation, calculating price predictions and renting a vehicle. Many people perform transactions related to vehicles in their daily life; transportation authorities also perform vehicle transactions as part of managing vehicle fleets. But tracking these transactions is a challenging task. There are countrywide solutions that uses centralized systems. However, these solutions have problems with trust management, transparency, and access control. Therefore, we believe there is still room for integrated automation of various vehicle-related transactions. In this paper, we present a blockchain-based framework for vehicle tracking that incorporates the mentioned features. Moreover, blockchain is customized to enable usage control for additional transactions, such as inspection, renting and islamic insurance. The usage control model is integrated with IoT devices to continuously monitor the vehicles for certain conditions and remotely revoke access if needed. The complete transaction set is recorded over an immutable ledger that provides trust, transparency and a complete history of record. In this paper, we also presents a prototype implementation of a permissioned blockchain, which will be made available under the GNUv3 General Public License. Performance analysis is performed on the newly proposed framework implementation over the permissioned blockchain to measure its adoption and suitability. © 2013 IEEE.","Blockchain; decentralized applications; smart contracts; vehicle life cycle tracking","Article","Scopus"
"Vasantha Kumari N.; Shanmugaratinam","Vasantha Kumari, N. (57736119600); Shanmugaratinam (57735793600)","57736119600; 57735793600","IMPROVED PERFORMANCE OF CLOUD ENERGY USING CONTAINERIZATION WITH MULTIPLE MANAGERS AND CONSENSUS ALGORITHM","2022","Journal of Theoretical and Applied Information Technology","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131752645&partnerID=40&md5=fa5a3f3e1fab91dfcc4f7524a2370091","One of the favored topics in data centers and web application developers today is Containerization. Within the path of reducing the energy in cloud data centers virtualization is one among the important solution for minimization of energy in cloud. In recent trends of software data centers, Docker container is hottest tool used for Virtualization. In this paper, main concern is to construct the cluster node and schedule for docker containers. With the adverse use of containers by IT administrators and developers, cluster nodes are often established as one virtual machine. Docker is an open source engine which was introduced by Docker Inc. in 2013 under apache 2.0 license. The most objective of the Docker is to make an environment where programmers develop the code efficiently. A recent trend in docker technology with the introduction of tool called Swarm which extends its feature to numerous swarms in multiple clouds. Swarms of Docker containers with multiple managers help guarantee high service availability and improve election time during execution using Consensus Algorithm. Swarm with multiple managers, performance is improved with the algorithm. When there are increased numbers of managers any failures of the node are often recovered without downtime. This paper also explains about model of constructing a virtual system on multiple clouds in distributed systems. It also discusses about novel methodology for traditional virtualization. © 2022 Little Lion Scientific","Cloud; Container; Docker; Swarm; Virtual Machine","Article","Scopus"
"Costa P.; Phillips E.; Brandt L.; Fatica M.","Costa, Pedro (56992161700); Phillips, Everett (25227798800); Brandt, Luca (7202731727); Fatica, Massimiliano (6602390800)","56992161700; 25227798800; 7202731727; 6602390800","GPU acceleration of CaNS for massively-parallel direct numerical simulations of canonical fluid flows","2021","Computers and Mathematics with Applications","10.1016/j.camwa.2020.01.002","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078049969&doi=10.1016%2fj.camwa.2020.01.002&partnerID=40&md5=de55d154d94c825793f9414e02bda912","This work presents the GPU acceleration of the open-source code CaNS for very fast massively-parallel simulations of canonical fluid flows. The distinct feature of the many-CPU Navier–Stokes solver in CaNS is its fast direct solver for the second-order finite-difference Poisson equation, based on the method of eigenfunction expansions. The solver implements all the boundary conditions valid for this type of problems in a unified framework. Here, we extend the solver for GPU-accelerated clusters using CUDA Fortran. The porting makes extensive use of CUF kernels and has been greatly simplified by the unified memory feature of CUDA Fortran, which handles the data migration between host (CPU) and device (GPU) without defining new arrays in the source code. The overall implementation has been validated against benchmark data for turbulent channel flow and its performance assessed on a NVIDIA DGX-2 system (16 T V100 32Gb, connected with NVLink via NVSwitch). The wall-clock time per time step of the GPU-accelerated implementation is impressively small when compared to its CPU implementation on state-of-the-art many-CPU clusters, as long as the domain partitioning is sufficiently small that the data resides mostly on the GPUs. The implementation has been made freely available and open source under the terms of an MIT license. © 2020 Elsevier Ltd","Computational fluid dynamics; Direct numerical simulation; Fast Poisson solver; GPU acceleration","Article","Scopus"
"Keller O.; Benoit M.; Müller A.; Schmeling S.","Keller, Oliver (57192211556); Benoit, Mathieu (36553833700); Müller, Andreas (57201510778); Schmeling, Sascha (55912270000)","57192211556; 36553833700; 57201510778; 55912270000","Smartphone and tablet-based sensing of environmental radioactivity: Mobile low-cost measurements for monitoring, citizen science, and educational purposes","2019","Sensors (Switzerland)","10.3390/s19194264","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072918973&doi=10.3390%2fs19194264&partnerID=40&md5=4257f120ff418d1bf48435003e6097af","Sensors for environmental radioactivity based on two novel setups using photodiodes, on the one hand, and an advanced tablet-based hybrid pixel detector, on the other hand, are presented. Measurements of four kinds of terrestrial and every-day radiation sources are carried out: Airborne radon, a mineral containing traces of uranium, edible potassium salt, and an old radium watch. These measurements permit comparisons between different types of ambient radioactive sources and enable environmental monitoring. Available data comprise discrimination between α-and β−-particles in an energy range of 33 keV to 8 MeV and under ambient air conditions. The diode-based sensor is particularly useful in portable applications since it is small and sturdy with little power consumption. It can be directly connected to a smartphone via the headset socket. For its development, the low-cost silicon positive-intrinsic-negative (PIN) diodes BPX61 and BPW34 have been characterised with capacitance versus voltage (C-V) curves. Physical detection limits for ionising radiation are discussed based on obtained depletion layer width: (50 ± 8) µm at 8 V. The mobile and low-cost character of these sensors, as alternatives to Geiger counters or other advanced equipment, allows for a widespread use by individuals and citizen science groups for environmental and health protection purposes, or in educational settings. Source code and hardware design files are released under open source licenses with this publication. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.","Citizen science; Formal and informal learning; Hybrid pixel detector; Learning tool; Low-cost; Natural radioactivity; Open educational resource; Radon; Silicon sensor; Terrestrial radiation","Article","Scopus"
"Maldonado E.; Almeida D.; Escalona T.; Khan I.; Vasconcelos V.; Antunes A.","Maldonado, Emanuel (49863933700); Almeida, Daniela (56393987300); Escalona, Tibisay (25651563900); Khan, Imran (16555175100); Vasconcelos, Vitor (7004649080); Antunes, Agostinho (7102537544)","49863933700; 56393987300; 25651563900; 16555175100; 7004649080; 7102537544","LMAP: Lightweight Multigene Analyses in PAML","2016","BMC Bioinformatics","10.1186/s12859-016-1204-5","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985037160&doi=10.1186%2fs12859-016-1204-5&partnerID=40&md5=9e506cb4b85cd04621a014aacfe1d63f","Background: Uncovering how phenotypic diversity arises and is maintained in nature has long been a major interest of evolutionary biologists. Recent advances in genome sequencing technologies have remarkably increased the efficiency to pinpoint genes involved in the adaptive evolution of phenotypes. Reliability of such findings is most often examined with statistical and computational methods using Maximum Likelihood codon-based models (i.e., site, branch, branch-site and clade models), such as those available in codeml from the Phylogenetic Analysis by Maximum Likelihood (PAML) package. While these models represent a well-defined workflow for documenting adaptive evolution, in practice they can be challenging for researchers having a vast amount of data, as multiple types of relevant codon-based datasets are generated, making the overall process hard and tedious to handle, error-prone and time-consuming. Results: We introduce LMAP (Lightweight Multigene Analyses in PAML), a user-friendly command-line and interactive package, designed to handle the codeml workflow, namely: directory organization, execution, results gathering and organization for Likelihood Ratio Test estimations with minimal manual user intervention. LMAP was developed for the workstation multi-core environment and provides a unique advantage for processing one, or more, if not all codeml codon-based models for multiple datasets at a time. Our software, proved efficiency throughout the codeml workflow, including, but not limited, to simultaneously handling more than 20 datasets. Conclusions: We have developed a simple and versatile LMAP package, with outstanding performance, enabling researchers to analyze multiple different codon-based datasets in a high-throughput fashion. At minimum, two file types are required within a single input directory: one for the multiple sequence alignment and another for the phylogenetic tree. To our knowledge, no other software combines all codeml codon substitution models of adaptive evolution. LMAP has been developed as an open-source package, allowing its integration into more complex open-source bioinformatics pipelines. LMAP package is released under GPLv3 license and is freely available at http://lmapaml.sourceforge.net/. © 2016 The Author(s).","Adaptive evolution; codeml; Codon substitution models; Multi-core; Multigene; PAML; Software package","Article","Scopus"
"Gustafsson J.; Norberg P.; Qvick-Wester J.R.; Schliep A.","Gustafsson, Joel (57290900400); Norberg, Peter (7006200369); Qvick-Wester, Jan R. (57290730400); Schliep, Alexander (6506369556)","57290900400; 7006200369; 57290730400; 6506369556","Fast parallel construction of variable-length Markov chains","2021","BMC Bioinformatics","10.1186/s12859-021-04387-y","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116815738&doi=10.1186%2fs12859-021-04387-y&partnerID=40&md5=d7e9269d77ab4266f8bf169f616a41fe","Background: Alignment-free methods are a popular approach for comparing biological sequences, including complete genomes. The methods range from probability distributions of sequence composition to first and higher-order Markov chains, where a k-th order Markov chain over DNA has 4 k formal parameters. To circumvent this exponential growth in parameters, variable-length Markov chains (VLMCs) have gained popularity for applications in molecular biology and other areas. VLMCs adapt the depth depending on sequence context and thus curtail excesses in the number of parameters. The scarcity of available fast, or even parallel software tools, prompted the development of a parallel implementation using lazy suffix trees and a hash-based alternative. Results: An extensive evaluation was performed on genomes ranging from 12Mbp to 22Gbp. Relevant learning parameters were chosen guided by the Bayesian Information Criterion (BIC) to avoid over-fitting. Our implementation greatly improves upon the state-of-the-art even in serial execution. It exhibits very good parallel scaling with speed-ups for long sequences close to the optimum indicated by Amdahl’s law of 3 for 4 threads and about 6 for 16 threads, respectively. Conclusions: Our parallel implementation released as open-source under the GPLv3 license provides a practically useful alternative to the state-of-the-art which allows the construction of VLMCs even for very large genomes significantly faster than previously possible. Additionally, our parameter selection based on BIC gives guidance to end-users comparing genomes. © 2021, The Author(s).","Alignment-free; Parallel algorithms; Sequence analysis; Variable-length Markov chain","Article","Scopus"
"Droit A.; Cheung C.; Gottardo R.","Droit, Arnaud (57201966345); Cheung, Charles (57194049378); Gottardo, Raphael (12799324000)","57201966345; 57194049378; 12799324000","rMAT - An R/Bioconductor package for analyzing ChIP-chip experiments","2010","Bioinformatics","10.1093/bioinformatics/btq023","27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77949576511&doi=10.1093%2fbioinformatics%2fbtq023&partnerID=40&md5=6aee4c7ce28fec9f0f9ddaf0203ab692","Summary: Chromatin immunoprecipitation combined with DNA microarrays (ChIP-chip) has evolved as a popular technique to study DNA-protein binding or post-translational chromatin/histone modifications at the genomic level. However, the raw microarray intensities generate a massive amount of data, creating a need for efficient analysis algorithms and statistical methods to identify enriched regions. Results: We present a fast, free and powerful, open source R package, rMAT, that allows the identification of regions enriched for transcription factor binding sites in ChIP-chip experiments on Affymetrix tiling arrays. Availability: The R-package rMAT is available from the Bioconductor web site at http://bioconductor.org and runs on Linux, MAC OS and MS-Windows. rMAT is distributed under the terms of the Artistic Licence 2.0. Contact: arnaud.droit@ircm.qc.ca; raphael.gottardo@ircm.qc.ca Supplementary information: Supplementary data are available at Bioinformatics online. © The Author 2010. Published by Oxford University Press.","","Article","Scopus"
"Aksoy B.A.; Gao J.; Dresdner G.; Wang W.; Root A.; Jing X.; Cerami E.; Sander C.","Aksoy, Bülent Arman (55359957600); Gao, Jianjiong (55370612000); Dresdner, Gideon (55654042500); Wang, Weiqing (57192615135); Root, Alex (55809116700); Jing, Xiaohong (55810454100); Cerami, Ethan (57205565604); Sander, Chris (55146122100)","55359957600; 55370612000; 55654042500; 57192615135; 55809116700; 55810454100; 57205565604; 55146122100","PiHelper: An open source framework for drug-target and antibody-target data","2013","Bioinformatics","10.1093/bioinformatics/btt345","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881010255&doi=10.1093%2fbioinformatics%2fbtt345&partnerID=40&md5=bda8643295f00865a4d39e0c3523c620","Motivation: The interaction between drugs and their targets, often proteins, and between antibodies and their targets, is important for planning and analyzing investigational and therapeutic interventions in many biological systems. Although drug-target and antibody-target datasets are available in separate databases, they are not publicly available in an integrated bioinformatics resource. As medical therapeutics, especially in cancer, increasingly uses targeted drugs and measures their effects on biomolecular profiles, there is an unmet need for a user-friendly toolset that allows researchers to comprehensively and conveniently access and query information about drugs, antibodies and their targets. Summary: The PiHelper framework integrates human drug-target and antibody-target associations from publicly available resources to help meet the needs of researchers in systems pharmacology, perturbation biology and proteomics. PiHelper has utilities to (i) import drug- and antibody-target information; (ii) search the associations either programmatically or through a web user interface (UI); (iii) visualize the data interactively in a network; and (iv) export relationships for use in publications or other analysis tools. Availability: PiHelper is a free software under the GNU Lesser General Public License (LGPL) v3.0. Source code and documentation are at http://bit.ly/pihelper. We plan to coordinate contributions from the community by managing future releases. © 2013 The Author 2013. Published by Oxford University Press.","","Article","Scopus"
"Akalin Acar Z.; Makeig S.","Akalin Acar, Zeynep (26321270900); Makeig, Scott (7004563459)","26321270900; 7004563459","Neuroelectromagnetic forward modeling toolbox.","2008","Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Conference","10.1109/iembs.2008.4650084","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903803555&doi=10.1109%2fiembs.2008.4650084&partnerID=40&md5=bf9e6162a4547421c418bfa2354ffebb","This paper introduces a Neuroelectromagnetic Forward Modeling Toolbox running under MATLAB (The Mathworks, Inc.) for generating realistic head models from available data (MRI and/or electrode locations) and for solving the forward problem of electro-magnetic source imaging numerically. The toolbox includes tools for segmenting scalp, skull, cerebrospinal fluid (CSF) and brain tissues from T1-weighted magnetic resonance (MR) images. After extracting the segmented tissue volumes, mesh generation can be performed using deformable models. When MR images are not available, it is possible to warp a template head model to measured electrode locations to obtain a better-fitting realistic model. The Boundary Element Method (BEM) is used for the numerical solution of the forward problem. Toolbox functions can be called from either a graphic user interface or from the command line. Function help messages and a tutorial are included. The toolbox is freely available under the GNU Public License for noncommercial use and open source development.","","Article","Scopus"
"Huang B.; Jia D.; Feng J.; Levine H.; Onuchic J.N.; Lu M.","Huang, Bin (55907593800); Jia, Dongya (56704339200); Feng, Jingchen (55995081100); Levine, Herbert (35399029700); Onuchic, José N. (35602445700); Lu, Mingyang (8954191100)","55907593800; 56704339200; 55995081100; 35399029700; 35602445700; 8954191100","RACIPE: A computational tool for modeling gene regulatory circuits using randomization","2018","BMC Systems Biology","10.1186/s12918-018-0594-6","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048704058&doi=10.1186%2fs12918-018-0594-6&partnerID=40&md5=530f28e72e9946969fd6124f8d0d292f","Background: One of the major challenges in traditional mathematical modeling of gene regulatory circuits is the insufficient knowledge of kinetic parameters. These parameters are often inferred from existing experimental data and/or educated guesses, which can be time-consuming and error-prone, especially for large networks. Results: We present a user-friendly computational tool for the community to use our newly developed method named random circuit perturbation (RACIPE), to explore the robust dynamical features of gene regulatory circuits without the requirement of detailed kinetic parameters. Taking the network topology as the only input, RACIPE generates an ensemble of circuit models with distinct randomized parameters and uniquely identifies robust dynamical properties by statistical analysis. Here, we discuss the implementation of the software and the statistical analysis methods of RACIPE-generated data to identify robust gene expression patterns and the functions of genes and regulatory links. Finally, we apply the tool on coupled toggle-switch circuits and a published circuit of B-lymphopoiesis. Conclusions: We expect our new computational tool to contribute to a more comprehensive and unbiased understanding of mechanisms underlying gene regulatory networks. RACIPE is a free open source software distributed under (Apache 2.0) license and can be downloaded from GitHub ( https://github.com/simonhb1990/RACIPE-1.0 ). © 2018 The Author(s)..","Dynamical features; Gene regulatory circuits; GRNs; RACIPE; Random circuit perturbation; Statistical analysis","Article","Scopus"
"Grosse-Kunstleve R.W.; Terwilliger T.C.; Sauter N.K.; Adams P.D.","Grosse-Kunstleve, Ralf W. (6603963189); Terwilliger, Thomas C. (7006460445); Sauter, Nicholas K. (6602002752); Adams, Paul D. (56438865800)","6603963189; 7006460445; 6602002752; 56438865800","Automatic Fortran to C++ conversion with FABLE","2012","Source Code for Biology and Medicine","10.1186/1751-0473-7-5","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861433254&doi=10.1186%2f1751-0473-7-5&partnerID=40&md5=e844208393b47c036072957b0a901159","Background: In scientific computing, Fortran was the dominant implementation language throughout most of the second part of the 20th century. The many tools accumulated during this time have been difficult to integrate with modern software, which is now dominated by object-oriented languages.Results: Driven by the requirements of a large-scale scientific software project, we have developed a Fortran to C++ source-to-source conversion tool named FABLE. This enables the continued development of new methods even while switching languages. We report the application of FABLE in three major projects and present detailed comparisons of Fortran and C++ runtime performances.Conclusions: Our experience suggests that most Fortran 77 codes can be converted with an effort that is minor (measured in days) compared to the original development time (often measured in years). With FABLE it is possible to reuse and evolve legacy work in modern object-oriented environments, in a portable and maintainable way. FABLE is available under a nonrestrictive open source license. In FABLE the analysis of the Fortran sources is separated from the generation of the C++ sources. Therefore parts of FABLE could be reused for other target languages. © 2012 Grosse-Kunstleve et al; licensee BioMed Central Ltd. .","C++; Fortran; Python; Source-to-source conversion; Test-driven development","Article","Scopus"
"Kent E.; Hoops S.; Mendes P.","Kent, Edward (55319342200); Hoops, Stefan (15128967000); Mendes, Pedro (35510967800)","55319342200; 15128967000; 35510967800","Condor-COPASI: High-throughput computing for biochemical networks","2012","BMC Systems Biology","10.1186/1752-0509-6-91","34","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864151850&doi=10.1186%2f1752-0509-6-91&partnerID=40&md5=c954f06c1d87a094bf34b000dd441fa7","Background: Mathematical modelling has become a standard technique to improve our understanding of complex biological systems. As models become larger and more complex, simulations and analyses require increasing amounts of computational power. Clusters of computers in a high-throughput computing environment can help to provide the resources required for computationally expensive model analysis. However, exploiting such a system can be difficult for users without the necessary expertise.Results: We present Condor-COPASI, a server-based software tool that integrates COPASI, a biological pathway simulation tool, with Condor, a high-throughput computing environment. Condor-COPASI provides a web-based interface, which makes it extremely easy for a user to run a number of model simulation and analysis tasks in parallel. Tasks are transparently split into smaller parts, and submitted for execution on a Condor pool. Result output is presented to the user in a number of formats, including tables and interactive graphical displays.Conclusions: Condor-COPASI can effectively use a Condor high-throughput computing environment to provide significant gains in performance for a number of model simulation and analysis tasks. Condor-COPASI is free, open source software, released under the Artistic License 2.0, and is suitable for use by any institution with access to a Condor pool. Source code is freely available for download at http://code.google.com/p/condor-copasi/, along with full instructions on deployment and usage. © 2012 Kent et al.; licensee BioMed Central Ltd.","Computational modelling; Distributed computing; High-throughput computing; Simulation; Systems biology","Article","Scopus"
"Kožusznik J.; Bainar P.; Klímová J.; Krumnikl M.; Moravec P.; Svatoň V.; Tomančák P.","Kožusznik, Jan (6505556131); Bainar, Petr (57204054281); Klímová, Jana (57199230704); Krumnikl, Michal (21834007500); Moravec, Pavel (57193205474); Svatoň, Václav (54783390800); Tomančák, Pavel (6508156550)","6505556131; 57204054281; 57199230704; 21834007500; 57193205474; 54783390800; 6508156550","SPIM workflow manager for HPC","2019","Bioinformatics","10.1093/bioinformatics/btz140","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068478004&doi=10.1093%2fbioinformatics%2fbtz140&partnerID=40&md5=e9822af4ec3d115707af56864376204a","Summary: Here we introduce a Fiji plugin utilizing the HPC-as-a-Service concept, significantly mitigating the challenges life scientists face when delegating complex data-intensive processing workflows to HPC clusters. We demonstrate on a common Selective Plane Illumination Microscopy image processing task that execution of a Fiji workflow on a remote supercomputer leads to improved turnaround time despite the data transfer overhead. The plugin allows the end users to conveniently transfer image data to remote HPC resources, manage pipeline jobs and visualize processed results directly from the Fiji graphical user interface. Availability and implementation: The code is distributed free and open source under the MIT license. Source code: https://github.com/fiji-hpc/hpc-workflow-manager/, documentation: https://imagej.net/SPIM-Workflow-Manager-For-HPC. Supplementary information: Supplementary data are available at Bioinformatics online. © 2019 The Author(s). Published by Oxford University Press.","","Article","Scopus"
"Flint T.F.; Robson J.D.; Parivendhan G.; Cardiff P.","Flint, Thomas F. (57666709500); Robson, Joseph D. (58059080900); Parivendhan, Gowthaman (57372925300); Cardiff, Philip (55164687500)","57666709500; 58059080900; 57372925300; 55164687500","laserbeamFoam: Laser ray-tracing and thermally induced state transition simulation toolkit","2023","SoftwareX","10.1016/j.softx.2022.101299","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146056390&doi=10.1016%2fj.softx.2022.101299&partnerID=40&md5=247fd0e891de445426219b0c8f181f8c","The application of high energy density photonic sources to the surface of metallic substrates causes localised topological evolution as the interface deforms due to hydrodynamic forces through fusion and vapourisation state transitions. Understanding how this laser energy is deposited, which may involve multiple reflection events, coupled with a thermal-fluid-dynamics framework capable of describing the heat and mass transfer in the system, permits accurate predictions of many important processes, including Laser Powder Bed Fusion, selective laser melting and laser welding among many others. In this work, we present laserbeamFoam: a multi-phase thermal-fluid-dynamics solver incorporating a ray-tracing algorithm and associated Fresnel equation implementation to determine the absorptivity of the discretised laser rays as a function of incidence angle through multiple reflections. laserbeamFoam is released under the GNU general public license with source code available on GitHub. © 2022","Advanced manufacturing; Heat transfer; OpenFOAM; State Transition; Volume of fluid","Article","Scopus"
"Manongga D.; Utomo W.H.; Hendry","Manongga, Danny (55189993100); Utomo, Wiranto Herry (36171000200); Hendry (57197729542)","55189993100; 36171000200; 57197729542","E-learning development as public infrastructure of cloud computing","2014","Journal of Theoretical and Applied Information Technology","","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898413285&partnerID=40&md5=e5fad78587cdcad5a543bb22a361e7a6","The purpose of this article is to describe the model we implement to provides services, such as IaaS, PaaS, and SaaS, for e-learning and collaboration in the educational environment in Salatiga. Currently, the combination of cloud technology and e-learning is being explored. Several efforts of using IaaS cloud technology in education focus on the reservation of the VM for students. This research used Moodle technology as e-learning applications that is installed on the Cloud. Moodle is a software package for a training purpose- web and internet based training commonly known as a Learning Management System (LMS), Course Management System (CMS), or Virtual Learning Environment (VLE). Moodle is free, since it is an open source software (under the GNU Public License). Features of Cloud Computing platform using the OpenStack method quite appropriate for migration of learning system, so that it is able to form learning environments fully and efficiently, provide personalized contents, and facilitate the adaptation to the present model of education. © 2005 - 2014 JATIT & LLS. All rights reserved.","Cloud computing; E-learning; Moodle; Openstack; Public infrastructure","Article","Scopus"
"Hu Q.; Asghar M.R.; Zeadally S.","Hu, Qinwen (56468503900); Asghar, Muhammad Rizwan (54082782800); Zeadally, Sherali (7003472739)","56468503900; 54082782800; 7003472739","Blockchain-based public ecosystem for auditing security of software applications","2021","Computing","10.1007/s00607-021-00954-6","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106319410&doi=10.1007%2fs00607-021-00954-6&partnerID=40&md5=c304fb1abd4b5506db45f1c107785b56","Over the years, software applications have captured a big market ranging from smart devices (smartphones, smart wearable devices) to enterprise resource management including Enterprise Resource Planning, office applications, and the entertainment industry (video games and graphics design applications). Protecting the copyright of software applications and protection from malicious software (malware) have been topics of utmost interest for academia and industry for many years. The standard solutions use the software license key or rely on the Operating System (OS) protection mechanisms, such as Google Play Protect. However, some end users have broken these protections to bypass payments for applications that are not free. They have done so by downloading the software from an unauthorised website or by jailbreaking the OS protection mechanisms. As a result, they cannot determine whether the software they download is malicious or not. Further, if the software is uploaded to a third party platform by malicious users, the software developer has no way of knowing about it. In such cases, the authenticity or integrity of the software cannot be guaranteed. There is also a problem of information transparency among software platforms. In this study, we propose an architecture that is based on blockchain technology for providing data transparency, release traceability, and auditability. Our goal is to provide an open framework to allow users, software vendors, and security practitioners to monitor misbehaviour and assess software vulnerabilities for preventing malicious software downloads. Specifically, the proposed solution makes it possible to identify software developers who have gone rogue and are potentially developing malicious software. Furthermore, we introduce an incentive policy for encouraging security engineers, victims and software owners to participate in collaborative works. The outcomes will ensure the wide adoption of a software auditing ecosystem in software markets, specifically for some mobile device manufacturers that have been banned from using the open-source OS such as Android. Consequently, there is a demand for them to verify the application security without completely relying on the OS-specific security mechanisms. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature.","Blockchain; Security evaluation; Software audit; Software security","Article","Scopus"
"Mozzherin D.Y.; Myltsev A.A.; Patterson D.J.","Mozzherin, Dmitry Y. (55252632800); Myltsev, Alexander A. (57194459451); Patterson, David J. (57208540368)","55252632800; 57194459451; 57208540368","""gnparser"": A powerful parser for scientific names based on Parsing Expression Grammar","2017","BMC Bioinformatics","10.1186/s12859-017-1663-3","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020231250&doi=10.1186%2fs12859-017-1663-3&partnerID=40&md5=8f4f231bb72495ec888426fed110d223","Background: Scientific names in biology act as universal links. They allow us to cross-reference information about organisms globally. However variations in spelling of scientific names greatly diminish their ability to interconnect data. Such variations may include abbreviations, annotations, misspellings, etc. Authorship is a part of a scientific name and may also differ significantly. To match all possible variations of a name we need to divide them into their elements and classify each element according to its role. We refer to this as 'parsing' the name. Parsing categorizes name's elements into those that are stable and those that are prone to change. Names are matched first by combining them according to their stable elements. Matches are then refined by examining their varying elements. This two stage process dramatically improves the number and quality of matches. It is especially useful for the automatic data exchange within the context of ""Big Data"" in biology. Results: We introduce Global Names Parser (gnparser). It is a Java tool written in Scala language (a language for Java Virtual Machine) to parse scientific names. It is based on a Parsing Expression Grammar. The parser can be applied to scientific names of any complexity. It assigns a semantic meaning (such as genus name, species epithet, rank, year of publication, authorship, annotations, etc.) to all elements of a name. It is able to work with nested structures as in the names of hybrids. gnparser performs with ≈ 99% accuracy and processes 30 million name-strings/hour per CPU thread. The gnparser library is compatible with Scala, Java, R, Jython, and JRuby. The parser can be used as a command line application, as a socket server, a web-app or as a RESTful HTTP-service. It is released under an Open source MIT license. Conclusions: Global Names Parser (gnparser) is a fast, high precision tool for biodiversity informaticians and biologists working with large numbers of scientific names. It can replace expensive and error-prone manual parsing and standardization of scientific names in many situations, and can quickly enhance the interoperability of distributed biological information. © The Author(s) 2017.","Biodiversity; Biodiversity informatics; Names based cyberinfrastructure; Parser; Parsing Expression Grammar; Scala; Scientific name; Semantic parser","Article","Scopus"
"Berry D.M.; Moss G.","Berry, David M. (57192175396); Moss, Giles (55216661000)","57192175396; 55216661000","The politics of the libre commons","2006","First Monday","10.5210/fm.v11i9.1403","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33749382099&doi=10.5210%2ffm.v11i9.1403&partnerID=40&md5=65a46b13e66eddfc42229342154f07f6","The project of 'free culture' is committed to the creation of a cultural space, rather like the 'public domain', seeking to complement/replace that of proprietary cultural commodities and privatized meaning. This has been given a new impetus with the birth of the Creative Commons. This organization has sought to introduce cultural producers across the world to the possibilities of sharing, co-operation and commons-based peer-production by creating a set of interwoven licenses for creators to append to their artwork, music and text. In this paper, we chart the connections between this movement and the early Free Software and Open Source movements and question whether underlying assumptions that are ignored or de-politicized are a threat to the very free culture that the project purports to save. We then move to suggest a new discursive project linked to notions of radical democracy. Copyright © 2006, First Monday.","","Article","Scopus"
"Lowekamp B.C.; Chen D.T.; Ibáñez L.; Blezek D.","Lowekamp, Bradley C. (14825420700); Chen, David T. (8931664600); Ibáñez, Luis (34879831500); Blezek, Daniel (6603545781)","14825420700; 8931664600; 34879831500; 6603545781","The design of simpleITK","2013","Frontiers in Neuroinformatics","10.3389/fninf.2013.00045","286","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892593497&doi=10.3389%2ffninf.2013.00045&partnerID=40&md5=f0ad993686b231e30fbf4e0874763815","SimpleITK is a new interface to the Insight Segmentation and Registration Toolkit (ITK) designed to facilitate rapid prototyping, education and scientific activities via high level programming languages. ITK is a templated C++ library of image processing algorithms and frameworks for biomedical and other applications, and it was designed to be generic, flexible and extensible. Initially, ITK provided a direct wrapping interface to languages such as Python and Tcl through the WrapITK system. Unlike WrapITK, which exposed ITK's complex templated interface, SimpleITK was designed to provide an easy to use and simplified interface to ITK's algorithms. It includes procedural methods, hides ITK's demand driven pipeline, and provides a template-less layer. Also SimpleITK provides practical conveniences such as binary distribution packages and overloaded operators. Our user-friendly design goals dictated a departure from the direct interface wrapping approach of WrapITK, toward a new facade class structure that only exposes the required functionality, hiding ITK's extensive template use. Internally SimpleITK utilizes a manual description of each filter with code-generation and advanced C++ meta-programming to provide the higher-level interface, bringing the capabilities of ITK to a wider audience. SimpleITK is licensed as open source software library under the Apache License Version 2.0 and more information about downloading it can be found at http://www.simpleitk.org. © 2013 Lowek amp, Chen, Ibáñez and Blezek.","Image processing and analysis; Image processing software; Insight toolkit; Segmentation; Software design; Software development","Article","Scopus"
"Galili T.; O'Callaghan A.; Sidi J.; Sievert C.","Galili, Tal (51060906500); O'Callaghan, Alan (6701373755); Sidi, Jonathan (57057414900); Sievert, Carson (56310698800)","51060906500; 6701373755; 57057414900; 56310698800","Heatmaply: An R package for creating interactive cluster heatmaps for online publishing","2018","Bioinformatics","10.1093/bioinformatics/btx657","240","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047061082&doi=10.1093%2fbioinformatics%2fbtx657&partnerID=40&md5=844f3638ccfa9c7710e6527e487299a6","heatmaply is an R package for easily creating interactive cluster heatmaps that can be shared online as a stand-alone HTML file. Interactivity includes a tooltip display of values when hovering over cells, as well as the ability to zoom in to specific sections of the figure from the data matrix, the side dendrograms, or annotated labels. Thanks to the synergistic relationship between heatmaply and other R packages, the user is empowered by a refined control over the statistical and visual aspects of the heatmap layout. Availability and implementation The heatmaply package is available under the GPL-2 Open Source license. It comes with a detailed vignette, and is freely available from: http://cran.r-project.org/package=heatmaply. Contact tal.galili@math.tau.ac.il Supplementary informationSupplementary dataare available at Bioinformatics online. © The Author 2017. Published by Oxford University Press.","","Article","Scopus"
"Squire M.","Squire, Megan (27267963800)","27267963800","Data sets describing the circle of life in Ruby hosting, 2003–2016","2018","Empirical Software Engineering","10.1007/s10664-017-9581-6","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037649173&doi=10.1007%2fs10664-017-9581-6&partnerID=40&md5=817fc1046cf4a107622114fcc700ec40","Studying software repositories and hosting services can provide valuable insights into the behaviors of large groups of software developers and their projects. Traditionally, most analysis of metadata collected from software project hosting services has been conducted by specifying some short window of time, typically just a few years. To date, few - if any - studies have been built from data comprising the entirety of a hosting facility’s lifespan: from its birth to its death, and rebirth in another form. Thus, the first contribution of this paper is to present two data sets that support the historical analysis of over ten years of collected metadata from the now-defunct RubyForge project hosting site, as well as the follow-on successor to RubyForge, the RubyGems package (“gem”) hosting facility. The data sets and samples of usage demonstrated in this paper include: analyses of overall forge growth over time, presentation of data and analyses of project-level characteristics on both forges and their changes over time (for example in licenses, languages, and so on), and demonstration of how to use developer-level metadata (for example counts of new developers and calculation of developer-project density) to assess changes in person-level activity on both sites over time. Finally, because RubyForge was phased out and the gem-hosting portion of it was replaced by RubyGems, all the gems within RubyForge projects were transferred by project owners and by the site owners themselves into the RubyGems hosting facility. Thus, the data sets in this paper represent a unique opportunity to study projects as they moved from one ecosystem to another, and as such we show several methods for locating related projects between the two forges, and for building a cross-forge, longitudinal project history using information from both forges. These data sets and sample analyses in this paper will be relevant to researchers studying long-term software evolution, and distributed, hosted, or collaborative software development environments. © 2017, Springer Science+Business Media, LLC, part of Springer Nature.","Data; Dataset; Developer metadata; Forge; Open source software; Project hosting; Project metadata; Repository; Ruby; RubyForge; RubyGems; Software evolution","Article","Scopus"
"Schröder M.S.; Gusenleitner D.; Quackenbush J.; Culhane A.C.; Haibe-Kains B.","Schröder, Markus S. (55074742500); Gusenleitner, Daniel (36995300700); Quackenbush, John (7004974520); Culhane, Aedín C. (6601969704); Haibe-Kains, Benjamin (23667678400)","55074742500; 36995300700; 7004974520; 6601969704; 23667678400","RamiGO: An R/Bioconductor package providing an AmiGO Visualize interface","2013","Bioinformatics","10.1093/bioinformatics/bts708","24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874730555&doi=10.1093%2fbioinformatics%2fbts708&partnerID=40&md5=332a11e4c093bbeb956dfc108cb3f313","Summary: The R/Bioconductor package RamiGO is an R interface to AmiGO that enables visualization of Gene Ontology (GO) trees. Given a list of GO terms, RamiGO uses the AmiGO visualize API to import Graphviz-DOT format files into R, and export these either as images (SVG, PNG) or into Cytoscape for extended network analyses. RamiGO provides easy customization of annotation, highlighting of specific GO terms, colouring of terms by P-value or export of a simplified summary GO tree. We illustrate RamiGO functionalities in a genome-wide gene set analysis of prognostic genes in breast cancer.Availability and implementation: RamiGO is provided in R/Bioconductor, is open source under the Artistic-2.0 License and is available with a user manual containing installation, operating instructions and tutorials. It requires R version 2.15.0 or higher. URL: http://bioconductor.org/packages/release/bioc/html/RamiGO.htmlContact: Supplementary information: Supplementary data are available at Bioinformatics online. © 2013 The Author Published by Oxford University Press. All rights reserved.","","Article","Scopus"
"Kieser S.; Brown J.; Zdobnov E.M.; Trajkovski M.; McCue L.A.","Kieser, Silas (57192424151); Brown, Joseph (57195991190); Zdobnov, Evgeny M. (35395664900); Trajkovski, Mirko (6504554088); McCue, Lee Ann (6603195245)","57192424151; 57195991190; 35395664900; 6504554088; 6603195245","ATLAS: A Snakemake workflow for assembly, annotation, and genomic binning of metagenome sequence data","2020","BMC Bioinformatics","10.1186/s12859-020-03585-4","33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086886289&doi=10.1186%2fs12859-020-03585-4&partnerID=40&md5=715e08375aa2227478d316ebde9db9e8","Background: Metagenomics studies provide valuable insight into the composition and function of microbial populations from diverse environments; however, the data processing pipelines that rely on mapping reads to gene catalogs or genome databases for cultured strains yield results that underrepresent the genes and functional potential of uncultured microbes. Recent improvements in sequence assembly methods have eased the reliance on genome databases, thereby allowing the recovery of genomes from uncultured microbes. However, configuring these tools, linking them with advanced binning and annotation tools, and maintaining provenance of the processing continues to be challenging for researchers. Results: Here we present ATLAS, a software package for customizable data processing from raw sequence reads to functional and taxonomic annotations using state-of-the-art tools to assemble, annotate, quantify, and bin metagenome data. Abundance estimates at genome resolution are provided for each sample in a dataset. ATLAS is written in Python and the workflow implemented in Snakemake; it operates in a Linux environment, and is compatible with Python 3.5+ and Anaconda 3+ versions. The source code for ATLAS is freely available, distributed under a BSD-3 license. Conclusions: ATLAS provides a user-friendly, modular and customizable Snakemake workflow for metagenome data processing; it is easily installable with conda and maintained as open-source on GitHub at https://github.com/metagenome-atlas/atlas.  © 2020 The Author(s).","Analysis workflow; Annotation; Metagenome-assembled genomes; Metagenomics","Article","Scopus"
"Gel Moreno B.; Jenkinson A.M.; Jimenez R.C.; Messeguer Peypoch X..; Hermjakob H.","Gel Moreno, Bernat (15044169400); Jenkinson, Andrew M. (13205122000); Jimenez, Rafael C. (24481270200); Messeguer Peypoch, Xavier . (6602806584); Hermjakob, Henning (6701613156)","15044169400; 13205122000; 24481270200; 6602806584; 6701613156","EasyDAS: Automatic creation of DAS servers","2011","BMC Bioinformatics","10.1186/1471-2105-12-23","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651467553&doi=10.1186%2f1471-2105-12-23&partnerID=40&md5=20ee81f81558270fad8588330c3496ae","Background: The Distributed Annotation System (DAS) has proven to be a successful way to publish and share biological data. Although there are more than 750 active registered servers from around 50 organizations, setting up a DAS server comprises a fair amount of work, making it difficult for many research groups to share their biological annotations. Given the clear advantage that the generalized sharing of relevant biological data is for the research community it would be desirable to facilitate the sharing process.Results: Here we present easyDAS, a web-based system enabling anyone to publish biological annotations with just some clicks. The system, available at http://www.ebi.ac.uk/panda-srv/easydas is capable of reading different standard data file formats, process the data and create a new publicly available DAS source in a completely automated way. The created sources are hosted on the EBI systems and can take advantage of its high storage capacity and network connection, freeing the data provider from any network management work. easyDAS is an open source project under the GNU LGPL license.Conclusions: easyDAS is an automated DAS source creation system which can help many researchers in sharing their biological data, potentially increasing the amount of relevant biological data available to the scientific community. © 2011 Gel et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Sharma R.; Saha A.; Mahapatra A.K.","Sharma, Rashmi (57193120742); Saha, Anju (23393767100); Mahapatra, A.K. (57201807893)","57193120742; 23393767100; 57201807893","A comparative study of object-oriented software testing tools","2016","International Journal of Control Theory and Applications","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010976252&partnerID=40&md5=a032e2a70afe38ff15f8817e42ff247a","Software testing is one of the most essential steps of software development. Testing is the process of evaluating a system or its modules with the intent to find whether it fulfills the particular requirement or not. Software testing tools facilitate developers and testers to easily automate the procedure of testing in software development. Automated testing tools are competent of executing tests, reporting outcomes and comparing consequences with earlier test runs. Tests conceded out with these tools can be run repetitively, at any point of time. An ample range of software automated testing tools are accessible in the market. Some tools are free while others need a paid license. But it is significant for a user to choose a suitable tool for software testing. This research paper presents a feasibility study based on different parameters of object oriented software testing tools, mainly java testing tools that help developers or users to select the appropriate tool based on their requirements. In this paper, we analyze the concepts and features supported by three open source object oriented testing tools, namely CodePro AnalytiX, JUnit Test Builder (JUB) and Evosuite on the selected target application. The aim of this work is to explore these testing tools to access eccentrically pros and cons of these tools based on certain parameters, so that we can select an appropriate testing tool for the developed software. The main finding is that choice of testing tool depends mainly on application under test (AUT) and learning curve of the tool. If the learning time of the tool is acceptable for the desired goal, then one may select that tool. On the basis of execution of these testing tools on a target application, we have analysed that CodePro AnalytiX is much easier to use. © International Science Press.","AUT; Automated Testing; CodePro AnalytiX; Evosuite; Java; JUB; Software Testing; Test Case Generation","Article","Scopus"
"Maiolo M.; Gatti L.; Frei D.; Leidi T.; Gil M.; Anisimova M.","Maiolo, Massimo (55385813500); Gatti, Lorenzo (57130386300); Frei, Diego (57190858576); Leidi, Tiziano (25823305400); Gil, Manuel (35784222800); Anisimova, Maria (18833641200)","55385813500; 57130386300; 57190858576; 25823305400; 35784222800; 18833641200","ProPIP: a tool for progressive multiple sequence alignment with Poisson Indel Process","2021","BMC Bioinformatics","10.1186/s12859-021-04442-8","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117787877&doi=10.1186%2fs12859-021-04442-8&partnerID=40&md5=f0551f6751a98556e911b1d76f5e9b60","Background: Current alignment tools typically lack an explicit model of indel evolution, leading to artificially short inferred alignments (i.e., over-alignment) due to inconsistencies between the indel history and the phylogeny relating the input sequences. Results: We present a new progressive multiple sequence alignment tool ProPIP. The process of insertions and deletions is described using an explicit evolutionary model—the Poisson Indel Process or PIP. The method is based on dynamic programming and is implemented in a frequentist framework. The source code can be compiled on Linux, macOS and Microsoft Windows platforms. The algorithm is implemented in C++ as standalone program. The source code is freely available on GitHub at https://github.com/acg-team/ProPIP and is distributed under the terms of the GNU GPL v3 license. Conclusions: The use of an explicit indel evolution model allows to avoid over-alignment, to infer gaps in a phylogenetically consistent way and to make inferences about the rates of insertions and deletions. Instead of the arbitrary gap penalties, the parameters used by ProPIP are the insertion and deletion rates, which have biological interpretation and are contextualized in a probabilistic environment. As a result, indel rate settings may be optimised in order to infer phylogenetically meaningful gap patterns. © 2021, The Author(s).","Alignment software; Dynamic programming; Evolutionary alignment; Indel evolution; Multiple sequence alignmnet; Poisson Indel Process","Article","Scopus"
"Flint T.F.; Parivendhan G.; Ivankovic A.; Smith M.C.; Cardiff P.","Flint, Thomas F. (57666709500); Parivendhan, Gowthaman (57372925300); Ivankovic, Alojz (7003394210); Smith, Michael C. (57212869280); Cardiff, Philip (55164687500)","57666709500; 57372925300; 7003394210; 57212869280; 55164687500","beamWeldFoam: Numerical simulation of high energy density fusion and vapourisation-inducing processes","2022","SoftwareX","10.1016/j.softx.2022.101065","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129441062&doi=10.1016%2fj.softx.2022.101065&partnerID=40&md5=d1c3fce96ce2155e2f698e1d8bd4298d","High energy density advanced manufacturing processes, such as power beam welding and additive manufacturing, are notoriously difficult to simulate. Such processes initiate fusion, and vapourisation, state transitions in their respective (normally metallic) substrates generating complex metallic flows over incredibly short time scales. To mathematically model such processes, equations describing the conservation of momentum, conservation of energy, and an equation that describes the evolution of the metallic substrate interface must be considered. In this work, we present beamWeldFoam, an OpenFOAM solver capable of simulating these high energy density advanced manufacturing processes. In beamWeldFoam, the metallic substrate, and shielding gas phase, are treated as incompressible. The volumetric dilation due to the vapourisation state transition is neglected, instead, a phenomenological recoil pressure term is used to capture the contribution to the momentum and energy fields due to vaporisation events. beamWeldFoam is released under the GNU general public license, and its source code is available on Github. © 2022","Advanced manufacturing; Heat transfer; OpenFOAM; State transition; Volume-of-fluid","Article","Scopus"
"Børnich C.; Grytten I.; Hovig E.; Paulsen J.; Čech M.; Sandve G.K.","Børnich, Claus (57189591931); Grytten, Ivar (57189600811); Hovig, Eivind (7004194119); Paulsen, Jonas (55511750900); Čech, Martin (57189590580); Sandve, Geir Kjetil (14021897700)","57189591931; 57189600811; 7004194119; 55511750900; 57189590580; 14021897700","Galaxy Portal: Interacting with the galaxy platform through mobile devices","2016","Bioinformatics","10.1093/bioinformatics/btw042","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973279737&doi=10.1093%2fbioinformatics%2fbtw042&partnerID=40&md5=df3ef0495fc8c1c55322b584097f9806","Summary: We present Galaxy Portal app, an open source interface to the Galaxy system through smart phones and tablets. The Galaxy Portal provides convenient and efficient monitoring of job completion, as well as opportunities for inspection of results and execution history. In addition to being useful to the Galaxy community, we believe that the app also exemplifies a useful way of exploiting mobile interfaces for research/high-performance computing resources in general. Availability and implementation: The source is freely available under a GPL license on GitHub, along with user documentation and pre-compiled binaries and instructions for several platforms: https://github.com/Tarostar/QMLGalaxyPortal. It is available for iOS version 7 (and newer) through the Apple App Store, and for Android through Google Play for version 4.1 (API 16) or newer. © 2016 The Author 2016. Published by Oxford University Press.","","Article","Scopus"
"Ech-Cherif A.; Albarrak K.M.; Alnaim A.K.","Ech-Cherif, Ahmed (16068213200); Albarrak, Khalied M. (35145480300); Alnaim, Abdulrahman K. (57204561296)","16068213200; 35145480300; 57204561296","Leveraging Axiomatic Design and Research Information Systems to Promote Research Outcomes at Public Universities","2022","IEEE Access","10.1109/ACCESS.2022.3175995","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130423822&doi=10.1109%2fACCESS.2022.3175995&partnerID=40&md5=04c0340e9e91bf729110737ae66cff05","Due to the ever-stringent regulatory standards and financial pressure imposed by governments worldwide, public universities are striving to produce and deliver high quality knowledge by leveraging various organizational and technological tools. Despite their prominence and proliferation, research information management systems (RIMS) cover only the research management life-cycle of the institution and thereby presume that the scholars are actively engaged in research and are committed to feeding the system with accurate research data, which may not be the case at public universities. In this paper, we propose to leverage Axiomatic Design and Research Information Systems to support the entire research production life-cycle. The architecture of the proposed system is described in terms of a set of software modules, which may be incorporated into an open-source or a commercial Current Research Information System (CRIS). This will extend the CRIS functionality to cover the research production life-cycle in addition to the research management life-cycle making it well suited for developing research capacity at public universities.  © 2013 IEEE.","Axiomatic design; Current research information systems; Research capacity; Research support systems","Article","Scopus"
"Siegel S.F.; Zirkel T.K.","Siegel, Stephen F. (23010510800); Zirkel, Timothy K. (36873722300)","23010510800; 36873722300","TASS: The Toolkit for Accurate Scientific Software","2011","Mathematics in Computer Science","10.1007/s11786-011-0100-7","28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855540146&doi=10.1007%2fs11786-011-0100-7&partnerID=40&md5=aebb861922f053651e9c968d2ac27291","The Toolkit for Accurate Scientific Software (TASS) is a suite of integrated tools for the formal verification of programs used in computational science, including numerically-intensive message-passing-based parallel programs. While TASS can verify a number of standard safety properties (such as absence of deadlocks and out-of-bound array indexing), its most powerful feature is the ability to establish that two programs are functionally equivalent. These properties are verified by performing an explicit state enumeration of a model of the program(s). In this model, symbolic expressions are used to represent the inputs and the values of variables. TASS uses novel techniques to simplify the symbolic representation of the state and to reduce the number of states explored and saved. The TASS front-end supports a large subset of C, including (multi-dimensional) arrays, structs, dynamically allocated data, pointers and pointer arithmetic, functions and recursion, and other commonly used language constructs. A number of experiments on small but realistic numerical programs show that TASS can scale to reasonably large configurations and process counts. TASS is open source software distributed under the GNU Public License. The Java source code, examples, experimental results, and reference materials are all available at http://vsl. cis. udel. edu/tass. © 2011 Springer Basel AG.","Functional equivalence; Model checking; Parallel programming; Symbolic execution; Verification","Article","Scopus"
"Farrer R.A.","Farrer, Rhys A. (25937288800)","25937288800","Synima: A Synteny imaging tool for annotated genome assemblies","2017","BMC Bioinformatics","10.1186/s12859-017-1939-7","26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034632197&doi=10.1186%2fs12859-017-1939-7&partnerID=40&md5=d952d2afce07b49fe5f2019b3eba8616","Background: Ortholog prediction and synteny visualization across whole genomes are valuable methods for detecting and representing a range of evolutionary processes such as genome expansion, chromosomal rearrangement, and chromosomal translocation. Few standalone methods are currently available to visualize synteny across any number of annotated genomes. Results: Here, I present a Synteny Imaging tool (Synima) written in Perl, which uses the graphical features of R. Synima takes orthologues computed from reciprocal best BLAST hits or OrthoMCL, and DAGchainer, and outputs an overview of genome-wide synteny in PDF. Each of these programs are included with the Synima package, and a pipeline for their use. Synima has a range of graphical parameters including size, colours, order, and labels, which are specified in a config file generated by the first run of Synima - and can be subsequently edited. Synima runs quickly on a command line to generate informative and publication quality figures. Synima is open source and freely available from https://github.com/rhysf/Synima under the MIT License. Conclusions: Synima should be a valuable tool for visualizing synteny between two or more annotated genome assemblies. © 2017 The Author(s).","Imaging tool; Orthology; Synteny; Visualization","Article","Scopus"
"Velikajne N.; Moškon M.","Velikajne, Nina (57604824300); Moškon, Miha (24470299300)","57604824300; 24470299300","RhythmCount: A Python package to analyse the rhythmicity in count data","2022","Journal of Computational Science","10.1016/j.jocs.2022.101758","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133749769&doi=10.1016%2fj.jocs.2022.101758&partnerID=40&md5=3ba03fd75f67fee9a9b83e26b1869085","Analysis of rhythmicity in count data has become an important aspect in different fields from science and engineering to economy and process planning. Several methods have recently been implemented to investigate the rhythmicity of continuous data. However, in most cases, these need to be manually adapted to work with count data as well. Namely, non-negative integer data that are usually obtained by counting of specific events. Herein, we describe the implementation of RhythmCount, an open-source Python module specifically devoted to rhythmicity analysis of count data. RhythmCount combines the cosinor regression model with different count data models. The proposed implementation allows automatic identification of the most suitable model for a given dataset, assessment of different measures and parameters of the rhythmicity of the dataset, and production of publication-ready figures that can be used for a straightforward interpretation of the obtained results. We demonstrate an application of the proposed module in the analysis and comparison of the daily traffic trends during the COVID-19 epidemic with the daily traffic trends in normal (non-epidemic) conditions. RhythmCount is available at https://github.com/ninavelikajne/RhythmCount under the MIT license. The implementation reported in this paper corresponds to the software release v1.1. © 2022 The Author(s)","Cosinor regression; Count data; COVID-19; Rhythmicity analysis; Rhythmometry","Article","Scopus"
"Vidgen R.; Padget J.","Vidgen, Richard (6603402952); Padget, Julian (7003333790)","6603402952; 7003333790","Sendero: An extended, agent-based implementation of kauffman's NKCS model","2009","JASSS","","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350638838&partnerID=40&md5=46e9a96b79a7c1d47c020094eea8aeab","The idea of agents exploring a fitness landscape in which they seek to move from 'fitness valleys' to higher 'fitness peaks' has been presented by Kauffman in the NK and NKCS models. The NK model addresses single species while the NKCS extension illustrates coevolving species on coupled fitness landscapes. We describe an agent-based simulation (Sendero), built in Repast, of the NK and NKCS models. The results from Sendero are validated against Kauffman's findings for the NK and NKCS models. We also describe extensions to the basic model, including population dynamics and communication networks for NK, and directed graphs and variable change rates for NKCS. The Sendero software is available as open source under the BSD licence and is thus available for download and extension by the research community. © JASSS.","Agent-Based Modelling; Coevolution; Fitness Landscape; NK; NKCS","Article","Scopus"
"Doǧruel M.; Down T.A.; Hubbard T.J.","Doǧruel, Mutlu (23984596900); Down, Thomas A (57206548831); Hubbard, Tim Jp (19534744500)","23984596900; 57206548831; 19534744500","NestedMICA as an ab initio protein motif discovery tool.","2008","BMC bioinformatics","10.1186/1471-2105-9-19","27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-41149162675&doi=10.1186%2f1471-2105-9-19&partnerID=40&md5=94d1b9da4821c4e65ccb4928eb19c803","BACKGROUND: Discovering overrepresented patterns in amino acid sequences is an important step in protein functional element identification. We adapted and extended NestedMICA, an ab initio motif finder originally developed for finding transcription binding site motifs, to find short protein signals, and compared its performance with another popular protein motif finder, MEME. NestedMICA, an open source protein motif discovery tool written in Java, is driven by a Monte Carlo technique called Nested Sampling. It uses multi-class sequence background models to represent different ""uninteresting"" parts of sequences that do not contain motifs of interest. In order to assess NestedMICA as a protein motif finder, we have tested it on synthetic datasets produced by spiking instances of known motifs into a randomly selected set of protein sequences. NestedMICA was also tested using a biologically-authentic test set, where we evaluated its performance with respect to varying sequence length. RESULTS: Generally NestedMICA recovered most of the short (3-9 amino acid long) test protein motifs spiked into a test set of sequences at different frequencies. We showed that it can be used to find multiple motifs at the same time, too. In all the assessment experiments we carried out, its overall motif discovery performance was better than that of MEME. CONCLUSION: NestedMICA proved itself to be a robust and sensitive ab initio protein motif finder, even for relatively short motifs that exist in only a small fraction of sequences. AVAILABILITY: NestedMICA is available under the Lesser GPL open-source license from: http://www.sanger.ac.uk/Software/analysis/nmica/","","Article","Scopus"
"Czech E.; Aksoy B.A.; Aksoy P.; Hammerbacher J.","Czech, Eric (57210883392); Aksoy, Bulent Arman (55359957600); Aksoy, Pinar (56767967200); Hammerbacher, Jeff (54683801000)","57210883392; 55359957600; 56767967200; 54683801000","Cytokit: A single-cell analysis toolkit for high dimensional fluorescent microscopy imaging","2019","BMC Bioinformatics","10.1186/s12859-019-3055-3","24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071748398&doi=10.1186%2fs12859-019-3055-3&partnerID=40&md5=c2d4d4610e02d4d9976d81007ed2aabb","Background: Multiplexed in-situ fluorescent imaging offers several advantages over single-cell assays that do not preserve the spatial characteristics of biological samples. This spatial information, in addition to morphological properties and extensive intracellular or surface marker profiling, comprise promising avenues for rapid advancements in the understanding of disease progression and diagnosis. As protocols for conducting such imaging experiments continue to improve, it is the intent of this study to provide and validate software for processing the large quantity of associated data in kind. Results: Cytokit offers (i) an end-to-end, GPU-accelerated image processing pipeline; (ii) efficient input/output (I/O) strategies for operations specific to high dimensional microscopy; and (iii) an interactive user interface for cross filtering of spatial, graphical, expression, and morphological cell properties within the 100+ GB image datasets common to multiplexed immunofluorescence. Image processing operations supported in Cytokit are generally sourced from existing deep learning models or are at least in part adapted from open source packages to run in a single or multi-GPU environment. The efficacy of these operations is demonstrated through several imaging experiments that pair Cytokit results with those from an independent but comparable assay. A further validation also demonstrates that previously published results can be reproduced from a publicly available multiplexed image dataset. Conclusion: Cytokit is a collection of open source tools for quantifying and analyzing properties of individual cells in large fluorescent microscopy datasets that are often, but not necessarily, generated from multiplexed antibody labeling protocols over many fields of view or time periods. This project is best suited to bioinformaticians or other technical users that wish to analyze such data in a batch-oriented, high-throughput setting. All source code, documentation, and data generated for this article are available under the Apache License 2.0 at https://github.com/hammerlab/cytokit. © 2019 The Author(s).","Automatic image processing; CellProfiler; Data exploration; Data visualization; GPU; Multiplexed fluorescence imaging","Article","Scopus"
"Lätti S.; Niinivehmas S.; Pentikäinen O.T.","Lätti, Sakari (55645210300); Niinivehmas, Sanna (41862178600); Pentikäinen, Olli T. (6602134444)","55645210300; 41862178600; 6602134444","Rocker: Open source, easy-to-use tool for AUC and enrichment calculations and ROC visualization","2016","Journal of Cheminformatics","10.1186/s13321-016-0158-y","58","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985987279&doi=10.1186%2fs13321-016-0158-y&partnerID=40&md5=b65d0d65421602dbda06b53acc74600e","Receiver operating characteristics (ROC) curve with the calculation of area under curve (AUC) is a useful tool to evaluate the performance of biomedical and chemoinformatics data. For example, in virtual drug screening ROC curves are very often used to visualize the efficiency of the used application to separate active ligands from inactive molecules. Unfortunately, most of the available tools for ROC analysis are implemented into commercially available software packages, or are plugins in statistical software, which are not always the easiest to use. Here, we present Rocker, a simple ROC curve visualization tool that can be used for the generation of publication quality images. Rocker also includes an automatic calculation of the AUC for the ROC curve and Boltzmann-enhanced discrimination of ROC (BEDROC). Furthermore, in virtual screening campaigns it is often important to understand the early enrichment of active ligand identification, for this Rocker offers automated calculation routine. To enable further development of Rocker, it is freely available (MIT-GPL license) for use and modifications from our web-site (http://www.jyu.fi/rocker). Graphical Abstract: © 2016 The Author(s).","","Article","Scopus"
"Zou Y.; Wu Z.; Deng L.; Wu A.; Wu F.; Li K.; Jiang T.; Peng Y.","Zou, Yuanqiang (55980514000); Wu, Zhiqiang (57194632749); Deng, Lizong (56645533500); Wu, Aiping (36611071500); Wu, Fan (57198942984); Li, Kenli (7404988992); Jiang, Taijiao (7402148439); Peng, Yousong (36673675100)","55980514000; 57194632749; 56645533500; 36611071500; 57198942984; 7404988992; 7402148439; 36673675100","CooccurNet: An R package for co-occurrence network construction and analysis","2017","Bioinformatics","10.1093/bioinformatics/btx062","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021336217&doi=10.1093%2fbioinformatics%2fbtx062&partnerID=40&md5=33637ed57eb3729193ed85d43b120e5b","Motivation: Previously, we developed a computational model to identify genomic co-occurrence networks that was applied to capture the coevolution patterns within genomes of influenza viruses. To facilitate easy public use of this model, an R package'cooccurNet' is presented here. Results:'cooccurNet' includes functionalities of construction and analysis of residues (e.g. nucleotides, amino acids and SNPs) co-occurrence network. In addition, a new method for measuring residues coevolution, defined as residue co-occurrence score (RCOS), is proposed and implemented in'cooccurNet' based on the co-occurrence network. Availability and Implementation:'cooccurNet' is publicly available on CRAN repositories under the GPL-3 Open Source License (http://cran.r-project.org/package=cooccurNet) © The Author 2017. Published by Oxford University Press. All rights reserved.","","Article","Scopus"
"Kuśmirek W.; Nowak R.","Kuśmirek, Wiktor (57203014777); Nowak, Robert (15134573600)","57203014777; 15134573600","De novo assembly of bacterial genomes with repetitive DNA regions by dnaasm application","2018","BMC Bioinformatics","10.1186/s12859-018-2281-4","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050278755&doi=10.1186%2fs12859-018-2281-4&partnerID=40&md5=a526ef1b52c4b6276877c585c5c531c6","Background: Many organisms, in particular bacteria, contain repetitive DNA fragments called tandem repeats. These structures are restored by DNA assemblers by mapping paired-end tags to unitigs, estimating the distance between them and filling the gap with the specified DNA motif, which could be repeated many times. However, some of the tandem repeats are longer than the distance between the paired-end tags. Results: We present a new algorithm for de novo DNA assembly, which uses the relative frequency of reads to properly restore tandem repeats. The main advantage of the presented algorithm is that long tandem repeats, which are much longer than maximum reads length and the insert size of paired-end tags can be properly restored. Moreover, repetitive DNA regions covered only by single-read sequencing data could also be restored. Other existing de novo DNA assemblers fail in such cases. The presented application is composed of several steps, including: (i) building the de Bruijn graph, (ii) correcting the de Bruijn graph, (iii) normalizing edge weights, and (iv) generating the output set of DNA sequences. We tested our approach on real data sets of bacterial organisms. Conclusions: The software library, console application and web application were developed. Web application was developed in client-server architecture, where web-browser is used to communicate with end-user and algorithms are implemented in C++ and Python. The presented approach enables proper reconstruction of tandem repeats, which are longer than the insert size of paired-end tags. The application is freely available to all users under GNU Library or Lesser General Public License version 3.0 (LGPLv3). © 2018 The Author(s).","De Bruijn graph; De novo assembling; Next generation sequencing; Tandem repeats","Article","Scopus"
"D'Antoni M.; Rossi M.A.","D'Antoni, Massimo (57210322216); Rossi, Maria Alessandra (7403708643)","57210322216; 7403708643","Appropriability and incentives with complementary innovations","2014","Journal of Economics and Management Strategy","10.1111/jems.12040","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891895196&doi=10.1111%2fjems.12040&partnerID=40&md5=8ab7de4fc4afd03260af9fc111ab5a5f","This paper analyzes the effects on incentives to invest in the development of complementary innovations within research and development (R&D) collaborations of two alternative appropriability regimes: an ""openness regime"" whereby parties make an ex ante commitment to reciprocal access to each other's R&D outputs and an ""exclusion regime"" whereby no such commitment is made. We consider a model with efficient bargaining ex ante in which firms do not compete in the final market. Assuming that the complementary innovations constitute a common input and that agents make complementary investments in its private exploitation, we find that, when complementarities are sufficiently strong, a commitment to openness may provide greater incentives than an exclusion regime. The theoretical framework may be applied to interpret Open Source Software licenses, intellectual property rights licensing arrangements within research joint ventures and royalty stacking issues. From a public policy standpoint, the paper allows to identify conditions under which the openness regime may be an appropriate choice to elicit further development of publicly funded technologies. © 2014 Wiley Periodicals, Inc.","","Article","Scopus"
"Maldonado E.; Antunes A.","Maldonado, Emanuel (49863933700); Antunes, Agostinho (7102537544)","49863933700; 7102537544","LMAP_S: Lightweight Multigene Alignment and Phylogeny eStimation","2019","BMC Bioinformatics","10.1186/s12859-019-3292-5","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077313643&doi=10.1186%2fs12859-019-3292-5&partnerID=40&md5=622d37a003759921b9d30ea1ae75eccf","Background: Recent advances in genome sequencing technologies and the cost drop in high-throughput sequencing continue to give rise to a deluge of data available for downstream analyses. Among others, evolutionary biologists often make use of genomic data to uncover phenotypic diversity and adaptive evolution in protein-coding genes. Therefore, multiple sequence alignments (MSA) and phylogenetic trees (PT) need to be estimated with optimal results. However, the preparation of an initial dataset of multiple sequence file(s) (MSF) and the steps involved can be challenging when considering extensive amount of data. Thus, it becomes necessary the development of a tool that removes the potential source of error and automates the time-consuming steps of a typical workflow with high-throughput and optimal MSA and PT estimations. Results: We introduce LMAP_S (Lightweight Multigene Alignment and Phylogeny eStimation), a user-friendly command-line and interactive package, designed to handle an improved alignment and phylogeny estimation workflow: MSF preparation, MSA estimation, outlier detection, refinement, consensus, phylogeny estimation, comparison and editing, among which file and directory organization, execution, manipulation of information are automated, with minimal manual user intervention. LMAP_S was developed for the workstation multi-core environment and provides a unique advantage for processing multiple datasets. Our software, proved to be efficient throughout the workflow, including, the (unlimited) handling of more than 20 datasets. Conclusions: We have developed a simple and versatile LMAP_S package enabling researchers to effectively estimate multiple datasets MSAs and PTs in a high-throughput fashion. LMAP_S integrates more than 25 software providing overall more than 65 algorithm choices distributed in five stages. At minimum, one FASTA file is required within a single input directory. To our knowledge, no other software combines MSA and phylogeny estimation with as many alternatives and provides means to find optimal MSAs and phylogenies. Moreover, we used a case study comparing methodologies that highlighted the usefulness of our software. LMAP_S has been developed as an open-source package, allowing its integration into more complex open-source bioinformatics pipelines. LMAP_S package is released under GPLv3 license and is freely available at https://lmap-s.sourceforge.io/. © 2019 The Author(s).","Accuracy; Character coding; Consensus; High-throughput; Multi-core; Multigene; Multiple sequence alignment; Phylogeny; Software package; Uncertainty","Article","Scopus"
"Teixeira S.; Agrizzi B.A.; Filho J.G.P.; Rossetto S.; Pereira I.S.A.; Costa P.D.; Branco A.F.; Martinelli R.R.","Teixeira, Sergio (57194683645); Agrizzi, Bruno Alves (57194684381); Filho, José Gonçalves Pereira (56105934800); Rossetto, Silvana (21743607300); Pereira, Isaac Simões Araújo (55513845400); Costa, Patrícia Dockhorn (14631736200); Branco, Adriano Francisco (56147589500); Martinelli, Ruan Rocha (57212376863)","57194683645; 57194684381; 56105934800; 21743607300; 55513845400; 14631736200; 56147589500; 57212376863","LAURA architecture: Towards a simpler way of building situation-aware and business-aware IoT applications","2020","Journal of Systems and Software","10.1016/j.jss.2019.110494","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076549690&doi=10.1016%2fj.jss.2019.110494&partnerID=40&md5=5534d08c73f459d4d8dac7dcc9c83e95","The explosion of smart objects made companies rethink their Business Model (BM) using Wireless Sensor Networks (WSN) and the Internet of Things (IoT) aiming to improve their Business Processes (BP) to achieve competitiveness. Business environments are complex due to the wide variety of technologies, hardware and software solutions that compose heterogeneous enterprise environments. On the other hand, putting real-world IoT scenarios into practice is still a challenge for even experienced developers, because it requires low-level programming skills and, at the same time, specific domain knowledge of a company‘s BM. This research paper proposes LAURA – Lean AUtomatic code generation for situation-aware and business-awaRe Applications, a flexible, service-oriented and general open-source conceptual architecture, designed to support the deployment of decoupled IoT applications. Empirical evaluation has shown that LAURA simplifies the development of final Situation-Aware or Business-Aware applications, reducing the need for specialized IoT low-level knowledge, while showing an acceptable performance. LAURA also provides the freedom and independence to modify, adapt or integrate its architecture according to specific needs of the stakeholders. © 2019 Elsevier Inc.","Business Process; Internet of things; IoT Architecture; Situation-Awareness; Wireless sensor networks","Article","Scopus"
"Miclotte G.; Plaisance S.; Rombauts S.; Van de Peer Y.; Audenaert P.; Fostier J.","Miclotte, Giles (56971493100); Plaisance, Stéphane (57205754882); Rombauts, Stephane (6601946312); Van de Peer, Yves (7006594796); Audenaert, Pieter (23491487100); Fostier, Jan (15063921100)","56971493100; 57205754882; 6601946312; 7006594796; 23491487100; 15063921100","OMSim: a simulator for optical map data","2017","Bioinformatics (Oxford, England)","10.1093/bioinformatics/btx293","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045975348&doi=10.1093%2fbioinformatics%2fbtx293&partnerID=40&md5=a2b9c4491639a05ef19d6d44d3728f1e","Motivation: The Bionano Genomics platform allows for the optical detection of short sequence patterns in very long DNA molecules (up to 2.5 Mbp). Molecules with overlapping patterns can be assembled to generate a consensus optical map of the entire genome. In turn, these optical maps can be used to validate or improve de novo genome assembly projects or to detect large-scale structural variation in genomes. Simulated optical map data can assist in the development and benchmarking of tools that operate on those data, such as alignment and assembly software. Additionally, it can help to optimize the experimental setup for a genome of interest. Such a simulator is currently not available.; Results: We have developed a simulator, OMSim, that produces synthetic optical map data that mimics real Bionano Genomics data. These simulated data have been tested for compatibility with the Bionano Genomics Irys software system and the Irys-scaffolding scripts. OMSim is capable of handling very large genomes (over 30 Gbp) with high throughput and low memory requirements.; Availability and implementation: The Python simulation tool and a cross-platform graphical user interface are available as open source software under the GNU GPL v2 license ( http://www.bioinformatics.intec.ugent.be/omsim ).; Contact: jan.fostier@ugent.be.; Supplementary information: Supplementary data are available at Bioinformatics online. © The Author(s) 2017. Published by Oxford University Press.","","Article","Scopus"
"Zhou L.; Feng T.; Xu S.; Gao F.; Lam T.T.; Wang Q.; Wu T.; Huang H.; Zhan L.; Li L.; Guan Y.; Dai Z.; Yu G.","Zhou, Lang (57214627416); Feng, Tingze (57214630992); Xu, Shuangbin (57799501400); Gao, Fangluan (26535670400); Lam, Tommy T. (56549450000); Wang, Qianwen (57215607498); Wu, Tianzhi (57211593232); Huang, Huina (57815522900); Zhan, Li (57226728170); Li, Lin (57815426200); Guan, Yi (57221708595); Dai, Zehan (56829974200); Yu, Guangchuang (35204197400)","57214627416; 57214630992; 57799501400; 26535670400; 56549450000; 57215607498; 57211593232; 57815522900; 57226728170; 57815426200; 57221708595; 56829974200; 35204197400","Ggmsa: A visual exploration tool for multiple sequence alignment and associated data","2022","Briefings in Bioinformatics","10.1093/bib/bbac222","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134720568&doi=10.1093%2fbib%2fbbac222&partnerID=40&md5=03ae9aae3fa87ac393a5d545a436cb47","The identification of the conserved and variable regions in the multiple sequence alignment (MSA) is critical to accelerating the process of understanding the function of genes. MSA visualizations allow us to transform sequence features into understandable visual representations. As the sequence-structure-function relationship gains increasing attention in molecular biology studies, the simple display of nucleotide or protein sequence alignment is not satisfied. A more scalable visualization is required to broaden the scope of sequence investigation. Here we present ggmsa, an R package for mining comprehensive sequence features and integrating the associated data of MSA by a variety of display methods. To uncover sequence conservation patterns, variations and recombination at the site level, sequence bundles, sequence logos, stacked sequence alignment and comparative plots are implemented. ggmsa supports integrating the correlation of MSA sequences and their phenotypes, as well as other traits such as ancestral sequences, molecular structures, molecular functions and expression levels. We also design a new visualization method for genome alignments in multiple alignment format to explore the pattern of within and between species variation. Combining these visual representations with prime knowledge, ggmsa assists researchers in discovering MSA and making decisions. The ggmsa package is open-source software released under the Artistic-2.0 license, and it is freely available on Bioconductor (https://bioconductor.org/packages/ggmsa) and Github (https://github.com/YuLab-SMU/ggmsa).  © 2022 The Author(s). Published by Oxford University Press. All rights reserved.","Multiple sequence alignment; Phylogeny; Sequence bundle; Sequence recombination","Article","Scopus"
"Cheng Y.-H.; Liaw J.-J.; Kuo C.-N.","Cheng, Yu-Huei (12783989200); Liaw, Jiun-Jian (7006771477); Kuo, Che-Nan (16304570300)","12783989200; 7006771477; 16304570300","REHUNT: A reliable and open source package for restriction enzyme hunting","2018","BMC Bioinformatics","10.1186/s12859-018-2168-4","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051339021&doi=10.1186%2fs12859-018-2168-4&partnerID=40&md5=75f131c6aad5f509dedde2ef24367dbb","Background: Restriction enzymes are used frequently in biotechnology. However, manual mining of restriction enzymes is challenging. Furthermore, integrating available restriction enzymes into different bioinformatics systems is necessary for many biotechnological applications, such as polymerase chain reaction-restriction fragment length polymorphism (PCR-RFLP). Thus, in the present study, we developed the package REHUNT (Restriction Enzymes HUNTing), which mines restriction enzymes from the public database REBASE using a series of search operations. Results: REHUNT is a reliable and open source package implemented in JAVA. It provides useful methods and manipulations for biological sequence analysis centered around restriction enzymes contained in REBASE. All available restriction enzymes for the imported biological sequences can be identified by REHUNT. Different genotypes can be identified using PCR-RFLP based on REHUNT for single nucleotide polymorphism (SNP), mutations, and the other variations. REHUNT robustly recognizes multiple inputs with different formats, e.g. regular DNA sequences, variation-in-sequence indicated by IUPAC code, as well as variation-in-sequence indicated by dNTPs format. Variations including di-, tri-, and tetra-allelic types and indel formats are also acceptable. Furthermore, REHUNT provides classified restriction enzymes output, including IUPAC and general sequence types, as well as commercial and non-commercial availabilities. REHUNT also enables analysis for high throughput screening (HTS) technologies. Conclusions: REHUNT is open source software with GPL v3 license and can be run on all platforms. Its features include: 1) Quick restriction enzymes search throughout a sequence based on the Boyer-Moore algorithm; 2) all available restriction enzymes provided and regularly updated from REBASE; 3) an open source API available of integrating all types of bioinformatics systems and applications; 4) SNP genotyping available for plant and animal marker-assisted breeding, and for human genetics; and 5) high throughput analysis available for Next Generation Sequencing (NGS). REHUNT not only to effectively looks for restriction enzymes in a sequence, but also available for SNP genotyping. Furthermore, it can be integrated into other biological and medical applications. REHUNT offers a convenient and flexible package for powerful restriction enzymes analyses in association studies, and supports high throughput analysis. The source codes and complete API documents are available at SourceForge: https://sourceforge.net/projects/rehunt/ , GitHub: https://github.com/yuhuei/rehunt , and at: https://sites.google.com/site/yhcheng1981/rehunt. © 2018 The Author(s).","","Article","Scopus"
"Le Guilloux V.; Schmidtke P.; Tuffery P.","Le Guilloux, Vincent (26659097100); Schmidtke, Peter (36764104900); Tuffery, Pierre (55941863600)","26659097100; 36764104900; 55941863600","Fpocket: An open source platform for ligand pocket detection","2009","BMC Bioinformatics","10.1186/1471-2105-10-168","756","https://www.scopus.com/inward/record.uri?eid=2-s2.0-67649422714&doi=10.1186%2f1471-2105-10-168&partnerID=40&md5=0d742d732998ec043a3b82ebb03a7921","Background: Virtual screening methods start to be well established as effective approaches to identify hits, candidates and leads for drug discovery research. Among those, structure based virtual screening (SBVS) approaches aim at docking collections of small compounds in the target structure to identify potent compounds. For SBVS, the identification of candidate pockets in protein structures is a key feature, and the recent years have seen increasing interest in developing methods for pocket and cavity detection on protein surfaces. Results: Fpocket is an open source pocket detection package based on Voronoi tessellation and alpha spheres built on top of the publicly available package Qhull. The modular source code is organised around a central library of functions, a basis for three main programs: (i) Fpocket, to perform pocket identification, (ii) Tpocket, to organise pocket detection benchmarking on a set of known protein-ligand complexes, and (iii) Dpocket, to collect pocket descriptor values on a set of proteins. Fpocket is written in the C programming language, which makes it a platform well suited for the scientific community willing to develop new scoring functions and extract various pocket descriptors on a large scale level. Fpocket 1.0, relying on a simple scoring function, is able to detect 94% and 92% of the pockets within the best three ranked pockets from the holo and apo proteins respectively, outperforming the standards of the field, while being faster. Conclusion: Fpocket provides a rapid, open source and stable basis for further developments related to protein pocket detection, efficient pocket descriptor extraction, or drugablity prediction purposes. Fpocket is freely available under the GNU GPL license at http://fpocket.sourceforge.net. © 2009 Le Guilloux et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Bonnet E.; Calzone L.; Michoel T.","Bonnet, Eric (7005940887); Calzone, Laurence (23975457300); Michoel, Tom (6602570838)","7005940887; 23975457300; 6602570838","Integrative Multi-omics Module Network Inference with Lemon-Tree","2015","PLoS Computational Biology","10.1371/journal.pcbi.1003983","65","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924370895&doi=10.1371%2fjournal.pcbi.1003983&partnerID=40&md5=a5c8fd7b8fd99bbfea10d774c0779ab0","Module network inference is an established statistical method to reconstruct co-expression modules and their upstream regulatory programs from integrated multi-omics datasets measuring the activity levels of various cellular components across different individuals, experimental conditions or time points of a dynamic process. We have developed Lemon-Tree, an open-source, platform-independent, modular, extensible software package implementing state-of-the-art ensemble methods for module network inference. We benchmarked Lemon-Tree using large-scale tumor datasets and showed that Lemon-Tree algorithms compare favorably with state-of-the-art module network inference software. We also analyzed a large dataset of somatic copy-number alterations and gene expression levels measured in glioblastoma samples from The Cancer Genome Atlas and found that Lemon-Tree correctly identifies known glioblastoma oncogenes and tumor suppressors as master regulators in the inferred module network. Novel candidate driver genes predicted by Lemon-Tree were validated using tumor pathway and survival analyses. Lemon-Tree is available from http://lemon-tree.googlecode.com under the GNU General Public License version 2.0. © 2015 Bonnet et al.","","Article","Scopus"
"Diaz-Uriarte R.; Herrera-Nieto P.","Diaz-Uriarte, Ramon (6603594977); Herrera-Nieto, Pablo (57218227881)","6603594977; 57218227881","EvAM-Tools: tools for evolutionary accumulation and cancer progression models","2022","Bioinformatics (Oxford, England)","10.1093/bioinformatics/btac710","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144587450&doi=10.1093%2fbioinformatics%2fbtac710&partnerID=40&md5=938fb81e66e67d22a4544e135b4b81a7","SUMMARY: EvAM-Tools is an R package and web application that provides a unified interface to state-of-the-art cancer progression models and, more generally, evolutionary models of event accumulation. The output includes, in addition to the fitted models, the transition (and transition rate) matrices between genotypes and the probabilities of evolutionary paths. Generation of random cancer progression models is also available. Using the GUI in the web application, users can easily construct models (modifying directed acyclic graphs of restrictions, matrices of mutual hazards or specifying genotype composition), generate data from them (with user-specified observational/genotyping error) and analyze the data. AVAILABILITY AND IMPLEMENTATION: Implemented in R and C; open source code available under the GNU Affero General Public License v3.0 at https://github.com/rdiaz02/EvAM-Tools. Docker images freely available from https://hub.docker.com/u/rdiaz02. Web app freely accessible at https://iib.uam.es/evamtools. SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online. © The Author(s) 2022. Published by Oxford University Press.","","Article","Scopus"
"Beard E.J.; Cole J.M.","Beard, Edward J. (57204944674); Cole, Jacqueline M. (56305941600)","57204944674; 56305941600","Chem Schematic Resolver: A Toolkit to Decode 2D Chemical Diagrams with Labels and R-Groups into Annotated Chemical Named Entities","2020","Journal of Chemical Information and Modeling","10.1021/acs.jcim.0c00042","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084101111&doi=10.1021%2facs.jcim.0c00042&partnerID=40&md5=720060998fd81e3f5fec8d2808f21c92","The number of journal articles in the scientific domain has grown to the point where it has become impossible for researchers to capitalize on all findings in their relevant discipline. Information is stored in these articles in a number of ways, including figures that describe important results. In organic chemistry, these figures often present chemical schematic diagrams that graphically define the structures of carbon-based compounds. These diagrams are intuitive for an expert to comprehend, but they are not designed for machines. This work presents ChemSchematicResolver, a software tool that can be used to identify chemical schematic diagrams within the figure of a document, resolve any R-group substituents within them, and convert the resulting diagrams to a machine-readable format in a high-throughput, autonomous fashion. The tool includes a new algorithm that is used to identify relevant diagrams and a mechanism that combines these data with contextual information from the rest of the document for the creation of highly relational databases. It includes support for a variety of general R-group structures, the first time this is available in any open-source chemical schematic diagram extraction tool. It is presented alongside a self-generated evaluation set, on which the most important assessment metric, precision, achieved 83-100% for all assessed areas. The ChemSchematicResolver tool is released under the MIT license and is available to download from www.chemschematicresolver.org.  Copyright © 2020 American Chemical Society.","","Article","Scopus"
"Lounkine E.; Wawer M.; Wassermann A.M.; Bajorath J.","Lounkine, Eugen (23091161900); Wawer, Mathias (25226082200); Wassermann, Anne Mai (26532151200); Bajorath, Jürgen (7101742328)","23091161900; 25226082200; 26532151200; 7101742328","SARANEA: A freely available program to mine structure-activity and structure-selectivity relationship information in compound data sets","2010","Journal of Chemical Information and Modeling","10.1021/ci900416a","65","https://www.scopus.com/inward/record.uri?eid=2-s2.0-75749102958&doi=10.1021%2fci900416a&partnerID=40&md5=aec2b93c1059bb5821328dcd723a72b8","We introduce SARANEA, an open-source Java application for interactive exploration of structure-activity relationship (SAR) and structure-selectivity relationship (SSR) information in compound sets of any source. SARANEA integrates various SAR and SSR analysis functions and utilizes a network-like similarity graph data structure for visualization. The program enables the systematic detection of activity and selectivity cliffs and corresponding key compounds across multiple targets. Advanced SAR analysis functions implemented in SARANEA include, among others, layered chemical neighborhood graphs, cliff indices, selectivity trees, editing functions for molecular networks and pathways, bioactivity summaries of key compounds, and markers for bioactive compounds having potential side effects. We report the application of SARANEA to identify SAR and SSR determinants in different sets of serine protease inhibitors. It is found that key compounds can influence SARs and SSRs in rather different ways. Such compounds and their SAR/SSR characteristics can be systematically identified and explored using SARANEA, The program and source code are made freely available under the GNU General Public License. © 2010 American Chemical Society.","","Article","Scopus"
"Pukdesree S.; Lacharoj V.; Sirisang P.","Pukdesree, Sorapak (8539888500); Lacharoj, Vitalwonhyo (8539888400); Sirisang, Parinya (39762667100)","8539888500; 8539888400; 39762667100","Performance evaluation of distributed database on PC cluster computers","2011","WSEAS Transactions on Computers","","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79958244158&partnerID=40&md5=903b1f8858354a5f338009afd7222e19","Presently, Information is very importance aspect to be recognized on every application. Modern organizations have stored and managed their information using database management system. The proprietary DBMSs Software is very expensive license to spend depending on the scale of capability to handle their transactions. Therefore this research would like to represent the distributed database methodology that can be scalable to improve performance the database system to meet business requirements. To implement the distributed database methodology, researcher will use an open source DMBS named MySQL Cluster as research's tool. MySQL Cluster deploys on distributed database technology that can be scaled the performance dynamically on the PC Clustering computers. MySQL Cluster can provide higher performance with significantly lower cost than enterprise DBMSs based on PC Clustering computers. This research focuses on the small and medium of enterprise businesses in Thailand which their incomes are less than one and a half million dollar per year. Most of their budget have been spent on productions rather than invested on information technology section. Therefore SMEs businesses in Thailand can utilize this research's information to make their plans for the database management system to meet the requirements of their businesses.","Database; Distributed database; Distributed processing; High performance computing; MySQL cluster; PC clustering computers","Article","Scopus"
"Stocker G.; Fischer M.; Rieder D.; Bindea G.; Kainz S.; Oberstolz M.; McNally J.G.; Trajanoski Z.","Stocker, Gernot (8852641800); Fischer, Maria (56667916700); Rieder, Dietmar (6602925519); Bindea, Gabriela (16302872200); Kainz, Simon (57217046837); Oberstolz, Michael (35208793800); McNally, James G. (7102726189); Trajanoski, Zlatko (7003575554)","8852641800; 56667916700; 6602925519; 16302872200; 57217046837; 35208793800; 7102726189; 7003575554","ILAP: A workflow-driven software for experimental protocol development, data acquisition and analysis","2009","BMC Bioinformatics","10.1186/1471-2105-10-390","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-71549130732&doi=10.1186%2f1471-2105-10-390&partnerID=40&md5=7bd406be29e240b2f6dd37eb6f26ad69","Background: In recent years, the genome biology community has expended considerable effort to confront the challenges of managing heterogeneous data in a structured and organized way and developed laboratory information management systems (LIMS) for both raw and processed data. On the other hand, electronic notebooks were developed to record and manage scientific data, and facilitate data-sharing. Software which enables both, management of large datasets and digital recording of laboratory procedures would serve a real need in laboratories using medium and high-throughput techniques. Results: We have developed iLAP (Laboratory data management, Analysis, and Protocol development), a workflow-driven information management system specifically designed to create and manage experimental protocols, and to analyze and share laboratory data. The system combines experimental protocol development, wizard-based data acquisition, and high-throughput data analysis into a single, integrated system. We demonstrate the power and the flexibility of the platform using a microscopy case study based on a combinatorial multiple fluorescence in situ hybridization (m-FISH) protocol and 3D-image reconstruction. iLAP is freely available under the open source license AGPL from http://genome.tugraz.at/iLAP/. Conclusion: iLAP is a flexible and versatile information management system, which has the potential to close the gap between electronic notebooks and LIMS and can therefore be of great value for a broad scientific community. © 2009 Stocker et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Roller E.; Ivakhno S.; Lee S.; Royce T.; Tanner S.","Roller, Eric (57191535893); Ivakhno, Sergii (15044823900); Lee, Steve (57191541355); Royce, Thomas (6602581040); Tanner, Stephen (9743863200)","57191535893; 15044823900; 57191541355; 6602581040; 9743863200","Canvas: Versatile and scalable detection of copy number variants","2016","Bioinformatics","10.1093/bioinformatics/btw163","90","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991498358&doi=10.1093%2fbioinformatics%2fbtw163&partnerID=40&md5=1ea01b94a56720ba1139039b96f722b2","Motivation: Versatile and efficient variant calling tools are needed to analyze large scale sequencing datasets. In particular, identification of copy number changes remains a challenging task due to their complexity, susceptibility to sequencing biases, variation in coverage data and dependence on genome-wide sample properties, such as tumor polyploidy or polyclonality in cancer samples. Results: We have developed a new tool, Canvas, for identification of copy number changes from diverse sequencing experiments including whole-genome matched tumor-normal and single-sample normal re-sequencing, as well as whole-exome matched and unmatched tumor-normal studies. In addition to variant calling, Canvas infers genome-wide parameters such as cancer ploidy, purity and heterogeneity. It provides fast and easy-to-run workflows that can scale to thousands of samples and can be easily incorporated into variant calling pipelines. Availability and Implementation: Canvas is distributed under an open source license and can be downloaded from https://github.com/Illumina/canvas. © 2016 The Author 2016. Published by Oxford University Press. All rights reserved.","","Article","Scopus"
"Albano R.; Manfreda S.; Celano G.","Albano, Raffaele (54963014000); Manfreda, Salvatore (13403143600); Celano, Giuseppe (7004000989)","54963014000; 13403143600; 7004000989","MY SIRR: Minimalist agro-hYdrological model for Sustainable IRRigation management—Soil moisture and crop dynamics","2017","SoftwareX","10.1016/j.softx.2017.04.005","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020621938&doi=10.1016%2fj.softx.2017.04.005&partnerID=40&md5=3aa8b4876769ae3def8a314deb5b4324","The paper introduces a minimalist water-driven crop model for sustainable irrigation management using an eco-hydrological approach. Such model, called MY SIRR, uses a relatively small number of parameters and attempts to balance simplicity, accuracy, and robustness. MY SIRR is a quantitative tool to assess water requirements and agricultural production across different climates, soil types, crops, and irrigation strategies. The MY SIRR source code is published under copyleft license. The FOSS approach could lower the financial barriers of smallholders, especially in developing countries, in the utilization of tools for better decision-making on the strategies for short- and long-term water resource management. © 2017","Agro-hydrology; Crop dynamics; Irrigation management; Soil moisture","Article","Scopus"
"Jalili V.; Matteucci M.; Masseroli M.; Ceri S.","Jalili, Vahid (56685367300); Matteucci, Matteo (7005216953); Masseroli, Marco (56219698500); Ceri, Stefano (7006299676)","56685367300; 7005216953; 56219698500; 7006299676","Explorative visual analytics on interval-based genomic data and their metadata","2017","BMC Bioinformatics","10.1186/s12859-017-1945-9","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037363030&doi=10.1186%2fs12859-017-1945-9&partnerID=40&md5=d6bea9e353a5626320525ae42fc3358b","Background: With the wide-spreading of public repositories of NGS processed data, the availability of user-friendly and effective tools for data exploration, analysis and visualization is becoming very relevant. These tools enable interactive analytics, an exploratory approach for the seamless ""sense-making"" of data through on-the-fly integration of analysis and visualization phases, suggested not only for evaluating processing results, but also for designing and adapting NGS data analysis pipelines. Results: This paper presents abstractions for supporting the early analysis of NGS processed data and their implementation in an associated tool, named GenoMetric Space Explorer (GeMSE). This tool serves the needs of the GenoMetric Query Language, an innovative cloud-based system for computing complex queries over heterogeneous processed data. It can also be used starting from any text files in standard BED, BroadPeak, NarrowPeak, GTF, or general tab-delimited format, containing numerical features of genomic regions; metadata can be provided as text files in tab-delimited attribute-value format. GeMSE allows interactive analytics, consisting of on-the-fly cycling among steps of data exploration, analysis and visualization that help biologists and bioinformaticians in making sense of heterogeneous genomic datasets. By means of an explorative interaction support, users can trace past activities and quickly recover their results, seamlessly going backward and forward in the analysis steps and comparative visualizations of heatmaps. Conclusions: GeMSE effective application and practical usefulness is demonstrated through significant use cases of biological interest. GeMSE is available at http://www.bioinformatics.deib.polimi.it/GeMSE/ , and its source code is available at https://github.com/Genometric/GeMSEunder GPLv3 open-source license. © 2017 The Author(s).","Comparative evaluation; Exploration; Genomic data analysis; Interactive and visual analytics; Next Generation Sequencing; Visualization","Article","Scopus"
"Bethge A.; Schumacher U.; Wedemann G.","Bethge, Anja (55193794200); Schumacher, Udo (7102933228); Wedemann, Gero (6507993432)","55193794200; 7102933228; 6507993432","Simulation of metastatic progression using a computer model including chemotherapy and radiation therapy","2015","Journal of Biomedical Informatics","10.1016/j.jbi.2015.07.011","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949487704&doi=10.1016%2fj.jbi.2015.07.011&partnerID=40&md5=b87b59a11e518d3e46b52a414e8fda16","Introduction: Despite considerable research efforts, the process of metastasis formation is still a subject of intense discussion, and even established models differ considerably in basic details and in the conclusions drawn from them. Mathematical and computational models add a new perspective to the research as they can quantitatively investigate the processes of metastasis and the effects of treatment. However, existing models look at only one treatment option at a time. Methods: We enhanced a previously developed computer model (called CaTSiT) that enables quantitative comparison of different metastasis formation models with clinical and experimental data, to include the effects of chemotherapy, external beam radiation, radioimmunotherapy and radioembolization. CaTSiT is based on a discrete event simulation procedure. The growth of the primary tumor and its metastases is modeled by a piecewise-defined growth function that describes the growth behavior of the primary tumor and metastases during various time intervals. The piecewise-defined growth function is composed of analytical functions describing the growth behavior of the tumor based on characteristics of the tumor, such as dormancy, or the effects of various therapies. The spreading of malignant cells into the blood is modeled by intravasation events, which are generated according to a rate function. Further events in the model describe the behavior of the released malignant cells until the formation of a new metastasis. The model is published under the GNU General Public License version 3. Results: To demonstrate the application of the computer model, a case of a patient with a hepatocellular carcinoma and multiple metastases in the liver was simulated. Besides the untreated case, different treatments were simulated at two time points: one directly after diagnosis of the primary tumor and the other several months later. Except for early applied radioimmunotherapy, no treatment strategy was able to eliminate all metastases. These results emphasize the importance of early diagnosis and of proceeding with treatment even if no clinically detectable metastases are present at the time of diagnosis of the primary tumor. Conclusion: CaTSiT could be a valuable tool for quantitative investigation of the process of tumor growth and metastasis formation, including the effects of various treatment options. © 2015 Elsevier Inc.","Chemotherapy; Computer simulation; Metastasis; Radioembolization; Radioimmunotherapy; Radiotherapy","Article","Scopus"
"Clark S.C.; Egan R.; Frazier P.I.; Wang Z.","Clark, Scott C. (55605908100); Egan, Rob (37360894800); Frazier, Peter I. (21742757900); Wang, Zhong (57192442070)","55605908100; 37360894800; 21742757900; 57192442070","ALE: A generic assembly likelihood evaluation framework for assessing the accuracy of genome and metagenome assemblies","2013","Bioinformatics","10.1093/bioinformatics/bts723","115","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874322149&doi=10.1093%2fbioinformatics%2fbts723&partnerID=40&md5=40fbbe3850dc27a98860975adc022879","Motivation: Researchers need general purpose methods for objectively evaluating the accuracy of single and metagenome assemblies and for automatically detecting any errors they may contain. Current methods do not fully meet this need because they require a reference, only consider one of the many aspects of assembly quality or lack statistical justification, and none are designed to evaluate metagenome assemblies. Results: In this article, we present an Assembly Likelihood Evaluation (ALE) framework that overcomes these limitations, systematically evaluating the accuracy of an assembly in a reference-independent manner using rigorous statistical methods. This framework is comprehensive, and integrates read quality, mate pair orientation and insert length (for paired-end reads), sequencing coverage, read alignment and k-mer frequency. ALE pinpoints synthetic errors in both single and metagenomic assemblies, including single-base errors, insertions/deletions, genome rearrangements and chimeric assemblies presented in metagenomes. At the genome level with real-world data, ALE identifies three large misassemblies from the Spirochaeta smaragdinae finished genome, which were all independently validated by Pacific Biosciences sequencing. At the single-base level with Illumina data, ALE recovers 215 of 222 (97%) single nucleotide variants in a training set from a GC-rich Rhodobacter sphaeroides genome. Using real Pacific Biosciences data, ALE identifies 12 of 12 synthetic errors in a Lambda Phage genome, surpassing even Pacific Biosciences' own variant caller, EviCons. In summary, the ALE framework provides a comprehensive, reference-independent and statistically rigorous measure of single genome and metagenome assembly accuracy, which can be used to identify misassemblies or to optimize the assembly process. Availability: ALE is released as open source software under the UoI/NCSA license at http://www.alescore.org. It is implemented in C and Python. © 2013 The Author.","","Article","Scopus"
"Churches T.; Christen P.; Lim K.; Zhu J.X.","Churches, Tim (6602724787); Christen, Peter (7101797961); Lim, Kim (7403176034); Zhu, Justin Xi (55357183000)","6602724787; 7101797961; 7403176034; 55357183000","Preparation of name and address data for record linkage using hiddenMarkov models","2002","BMC Medical Informatics and Decision Making","10.1186/1472-6947-2-1","75","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884417241&doi=10.1186%2f1472-6947-2-1&partnerID=40&md5=0a5268044ad280988652a81d4aa2e2ae","Background: Record linkage refers to the process of joining records that relate to the same entity or event in one or more data collections. In the absence of a shared, unique key, record linkage involves the comparison of ensembles of partially-identifying, non-unique data items between pairs of records. Data items with variable formats, such as names and addresses, need to be transformed and normalised in order to validly carry out these comparisons. Traditionally, deterministic rule-based data processing systems have been used to carry out this pre-processing, which is commonly referred to as ""standardisation"". This paper describes an alternative approach to standardisation, using a combination of lexicon-based tokenisation and probabilistic hidden Markov models (HMMs). Methods: HMMs were trained to standardise typical Australian name and address data drawn from a range of health data collections. The accuracy of the results was compared to that produced by rule-based systems. Results: Training of HMMs was found to be quick and did not require any specialised skills. For addresses, HMMs produced equal or better standardisation accuracy than a widely-used rule-based system. However, acccuracy was worse when used with simpler name data. Possible reasons for this poorer performance are discussed. Conclusion: Lexicon-based tokenisation and HMMs provide a viable and effort-effective alternative to rule-based systems for pre-processing more complex variably formatted data such as addresses. Further work is required to improve the performance of this approach with simpler data such as names. Software which implements the methods described in this paper is freely available under an open source license for other researchers to use and improve.","","Article","Scopus"
"Vernikouskaya I.; Bertsche D.; Rottbauer W.; Rasche V.","Vernikouskaya, Ina (55540068800); Bertsche, Dagmar (57221699264); Rottbauer, Wolfgang (6506009499); Rasche, Volker (6701536469)","55540068800; 57221699264; 6506009499; 6701536469","Deep learning-based framework for motion-compensated image fusion in catheterization procedures","2022","Computerized Medical Imaging and Graphics","10.1016/j.compmedimag.2022.102069","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130396710&doi=10.1016%2fj.compmedimag.2022.102069&partnerID=40&md5=c94dea184b3c741f482115213de71669","Objective: Augmenting X-ray (XR) fluoroscopy with 3D anatomic overlays is an essential technique to improve the guidance of the catheterization procedures. Unfortunately, cardiac and respiratory motion compromises the augmented fluoroscopy. Motion compensation methods can be applied to update the overlay of a static model with regard to respiratory and cardiac motion. We investigate the feasibility of motion detection between two fluoroscopic frames by applying a convolutional neural network (CNN). Its integration in the existing open-source software framework 3D-XGuide is demonstrated, such extending its functionality to automatic motion detection and compensation. Methods: The CNN is trained on reference data generated from tracking of the rapid pacing catheter tip by applying template matching with normalized cross-correlation (CC). The developed CNN motion compensation model is packaged in a standalone web service, allowing for independent use via a REST API. For testing and demonstration purposes, we have extended the functionality of 3D-XGuide navigation framework by an additional motion compensation module, which uses the displacement predictions of the standalone CNN model service for motion compensation of the static 3D model overlay. We provide the source code on GitHub under BSD license. Results: The performance of the CNN motion compensation model was evaluated on a total of 1690 fluoroscopic image pairs from ten clinical datasets. The CNN model-based motion compensation method clearly overperformed the tracking of the rapid pacing catheter tip with CC with prediction frame rates suitable for live application in the clinical setting. Conclusion: A novel CNN model-based method for automatic motion compensation during fusion of 3D anatomic models with XR fluoroscopy is introduced and its integration with a real software application demonstrated. Automatic motion extraction from 2D XR images using a CNN model appears as a substantial improvement for reliable augmentation during catheter interventions. © 2022 The Authors","Convolutional neural network; Cross-correlation; Image-guided interventions; Model serving; Motion compensation; Rapid pacing catheter","Article","Scopus"
"Helfer T.; Michel B.; Proix J.-M.; Salvo M.; Sercombe J.; Casella M.","Helfer, Thomas (56350188400); Michel, Bruno (7202124400); Proix, Jean-Michel (6506291017); Salvo, Maxime (56374027800); Sercombe, Jérôme (6701647815); Casella, Michel (56730272100)","56350188400; 7202124400; 6506291017; 56374027800; 6701647815; 56730272100","Introducing the open-source mfront code generator: Application to mechanical behaviours and material knowledge management within the PLEIADES fuel element modelling platform","2015","Computers and Mathematics with Applications","10.1016/j.camwa.2015.06.027","56","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944384373&doi=10.1016%2fj.camwa.2015.06.027&partnerID=40&md5=46a55bdbe6dcab574c6a7e9b0c7e9f6b","The PLEIADES software environment is devoted to the thermomechanical simulation of nuclear fuel elements behaviour under irradiation. This platform is co-developed in the framework of a research cooperative program between Électricité de France (EDF), AREVA and the French Atomic Energy Commission (CEA). As many thermomechanical solvers are used within the platform, one of the PLEAIADES's main challenge is to propose a unified software environment for capitalisation of material knowledge coming from research and development programs on various nuclear systems. This paper introduces a tool called mfront which is basically a code generator based on C++ (Stroustrup and Eberhardt, 2004). Domain specific languages are provided which were designed to simplify the implementations of new material properties, mechanical behaviours and simple material models. mfront was recently released under the GPL open-source licence and is available on its web site: http://tfel.sourceforge.net/. The authors hope that it will prove useful for researchers and engineers, in particular in the field of solid mechanics. mfront interfaces generate code specific to each solver and language considered. In this paper, after a general overview of mfront functionalities, a particular focus is made on mechanical behaviours which are by essence more complex and may have significant impact on the numerical performances of mechanical simulations. mfront users can describe all kinds of mechanical phenomena, such as viscoplasticity, plasticity and damage, for various types of mechanical behaviour (small strain or finite strain behaviour, cohesive zone models). Performance benchmarks, performed using the Code-Aster finite element solver, show that the code generated using mfront is in most cases on par or better than the behaviour implementations written in fortran natively available in this solver. The material knowledge management strategy that was set up within the PLEIADES platform is briefly discussed. A material database named sirius proposes a rigorous material verification workflow. We illustrate the use of mfront through two case of studies: a simple FFC single crystal viscoplastic behaviour and the implementation of a recent behaviour for the fuel material which describes various phenomena: fuel cracking, plasticity and viscoplasticity. © 2015 Elsevier Ltd.","Domain specific languages; Implicit integration schemes; Material knowledge management; Mechanical behaviour integration; Single crystal plasticity","Article","Scopus"
"Artigaud S.; Gauthier O.; Pichereau V.","Artigaud, Sébastien (55820165400); Gauthier, Olivier (57203950824); Pichereau, Vianney (6701487628)","55820165400; 57203950824; 6701487628","Identifying differentially expressed proteins in two-dimensional electrophoresis experiments: Inputs from transcriptomics statistical tools","2013","Bioinformatics","10.1093/bioinformatics/btt464","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886074872&doi=10.1093%2fbioinformatics%2fbtt464&partnerID=40&md5=8eac8283b7eaf7fa5b77e0ed9ec45650","Background: Two-dimensional electrophoresis is a crucial method in proteomics that allows the characterization of proteins' function and expression. This usually implies the identification of proteins that are differentially expressed between two contrasting conditions, for example, healthy versus diseased in human proteomics biomarker discovery and stressful conditions versus control in animal experimentation. The statistical procedures that lead to such identifications are critical steps in the 2-DE analysis workflow. They include a normalization step and a test and probability correction for multiple testing. Statistical issues caused by the high dimensionality of the data and large-scale multiple testing have been a more active topic in transcriptomics than proteomics, especially in microarray analysis. We thus propose to adapt innovative statistical tools developed for microarray analysis and incorporate them in the 2-DE analysis pipeline. Results: In this article, we evaluate the performance of different normalization procedures, different statistical tests and false discovery rate calculation methods with both real and simulated datasets. We demonstrate that the use of statistical procedures adapted from microarrays lead to notable increase in power as well as a minimization of false-positive discovery rate. More specifically, we obtained the best results in terms of reliability and sensibility when using the 'moderate t-test' from Smyth in association with classic false discovery rate from Benjamini and Hochberg. Availability: The methods discussed are freely available in the 'prot2D' open source R-package from Bioconductor (http://www.bioconductor.org//) under the terms of the GNU General Public License (version 2 or later). © 2013 The Author 2013.","","Article","Scopus"
"Gainza P.; Roberts K.E.; Donald B.R.","Gainza, Pablo (25824841800); Roberts, Kyle E. (37087650600); Donald, Bruce R. (7005215486)","25824841800; 37087650600; 7005215486","Protein design using continuous rotamers","2012","PLoS Computational Biology","10.1371/journal.pcbi.1002335","80","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857498912&doi=10.1371%2fjournal.pcbi.1002335&partnerID=40&md5=d20c6949e3436bac25de2e3eee6e0a3c","Optimizing amino acid conformation and identity is a central problem in computational protein design. Protein design algorithms must allow realistic protein flexibility to occur during this optimization, or they may fail to find the best sequence with the lowest energy. Most design algorithms implement side-chain flexibility by allowing the side chains to move between a small set of discrete, low-energy states, which we call rigid rotamers. In this work we show that allowing continuous side-chain flexibility (which we call continuous rotamers) greatly improves protein flexibility modeling. We present a large-scale study that compares the sequences and best energy conformations in 69 protein-core redesigns using a rigid-rotamer model versus a continuous-rotamer model. We show that in nearly all of our redesigns the sequence found by the continuous-rotamer model is different and has a lower energy than the one found by the rigid-rotamer model. Moreover, the sequences found by the continuous-rotamer model are more similar to the native sequences. We then show that the seemingly easy solution of sampling more rigid rotamers within the continuous region is not a practical alternative to a continuous-rotamer model: at computationally feasible resolutions, using more rigid rotamers was never better than a continuous-rotamer model and almost always resulted in higher energies. Finally, we present a new protein design algorithm based on the dead-end elimination (DEE) algorithm, which we call iMinDEE, that makes the use of continuous rotamers feasible in larger systems. iMinDEE guarantees finding the optimal answer while pruning the search space with close to the same efficiency of DEE. <bold>Availability:</bold> Software is available under the Lesser GNU Public License v3. Contact the authors for source code. © 2012 Gainza et al.","","Article","Scopus"
"Adamczak R.; Meller J.","Adamczak, Rafal (57358686700); Meller, Jarek (7006142349)","57358686700; 7006142349","UQlust: Combining profile hashing with linear-time ranking for efficient clustering and analysis of big macromolecular data","2016","BMC Bioinformatics","10.1186/s12859-016-1381-2","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007453886&doi=10.1186%2fs12859-016-1381-2&partnerID=40&md5=8253f0bd722b72595c386b4d5029a0cf","Background: Advances in computing have enabled current protein and RNA structure prediction and molecular simulation methods to dramatically increase their sampling of conformational spaces. The quickly growing number of experimentally resolved structures, and databases such as the Protein Data Bank, also implies large scale structural similarity analyses to retrieve and classify macromolecular data. Consequently, the computational cost of structure comparison and clustering for large sets of macromolecular structures has become a bottleneck that necessitates further algorithmic improvements and development of efficient software solutions. Results: uQlust is a versatile and easy-to-use tool for ultrafast ranking and clustering of macromolecular structures. uQlust makes use of structural profiles of proteins and nucleic acids, while combining a linear-time algorithm for implicit comparison of all pairs of models with profile hashing to enable efficient clustering of large data sets with a low memory footprint. In addition to ranking and clustering of large sets of models of the same protein or RNA molecule, uQlust can also be used in conjunction with fragment-based profiles in order to cluster structures of arbitrary length. For example, hierarchical clustering of the entire PDB using profile hashing can be performed on a typical laptop, thus opening an avenue for structural explorations previously limited to dedicated resources. The uQlust package is freely available under the GNU General Public License at https://github.com/uQlust. Conclusion: uQlust represents a drastic reduction in the computational complexity and memory requirements with respect to existing clustering and model quality assessment methods for macromolecular structure analysis, while yielding results on par with traditional approaches for both proteins and RNAs. © 2016 The Author(s).","Hierarchical clustering; Macromolecular structure analysis; Model quality assessment; Profile hashing; Protein structure; RNA structure","Article","Scopus"
"Harvey W.; Park I.-H.; Rübel O.; Pascucci V.; Bremer P.-T.; Li C.; Wang Y.","Harvey, William (57198236162); Park, In-Hee (35314965400); Rübel, Oliver (24067719500); Pascucci, Valerio (7004091719); Bremer, Peer-Timo (57200136882); Li, Chenglong (35299728200); Wang, Yusu (57201620584)","57198236162; 35314965400; 24067719500; 7004091719; 57200136882; 35299728200; 57201620584","A collaborative visual analytics suite for protein folding research","2014","Journal of Molecular Graphics and Modelling","10.1016/j.jmgm.2014.06.003","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905196798&doi=10.1016%2fj.jmgm.2014.06.003&partnerID=40&md5=f3feb4289f26ba08f1dbec6b1cbc52a2","Molecular dynamics (MD) simulation is a crucial tool for understanding principles behind important biochemical processes such as protein folding and molecular interaction. With the rapidly increasing power of modern computers, large-scale MD simulation experiments can be performed regularly, generating huge amounts of MD data. An important question is how to analyze and interpret such massive and complex data. One of the (many) challenges involved in analyzing MD simulation data computationally is the high-dimensionality of such data. Given a massive collection of molecular conformations, researchers typically need to rely on their expertise and prior domain knowledge in order to retrieve certain conformations of interest. It is not easy to make and test hypotheses as the data set as a whole is somewhat ""invisible"" due to its high dimensionality. In other words, it is hard to directly access and examine individual conformations from a sea of molecular structures, and to further explore the entire data set. There is also no easy and convenient way to obtain a global view of the data or its various modalities of biochemical information. To this end, we present an interactive, collaborative visual analytics tool for exploring massive, high-dimensional molecular dynamics simulation data sets. The most important utility of our tool is to provide a platform where researchers can easily and effectively navigate through the otherwise ""invisible"" simulation data sets, exploring and examining molecular conformations both as a whole and at individual levels. The visualization is based on the concept of a topological landscape, which is a 2D terrain metaphor preserving certain topological and geometric properties of the high dimensional protein energy landscape. In addition to facilitating easy exploration of conformations, this 2D terrain metaphor also provides a platform where researchers can visualize and analyze various properties (such as contact density) overlayed on the top of the 2D terrain. Finally, the software provides a collaborative environment where multiple researchers can assemble observations and biochemical events into storyboards and share them in real time over the Internet via a client-server architecture. The software is written in Scala and runs on the cross-platform Java Virtual Machine. Binaries and source code are available at http://www.aylasoftware.org and have been released under the GNU General Public License. © 2014 Elsevier Inc.","Molecular simulation data; Visualization tool","Article","Scopus"
"Caspari A.; Fahr S.; Mitsos A.","Caspari, Adrian (57192162456); Fahr, Steffen (57219452891); Mitsos, Alexander (8979766700)","57192162456; 57219452891; 8979766700","Optimal Eco-Routing for Hybrid Vehicles With Powertrain Model Embedded","2022","IEEE Transactions on Intelligent Transportation Systems","10.1109/TITS.2021.3131298","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121341886&doi=10.1109%2fTITS.2021.3131298&partnerID=40&md5=e01b6715668c5a51ced87c19aabed9c7","Exploiting the full potential of hybrid electric vehicles (HEVs) requires suitable (i) route selection and (ii) power management. Due to coupling of the two subproblems, an integrated optimization problem is desired, i.e., optimizing simultaneously the route selection and the split between combustion engine and electric motor over the entire route selection. The resulting optimal route and vehicle operation can be used as a basis for a subordinate vehicle controller. We present an eco-routing approach that embeds a hybrid (mechanistic/data-driven) model of the HEV powertrain in an integrated routing and power management optimization problem. Formulating the integrated routing problem with the hybrid model yields a mixed-integer bilinear program which we reformulate and solve a mixed-integer linear program using a state-of-the-art solver. The results show the validity of the developed hybrid powertrain model and demonstrate that the eco routing approach with the powertrain model embedded can be applied to large-scale problems. We consider optimization for minimal travel time and minimum fuel consumption. The latter results in fuel demand reductions up to 70 %. Alternatively, we minimize the fuel consumption while constraining the travel time to a maximum value resulting in up to 50 % fuel demand reductions. The highest fuel demand reductions are achieved in urban environments. The entire framework is written in python and provided as an open-source version (MIT License) under https://git.rwth-aachen.de/avt-svt/public/optimal-routing that can readily be applied. © 2000-2011 IEEE.","carbon foot reduction; eco routing; hybrid vehicles; mechanistic/data-driven modeling; mixed-integer linear programming; Optimal vehicle routing and operation","Article","Scopus"
"Al-Jaff M.; Sandström E.; Grabherr M.","Al-Jaff, Mohammed (57194155190); Sandström, Eric (57194157872); Grabherr, Manfred (9744255400)","57194155190; 57194157872; 9744255400","MicroTaboo: A general and practical solution to the k-disjoint problem","2017","BMC Bioinformatics","10.1186/s12859-017-1644-6","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019007264&doi=10.1186%2fs12859-017-1644-6&partnerID=40&md5=748c2b56140ea041a33e895daee7b45e","Background: A common challenge in bioinformatics is to identify short sub-sequences that are unique in a set of genomes or reference sequences, which can efficiently be achieved by k-mer (k consecutive nucleotides) counting. However, there are several areas that would benefit from a more stringent definition of ""unique"", requiring that these sub-sequences of length W differ by more than k mismatches (i.e. a Hamming distance greater than k) from any other sub-sequence, which we term the k-disjoint problem. Examples include finding sequences unique to a pathogen for probe-based infection diagnostics; reducing off-target hits for re-sequencing or genome editing; detecting sequence (e.g. phage or viral) insertions; and multiple substitution mutations. Since both sensitivity and specificity are critical, an exhaustive, yet efficient solution is desirable. Results: We present microTaboo, a method that allows for efficient and extensive sequence mining of unique (k-disjoint) sequences of up to 100 nucleotides in length. On a number of simulated and real data sets ranging from microbe- to mammalian-size genomes, we show that microTaboo is able to efficiently find all sub-sequences of a specified length W that do not occur within a threshold of k mismatches in any other sub-sequence. We exemplify that microTaboo has many practical applications, including point substitution detection, sequence insertion detection, padlock probe target search, and candidate CRISPR target mining. Conclusions: microTaboo implements a solution to the k-disjoint problem in an alignment- and assembly free manner. microTaboo is available for Windows, Mac OS X, and Linux, running Java 7 and higher, under the GNU GPLv3 license, at: https://MohammedAlJaff.github.io/microTaboo © 2017 The Author(s).","K-disjoint problem; Sequence mining; Software","Article","Scopus"
"Caplan P.","Caplan, Priscilla (7003930494)","7003930494","The Florida digital archive and DAITSS: A model for digital preservation","2010","Library Hi Tech","10.1108/07378831011047631","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954011630&doi=10.1108%2f07378831011047631&partnerID=40&md5=8df7a2a8da765c0f3fef682f0153a1f2","Purpose: This paper aims to describe the Florida Digital Archive (FDA), a long-term preservation repository for the use of the public university system of Florida, and the DAITSS preservation repository application used by the FDA. It seeks to explain requirements that shaped DAITSS design, outline functions of the current software, and describe how DAITSS is being rearchitected as a series of Web Services (DAITSS 2). It also endeavours to place the FDA and DAITSS in the context of various models for implementing digital preservation functions. Design/methodology/approach: This is a case study of one model of digital preservation implementation that includes some comparison with examples of other models. The preservation protocol implemented by DAITSS combines bit-level preservation, format normalization, and forward format migration; extensive preservation and format-specific metadata are supported, and authenticity of content is maintained through application design and a complete record of digital provenance. Findings: The formal OAIS model has much to offer, and DAITSS could be part of a preservation solution for large academic/research libraries and for consortia who can share central computing facilities and staff. Practical implications: When DAITSS 2 is completed and implemented by the Florida Digital Archive, the code will be released for use under an open source license. Institutions, consortia and third party service providers looking for a more complete preservation solution than simple replication can consider using DAITSS 2 as their digital preservation repository application. Originality/value: There are very few preservation repository applications that do nothing but digital preservation, do it well, and formally implement the OAIS model. The Florida Digital Archive's DAITSS was the first of its kind in the USA. DAITSS 2 will conform to the same requirements as DAITSS and will retain the same functionality, but it will be easier to implement and manage in production, and easier to maintain and enhance. © Emerald Group Publishing Limited.","Archives management; Digital libraries; Digital storage","Article","Scopus"
"Sateli B.; Löffler F.; König-Ries B.; Witte R.","Sateli, Bahar (39062011400); Löffler, Felicitas (56414391800); König-Ries, Birgitta (55864942100); Witte, René (23010981400)","39062011400; 56414391800; 55864942100; 23010981400","ScholarLens: Extracting competences from research publications for the automatic generation of semantic user profiles","2017","PeerJ Computer Science","10.7717/peerj-cs.121","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030097558&doi=10.7717%2fpeerj-cs.121&partnerID=40&md5=dd858ea8b2fdcf1f5031ef1c04f31f3f","Motivation. Scientists increasingly rely on intelligent information systems to help them in their daily tasks, in particular for managing research objects, like publications or datasets. The relatively young research field of Semantic Publishing has been addressing the question how scientific applications can be improved through semantically rich representations of research objects, in order to facilitate their discovery and re-use. To complement the efforts in this area, we propose an automatic workflow to construct semantic user profiles of scholars, so that scholarly applications, like digital libraries or data repositories, can better understand their users' interests, tasks, and competences, by incorporating these user profiles in their design. To make the user profiles sharable across applications, we propose to build them based on standard semantic web technologies, in particular the Resource Description Framework (RDF) for representing user profiles and Linked Open Data (LOD) sources for representing competence topics. To avoid the cold start problem, we suggest to automatically populate these profiles by analyzing the publications (co-)authored by users, which we hypothesize reflect their research competences. Results. We developed a novel approach, ScholarLens, which can automatically generate semantic user profiles for authors of scholarly literature. For modeling the competences of scholarly users and groups, we surveyed a number of existing linked open data vocabularies. In accordance with the LOD best practices, we propose an RDF Schema (RDFS) based model for competence records that reuses existing vocabularies where appropriate. To automate the creation of semantic user profiles, we developed a complete, automated workflow that can generate semantic user profiles by analyzing full-text research articles through various natural language processing (NLP) techniques. In our method, we start by processing a set of research articles for a given user. Competences are derived by text mining the articles, including syntactic, semantic, and LOD entity linking steps. We then populate a knowledge base in RDF format with user profiles containing the extracted competences.We implemented our approach as an open source library and evaluated our system through two user studies, resulting in mean average precision (MAP) of up to 95%. As part of the evaluation, we also analyze the impact of semantic zoning of research articles on the accuracy of the resulting profiles. Finally, we demonstrate how these semantic user profiles can be applied in a number of use cases, including article ranking for personalized search and finding scientists competent in a topic -e.g., to find reviewers for a paper. Availability. All software and datasets presented in this paper are available under open source licenses in the supplements and documented at http://www.semanticsoftware. info/semantic-user-profiling-peerj-2016-supplements. Additionally, development releases of ScholarLens are available on our GitHub page: https://github.com/ SemanticSoftwareLab/ScholarLens. © 2017 Sateli et al.","Linked open data; Natural language processing; Scholarly user modeling; Semantic publishing; Semantic user profile","Article","Scopus"
"Diaz-Guerra D.; Miguel A.; Beltran J.R.","Diaz-Guerra, David (57203925234); Miguel, Antonio (7004814137); Beltran, Jose R. (7102677859)","57203925234; 7004814137; 7102677859","gpuRIR: A python library for room impulse response simulation with GPU acceleration","2021","Multimedia Tools and Applications","10.1007/s11042-020-09905-3","24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092419240&doi=10.1007%2fs11042-020-09905-3&partnerID=40&md5=9b97adfc9732f78ed92abc828b7daaae","The Image Source Method (ISM) is one of the most employed techniques to calculate acoustic Room Impulse Responses (RIRs), however, its computational complexity grows fast with the reverberation time of the room and its computation time can be prohibitive for some applications where a huge number of RIRs are needed. In this paper, we present a new implementation that dramatically improves the computation speed of the ISM by using Graphic Processing Units (GPUs) to parallelize both the simulation of multiple RIRs and the computation of the images inside each RIR. Additional speedups were achieved by exploiting the mixed precision capabilities of the newer GPUs and by using lookup tables. We provide a Python library under GNU license that can be easily used without any knowledge about GPU programming and we show that it is about 100 times faster than other state of the art CPU libraries. It may become a powerful tool for many applications that need to perform a large number of acoustic simulations, such as training machine learning systems for audio signal processing, or for real-time room acoustics simulations for immersive multimedia systems, such as augmented or virtual reality. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","Graphic processing units (GPUs); Image source method (ISM); Room acoustics; Room impulse response (RIR)","Article","Scopus"
"Capra J.A.; Williams A.G.; Pollard K.S.","Capra, John A. (19639806400); Williams, Alexander G. (57211866826); Pollard, Katherine S. (35235175500)","19639806400; 57211866826; 35235175500","Proteinhistorian: Tools for the comparative analysis of eukaryote protein origin","2012","PLoS Computational Biology","10.1371/journal.pcbi.1002567","58","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864065413&doi=10.1371%2fjournal.pcbi.1002567&partnerID=40&md5=f186965bc82ba85936805e4f10e3884d","The evolutionary history of a protein reflects the functional history of its ancestors. Recent phylogenetic studies identified distinct evolutionary signatures that characterize proteins involved in cancer, Mendelian disease, and different ontogenic stages. Despite the potential to yield insight into the cellular functions and interactions of proteins, such comparative phylogenetic analyses are rarely performed, because they require custom algorithms. We developed ProteinHistorian to make tools for performing analyses of protein origins widely available. Given a list of proteins of interest, ProteinHistorian estimates the phylogenetic age of each protein, quantifies enrichment for proteins of specific ages, and compares variation in protein age with other protein attributes. ProteinHistorian allows flexibility in the definition of protein age by including several algorithms for estimating ages from different databases of evolutionary relationships. We illustrate the use of ProteinHistorian with three example analyses. First, we demonstrate that proteins with high expression in human, compared to chimpanzee and rhesus macaque, are significantly younger than those with human-specific low expression. Next, we show that human proteins with annotated regulatory functions are significantly younger than proteins with catalytic functions. Finally, we compare protein length and age in many eukaryotic species and, as expected from previous studies, find a positive, though often weak, correlation between protein age and length. ProteinHistorian is available through a web server with an intuitive interface and as a set of command line tools; this allows biologists and bioinformaticians alike to integrate these approaches into their analysis pipelines. ProteinHistorian's modular, extensible design facilitates the integration of new datasets and algorithms. The ProteinHistorian web server, source code, and pre-computed ages for 32 eukaryotic genomes are freely available under the GNU public license at http://lighthouse.ucsf.edu/ProteinHistorian/. © 2012 Capra et al.","","Article","Scopus"
"Côté R.G.; Jones P.; Apweiler R.; Hermjakob H.","Côté, Richard G. (12776864100); Jones, Philip (36080069100); Apweiler, Rolf (7005058025); Hermjakob, Henning (6701613156)","12776864100; 36080069100; 7005058025; 6701613156","The Ontology Lookup Service, a lightweight cross-platform tool for controlled vocabulary queries","2006","BMC Bioinformatics","10.1186/1471-2105-7-97","162","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33645348241&doi=10.1186%2f1471-2105-7-97&partnerID=40&md5=ea45327f24364ddda0def0ddf9c00530","Background: With the vast amounts of biomedical data being generated by high-throughput analysis methods, controlled vocabularies and ontologies are becoming increasingly important to annotate units of information for ease of search and retrieval. Each scientific community tends to create its own locally available ontology. The interfaces to query these ontologies tend to vary from group to group. We saw the need for a centralized location to perform controlled vocabulary queries that would offer both a lightweight web-accessible user interface as well as a consistent, unified SOAP interface for automated queries. Results: The Ontology Lookup Service (OLS) was created to integrate publicly available biomedical ontologies into a single database. All modified ontologies are updated daily. A list of currently loaded ontologies is available online. The database can be queried to obtain information on a single term or to browse a complete ontology using AJAX. Auto-completion provides a user-friendly search mechanism. An AJAX-based ontology viewer is available to browse a complete ontology or subsets of it. A programmatic interface is available to query the webservice using SOAP. The service is described by a WSDL descriptor file available online. A sample Java client to connect to the webservice using SOAP is available for download from SourceForge. All OLS source code is publicly available under the open source Apache Licence. Conclusion: The OLS provides a user-friendly single entry point for publicly available ontologies in the Open Biomedical Ontology (OBO) format. It can be accessed interactively or programmatically at http://www.ebi.ac.uk/ontology-lookup/. © 2006 Côté et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Scrima S.; Tiberti M.; Campo A.; Corcelle-Termeau E.; Judith D.; Foged M.M.; Clemmensen K.K.B.; Tooze S.A.; Jäättelä M.; Maeda K.; Lambrughi M.; Papaleo E.","Scrima, Simone (57238620800); Tiberti, Matteo (42462578900); Campo, Alessia (57470354100); Corcelle-Termeau, Elisabeth (45660975100); Judith, Delphine (55070011800); Foged, Mads Møller (57209240586); Clemmensen, Knut Kristoffer Bundgaard (57471184600); Tooze, Sharon A. (7004652751); Jäättelä, Marja (57205857274); Maeda, Kenji (56998106500); Lambrughi, Matteo (55520006900); Papaleo, Elena (11339375000)","57238620800; 42462578900; 57470354100; 45660975100; 55070011800; 57209240586; 57471184600; 7004652751; 57205857274; 56998106500; 55520006900; 11339375000","Unraveling membrane properties at the organelle-level with LipidDyn","2022","Computational and Structural Biotechnology Journal","10.1016/j.csbj.2022.06.054","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133941560&doi=10.1016%2fj.csbj.2022.06.054&partnerID=40&md5=aca443005949c760fe906e46aca37cf0","Cellular membranes are formed from different lipids in various amounts and proportions depending on the subcellular localization. The lipid composition of membranes is sensitive to changes in the cellular environment, and its alterations are linked to several diseases. Lipids not only form lipid-lipid interactions but also interact with other biomolecules, including proteins. Molecular dynamics (MD) simulations are a powerful tool to study the properties of cellular membranes and membrane-protein interactions on different timescales and resolutions. Over the last few years, software and hardware for biomolecular simulations have been optimized to routinely run long simulations of large and complex biological systems. On the other hand, high-throughput techniques based on lipidomics provide accurate estimates of the composition of cellular membranes at the level of subcellular compartments. Lipidomic data can be analyzed to design biologically relevant models of membranes for MD simulations. Similar applications easily result in a massive amount of simulation data where the bottleneck becomes the analysis of the data. In this context, we developed LipidDyn, a Python-based pipeline to streamline the analyses of MD simulations of membranes of different compositions. Once the simulations are collected, LipidDyn provides average properties and time series for several membrane properties such as area per lipid, thickness, order parameters, diffusion motions, lipid density, and lipid enrichment/depletion. The calculations exploit parallelization, and the pipeline includes graphical outputs in a publication-ready form. We applied LipidDyn to different case studies to illustrate its potential, including membranes from cellular compartments and transmembrane protein domains. LipidDyn is available free of charge under the GNU General Public License from https://github.com/ELELAB/LipidDyn. © 2022","Autophagy; Lipid structure; Lipidomics; Molecular dynamics; Organelles; Protein-lipid interactions","Article","Scopus"
"Chung R.-H.; Tsai W.-Y.; Kang C.-Y.; Yao P.-J.; Tsai H.-J.; Chen C.-H.","Chung, Ren-Hua (8896319300); Tsai, Wei-Yun (56382686700); Kang, Chen-Yu (57190284231); Yao, Po-Ju (57155854700); Tsai, Hui-Ju (7402649638); Chen, Chia-Hsiang (35197794800)","8896319300; 56382686700; 57190284231; 57155854700; 7402649638; 35197794800","FamPipe: An Automatic Analysis Pipeline for Analyzing Sequencing Data in Families for Disease Studies","2016","PLoS Computational Biology","10.1371/journal.pcbi.1004980","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978864803&doi=10.1371%2fjournal.pcbi.1004980&partnerID=40&md5=acd51811a35f8c0dc0dac1f18909ae04","In disease studies, family-based designs have become an attractive approach to analyzing next-generation sequencing (NGS) data for the identification of rare mutations enriched in families. Substantial research effort has been devoted to developing pipelines for automating sequence alignment, variant calling, and annotation. However, fewer pipelines have been designed specifically for disease studies. Most of the current analysis pipelines for family-based disease studies using NGS data focus on a specific function, such as identifying variants with Mendelian inheritance or identifying shared chromosomal regions among affected family members. Consequently, some other useful family-based analysis tools, such as imputation, linkage, and association tools, have yet to be integrated and automated. We developed FamPipe, a comprehensive analysis pipeline, which includes several family-specific analysis modules, including the identification of shared chromosomal regions among affected family members, prioritizing variants assuming a disease model, imputation of untyped variants, and linkage and association tests. We used simulation studies to compare properties of some modules implemented in FamPipe, and based on the results, we provided suggestions for the selection of modules to achieve an optimal analysis strategy. The pipeline is under the GNU GPL License and can be downloaded for free at http://fampipe.sourceforge.net. © 2016 Chung et al.","","Article","Scopus"
"Bassen D.M.; Vilkhovoy M.; Minot M.; Butcher J.T.; Varner J.D.","Bassen, David M. (55943655100); Vilkhovoy, Michael (56655160600); Minot, Mason (57193122312); Butcher, Jonathan T. (7102431189); Varner, Jeffrey D. (7102417132)","55943655100; 56655160600; 57193122312; 7102431189; 7102417132","JuPOETs: A constrained multiobjective optimization approach to estimate biochemical model ensembles in the Julia programming language","2017","BMC Systems Biology","10.1186/s12918-016-0380-2","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010934699&doi=10.1186%2fs12918-016-0380-2&partnerID=40&md5=fac6be401282f89b782c0fbaf6348337","Background: Ensemble modeling is a promising approach for obtaining robust predictions and coarse grained population behavior in deterministic mathematical models. Ensemble approaches address model uncertainty by using parameter or model families instead of single best-fit parameters or fixed model structures. Parameter ensembles can be selected based upon simulation error, along with other criteria such as diversity or steady-state performance. Simulations using parameter ensembles can estimate confidence intervals on model variables, and robustly constrain model predictions, despite having many poorly constrained parameters. Results: In this software note, we present a multiobjective based technique to estimate parameter or models ensembles, the Pareto Optimal Ensemble Technique in the Julia programming language (JuPOETs). JuPOETs integrates simulated annealing with Pareto optimality to estimate ensembles on or near the optimal tradeoff surface between competing training objectives. We demonstrate JuPOETs on a suite of multiobjective problems, including test functions with parameter bounds and system constraints as well as for the identification of a proof-of-concept biochemical model with four conflicting training objectives. JuPOETs identified optimal or near optimal solutions approximately six-fold faster than a corresponding implementation in Octave for the suite of test functions. For the proof-of-concept biochemical model, JuPOETs produced an ensemble of parameters that gave both the mean of the training data for conflicting data sets, while simultaneously estimating parameter sets that performed well on each of the individual objective functions. Conclusions: JuPOETs is a promising approach for the estimation of parameter and model ensembles using multiobjective optimization. JuPOETs can be adapted to solve many problem types, including mixed binary and continuous variable types, bilevel optimization problems and constrained problems without altering the base algorithm. JuPOETs is open source, available under an MIT license, and can be installed using the Julia package manager from the JuPOETs GitHub repository © 2017 The Author(s).","Ensemble modeling; Julia; Multiobjective optimization","Article","Scopus"
"Heinen S.; Thielen B.; Schomburg D.","Heinen, Stephanie (33867598300); Thielen, Bernhard (15761297200); Schomburg, Dietmar (15920858600)","33867598300; 15761297200; 15920858600","KID - an algorithm for fast and efficient text mining used to automatically generate a database containing kinetic information of enzymes","2010","BMC Bioinformatics","10.1186/1471-2105-11-375","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954401193&doi=10.1186%2f1471-2105-11-375&partnerID=40&md5=b61254090739a9f84b52dd059f543fa1","Background: The amount of available biological information is rapidly increasing and the focus of biological research has moved from single components to networks and even larger projects aiming at the analysis, modelling and simulation of biological networks as well as large scale comparison of cellular properties. It is therefore essential that biological knowledge is easily accessible. However, most information is contained in the written literature in an unstructured way, so that methods for the systematic extraction of knowledge directly from the primary literature have to be deployed.Description: Here we present a text mining algorithm for the extraction of kinetic information such as KM, Ki, kcat etc. as well as associated information such as enzyme names, EC numbers, ligands, organisms, localisations, pH and temperatures. Using this rule- and dictionary-based approach, it was possible to extract 514,394 kinetic parameters of 13 categories (KM, Ki, kcat, kcat/KM, Vmax, IC50, S0.5, Kd, Ka, t1/2, pI, nH, specific activity, Vmax/KM) from about 17 million PubMed abstracts and combine them with other data in the abstract.A manual verification of approx. 1,000 randomly chosen results yielded a recall between 51% and 84% and a precision ranging from 55% to 96%, depending of the category searched.The results were stored in a database and are available as ""KID the KInetic Database"" via the internet.Conclusions: The presented algorithm delivers a considerable amount of information and therefore may aid to accelerate the research and the automated analysis required for today's systems biology approaches. The database obtained by analysing PubMed abstracts may be a valuable help in the field of chemical and biological kinetics. It is completely based upon text mining and therefore complements manually curated databases.The database is available at http://kid.tu-bs.de. The source code of the algorithm is provided under the GNU General Public Licence and available on request from the author. © 2010 Heinen et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Zhang Y.; Li C.; Bai Y.","Zhang, Yang (55816561700); Li, Chunxia (57310396100); Bai, Yu (57226482984)","55816561700; 57310396100; 57226482984","Consistency validation method for Java fine-grained lock refactoring","2021","IEEE Access","10.1109/ACCESS.2021.3120414","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117774364&doi=10.1109%2fACCESS.2021.3120414&partnerID=40&md5=9a2bc43c27ae50788aefeabfbd144e46","Many existing refactoring tools reduce the possibility of lock conflicts and improve the concurrency of the system by reducing lock granularity and narrowing the scope of locked objects. However, such refactorings can lead to changes in concurrent program behavior, introduce concurrency errors, and often even produce code that does not compile or can be compiled but has changed semantics. To address the problem of changes in concurrent program behavior caused by transferring from coarse-grained locking to fine-grained lock refactoring, a refactoring consistency validation method for fine-grained locking is proposed. Firstly, the types of behavioral changes caused by the existing refactoring engine are analyzed in terms of thread interactions. Secondly, the relevant consistency checking rules are summarized according to the types. Finally, with the help of various program analysis techniques such as call graph analysis, alias analysis and side-effect analysis, the corresponding checking algorithms are designed according to the consistency checking rules to check the consistency of the program before and after refactoring. We implement an automatic validation tool as an Eclipse plug-in. Our approach is verified by ten open-source projects including HSQLDB, Xalan and Cassandra, etc. A total of 1,483 refactoring methods were tested, and 60 inconsistent synchronization behaviors were found, which improved the robustness of refactoring in terms of data dependence and execution order. © 2021 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","Alias analysis; Consistency validation; Fine-grained lock; Refactoring; Side-effect analysis","Article","Scopus"
"Curiale A.H.; Bernardo A.; Cárdenas R.; Mato G.","Curiale, Ariel Hernán (55785298900); Bernardo, Agustín (57219916185); Cárdenas, Rodrigo (57217870874); Mato, German (6701804115)","55785298900; 57219916185; 57217870874; 6701804115","CardIAc: an open-source application for myocardial strain analysis","2021","International Journal of Computer Assisted Radiology and Surgery","10.1007/s11548-020-02291-z","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096073612&doi=10.1007%2fs11548-020-02291-z&partnerID=40&md5=d02723b479d1b10d3f94731465d1fd9f","Purpose: This paper presents CardIAc, an open-source application designed as an alternative to commercial software for left ventricle myocardial strain quantification in short-axis cardiac magnetic resonance images. The aim is to provide a useful extension for myocardial strain analysis that can be easily adapted to incorporate different strategies of motion tracking to improve the strain accuracy.In this way, users with programming skills can easily modify the code and adjust the program’s performance according to their own scientific or clinical requirements. The software is intended for research and clinical use is not advised. Methods: CardIAc was developed as a 3D Slicer extension for an easy installation and usability. The main contribution of this article is to provide a general workflow, going from data and segmentation loading, 3D heart modeling, analysis and several options for visualization of the myocardial strain. Results: CardIAc strain feature was evaluated on a public dataset (Cardiac Motion Analysis Challenge—STACOM 2011) of 15 volunteers, and a synthetic one generated from this real dataset. Results on the real dataset show that cardIAc achieves suitable accuracy for myocardial motion estimation with a median error of 3.66 mm. In particular, global strain curves show strong correlation with the bibliography for healthy patients and similar approaches. On the other hand, results on the synthetic dataset show a mean global error of 4.07%, 7.76% and 8.18% for circumferential, radial and longitudinal strain. Conclusion: This paper introduces a new open-source application for strain analysis distributed under a BSD-style open-source license. Results demonstrate the capability and merits of the proposed application for strain analysis. © 2020, CARS.","3D Slicer extension; Cardiac quantification; Open source; Strain; Strain rate","Article","Scopus"
"McNutt A.T.; Francoeur P.; Aggarwal R.; Masuda T.; Meli R.; Ragoza M.; Sunseri J.; Koes D.R.","McNutt, Andrew T. (57271196800); Francoeur, Paul (57202890648); Aggarwal, Rishal (57219827455); Masuda, Tomohide (57219234939); Meli, Rocco (57188582571); Ragoza, Matthew (57190972676); Sunseri, Jocelyn (6506162431); Koes, David Ryan (6504625843)","57271196800; 57202890648; 57219827455; 57219234939; 57188582571; 57190972676; 6506162431; 6504625843","GNINA 1.0: molecular docking with deep learning","2021","Journal of Cheminformatics","10.1186/s13321-021-00522-2","48","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107452496&doi=10.1186%2fs13321-021-00522-2&partnerID=40&md5=569ab6578675494f79918d58fceb5923","Molecular docking computationally predicts the conformation of a small molecule when binding to a receptor. Scoring functions are a vital piece of any molecular docking pipeline as they determine the fitness of sampled poses. Here we describe and evaluate the 1.0 release of the Gnina docking software, which utilizes an ensemble of convolutional neural networks (CNNs) as a scoring function. We also explore an array of parameter values for Gnina 1.0 to optimize docking performance and computational cost. Docking performance, as evaluated by the percentage of targets where the top pose is better than 2Å root mean square deviation (Top1), is compared to AutoDock Vina scoring when utilizing explicitly defined binding pockets or whole protein docking. Gnina, utilizing a CNN scoring function to rescore the output poses, outperforms AutoDock Vina scoring on redocking and cross-docking tasks when the binding pocket is defined (Top1 increases from 58% to 73% and from 27% to 37%, respectively) and when the whole protein defines the binding pocket (Top1 increases from 31% to 38% and from 12% to 16%, respectively). The derived ensemble of CNNs generalizes to unseen proteins and ligands and produces scores that correlate well with the root mean square deviation to the known binding pose. We provide the 1.0 version of Gnina under an open source license for use as a molecular docking tool at https://github.com/gnina/gnina. © 2021, The Author(s).","Deep learning; Molecular docking; Structure-based drug design","Article","Scopus"
"Miles A.; Zhao J.; Klyne G.; White-Cooper H.; Shotton D.","Miles, Alistair (16747190700); Zhao, Jun (55169120800); Klyne, Graham (24385449500); White-Cooper, Helen (6602993922); Shotton, David (7003653225)","16747190700; 55169120800; 24385449500; 6602993922; 7003653225","OpenFlyData: An exemplar data web integrating gene expression data on the fruit fly Drosophila melanogaster","2010","Journal of Biomedical Informatics","10.1016/j.jbi.2010.04.004","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956268738&doi=10.1016%2fj.jbi.2010.04.004&partnerID=40&md5=1c8bd6ec29108f926f37e35730eb99a5","Motivation: Integrating heterogeneous data across distributed sources is a major requirement for in silico bioinformatics supporting translational research. For example, genome-scale data on patterns of gene expression in the fruit fly Drosophila melanogaster are widely used in functional genomic studies in many organisms to inform candidate gene selection and validate experimental results. However, current data integration solutions tend to be heavy weight, and require significant initial and ongoing investment of effort. Development of a common Web-based data integration infrastructure (a.k.a. data web), using Semantic Web standards, promises to alleviate these difficulties, but little is known about the feasibility, costs, risks or practical means of migrating to such an infrastructure. Results: We describe the development of OpenFlyData, a proof-of-concept system integrating gene expression data on D. melanogaster, combining Semantic Web standards with light-weight approaches to Web programming based on Web 2.0 design patterns. To support researchers designing and validating functional genomic studies, OpenFlyData includes user-facing search applications providing intuitive access to and comparison of gene expression data from FlyAtlas, the BDGP in situ database, and FlyTED, using data from FlyBase to expand and disambiguate gene names. OpenFlyData's services are also openly accessible, and are available for reuse by other bioinformaticians and application developers. Semi-automated methods and tools were developed to support labour- and knowledge-intensive tasks involved in deploying SPARQL services. These include methods for generating ontologies and relational-to-RDF mappings for relational databases, which we illustrate using the FlyBase Chado database schema; and methods for mapping gene identifiers between databases. The advantages of using Semantic Web standards for biomedical data integration are discussed, as are open issues. In particular, although the performance of open source SPARQL implementations is sufficient to query gene expression data directly from user-facing applications such as Web-based data fusions (a.k.a. mashups), we found open SPARQL endpoints to be vulnerable to denial-of-service-type problems, which must be mitigated to ensure reliability of services based on this standard. These results are relevant to data integration activities in translational bioinformatics. Availability: The gene expression search applications and SPARQL endpoints developed for OpenFlyData are deployed at http://openflydata.org. FlyUI, a library of JavaScript widgets providing re-usable user-interface components for Drosophila gene expression data, is available at http://flyui.googlecode.com. Software and ontologies to support transformation of data from FlyBase, FlyAtlas, BDGP and FlyTED to RDF are available at http://openflydata.googlecode.com. SPARQLite, an implementation of the SPARQL protocol, is available at http://sparqlite.googlecode.com. All software is provided under the GPL version 3 open source license. © 2010 Elsevier Inc.","Chado; Data integration; Data web; Drosophila; Gene expression; Performance; RDF; SPARQL; Triple store; User interface","Article","Scopus"
"Shamonin D.P.; Bron E.E.; Lelieveldt B.P.F.; Smits M.; Klein S.; Staring M.","Shamonin, Denis P. (8855815500); Bron, Esther E. (55325840900); Lelieveldt, Boudewijn P. F. (7003267462); Smits, Marion (56006797000); Klein, Stefan (35147968700); Staring, Marius (55886447500)","8855815500; 55325840900; 7003267462; 56006797000; 35147968700; 55886447500","Fast parallel image registration on CPU and GPU for diagnostic classification of Alzheimer's disease","2014","Frontiers in Neuroinformatics","10.3389/fninf.2013.00050","346","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892620757&doi=10.3389%2ffninf.2013.00050&partnerID=40&md5=62980d4f4accb021da10cf696e1c916a","Nonrigid image registration is an important, but time-consuming task in medical image analysis. In typical neuroimaging studies, multiple image registrations are performed, i.e., for atlas-based segmentation or template construction. Faster image registration routines would therefore be beneficial. In this paper we explore acceleration of the image registration package elastix by a combination of several techniques: (i) parallelization on the CPU, to speed up the cost function derivative calculation; (ii) parallelization on the GPU building on and extending the OpenCL framework from ITKv4, to speed up the Gaussian pyramid computation and the image resampling step; (iii) exploitation of certain properties of the B-spline transformation model; (iv) further software optimizations. The accelerated registration tool is employed in a study on diagnostic classification of Alzheimer's disease and cognitively normal controls based on T1-weighted MRI. We selected 299 participants from the publicly available Alzheimer's Disease Neuroimaging Initiative database. Classification is performed with a support vector machine based on gray matter volumes as a marker for atrophy. We evaluated two types of strategies (voxel-wise and region-wise) that heavily rely on nonrigid image registration. Parallelization and optimization resulted in an acceleration factor of 4-5x on an 8-core machine. Using OpenCL a speedup factor of 2 was realized for computation of the Gaussian pyramids, and 15-60 for the resampling step, for larger images. The voxel-wise and the region-wise classification methods had an area under the receiver operator characteristic curve of 88 and 90%, respectively, both for standard and accelerated registration. We conclude that the image registration package elastix was substantially accelerated, with nearly identical results to the non-optimized version. The new functionality will become available in the next release of elastix as open source under the BSD license. © 2014 Shamonin, Bron, Lelieveldt, Smits, Klein and Staring.","Acceleration; Alzheimer's disease; Elastix; Image registration; OpenCL; Parallelization","Article","Scopus"
"Sinha S.","Sinha, Shriprakash (55520033000)","55520033000","A pedagogical walkthrough of computational modeling and simulation of Wnt signaling pathway using static causal models in MATLAB","2016","Eurasip Journal on Bioinformatics and Systems Biology","10.1186/s13637-016-0044-y","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981287638&doi=10.1186%2fs13637-016-0044-y&partnerID=40&md5=bd680cc5804cb3bdc18134cf3486c5e5","Simulation study in systems biology involving computational experiments dealing with Wnt signaling pathways abound in literature but often lack a pedagogical perspective that might ease the understanding of beginner students and researchers in transition, who intend to work on the modeling of the pathway. This paucity might happen due to restrictive business policies which enforce an unwanted embargo on the sharing of important scientific knowledge. A tutorial introduction to computational modeling of Wnt signaling pathway in a human colorectal cancer dataset using static Bayesian network models is provided. The walkthrough might aid biologists/informaticians in understanding the design of computational experiments that is interleaved with exposition of the Matlab code and causal models from Bayesian network toolbox. The manuscript elucidates the coding contents of the advance article by Sinha (Integr. Biol. 6:1034–1048, 2014) and takes the reader in a step-by-step process of how (a) the collection and the transformation of the available biological information from literature is done, (b) the integration of the heterogeneous data and prior biological knowledge in the network is achieved, (c) the simulation study is designed, (d) the hypothesis regarding a biological phenomena is transformed into computational framework, and (e) results and inferences drawn using d-connectivity/separability are reported. The manuscript finally ends with a programming assignment to help the readers get hands-on experience of a perturbation project. Description of Matlab files is made available under GNU GPL v3 license at the Google code project on https://code.google.com/p/static-bn-for-wnt-signaling-pathway and https: //sites.google.com/site/shriprakashsinha/shriprakashsinha/projects/static-bn-for-wnt-signaling-pathway. Latest updates can be found in the latter website. © 2016, The Author(s).","Bayesian network; Epigenetic information; Heterogeneous data integration; Hypothesis testing; Inference; Prior biological knowledge; Wnt signaling pathway","Article","Scopus"
"Hepler N.L.; Scheffler K.; Weaver S.; Murrell B.; Richman D.D.; Burton D.R.; Poignard P.; Smith D.M.; Kosakovsky Pond S.L.","Hepler, N. Lance (55918245100); Scheffler, Konrad (13103633800); Weaver, Steven (56375175300); Murrell, Ben (57216109967); Richman, Douglas D. (7202383409); Burton, Dennis R. (7401577043); Poignard, Pascal (6601959415); Smith, Davey M. (57202523532); Kosakovsky Pond, Sergei L. (7801633431)","55918245100; 13103633800; 56375175300; 57216109967; 7202383409; 7401577043; 6601959415; 57202523532; 7801633431","IDEPI: Rapid Prediction of HIV-1 Antibody Epitopes and Other Phenotypic Features from Sequence Data Using a Flexible Machine Learning Platform","2014","PLoS Computational Biology","10.1371/journal.pcbi.1003842","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907588544&doi=10.1371%2fjournal.pcbi.1003842&partnerID=40&md5=363e4aae96d6dbf0133e4b23d06de475","Since its identification in 1983, HIV-1 has been the focus of a research effort unprecedented in scope and difficulty, whose ultimate goals — a cure and a vaccine – remain elusive. One of the fundamental challenges in accomplishing these goals is the tremendous genetic variability of the virus, with some genes differing at as many as 40% of nucleotide positions among circulating strains. Because of this, the genetic bases of many viral phenotypes, most notably the susceptibility to neutralization by a particular antibody, are difficult to identify computationally. Drawing upon open-source general-purpose machine learning algorithms and libraries, we have developed a software package IDEPI (IDentify EPItopes) for learning genotype-to-phenotype predictive models from sequences with known phenotypes. IDEPI can apply learned models to classify sequences of unknown phenotypes, and also identify specific sequence features which contribute to a particular phenotype. We demonstrate that IDEPI achieves performance similar to or better than that of previously published approaches on four well-studied problems: finding the epitopes of broadly neutralizing antibodies (bNab), determining coreceptor tropism of the virus, identifying compartment-specific genetic signatures of the virus, and deducing drug-resistance associated mutations. The cross-platform Python source code (released under the GPL 3.0 license), documentation, issue tracking, and a pre-configured virtual machine for IDEPI can be found at https://github.com/veg/idepi. © 2014 Hepler et al.","","Article","Scopus"
"Wagner M.; Bothner C.L.; Rau E.; Zeng P.Z.; Waisanen E.H.; Czerwinski M.A.; Fickes B.; Eastin I.; Hardin R.D.","Wagner, Meghan (56378520400); Bothner, Cameron L. (57191259182); Rau, Emily (57456254200); Zeng, Pearl Zhu (57191247872); Waisanen, Edward H. (57222903801); Czerwinski, Megan A. (57455467300); Fickes, Bret (57455467400); Eastin, Ivan (6602512502); Hardin, Rebecca D. (24401428500)","56378520400; 57191259182; 57456254200; 57191247872; 57222903801; 57455467300; 57455467400; 6602512502; 24401428500","Gala: An Open-Access Platform for Interactive Learning With Sustainability Case Studies","2021","IEEE Transactions on Learning Technologies","10.1109/TLT.2022.3148723","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124753031&doi=10.1109%2fTLT.2022.3148723&partnerID=40&md5=66e1a0536f9fc50425873586adec209d","Sustainability science has been gaining traction within academic research and teaching over the past few decades, and it is now entering a phase of greater maturity as a discipline, with links to sectors beyond the academy including energy, finance, advocacy, development, design, construction, agriculture, and healthcare. Concurrently, the growth of the internet has spurred innovation in platform development. This convergence has generated technology-enabled opportunities for training sustainability scholars and practitioners grounded in active learning pedagogies. Case studies are one active learning strategy becoming established within the fields of environment and sustainability. However, the traditional case study form and mode of delivery, which excel at a retroactive analysis of strategic decision-making and outcomes, can create challenges for teaching about issues involving emergent technologies and rapidly changing scientific and social dimensions. This article describes one novel platform, called Gala, for teaching and learning about sustainability science through case studies that address these challenges. Gala closely integrates text and multimedia components, is easily updated, and embraces content consumers as content creators and vice versa. We also report here the results of one pilot study that investigated differences between graduate and undergraduate student interactions with different case components. Results indicate that both groups heavily used the case narrative, but varied in their use of multimedia components. Such insights into patterns of case use are informing decisions about improvements to Gala and directions for future case production, teaching, and assessment, in order to create better tools for teaching and learning about sustainability.  © 2008-2011 IEEE.","Authoring tools; collaborative learning tools; learning platform; open access; sustainability education; user-generated learning content","Article","Scopus"
"Sadeghi L.; Bonilla C.; Strålfors A.; Ekwall K.; Svensson J.P.","Sadeghi, Laia (51161779200); Bonilla, Carolina (57203046473); Strålfors, Annelie (35076573100); Ekwall, Karl (7004451584); Svensson, J. Peter (56799999200)","51161779200; 57203046473; 35076573100; 7004451584; 56799999200","Podbat: A novel genomic tool reveals swr1-independent H2A.Z incorporation at gene coding sequences through epigenetic meta-analysis","2011","PLoS Computational Biology","10.1371/journal.pcbi.1002163","27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052313379&doi=10.1371%2fjournal.pcbi.1002163&partnerID=40&md5=c5462ed734817ac1098397b2bba261c7","Epigenetic regulation consists of a multitude of different modifications that determine active and inactive states of chromatin. Conditions such as cell differentiation or exposure to environmental stress require concerted changes in gene expression. To interpret epigenomics data, a spectrum of different interconnected datasets is needed, ranging from the genome sequence and positions of histones, together with their modifications and variants, to the transcriptional output of genomic regions. Here we present a tool, Podbat (Positioning database and analysis tool), that incorporates data from various sources and allows detailed dissection of the entire range of chromatin modifications simultaneously. Podbat can be used to analyze, visualize, store and share epigenomics data. Among other functions, Podbat allows data-driven determination of genome regions of differential protein occupancy or RNA expression using Hidden Markov Models. Comparisons between datasets are facilitated to enable the study of the comprehensive chromatin modification system simultaneously, irrespective of data-generating technique. Any organism with a sequenced genome can be accommodated. We exemplify the power of Podbat by reanalyzing all to-date published genome-wide data for the histone variant H2A.Z in fission yeast together with other histone marks and also phenotypic response data from several sources. This meta-analysis led to the unexpected finding of H2A.Z incorporation in the coding regions of genes encoding proteins involved in the regulation of meiosis and genotoxic stress responses. This incorporation was partly independent of the H2A.Z-incorporating remodeller Swr1. We verified an Swr1-independent role for H2A.Z following genotoxic stress in vivo. Podbat is open source software freely downloadable from www.podbat.org, distributed under the GNU LGPL license. User manuals, test data and instructions are available at the website, as well as a repository for third party-developed plug-in modules. Podbat requires Java version 1.6 or higher. © 2011 Sadeghi et al.","","Article","Scopus"
"Woo J.-E.; Han J.; Han D.-G.","Woo, Ji-Eun (57792054000); Han, Jaeseung (57222483655); Han, Dong-Guk (8662002000)","57792054000; 57222483655; 8662002000","Deep-Learning-Based Side-Channel Analysis of Block Cipher PIPO With Bitslice Implementation","2022","IEEE Access","10.1109/ACCESS.2022.3187201","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133759439&doi=10.1109%2fACCESS.2022.3187201&partnerID=40&md5=343155d12f0e0e016553d4eaa588d08a","Recently, as deep learning has been applied to various fields, deep-learning-based side-channel analysis (SCA) has been widely investigated. Unlike traditional SCA, it can perform well independently of the attacker's ability. In this paper, we propose deep-learning-based profiled and non-profiled SCA of PIPO, (Plug-In Plug-Out), which is a bitslice block cipher that can effectively apply a countermeasure for SCA. Our datasets were captured from three different boards (XMEGA128D4, MSP430F2618, STM32F303) running PIPO-64/128. For profiled SCA, the identity (ID) labeling method exhibited better performance than the most significant bit (MSB) and hamming weight (HW) labeling methods. That is, even if each bit of the S-Box output was distributed in the power traces by the bitslice implementation, the neural network trained well each bit of the S-Box output by itself. For non-profiled SCA, we proposed a novel labeling technique that considers bitslice characteristics. We compared our proposed labeling method to MSB and HW labeling by analyzing the three aforementioned datasets. For non-profiled SCA, the proposed labeling method was more effective than the MSB and HW labeling methods on all datasets.  © 2013 IEEE.","bitslice implementation; block cipher; deep learning; non-profiled SCA; PIPO; profiled SCA; Side-channel analysis","Article","Scopus"
"Ungerleider N.; Flemington E.","Ungerleider, Nathan (37111397800); Flemington, Erik (7003797209)","37111397800; 7003797209","SpliceV: Analysis and publication quality printing of linear and circular RNA splicing, expression and regulation","2019","BMC Bioinformatics","10.1186/s12859-019-2865-7","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065501292&doi=10.1186%2fs12859-019-2865-7&partnerID=40&md5=a033878f3dbeb1f5229fc7e1ef7a0310","Background: In eukaryotes, most genes code for multiple transcript isoforms that are generated through the complex and tightly regulated process of RNA splicing. Despite arising from identical precursor transcripts, alternatively spliced RNAs can have dramatically different functions. Transcriptome complexity is elevated further by the production of circular RNAs (circRNAs), another class of mature RNA that results from the splicing of a downstream splice donor to an upstream splice acceptor. While there has been a rapid expansion of circRNA catalogs in the last few years through the utilization of next generation sequencing approaches, our understanding of the mechanisms and regulation of circular RNA biogenesis, the impact that circRNA generation has on parental transcript processing, and the functions carried out by circular RNAs remains limited. Results: Here, we present a visualization and analysis tool, SpliceV, that rapidly plots all relevant forward- A nd back-splice data, with exon and single nucleotide level coverage information from RNA-seq experiments in a publication quality format. SpliceV also integrates analysis features that assist investigations into splicing regulation and transcript functions through the display of predicted RNA binding protein sites and the configuration of repetitive elements along the primary transcript. Conclusions: SpliceV is an easy-to-use splicing visualization tool, compatible with both Python 2.7 and 3+, and distributed under the GNU Public License. The source code is freely available for download at https://github.com/flemingtonlab/SpliceV and can be installed from PyPI using pip. © 2019 The Author(s).","Alternative splicing; circRNA; Exon skipping; Intron retention; Isoform","Article","Scopus"
"Medina-Ortiz D.; Contreras S.; Quiroz C.; Asenjo J.A.; Olivera-Nappa Á.","Medina-Ortiz, David (57214673649); Contreras, Sebastián (57212808478); Quiroz, Cristofer (57216824798); Asenjo, Juan A. (56908691200); Olivera-Nappa, Álvaro (6506073343)","57214673649; 57212808478; 57216824798; 56908691200; 6506073343","DMAKit: A user-friendly web platform for bringing state-of-the-art data analysis techniques to non-specific users","2020","Information Systems","10.1016/j.is.2020.101557","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084851363&doi=10.1016%2fj.is.2020.101557&partnerID=40&md5=05f651c8d87dd231a8bb4c2baee2345f","Tremendous advances in different areas of knowledge are producing vast volumes of data, a quantity so large that it has made necessary the development of new computational algorithms. Among the algorithms developed, we find Machine Learning models and specific data mining techniques that might be useful for all areas of knowledge. The use of computational tools for data analysis is increasingly required, given the need to extract meaningful information from such large volumes of data. However, there are no free access libraries, modules, or web services that comprise a vast array of analytical techniques in a user-friendly environment for non-specific users. Those that exist raise high usability barriers for those untrained in the field as they usually have specific installation requirements and require in-depth programming knowledge, or may result expensive. As an alternative, we have developed DMAKit, a user-friendly web platform powered by DMAKit-lib, a new library implemented in Python, which facilitates the analysis of data of different kind and origins. Our tool implements a wide array of state-of-the-art data mining and pattern recognition techniques, allowing the user to quickly implement classification, prediction or clustering models, statistical evaluation, and feature analysis of different attributes in diverse datasets without requiring any specific programming knowledge. DMAKit is especially useful for users who have large volumes of data to be analyzed but do not have the informatics, mathematical, or statistical knowledge to implement models. We expect this platform to provide a way to extract information and analyze patterns through data mining techniques for anyone interested in applying them with no specific knowledge required. Particularly, we present several cases of study in the areas of biology, biotechnology, and biomedicine, where we highlight the applicability of our tool to ease the labor of non-specialist users to apply data analysis and pattern recognition techniques. DMAKit is available for non-commercial use as an open-access library, licensed under the GNU General Public License, version GPL 3.0. The web platform is publicly available at https://pesb2.cl/dmakitWeb. Demonstrative and tutorial videos for the web platform are available in https://pesb2.cl/dmakittutorials/. Complete urls for relevant content are listed in the Data Availability section. © 2020 Elsevier Ltd","Data mining; Machine learning; Pattern recognition; Statistics; User-friendly web platform","Article","Scopus"
"Lawless C.; Wilkinson D.J.; Young A.; Addinall S.G.; Lydall D.A.","Lawless, Conor (12545116100); Wilkinson, Darren J. (7401870210); Young, Alexander (56221264200); Addinall, Stephen G. (6603545024); Lydall, David A. (57194561626)","12545116100; 7401870210; 56221264200; 6603545024; 57194561626","Colonyzer: Automated quantification of micro-organism growth characteristics on solid agar","2010","BMC Bioinformatics","10.1186/1471-2105-11-287","46","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952726404&doi=10.1186%2f1471-2105-11-287&partnerID=40&md5=93d641e15a5149c9ade4205ac34dae89","Background: High-throughput screens comparing growth rates of arrays of distinct micro-organism cultures on solid agar are useful, rapid methods of quantifying genetic interactions. Growth rate is an informative phenotype which can be estimated by measuring cell densities at one or more times after inoculation. Precise estimates can be made by inoculating cultures onto agar and capturing cell density frequently by plate-scanning or photography, especially throughout the exponential growth phase, and summarising growth with a simple dynamic model (e.g. the logistic growth model). In order to parametrize such a model, a robust image analysis tool capable of capturing a wide range of cell densities from plate photographs is required.Results: Colonyzer is a collection of image analysis algorithms for automatic quantification of the size, granularity, colour and location of micro-organism cultures grown on solid agar. Colonyzer is uniquely sensitive to extremely low cell densities photographed after dilute liquid culture inoculation (spotting) due to image segmentation using a mixed Gaussian model for plate-wide thresholding based on pixel intensity. Colonyzer is robust to slight experimental imperfections and corrects for lighting gradients which would otherwise introduce spatial bias to cell density estimates without the need for imaging dummy plates. Colonyzer is general enough to quantify cultures growing in any rectangular array format, either growing after pinning with a dense inoculum or growing with the irregular morphology characteristic of spotted cultures. Colonyzer was developed using the open source packages: Python, RPy and the Python Imaging Library and its source code and documentation are available on SourceForge under GNU General Public License. Colonyzer is adaptable to suit specific requirements: e.g. automatic detection of cultures at irregular locations on streaked plates for robotic picking, or decreasing analysis time by disabling components such as lighting correction or colour measures.Conclusion: Colonyzer can automatically quantify culture growth from large batches of captured images of microbial cultures grown during genome-wide scans over the wide range of cell densities observable after highly dilute liquid spot inoculation, as well as after more concentrated pinning inoculation. Colonyzer is open-source, allowing users to assess it, adapt it to particular research requirements and to contribute to its development. © 2010 Lawless et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Durrant J.D.; McCammon J.A.","Durrant, Jacob D. (12239804300); McCammon, J. Andrew (36050413200)","12239804300; 36050413200","Autoclickchem: Click chemistry in silico","2012","PLoS Computational Biology","10.1371/journal.pcbi.1002397","33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861148356&doi=10.1371%2fjournal.pcbi.1002397&partnerID=40&md5=4dfcc16a0d5267bce4c34c407c71fbad","Academic researchers and many in industry often lack the financial resources available to scientists working in ""big pharma."" High costs include those associated with high-throughput screening and chemical synthesis. In order to address these challenges, many researchers have in part turned to alternate methodologies. Virtual screening, for example, often substitutes for high-throughput screening, and click chemistry ensures that chemical synthesis is fast, cheap, and comparatively easy. Though both in silico screening and click chemistry seek to make drug discovery more feasible, it is not yet routine to couple these two methodologies. We here present a novel computer algorithm, called AutoClickChem, capable of performing many click-chemistry reactions in silico. AutoClickChem can be used to produce large combinatorial libraries of compound models for use in virtual screens. As the compounds of these libraries are constructed according to the reactions of click chemistry, they can be easily synthesized for subsequent testing in biochemical assays. Additionally, in silico modeling of click-chemistry products may prove useful in rational drug design and drug optimization. AutoClickChem is based on the pymolecule toolbox, a framework that may facilitate the development of future python-based programs that require the manipulation of molecular models. Both the pymolecule toolbox and AutoClickChem are released under the GNU General Public License version 3 and are available for download from http://autoclickchem.ucsd.edu. © 2012 Durrant, McCammon.","","Article","Scopus"
"Yao Z.; Zhang L.; Gao B.; Cui D.; Wang F.; He X.; Zhang J.Z.H.; Wei D.","Yao, Zhiqiang (55840263800); Zhang, Lujia (35085670200); Gao, Bei (55485112300); Cui, Dongbing (35866916000); Wang, Fengqing (56139752000); He, Xiao (35310678900); Zhang, John Z. H. (35235961100); Wei, Dongzhi (55758064000)","55840263800; 35085670200; 55485112300; 35866916000; 56139752000; 35310678900; 35235961100; 55758064000","A Semiautomated Structure-Based Method to Predict Substrates of Enzymes via Molecular Docking: A Case Study with Candida antarctica Lipase B","2016","Journal of Chemical Information and Modeling","10.1021/acs.jcim.5b00585","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992735283&doi=10.1021%2facs.jcim.5b00585&partnerID=40&md5=8eb1bb7f4aac303c0bb12e6f3126c9be","The discovery of unique substrates is important for developing potential applications of enzymes. However, the experimental procedures for substrate identification are laborious, time-consuming, and expensive. Although in silico structure-based approaches show great promise, recent extensive studies have shown that these approaches remain a formidable challenge for current biocomputational methodologies. Here we present an open-source, extensible, and flexible software platform for predicting enzyme substrates called THEMIS, which performs in silico virtual screening for potential catalytic targets of an enzyme on the basis of the enzyme's catalysis mechanism. On the basis of a generalized transition state theory of enzyme catalysis, we introduce a modified docking procedure called ""mechanism-based restricted docking"" (MBRD) for novel substrate recognition from molecular docking. Comprising a series of utilities written in C/Python, THEMIS automatically executes parallel-computing MBRD tasks and evaluates the results with various molecular mechanics (MM) criteria such as energy, distance, angle, and dihedral angle to help identify desired substrates. Exhaustive sampling and statistical measures were used to improve the robustness and reproducibility of the method. We used Candida antarctica lipase B (CALB) as a test system to demonstrate the effectiveness of our computational prediction of (non)substrates. A novel MM score function for CALB substrate identification derived from the near-attack conformation was used to evaluate the possibility of chemical transformation. A highly positive rate of 93.4% was achieved from a CALB substrate library with 61 known substrates and 35 nonsubstrates, and the screening rate has reached 103 compounds/day (96 CPU cores, 100 samples/compound). The performance shows that the present method is perhaps the first reported scheme to meet the requirement for practical applicability to enzyme studies. An additional study was performed to validate the universality of our method. In this verification we employed two distinct enzymes, nitrilase Nit6803 and SDR Gox2181, where the correct rates of both enzymes exceeded 90%. The source code used will be released under the GNU General Public License (GPLv3) and will be free to download. We believe that the present method will provide new insights into enzyme research and accelerate the development of novel enzyme applications. © 2016 American Chemical Society.","","Article","Scopus"
"Paci P.; Fiscon G.","Paci, Paola (36890340300); Fiscon, Giulia (56124184700)","36890340300; 56124184700","SPINNAKER: an R-based tool to highlight key RNA interactions in complex biological networks","2022","BMC Bioinformatics","10.1186/s12859-022-04695-x","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129714354&doi=10.1186%2fs12859-022-04695-x&partnerID=40&md5=d98e1bfc307b58edefaa7168393905be","Background: Recently, we developed a mathematical model for identifying putative competing endogenous RNA (ceRNA) interactions. This methodology has aroused a broad acknowledgment within the scientific community thanks to the encouraging results achieved when applied to breast invasive carcinoma, leading to the identification of PVT1, a long non-coding RNA functioning as ceRNA for the miR-200 family. The main shortcoming of the model is that it is no freely available and implemented in MATLAB®, a proprietary programming platform requiring a paid license for installing, operating, manipulating, and running the software. Results: Breaking through these model limitations demands to distribute it in an open-source, freely accessible environment, such as R, designed for an ordinary audience of users that are not able to afford a proprietary solution. Here, we present SPINNAKER (SPongeINteractionNetworkmAKER), the open-source version of our widely established mathematical model for predicting ceRNAs crosstalk, that is released as an exhaustive collection of R functions. SPINNAKER has been even designed for providing many additional features that facilitate its usability, make it more efficient in terms of further implementation and extension, and less intense in terms of computational execution time. Conclusions: SPINNAKER source code is freely available at https://github.com/sportingCode/SPINNAKER.git together with a thoroughgoing PPT-based guideline. In order to help users get the key points more conveniently, also a practical R-styled plain-text guideline is provided. Finally, a short movie is available to help the user to set the own directory, properly. © 2022, The Author(s).","Algorithms; ceRNA network; miRNA sponge; Network theory","Article","Scopus"
"Tolga E.; Demircan M.L.; Kahraman C.","Tolga, Ethem (6602674545); Demircan, Murat Levent (8502106200); Kahraman, Cengiz (7003388495)","6602674545; 8502106200; 7003388495","Operating system selection using fuzzy replacement analysis and analytic hierarchy process","2005","International Journal of Production Economics","10.1016/j.ijpe.2004.07.001","143","https://www.scopus.com/inward/record.uri?eid=2-s2.0-19944420825&doi=10.1016%2fj.ijpe.2004.07.001&partnerID=40&md5=677199fbeba6514e4764fa23b5dcd262","This study aims at creating an Operating System (OS) selection framework for decision makers (DMs). Since DMs have to consider both economic and non-economic aspects of technology selection, both factors have been considered in the developed framework. The economic part of the decision process has been developed by Fuzzy Replacement Analysis. Non-economic factors and financial figures have been combined using a fuzzy analytic hierarchy process (Fuzzy AHP) approach. Since there exists incomplete and vague information of future cash flows and the crisp AHP cannot reflect the human thinking style in capturing the expert's knowledge, the fuzzy sets theory has been applied to both AHP and replacement analysis, which compares two OSs with and without license, respectively. A real numerical application has also been demonstrated. Both the theoretical and the practical background of this paper have shown that fuzzy AHP and fuzzy replacement analysis can cover the uncertainty of assigning crisp concepts in related investment decision-making topics. © 2004 Elsevier B.V. All rights reserved.","AHP; Fuzzy sets; Replacement analysis; Technology selection","Article","Scopus"
"Boudet S.; Houzé de l'Aulnoit A.; Demailly R.; Peyrodie L.; Beuscart R.; Houzé de l'Aulnoit D.","Boudet, Samuel (16174534300); Houzé de l'Aulnoit, Agathe (57195965770); Demailly, Romain (57192919345); Peyrodie, Laurent (15023267500); Beuscart, Régis (56186723400); Houzé de l'Aulnoit, Denis (6603873149)","16174534300; 57195965770; 57192919345; 15023267500; 56186723400; 6603873149","Fetal heart rate baseline computation with a weighted median filter","2019","Computers in Biology and Medicine","10.1016/j.compbiomed.2019.103468","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072707318&doi=10.1016%2fj.compbiomed.2019.103468&partnerID=40&md5=149b7d216a80f27c8b800245c840a543","Background: Automated fetal heart rate (FHR) analysis removes inter- and intra-expert variability, and is a promising solution for reducing the occurrence of fetal acidosis and the implementation of unnecessary medical procedures. The first steps in automated FHR analysis are determination of the baseline, and detection of accelerations and decelerations (A/D). We describe a new method in which a weighted median filter baseline (WMFB) is computed and A/Ds are then detected. Method: The filter weightings are based on the prior probability that the sampled FHR is in the baseline state or in an A/D state. This probability is computed by estimating the signal's stability at low frequencies and by progressively trimming the signal. Using a competition dataset of 90 previously annotated FHR recordings, we evaluated the WMFB method and 11 recently published literature methods against the ground truth of an expert consensus. The level of agreement between the WMFB method and the expert consensus was estimated by calculating several indices (primarily the morphological analysis discordance index, MADI). The agreement indices were then compared with the values for eleven other methods. We also compared the level of method-expert agreement with the level of interrater agreement. Results: For the WMFB method, the MADI indicated a disagreement of 4.02% vs. the consensus; this value is significantly lower (p<10−13) than that calculated for the best of the 11 literature methods (7.27%, for Lu and Wei's empirical mode decomposition method). The level of inter-expert agreement (according to the MADI) and the level of WMFB-expert agreement did not differ significantly (p=0.22). Conclusion: The WMFB method reproduced the expert consensus analysis better than 11 other methods. No differences in performance between the WMFB method and individual experts were observed. The method Matlab source code is available under General Public Licence at http://utsb.univ-catholille.fr/fhr-wmfb. © 2019 Elsevier Ltd","Baseline; Biomedical signal processing; Deceleration; Fetal acidosis; Fetal heart rate; Median filter; Nonlinear filter","Article","Scopus"
"Liu Q.; Wang J.; Wang C.; Wei F.; Zhang C.; Wei H.; Ye X.; Xu J.","Liu, Qiangqiang (56903225400); Wang, Junjie (57538741100); Wang, Changquan (57218536346); Wei, Fang (57538330400); Zhang, Chencheng (57192310868); Wei, Hongjiang (56814095100); Ye, Xiaolai (57191890993); Xu, Jiwen (37122934700)","56903225400; 57538741100; 57218536346; 57538330400; 57192310868; 56814095100; 57191890993; 37122934700","FreeSurfer and 3D Slicer-Assisted SEEG Implantation for Drug-Resistant Epilepsy","2022","Frontiers in Neurorobotics","10.3389/fnbot.2022.848746","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126723779&doi=10.3389%2ffnbot.2022.848746&partnerID=40&md5=cc61cd566bdc61ffc774a7eaeff6f03d","Objective: Our study aimed to develop an approach to improve the speed and resolution of cerebral-hemisphere and lesion modeling and evaluate the advantages and disadvantages of robot-assisted surgical planning software. Methods: We applied both conventional robot planning software (method 1) and open-source auxiliary software (FreeSurfer and 3D Slicer; method 2) to model the brain and lesions in 19 patients with drug-resistant epilepsy. The patients' mean age at implantation was 21.4 years (range, 6–52 years). Each patient received an average of 12 electrodes (range, 9–16) between May and November 2021. The electrode-implantation plan was designed based on the models established using the two methods. We statistically analyzed and compared the duration of designing the models and planning the implantation using these two methods and performed the surgeries with the implantation plan designed using the auxiliary software. Results: A significantly longer time was needed to reconstruct a cerebral-hemisphere model using method 1 (mean, 206 s) than using method 2 (mean, 20 s) (p < 0.05). Both methods identified a mean of 1.4 lesions (range, 1–5) in each patient. Overall, using method 1 required longer (mean, 130 s; range, 48–436) than using method 2 (mean, 68.1 s; range, 50–104; p < 0.05). In addition, the clarity of the model based on method 1 was lower than that based on method 2. To devise an electrode-implantation plan, it took 9.1–25.5 min (mean, 16) and 6.6–14.8 min (mean, 10.2) based on methods 1 and 2, respectively (p < 0.05). The average target point error of 231 electrodes amounted to 1.90 mm ± 0.37 mm (range, 0.33–3.61 mm). The average entry point error was 0.89 ± 0.26 mm (range, 0.17–1.67 mm). None of the patients presented with intracranial hemorrhage or infection, and no other serious complications were observed. Conclusions: FreeSurfer and 3D Slicer-assisted SEEG implantation is an excellent approach to enhance modeling speed and resolution, shorten the electrode-implantation planning time, and boost the efficiency of clinical work. These well-known, trusted open-source programs do not have explicitly restricted licenses. These tools, therefore, seem well suited for clinical-research applications under the premise of approval by an ethics committee, informed consent of the patient, and clinical judgment of the surgeon. Copyright © 2022 Liu, Wang, Wang, Wei, Zhang, Wei, Ye and Xu.","3D Slicer; FreeSurfer; robotics; stereoelectroencephalography (SEEG); stereotactic neurosurgery","Article","Scopus"
"Zanovello U.; Seifert F.; Bottauscio O.; Winter L.; Zilberti L.; Ittermann B.","Zanovello, Umberto (57191070895); Seifert, Frank (36146211500); Bottauscio, Oriano (7006218126); Winter, Lukas (49965102000); Zilberti, Luca (24463091200); Ittermann, Bernd (6701862084)","57191070895; 36146211500; 7006218126; 49965102000; 24463091200; 6701862084","CoSimPy: An open-source python library for MRI radiofrequency Coil EM/Circuit Cosimulation","2022","Computer Methods and Programs in Biomedicine","10.1016/j.cmpb.2022.106684","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124249302&doi=10.1016%2fj.cmpb.2022.106684&partnerID=40&md5=84cb0eff79eeada9c5e73427624a175f","Background and objectives: The Electromagnetic/Circuit cosimulation method represents a valuable and effective strategy to address those problems where a radiative structure has to interact with external supporting circuitries. This is of particular concern for Magnetic Resonance Imaging (MRI), radiofrequency (RF) coils design, where the supporting circuitry optimisation represents, generally, a crucial aspect. This article presents CoSimPy, an open-source Python circuit simulation library for Electromagnetic/Circuit cosimulations and specifically optimised for MRI, RF coils design. Methods: CoSimPy is designed following an Object-orientated programming. In addition to the essential methods aimed to performed the Electromagnetic/Circuit cosimulations, many others are implemented both to simplify the standard workflow and to evaluate the RF coils performance. In this article, the theory which underlies the fundamental methods of CoSimPy is shown together with the basic framework of the library. Results: In the paper, the reliability of CoSimPy is successfully tested against a full-wave electromagnetic simulations involving a reference setup. The library is made available under https://github.com/umbertozanovello/CoSimPy together with a detailed documentation providing guidelines and examples. CoSimPy is distributed under the Massachusetts Institute of Technology (MIT) license. Conclusions: CoSimPy demonstrated to be an agile tool employable for Electromagnetic/Circuit cosimulations. Its distribution is meant to fulfil the needs of several researchers also avoiding duplication of effort in writing custom implementations. CoSimPy is under constant development and aims to represent a coworking environment where scientists can implement additional methods whose sharing can represent an advantage for the community. Finally, even if CoSimPy is designed with special focus on MRI, it represents an efficient and practical tool potentially employable wherever electronic devices made of radiative and circuitry components are involved. © 2022","Electromagnetic (EM) simulations; EM/Circuit cosimulation; Magnetic Resonance Imaging (MRI); Open source Python library; Radio-frequency (RF) coils","Article","Scopus"
"Medema M.H.; Paalvast Y.; Nguyen D.D.; Melnik A.; Dorrestein P.C.; Takano E.; Breitling R.","Medema, Marnix H. (35115339800); Paalvast, Yared (57204716981); Nguyen, Don D. (55910385600); Melnik, Alexey (56375294100); Dorrestein, Pieter C. (8644051700); Takano, Eriko (13806252500); Breitling, Rainer (15757011000)","35115339800; 57204716981; 55910385600; 56375294100; 8644051700; 13806252500; 15757011000","Pep2Path: Automated Mass Spectrometry-Guided Genome Mining of Peptidic Natural Products","2014","PLoS Computational Biology","10.1371/journal.pcbi.1003822","69","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907584619&doi=10.1371%2fjournal.pcbi.1003822&partnerID=40&md5=85e80dd6830e124dce2ba3b2894b9667","Nonribosomally and ribosomally synthesized bioactive peptides constitute a source of molecules of great biomedical importance, including antibiotics such as penicillin, immunosuppressants such as cyclosporine, and cytostatics such as bleomycin. Recently, an innovative mass-spectrometry-based strategy, peptidogenomics, has been pioneered to effectively mine microbial strains for novel peptidic metabolites. Even though mass-spectrometric peptide detection can be performed quite fast, true high-throughput natural product discovery approaches have still been limited by the inability to rapidly match the identified tandem mass spectra to the gene clusters responsible for the biosynthesis of the corresponding compounds. With Pep2Path, we introduce a software package to fully automate the peptidogenomics approach through the rapid Bayesian probabilistic matching of mass spectra to their corresponding biosynthetic gene clusters. Detailed benchmarking of the method shows that the approach is powerful enough to correctly identify gene clusters even in data sets that consist of hundreds of genomes, which also makes it possible to match compounds from unsequenced organisms to closely related biosynthetic gene clusters in other genomes. Applying Pep2Path to a data set of compounds without known biosynthesis routes, we were able to identify candidate gene clusters for the biosynthesis of five important compounds. Notably, one of these clusters was detected in a genome from a different subphylum of Proteobacteria than that in which the molecule had first been identified. All in all, our approach paves the way towards high-throughput discovery of novel peptidic natural products. Pep2Path is freely available from http://pep2path.sourceforge.net/, implemented in Python, licensed under the GNU General Public License v3 and supported on MS Windows, Linux and Mac OS X. © 2014 Medema et al.","","Article","Scopus"
"De Figueiredo F.A.P.; Jiao X.; Liu W.; Mennes R.; Jabandzic I.; Moerman I.","De Figueiredo, Felipe A.P. (55844394700); Jiao, Xianjun (57193631005); Liu, Wei (52564001000); Mennes, Ruben (57193081391); Jabandzic, Irfan (57192234327); Moerman, Ingrid (7005875225)","55844394700; 57193631005; 52564001000; 57193081391; 57192234327; 7005875225","A spectrum sharing framework for intelligent next generation wireless networks","2018","IEEE Access","10.1109/ACCESS.2018.2875047","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054702041&doi=10.1109%2fACCESS.2018.2875047&partnerID=40&md5=032023eba1b3a5d55e0aa1a0874022c1","The explosive emergence of wireless technologies and standards, covering licensed and unlicensed spectrum bands, has triggered the appearance of a huge amount of wireless technologies, with many of them competing for the same spectrum band instead of harmoniously sharing it. Unfortunately, the wireless spectrum is a scarce resource, and the available frequency bands will not scale with the foreseen demand for new capacity. Certain parts of the spectrum, in particular the license-free ISM bands, are overcrowded, while other parts, mostly licensed bands, may be significantly underutilized. As such, there is a need to introduce more advanced techniques to access and share the wireless medium, either to improve the coordination within a given band or to explore the possibilities of intelligently using unused spectrum in underutilized (e.g., licensed) bands. Therefore, in this paper, we present an open source software-defined radio-based framework that can be employed to devise disruptive techniques to optimize the sub-optimal use of radio spectrum that exists today. We describe three use cases where the framework can be employed along with intelligent algorithms to achieve improved spectrum utilization. In addition, we provide several experimental results showing the performance and effectiveness of the proposed framework. © 2018 IEEE.","coexistence; cognitive radios; collaborative intelligent radio networks; experimental evaluation; Next generation wireless networks; spectrum sharing","Article","Scopus"
"Bundhoo E.; Ghoorah A.W.; Jaufeerally-Fakim Y.","Bundhoo, Eshan (57306552100); Ghoorah, Anisah W. (38561375100); Jaufeerally-Fakim, Yasmina (6507996098)","57306552100; 38561375100; 6507996098","TAGOPSIN: collating taxa-specific gene and protein functional and structural information","2021","BMC Bioinformatics","10.1186/s12859-021-04429-5","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117700180&doi=10.1186%2fs12859-021-04429-5&partnerID=40&md5=4d8d0e28a18cfa9d5bc7aa8a51fe7889","Background: The wealth of biological information available nowadays in public databases has triggered an unprecedented rise in multi-database search and data retrieval for obtaining detailed information about key functional and structural entities. This concerns investigations ranging from gene or genome analysis to protein structural analysis. However, the retrieval of interconnected data from a number of different databases is very often done repeatedly in an unsystematic way. Results: Here, we present TAxonomy, Gene, Ontology, Protein, Structure INtegrated (TAGOPSIN), a command line program written in Java for rapid and systematic retrieval of select data from seven of the most popular public biological databases relevant to comparative genomics and protein structure studies. The program allows a user to retrieve organism-centred data and assemble them in a single data warehouse which constitutes a useful resource for several biological applications. TAGOPSIN was tested with a number of organisms encompassing eukaryotes, prokaryotes and viruses. For example, it successfully integrated data for about 17,000 UniProt entries of Homo sapiens and 21 UniProt entries of human coronavirus. Conclusion: TAGOPSIN demonstrates efficient data integration whereby manipulation of interconnected data is more convenient than doing multi-database queries. The program facilitates for instance interspecific comparative analyses of protein-coding genes in a molecular evolutionary study, or identification of taxa-specific protein domains and three-dimensional structures. TAGOPSIN is available as a JAR file at https://github.com/ebundhoo/TAGOPSIN and is released under the GNU General Public License. © 2021, The Author(s).","Comparative genomics; Data integration; Data retrieval; Database; Object-oriented biology","Article","Scopus"
"Salvadore F.; Ponzini R.","Salvadore, F. (54781793300); Ponzini, R. (14830357700)","54781793300; 14830357700","LincoSim: a Web Based HPC-Cloud Platform for Automatic Virtual Towing Tank Analysis","2019","Journal of Grid Computing","10.1007/s10723-019-09494-y","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074852816&doi=10.1007%2fs10723-019-09494-y&partnerID=40&md5=e51b0f4c6795f78f2f68cc847d13be53","Thanks to evolving web technologies, computational platforms, automation tools and open-source software business model, today, it is possible to develop powerful automatic and virtualized web services for complex physical problems in engineering and design. In particular, in this work, we are presenting a new web based HPC-cloud platform for automatic virtual towing tank analysis. It is well known that the design project of a new hull requires a continuous integration of shape hypothesis and hydrodynamics verifications using analytical tools, 3D computational methods, experimental facilities and sea keeping trial tests. The complexity and the cost of such design tools increase considerably moving from analytical tools to sea keeping trials. In order to perform a meaningful trade-off between costs and high quality data acquiring, during the last decade the usage of 3D computational models has grown pushed also by well-known technological factors. Nevertheless, in the past, there were several limiting factors on the wide diffusion of 3D computational models to perform virtual towing tank data acquiring. On one hand software licensing and hardware infrastructure costs, on the other hand the need of very specific technological skills limited the usage of such virtualized tools only to research centers and/or to large industrial companies. In this work we propose an innovative high-level approach which is embodied in the so-called LincoSim [17] web application in which a hypothetical designer user can carry out the simulation only starting from its own geometry and a set of meaningful physical parameters. LincoSim automatically manages and hides to the user all the necessary details of Computational Fluid Dynamics (CFD) modelling and of HPC infrastructure usage allowing them to access, visualize and analyze the outputs from the same single access point made up from the web browser. In addition to the web interface, the platform includes a back-end server which implements a Cloud logic and can be connected to multiple HPC machines for computing. LincoSim is currently set up with finite volume Open-FOAM CFD engine. A preliminary validation campaign has been performed to assess the robustness and the reliability of the tool and is proposed as a novel approach for the development of Computer Aided Engineering (CAE) applications. © 2019, Springer Nature B.V.","Cloud; Computational fluid dynamics; Design; High performance computing; Naval engineering; OpenFOAM","Article","Scopus"
"Newman N.; Fréchette A.; Leyton-Brown K.","Newman, Neil (57192661099); Fréchette, Alexandre (55838254800); Leyton-Brown, Kevin (6602662604)","57192661099; 55838254800; 6602662604","Deep optimization for spectrum repacking","2018","Communications of the ACM","10.1145/3107548","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040097020&doi=10.1145%2f3107548&partnerID=40&md5=594a018580c61236c6674828be4f813d","Over 13 months in 2016-17 the U.S. Federal Communications Commission conducted an ""incentive auction"" to repurpose radio spectrum from broadcast television to wireless internet. In the end, the auction yielded $19.8 bn, $10.05 bn of which was paid to 175 broadcasters for voluntarily relinquishing their licenses across 14 Ultra High Frequency (UHF) channels. Stations that continued broadcasting were assigned potentially new channels to fit as densely as possible into the channels that remained. The government netted more than $7 bn (used to pay down the national debt) after covering costs (including retuning). A crucial element of the auction design was the construction of a solver, dubbed SAT-based Feasibility Checker (SATFC), that determined whether sets of stations could be ""repacked"" in this way; it needed to run every time a station was given a price quote. This paper describes the process by which we built SATFC. We adopted an approach we dub ""deep optimization,"" taking a data-driven, highly parametric, and computationally intensive approach to solver design. More specifically, to build SATFC we designed software that could pair both complete and local-search SAT-encoded feasibility checking with a wide range of domain-specific techniques, such as constraint graph decomposition and novel caching mechanisms that allow for reuse of partial solutions from related, solved problems. We then used automatic algorithm configuration techniques to construct a portfolio of 8 complementary algorithms to be run in parallel, aiming to achieve good performance on instances that arose in proprietary auction simulations. To evaluate the impact of our solver in this paper, we built an open-source reverse auction simulator. We found that within the short time budget required in practice, SATFC solved more than 95% of the problems it encountered. Furthermore, the incentive auction paired with SATFC produced nearly optimal allocations in a restricted setting and substantially outperformed other alternatives at national scale.","","Article","Scopus"
"Schön M.E.; Eme L.; Ettema T.J.G.","Schön, Max E. (57117396700); Eme, Laura (26433309900); Ettema, Thijs J.G. (6602489896)","57117396700; 26433309900; 6602489896","PhyloMagnet: Fast and accurate screening of short-read meta-omics data using gene-centric phylogenetics","2020","Bioinformatics","10.1093/bioinformatics/btz799","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082147874&doi=10.1093%2fbioinformatics%2fbtz799&partnerID=40&md5=a82819af362fc537e32bdbcf0b137886","Motivation: Metagenomic and metatranscriptomic sequencing have become increasingly popular tools for producing massive amounts of short-read data, often used for the reconstruction of draft genomes or the detection of (active) genes in microbial communities. Unfortunately, sequence assemblies of such datasets generally remain a computationally challenging task. Frequently, researchers are only interested in a specific group of organisms or genes; yet, the assembly of multiple datasets only to identify candidate sequences for a specific question is sometimes prohibitively slow, forcing researchers to select a subset of available datasets to address their question. Here, we present PhyloMagnet, a workflow to screen meta-omics datasets for taxa and genes of interest using gene-centric assembly and phylogenetic placement of sequences. Results: Using PhyloMagnet, we could identify up to 87% of the genera in an in vitro mock community with variable abundances, while the false positive predictions per single gene tree ranged from 0 to 23%. When applied to a group of metagenomes for which a set of metagenome assembled genomes (MAGs) have been published, we could detect the majority of the taxonomic labels that the MAGs had been annotated with. In a metatranscriptomic setting, the phylogenetic placement of assembled contigs corresponds to that of transcripts obtained from transcriptome assembly. Availability and implementation: PhyloMagnet is built using Nextflow, available at github.com/maxemil/ PhyloMagnet and is developed and tested on Linux. It is released under the open source GNU GPL licence and documentation is available at phylomagnet.readthedocs.io. Version 0.5 of PhyloMagnet was used for all benchmarking experiments. © The Author(s) 2019. Published by Oxford University Press. All rights reserved.","","Article","Scopus"
"Magnusson R.; Lubovac-Pilav Z.","Magnusson, Rasmus (57213783169); Lubovac-Pilav, Zelmina (57195753317)","57213783169; 57195753317","TFTenricher: a python toolbox for annotation enrichment analysis of transcription factor target genes","2021","BMC Bioinformatics","10.1186/s12859-021-04357-4","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115057681&doi=10.1186%2fs12859-021-04357-4&partnerID=40&md5=c1107a5132a70d3947bd47a66fbeebfe","Background: Transcription factors (TFs) are the upstream regulators that orchestrate gene expression, and therefore a centrepiece in bioinformatics studies. While a core strategy to understand the biological context of genes and proteins includes annotation enrichment analysis, such as Gene Ontology term enrichment, these methods are not well suited for analysing groups of TFs. This is particularly true since such methods do not aim to include downstream processes, and given a set of TFs, the expected top ontologies would revolve around transcription processes. Results: We present the TFTenricher, a Python toolbox that focuses specifically at identifying gene ontology terms, cellular pathways, and diseases that are over-represented among genes downstream of user-defined sets of human TFs. We evaluated the inference of downstream gene targets with respect to false positive annotations, and found an inference based on co-expression to best predict downstream processes. Based on these downstream genes, the TFTenricher uses some of the most common databases for gene functionalities, including GO, KEGG and Reactome, to calculate functional enrichments. By applying the TFTenricher to differential expression of TFs in 21 diseases, we found significant terms associated with disease mechanism, while the gene set enrichment analysis on the same dataset predominantly identified processes related to transcription. Conclusions and availability: The TFTenricher package enables users to search for biological context in any set of TFs and their downstream genes. The TFTenricher is available as a Python 3 toolbox at https://github.com/rasma774/Tftenricher, under a GNU GPL license and with minimal dependencies. © 2021, The Author(s).","","Article","Scopus"
"Bramscher P.F.; Butler J.T.","Bramscher, Paul F. (6508152266); Butler, John T. (12776006700)","6508152266; 12776006700","LibData to LibCMS: One library's evolutionary pathway to a content management system","2006","Library Hi Tech","10.1108/07378830610652086","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33644866344&doi=10.1108%2f07378830610652086&partnerID=40&md5=083b14afb7987f90aff003a76a0baaff","Purpose - The University of Minnesota Libraries have developed and implemented LibCMS, an open architecture content management system (CMS) that combines with the previously-built LibData system to meet the web page publishing and site management needs of a large research library. The purpose of this paper is to present overall observations about CMSs and their implementation, and details the requirements and design of LibCMS. Design/methodology/approach - The system's development followed an evolutionary path moving from a modest data repository, to a large system with a three-tiered web page authoring environment, and now to a CMS with site-level management capability. This work leaned on abstract tree structures to manage navigational hierarchy both within and between pages. Methods were developed to represent tree architecture in an RDBMS while economizing traversal and maintenance of nodes. Findings - Developing the CMS locally ensured that design followed the requirements of a large academic library environment and its service/ business model. This also allowed the implementation to be an organic extension of existing authoring tools in the environment rather than the potentially disruptive incorporation of a new system. Research limitations/implications - Architectural problems encountered here have traditionally been treated outside of library and information science. The challenge both in implementation and in research has been to bridge gaps between computer science and applied technologies in libraries. Practical implications - Implementations of open source, library-oriented CMSs could, over time, open the door to community software development and distribution efforts. Originality/value - This paper uniquely details the rationale and design of a library-oriented, open architecture CMS, built to interoperate with a large, content repository. © Emerald Group Publishing Limited.","Content management; Libraries; Open systems","Article","Scopus"
"Liu J.; Li G.; Chang Z.; Yu T.; Liu B.; McMullen R.; Chen P.; Huang X.","Liu, Juntao (56042369900); Li, Guojun (7801516199); Chang, Zheng (56121723700); Yu, Ting (57149487900); Liu, Bingqiang (55832922200); McMullen, Rick (55916028900); Chen, Pengyin (7408354674); Huang, Xiuzhen (8720349300)","56042369900; 7801516199; 56121723700; 57149487900; 55832922200; 55916028900; 7408354674; 8720349300","BinPacker: Packing-Based De Novo Transcriptome Assembly from RNA-seq Data","2016","PLoS Computational Biology","10.1371/journal.pcbi.1004772","86","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959538601&doi=10.1371%2fjournal.pcbi.1004772&partnerID=40&md5=0df82f77ff39ed1e096e874600633a30","High-throughput RNA-seq technology has provided an unprecedented opportunity to reveal the very complex structures of transcriptomes. However, it is an important and highly challenging task to assemble vast amounts of short RNA-seq reads into transcriptomes with alternative splicing isoforms. In this study, we present a novel de novo assembler, BinPacker, by modeling the transcriptome assembly problem as tracking a set of trajectories of items with their sizes representing coverage of their corresponding isoforms by solving a series of bin-packing problems. This approach, which subtly integrates coverage information into the procedure, has two exclusive features: 1) only splicing junctions are involved in the assembling procedure; 2) massive pell-mell reads are assembled seemingly by moving a comb along junction edges on a splicing graph. Being tested on both real and simulated RNA-seq datasets, it outperforms almost all the existing de novo assemblers on all the tested datasets, and even outperforms those ab initio assemblers on the real dog dataset. In addition, it runs substantially faster and requires less memory space than most of the assemblers. BinPacker is published under GNU GENERAL PUBLIC LICENSE and the source is available from: http://sourceforge.net/projects/transcriptomeassembly/files/BinPacker_1.0.tar.gz/download. Quick installation version is available from: http://sourceforge.net/projects/transcriptomeassembly/files/BinPacker_binary.tar.gz/download. © 2016 Liu et al.","","Article","Scopus"
"Wilson M.L.; Okumoto S.; Adam L.; Peccoud J.","Wilson, Mandy L. (36098510100); Okumoto, Sakiko (6603936831); Adam, Laura (35268202400); Peccoud, Jean (6701730721)","36098510100; 6603936831; 35268202400; 6701730721","Development of a domain-specific genetic language to design Chlamydomonas reinhardtii expression vectors","2014","Bioinformatics","10.1093/bioinformatics/btt646","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892767284&doi=10.1093%2fbioinformatics%2fbtt646&partnerID=40&md5=43ccafedb939f6a7cb47845dba3b69e6","Motivation: Expression vectors used in different biotechnology applications are designed with domain-specific rules. For instance, promoters, origins of replication or homologous recombination sites are host-specific. Similarly, chromosomal integration or viral delivery of an expression cassette imposes specific structural constraints. As de novo gene synthesis and synthetic biology methods permeate many biotechnology specialties, the design of application-specific expression vectors becomes the new norm. In this context, it is desirable to formalize vector design strategies applicable in different domains.Results: Using the design of constructs to express genes in the chloroplast of Chlamydomonas reinhardtii as an example, we show that a vector design strategy can be formalized as a domain-specific language. We have developed a graphical editor of context-free grammars usable by biologists without prior exposure to language theory. This environment makes it possible for biologists to iteratively improve their design strategies throughout the course of a project. It is also possible to ensure that vectors designed with early iterations of the language are consistent with the latest iteration of the language.Availability and implementation: The context-free grammar editor is part of the GenoCAD application. A public instance of GenoCAD is available at http://www.genocad.org. GenoCAD source code is available from SourceForge and licensed under the Apache v2.0 open source license. © 2013 The Author.","","Article","Scopus"
"Pudjiastuti L.; Indrawati; Ariski H.; Arrum D.A.","Pudjiastuti, Lilik (57214676316); Indrawati (57214671142); Ariski, Hasbi (57217865403); Arrum, Desi Arianing (57217864798)","57214676316; 57214671142; 57217865403; 57217864798","Integrated E-supply chain management systems services as a form of acceleration of development in Indonesia","2020","International Journal of Supply Chain Management","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087789059&partnerID=40&md5=a36da2fd93acdf3cb31f282c56fba2d5","This article examines the effect of E-Supply Chain Management Systems in the Indonesia electronics services industry. It aims to review the ease of business licensing policy through the online system in the environmental field as a follow-up to the Online Single Submission Service policy which is intended to facilitate for entrepreneurs to obtain the legality of their business activities. Licensing in the environmental field aims to prevent environmental pollution and fulfill people's rights to obtain a good and healthy environment so that the existence of environmental licensing to achieve one of the Sustainable Development Goals (SDGs) targets, which is to reduce poverty and ensure equity development and environmental sustainability, especially the targets to minimize the danger of climate change caused by humans. Licensing service through OSS application is a policy that accelerates licensing services that have been considered long and expensive, but in the implementation of licensing services on line still raises legal problems, namely not fulfilling the principle of legal certainty, the principle of accuracy and the principle of transparency, so that the potential for business activities which has a license does not guarantee the creation of a good and healthy environment and achieving sustainable development. Discussion of this article through a conceptual analysis of licensing services and instruments for preventing pollution of the environment and analysis of laws and regulations in the field of environmental service sector licensing. © ExcelingTech Pub, UK.","And state administration decisions; Legitimate expectation; Licensing legal certainty; Service supply chain management; Sustainable development","Article","Scopus"
"Dehof A.K.; Loew S.; Lenhof H.-P.; Hildebrandt A.","Dehof, Anna Katharina (6504731195); Loew, Simon (56513652200); Lenhof, Hans-Peter (6602931980); Hildebrandt, Andreas (12238853600)","6504731195; 56513652200; 6602931980; 12238853600","NightShift: NMR shift inference by general hybrid model training - a framework for NMR chemical shift prediction","2013","BMC Bioinformatics","10.1186/1471-2105-14-98","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874943421&doi=10.1186%2f1471-2105-14-98&partnerID=40&md5=9b63640661ab47f011932d4adb66288c","Background: NMR chemical shift prediction plays an important role in various applications in computational biology. Among others, structure determination, structure optimization, and the scoring of docking results can profit from efficient and accurate chemical shift estimation from a three-dimensional model.A variety of NMR chemical shift prediction approaches have been presented in the past, but nearly all of these rely on laborious manual data set preparation and the training itself is not automatized, making retraining the model, e.g., if new data is made available, or testing new models a time-consuming manual chore.Results: In this work, we present the framework NightShift (NMR Shift Inference by General Hybrid Model Training), which enables automated data set generation as well as model training and evaluation of protein NMR chemical shift prediction.In addition to this main result - the NightShift framework itself - we describe the resulting, automatically generated, data set and, as a proof-of-concept, a random forest model called Spinster that was built using the pipeline.Conclusion: By demonstrating that the performance of the automatically generated predictors is at least en par with the state of the art, we conclude that automated data set and predictor generation is well-suited for the design of NMR chemical shift estimators.The framework can be downloaded from https://bitbucket.org/akdehof/nightshift. It requires the open source Biochemical Algorithms Library (BALL), and is available under the conditions of the GNU Lesser General Public License (LGPL). We additionally offer a browser-based user interface to our NightShift instance employing the Galaxy framework via https://ballaxy.bioinf.uni-sb.de/. © 2013 Dehof et al.; licensee BioMed Central Ltd.","","Article","Scopus"
"Dumolin C.; Aerts M.; Verheyde B.; Schellaert S.; Vandamme T.; Van der Jeugt F.; De Canck E.; Cnockaert M.; Wieme A.D.; Cleenwerck I.; Peiren J.; Dawyndt P.; Vandamme P.; Carlier A.","Dumolin, Charles (57191583360); Aerts, Maarten (15041730300); Verheyde, Bart (57190438068); Schellaert, Simon (57211013768); Vandamme, Tim (57211014000); Van der Jeugt, Felix (57189602102); De Canck, Evelien (55859668600); Cnockaert, Margo (6602748232); Wieme, Anneleen D. (55520732600); Cleenwerck, Ilse (6603193765); Peiren, Jindrich (55071069800); Dawyndt, Peter (6603237419); Vandamme, Peter (56211244100); Carlier, Aurélien (7005062911)","57191583360; 15041730300; 57190438068; 57211013768; 57211014000; 57189602102; 55859668600; 6602748232; 55520732600; 6603193765; 55071069800; 6603237419; 56211244100; 7005062911","Introducing SPEDE: High-throughput dereplication and accurate determination of microbial diversity from matrix-assisted laser desorption–ionization time of flight mass spectrometry data","2019","mSystems","10.1128/mSystems.00437-19","35","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072247248&doi=10.1128%2fmSystems.00437-19&partnerID=40&md5=dc9b19e4855e12b00b55e592de0b302e","The isolation of microorganisms from microbial community samples often yields a large number of conspecific isolates. Increasing the diversity covered by an isolate collection entails the implementation of methods and protocols to minimize the number of redundant isolates. Matrix-assisted laser desorption–ionization time-of-flight (MALDI-TOF) mass spectrometry methods are ideally suited to this dereplication problem because of their low cost and high throughput. However, the available software tools are cumbersome and rely either on the prior development of reference databases or on global similarity analyses, which are inconvenient and offer low taxonomic resolution. We introduce SPeDE, a user-friendly spectral data analysis tool for the dereplication of MALDI-TOF mass spectra. Rather than relying on global similarity approaches to classify spectra, SPeDE determines the number of unique spectral features by a mix of global and local peak comparisons. This approach allows the identification of a set of nonredundant spectra linked to operational isolation units. We evaluated SPeDE on a data set of 5,228 spectra representing 167 bacterial strains belonging to 132 genera across six phyla and on a data set of 312 spectra of 78 strains measured before and after lyophilization and subculturing. SPeDE was able to dereplicate with high efficiency by identifying redundant spectra while retrieving reference spectra for all strains in a sample. SPeDE can identify distinguishing features between spectra, and its performance exceeds that of established methods in speed and precision. SPeDE is open source under the MIT license and is available from https://github.com/LM-UGent/SPeDE. IMPORTANCE Estimation of the operational isolation units present in a MALDI-TOF mass spectral data set involves an essential dereplication step to identify redundant spectra in a rapid manner and without sacrificing biological resolution. We describe SPeDE, a new algorithm which facilitates culture-dependent clinical or environmental studies. SPeDE enables the rapid analysis and dereplication of isolates, a critical feature when long-term storage of cultures is limited or not feasible. We show that SPeDE can efficiently identify sets of similar spectra at the level of the species or strain, exceeding the taxonomic resolution of other methods. The high-throughput capacity, speed, and low cost of MALDI-TOF mass spectrometry and SPeDE dereplication over traditional gene marker-based sequencing approaches should facilitate adoption of the culturomics approach to bacterial isolation campaigns. Copyright © 2019 Dumolin et al. This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International license.","Bioinformatics; Dereplication; MALDI-TOF MS; Microbial ecology","Article","Scopus"
"Khan N.; Castro-Godinez J.; Xue S.; Henkel J.; Becker J.","Khan, Nadir (57208338871); Castro-Godinez, Jorge (57202588259); Xue, Shixiang (57221955020); Henkel, Jorg (35221700400); Becker, Jurgen (55842468000)","57208338871; 57202588259; 57221955020; 35221700400; 55842468000","Automatic Floorplanning and Standalone Generation of Bitstream-Level IP Cores","2021","IEEE Transactions on Very Large Scale Integration (VLSI) Systems","10.1109/TVLSI.2020.3023548","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100818798&doi=10.1109%2fTVLSI.2020.3023548&partnerID=40&md5=7c3459b5a1774ced344dea60852750f2","Partially reconfigurable designs on field-programmable gate array (FPGA) bring an opportunity for developers to license third-party intellectual property (IP) cores. There are multiple IP licensing models that can be used by the FPGA IP market. Their focus is mainly on feasibility and security; however, two major challenges have been ignored by almost all of them. First, both academic or industrial tools do not provide a flow to generate IPs in a standalone environment. Second, these tools only offer manual floorplanning of the IPs, which is both time and performance inefficient. In this work, we present a framework, that can be used by multiple parties to generate different parts of a design independently, that are compatible with each other. It also provides automatic floorplanning based on mixed-integer linear programming (MILP) that considers the distribution of heterogeneous resources in modern FPGAs, with efficient resource utilization as the main objective. The proposed floorplanning is evaluated with benchmarks from the related work. Furthermore, a use case of internal and open-source designs is used for the validation and evaluation of the independent IP generation and the floorplanner.  © 1993-2012 IEEE.","Design optimization; field-programmable gate array (FPGA); floorplanning; heterogeneous system-on-chips (SoC); intellectual property (IP); partial reconfiguration","Article","Scopus"
"Beretta S.; Patterson M.D.; Zaccaria S.; Della Vedova G.; Bonizzoni P.","Beretta, Stefano (55562133000); Patterson, Murray D. (28568010000); Zaccaria, Simone (56176857700); Della Vedova, Gianluca (57192181377); Bonizzoni, Paola (55798385100)","55562133000; 28568010000; 56176857700; 57192181377; 55798385100","HapCHAT: Adaptive haplotype assembly for efficiently leveraging high coverage in long reads","2018","BMC Bioinformatics","10.1186/s12859-018-2253-8","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049433287&doi=10.1186%2fs12859-018-2253-8&partnerID=40&md5=e791b8db258ce9fbf59cce0de9067c06","Background: Haplotype assembly is the process of assigning the different alleles of the variants covered by mapped sequencing reads to the two haplotypes of the genome of a human individual. Long reads, which are nowadays cheaper to produce and more widely available than ever before, have been used to reduce the fragmentation of the assembled haplotypes since their ability to span several variants along the genome. These long reads are also characterized by a high error rate, an issue which may be mitigated, however, with larger sets of reads, when this error rate is uniform across genome positions. Unfortunately, current state-of-the-art dynamic programming approaches designed for long reads deal only with limited coverages. Results: Here, we propose a new method for assembling haplotypes which combines and extends the features of previous approaches to deal with long reads and higher coverages. In particular, our algorithm is able to dynamically adapt the estimated number of errors at each variant site, while minimizing the total number of error corrections necessary for finding a feasible solution. This allows our method to significantly reduce the required computational resources, allowing to consider datasets composed of higher coverages. The algorithm has been implemented in a freely available tool, HapCHAT: Haplotype Assembly Coverage Handling by Adapting Thresholds. An experimental analysis on sequencing reads with up to 60 × coverage reveals improvements in accuracy and recall achieved by considering a higher coverage with lower runtimes. Conclusions: Our method leverages the long-range information of sequencing reads that allows to obtain assembled haplotypes fragmented in a lower number of unphased haplotype blocks. At the same time, our method is also able to deal with higher coverages to better correct the errors in the original reads and to obtain more accurate haplotypes as a result. Availability: HapCHAT is available at http://hapchat.algolab.eu under the GNU Public License (GPL). © 2018 The Author(s).","Haplotype assembly; High coverage; Long reads; Minimum error correction; Single individual haplotyping","Article","Scopus"
"Zhou J.; Xin J.; Niu Y.; Wu S.","Zhou, Jiapeng (57193167694); Xin, Jing (57193162503); Niu, Yayun (57193166881); Wu, Shiwen (14008593900)","57193167694; 57193162503; 57193166881; 14008593900","DMDtoolkit: A tool for visualizing the mutated dystrophin protein and predicting the clinical severity in DMD","2017","BMC Bioinformatics","10.1186/s12859-017-1504-4","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011340673&doi=10.1186%2fs12859-017-1504-4&partnerID=40&md5=ccd712576ec91ee785ffa0a3a261fe91","Background: Dystrophinopathy is one of the most common human monogenic diseases which results in Duchenne muscular dystrophy (DMD) and Becker muscular dystrophy (BMD). Mutations in the dystrophin gene are responsible for both DMD and BMD. However, the clinical phenotypes and treatments are quite different in these two muscular dystrophies. Since early diagnosis and treatment results in better clinical outcome in DMD it is essential to establish accurate early diagnosis of DMD to allow efficient management. Previously, the reading-frame rule was used to predict DMD versus BMD. However, there are limitations using this traditional tool. Here, we report a novel molecular method to improve the accuracy of predicting clinical phenotypes in dystrophinopathy. We utilized several additional molecular genetic rules or patterns such as ""ambush hypothesis"", ""hidden stop codons"" and ""exonic splicing enhancer (ESE)"" to predict the expressed clinical phenotypes as DMD versus BMD. Results: A computer software ""DMDtoolkit"" was developed to visualize the structure and to predict the functional changes of mutated dystrophin protein. It also assists statistical prediction for clinical phenotypes. Using the DMDtoolkit we showed that the accuracy of predicting DMD versus BMD raised about 3% in all types of dystrophin mutations when compared with previous methods. We performed statistical analyses using correlation coefficients, regression coefficients, pedigree graphs, histograms, scatter plots with trend lines, and stem and leaf plots. Conclusions: We present a novel DMDtoolkit, to improve the accuracy of clinical diagnosis for DMD/BMD. This computer program allows automatic and comprehensive identification of clinical risk and allowing them the benefit of early medication treatments. DMDtoolkit is implemented in Perl and R under the GNU license. This resource is freely available at http://github.com/zhoujp111/DMDtoolkit , and http://www.dmd-registry.com. © 2017 The Author(s).","Ambush hypothesis; Assisted diagnosis; Becker muscular dystrophy (BMD); Duchenne muscular dystrophy (DMD); Hidden stop codons","Article","Scopus"
"Korkmaz S.; Goksuluk D.; Zararsiz G.; Karahan S.","Korkmaz, Selcuk (56385234400); Goksuluk, Dincer (56386076800); Zararsiz, Gokmen (55257618200); Karahan, Sevilay (26637049200)","56385234400; 56386076800; 55257618200; 26637049200","geneSurv: An interactive web-based tool for survival analysis in genomics research","2017","Computers in Biology and Medicine","10.1016/j.compbiomed.2017.08.031","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028937468&doi=10.1016%2fj.compbiomed.2017.08.031&partnerID=40&md5=d4cb68c182e8414e6aba4fc7fd894662","Survival analysis methods are often used in cancer studies. It has been shown that the combination of clinical data with genomics increases the predictive performance of survival analysis methods. But, this leads to a high-dimensional data problem. Fortunately, new methods have been developed in the last decade to overcome this problem. However, there is a strong need for easily accessible, user-friendly and interactive tool to perform survival analysis in the presence of genomics data. We developed an open-source and freely available web-based tool for survival analysis methods that can deal with high-dimensional data. This tool includes classical methods, such as Kaplan-Meier, Cox proportional hazards regression, and advanced methods, such as penalized Cox regression and Random Survival Forests. It also offers an optimal cutoff determination method based on maximizing several test statistics. The tool has a simple and interactive interface, and it can handle high dimensional data through feature selection and ensemble methods. To dichotomize gene expressions, geneSurv can identify optimal cutoff points. Users can upload their microarray, RNA-Seq, chip-Seq, proteomics, metabolomics or clinical data as a nxp dimensional data matrix, where n refers to samples and p refers to genes. This tool is available free at www.biosoft.hacettepe.edu.tr/geneSurv. All source code is available at https://github.com/selcukorkmaz/geneSurv under the GPL-3 license. © 2017 Elsevier Ltd","Cox regression; Cutoff; Feature selection; Genomics; Kaplan-Meier; Survival analysis","Article","Scopus"
"McDonald D.; Kaehler B.; Gonzalez A.; DeReus J.; Ackermann G.; Marotz C.; Huttley G.; Knight R.","McDonald, Daniel (23667804700); Kaehler, Benjamin (55178354400); Gonzalez, Antonio (57189506114); DeReus, Jeff (57200565359); Ackermann, Gail (55863018900); Marotz, Clarisse (56938952300); Huttley, Gavin (6603868509); Knight, Rob (57202526255)","23667804700; 55178354400; 57189506114; 57200565359; 55863018900; 56938952300; 6603868509; 57202526255","Redbiom: A rapid sample discovery and feature characterization system","2019","mSystems","10.1128/mSystems.00215-19","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070972872&doi=10.1128%2fmSystems.00215-19&partnerID=40&md5=ce3f10a4218e2bb525fc1b2837b70bb8","Meta-analyses at the whole-community level have been important in microbiome studies, revealing profound features that structure Earth's microbial communities, such as the unique differentiation of microbes from the mammalian gut relative to free-living microbial communities, the separation of microbiomes in saline and nonsaline environments, and the role of pH in driving soil microbial compositions. However, our ability to identify the specific features of a microbiome that differentiate these community-level patterns have lagged behind, especially as evercheaper DNA sequencing has yielded increasingly large data sets. One critical gap is the ability to search for samples that contain specific features (for example, suboperational taxonomic units [sOTUs] identified by high-resolution statistical methods for removing amplicon sequencing errors). Here we introduce redbiom, a microbiome caching layer, which allows users to rapidly query samples that contain a given feature, retrieve sample data and metadata, and search for samples that match specified metadata values or ranges (e.g., all samples with a pH of >7), implemented using an in-memory NoSQL database called Redis. By default, redbiom allows public anonymous sample access for over 100,000 publicly available samples in the Qiita database. At over 100,000 samples, the caching server requires only 35 GB of resident memory. We highlight how redbiom enables a new type of characterization of microbiome samples and provide tutorials for using redbiom with QIIME 2. redbiom is open source under the BSD license, hosted on GitHub, and can be deployed independently of Qiita to enable search of proprietary or clinically restricted microbiome databases. IMPORTANCE Although analyses that combine many microbiomes at the wholecommunity level have become routine, searching rapidly for microbiomes that contain a particular sequence has remained difficult. The software we present here, redbiom, dramatically accelerates this process, allowing samples that contain microbiome features to be rapidly identified. This is especially useful when taxonomic annotation is limited, allowing users to identify environments in which unannotated microbes of interest were previously observed. This approach also allows environmental or clinical factors that correlate with specific features, or vice versa, to be identified rapidly, even at a scale of billions of sequences in hundreds of thousands of samples. The software is integrated with existing analysis tools to enable fast, large-scale microbiome searches and discovery of new microbiome relationships. Copyright © 2019 McDonald et al.","Database; Meta-analysis; Microbiome","Article","Scopus"
"Livingston K.M.; Bada M.; Baumgartner W.A.; Hunter L.E.","Livingston, Kevin M. (7007084985); Bada, Michael (55887393300); Baumgartner, William A. (55851941991); Hunter, Lawrence E. (57689685500)","7007084985; 55887393300; 55851941991; 57689685500","KaBOB: ontology-based semantic integration of biomedical databases","2015","BMC Bioinformatics","10.1186/s12859-015-0559-3","51","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930504533&doi=10.1186%2fs12859-015-0559-3&partnerID=40&md5=9811e1c31796159626f3bbc0fc6e5f8b","Background: The ability to query many independent biological databases using a common ontology-based semantic model would facilitate deeper integration and more effective utilization of these diverse and rapidly growing resources. Despite ongoing work moving toward shared data formats and linked identifiers, significant problems persist in semantic data integration in order to establish shared identity and shared meaning across heterogeneous biomedical data sources. Results: We present five processes for semantic data integration that, when applied collectively, solve seven key problems. These processes include making explicit the differences between biomedical concepts and database records, aggregating sets of identifiers denoting the same biomedical concepts across data sources, and using declaratively represented forward-chaining rules to take information that is variably represented in source databases and integrating it into a consistent biomedical representation. We demonstrate these processes and solutions by presenting KaBOB (the Knowledge Base Of Biomedicine), a knowledge base of semantically integrated data from 18 prominent biomedical databases using common representations grounded in Open Biomedical Ontologies. An instance of KaBOB with data about humans and seven major model organisms can be built using on the order of 500 million RDF triples. All source code for building KaBOB is available under an open-source license. Conclusions: KaBOB is an integrated knowledge base of biomedical data representationally based in prominent, actively maintained Open Biomedical Ontologies, thus enabling queries of the underlying data in terms of biomedical concepts (e.g., genes and gene products, interactions and processes) rather than features of source-specific data schemas or file formats. KaBOB resolves many of the issues that routinely plague biomedical researchers intending to work with data from multiple data sources and provides a platform for ongoing data integration and development and for formal reasoning over a wealth of integrated biomedical data. © 2015 Livingston et al.; licensee BioMed Central.","Biomedical; Databases; Knowledge representation and reasoning; Open biomedical ontologies; OWL; RDF; Semantic data integration; Semantic web","Article","Scopus"
"Weniger M.; Engelmann J.C.; Schultz J.","Weniger, Markus (36977019700); Engelmann, Julia C. (16678597900); Schultz, Jörg (57205412298)","36977019700; 16678597900; 57205412298","Genome Expression Pathway Analysis Tool - Analysis and visualization of microarray gene expression data under genomic, proteomic and metabolic context","2007","BMC Bioinformatics","10.1186/1471-2105-8-179","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34347210339&doi=10.1186%2f1471-2105-8-179&partnerID=40&md5=32a81d63d8c66d3d72c7fff59e459600","Background: Regulation of gene expression is relevant to many areas of biology and medicine, in the study of treatments, diseases, and developmental stages. Microarrays can be used to measure the expression level of thousands of mRNAs at the same time, allowing insight into or comparison of different cellular conditions. The data derived out of microarray experiments is highly dimensional and often noisy, and interpretation of the results can get intricate. Although programs for the statistical analysis of microarray data exist, most of them lack an integration of analysis results and biological interpretation. Results: We have developed GEPAT, Genome Expression Pathway Analysis Tool, offering an analysis of gene expression data under genomic, proteomic and metabolic context. We provide an integration of statistical methods for data import and data analysis together with a biological interpretation for subsets of probes or single probes on the chip. GEPAT imports various types of oligonucleotide and cDNA array data formats. Different normalization methods can be applied to the data, afterwards data annotation is performed. After import, GEPAT offers various statistical data analysis methods, as hierarchical, k-means and PCA clustering, a linear model based t-test or chromosomal profile comparison. The results of the analysis can be interpreted by enrichment of biological terms, pathway analysis or interaction networks. Different biological databases are included, to give various information for each probe on the chip. GEPAT offers no linear work flow, but allows the usage of any subset of probes and samples as a start for a new data analysis. GEPAT relies on established data analysis packages, offers a modular approach for an easy extension, and can be run on a computer grid to allow a large number of users. It is freely available under the LGPL open source license for academic and commercial users at http://gepat.sourceforge.net. Conclusion: GEPAT is a modular, scalable and professional-grade software integrating analysis and interpretation of microarray gene expression data. An installation available for academic users can be found at http://gepat.bioapps.biozentrum.uni-wuerzburg.de. © 2007 Weniger et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Krumholz M.R.; Forbes J.C.","Krumholz, M.R. (8316438800); Forbes, J.C. (55307706300)","8316438800; 55307706300","VADER: A flexible, robust, open-source code for simulating viscous thin accretion disks","2015","Astronomy and Computing","10.1016/j.ascom.2015.02.005","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925448788&doi=10.1016%2fj.ascom.2015.02.005&partnerID=40&md5=789f5fc7f2905a0323bf003a54471475","The evolution of thin axisymmetric viscous accretion disks is a classic problem in astrophysics. While models based on this simplified geometry provide only approximations to the true processes of instability-driven mass and angular momentum transport, their simplicity makes them invaluable tools for both semi-analytic modeling and simulations of long-term evolution where two- or three-dimensional calculations are too computationally costly. Despite the utility of these models, the only publicly-available frameworks for simulating them are rather specialized and non-general. Here we describe a highly flexible, general numerical method for simulating viscous thin disks with arbitrary rotation curves, viscosities, boundary conditions, grid spacings, equations of state, and rates of gain or loss of mass (e.g., through winds) and energy (e.g., through radiation). Our method is based on a conservative, finite-volume, second-order accurate discretization of the equations, which we solve using an unconditionally-stable implicit scheme. We implement Anderson acceleration to speed convergence of the scheme, and show that this leads to factor of ~5 speed gains over non-accelerated methods in realistic problems, though the amount of speedup is highly problem-dependent. We have implemented our method in the new code Viscous Accretion Disk Evolution Resource (VADER), which is freely available for download from https://bitbucket.org/krumholz/vader/ under the terms of the GNU General Public License. © 2015 Elsevier B.V.","Accretion; Accretion disks; Applied computing astronomy; Mathematics of computing nonlinear equations; Mathematics of computing partial differential equations; Methods: numerical","Article","Scopus"
"Musah A.; Dutra L.M.M.; Aldosery A.; Browning E.; Ambrizzi T.; Borges I.V.G.; Tunali M.; Başibüyük S.; Yenigün O.; Moreno G.M.M.; da Silva A.C.G.; dos Santos W.P.; de Lima C.L.; Massoni T.; Jones K.E.; Campos L.C.; Kostkova P.","Musah, Anwar (57210998260); Dutra, Livia Màrcia Mosso (56031940600); Aldosery, Aisha (57250106700); Browning, Ella (57197736235); Ambrizzi, Tercio (6602469258); Borges, Iuri Valerio Graciano (57249105400); Tunali, Merve (57217782116); Başibüyük, Selma (57249542300); Yenigün, Orhan (6701812910); Moreno, Giselle Machado Magalhaes (57224180971); da Silva, Ana Clara Gomes (57220187896); dos Santos, Wellington Pinheiro (57193746428); de Lima, Clarisse Lins (57220180472); Massoni, Tiago (8327557600); Jones, Kate Elizabeth (7404728090); Campos, Luiza Cintra (14043273200); Kostkova, Patty (6506790018)","57210998260; 56031940600; 57250106700; 57197736235; 6602469258; 57249105400; 57217782116; 57249542300; 6701812910; 57224180971; 57220187896; 57193746428; 57220180472; 8327557600; 7404728090; 14043273200; 6506790018","An Evaluation of the OpenWeatherMap API versus INMET Using Weather Data from Two Brazilian Cities: Recife and Campina Grande","2022","Data","10.3390/data7080106","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136817285&doi=10.3390%2fdata7080106&partnerID=40&md5=c2da47bdde0c3e647ccd6da1069b535b","Certain weather conditions are inadvertently related to increased population of various mosquitoes. In order to predict the burden of mosquito populations in the Global South, it is imperative to integrate weather-related risk factors into such predictive models. There are a lot of online open-source weather platforms that provide historical, current and future weather forecasts which can be utilised for general predictions, and these electronic sources serve as an alternate option for weather data when physical weather stations are inaccessible (or inactive). Before using data from such online source, it is important to assess the accuracy against some baseline measure. In this paper, we therefore evaluated the accuracy and suitability of weather forecasts of two parameters namely temperature and humidity from the OpenWeatherMap API (an online weather platform) and compared them with actual measurements collected from the Brazilian weather stations (INMET). The evaluation was focused on two Brazilian cites, namely, Recife and Campina Grande. The intention is to prepare an early warning model which will harness data from OpenWeatherMap API for mosquito prediction. Dataset:https://figshare.com/s/08449337eb8194848c72 (accessed on 21 July 2022) Dataset License: CC BY 4.0. © 2022 by the authors.","application programming interfaces; data sources; meteorological parameters; OpenWeatherMap; weather","Article","Scopus"
"Boland T.M.; Singh A.K.","Boland, Tara M. (57211545707); Singh, Arunima K. (57201303839)","57211545707; 57201303839","Computational synthesis of 2D materials: A high-throughput approach to materials design","2022","Computational Materials Science","10.1016/j.commatsci.2022.111238","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125545902&doi=10.1016%2fj.commatsci.2022.111238&partnerID=40&md5=a7298f25ee3e1166d456615ff0e2a870","2D materials find promising applications in next-generation devices, however, large-scale, low-defect, and reproducible synthesis of 2D materials remains a challenging task. To assist in the selection of suitable substrates for the synthesis of as-yet hypothetical 2D materials, we have developed an open-source high-throughput workflow package, Hetero2d, that searches for low-lattice mismatched substrate surfaces for any 2D material and determines the stability of these 2D-substrate heterostructures using density functional theory (DFT) simulations. Hetero2d automates the generation of 2D-substrate heterostructures, the creation of DFT input files, the submission and monitoring of computational jobs on supercomputing facilities, and the storage of relevant parameters alongside the post-processed results in a MongoDB database. We demonstrate the capability of Hetero2d in identifying stable 2D-substrate heterostructures for four 2D materials, namely 2H-MoS2, 1T- and 2H-NbO2, and hexagonal-ZnTe, considering 50 cubic elemental substrates. We find Cu, Hf, Mn, Nd, Ni, Pd, Re, Rh, Sc, Ta, Ti, V, W, Y, and Zr substrates sufficiently stabilize the formation energies of these 2D materials, with binding energies in the range of ∼0.1–0.6 eV/atom. Upon examining the z-separation, the charge transfer, and the electronic density of states at the 2D-substrate interface, we find a covalent type bonding at the interface which suggests that these substrates can be used as contact materials for the 2D materials. Hetero2d is available on GitHub as an open-source package under the GNU license. © 2022 Elsevier B.V.","DFT; Heterostructures; High-throughput; Surface Genome project; Two-dimensional","Article","Scopus"
"Abbood A.; Ullrich A.; Busche R.; Ghozzi S.","Abbood, Auss (57220176866); Ullrich, Alexander (57204170603); Busche, Rüdiger (57205348176); Ghozzi, Stéphane (6508354308)","57220176866; 57204170603; 57205348176; 6508354308","EventEpi-A natural language processing framework for event-based surveillance","2020","PLoS Computational Biology","10.1371/journal.pcbi.1008277","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097135320&doi=10.1371%2fjournal.pcbi.1008277&partnerID=40&md5=0892b21f198070448942ce99404a45df","According to the World Health Organization (WHO), around 60% of all outbreaks are detected using informal sources. In many public health institutes, including the WHO and the Robert Koch Institute (RKI), dedicated groups of public health agents sift through numerous articles and newsletters to detect relevant events. This media screening is one important part of event-based surveillance (EBS). Reading the articles, discussing their relevance, and putting key information into a database is a time-consuming process. To support EBS, but also to gain insights into what makes an article and the event it describes relevant, we developed a natural language processing framework for automated information extraction and relevance scoring. First, we scraped relevant sources for EBS as done at the RKI (WHO Disease Outbreak News and ProMED) and automatically extracted the articles' key data: disease, country, date, and confirmed-case count. For this, we performed named entity recognition in two steps: EpiTator, an open-source epidemiological annotation tool, suggested many different possibilities for each. We extracted the key country and disease using a heuristic with good results. We trained a naive Bayes classifier to find the key date and confirmed-case count, using the RKI's EBS database as labels which performed modestly. Then, for relevance scoring, we defined two classes to which any article might belong: The article is relevant if it is in the EBS database and irrelevant otherwise. We compared the performance of different classifiers, using bag-of-words, document and word embeddings. The best classifier, a logistic regression, achieved a sensitivity of 0.82 and an index balanced accuracy of 0.61. Finally, we integrated these functionalities into a web application called EventEpi where relevant sources are automatically analyzed and put into a database. The user can also provide any URL or text, that will be analyzed in the same way and added to the database. Each of these steps could be improved, in particular with larger labeled datasets and fine-tuning of the learning algorithms. The overall framework, however, works already well and can be used in production, promising improvements in EBS. The source code and data are publicly available under open licenses. © 2020 Abbood et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Article","Scopus"
"Xu Z.Z.; Amir A.; Sanders J.; Zhu Q.; Morton J.T.; Bletz M.C.; Tripathi A.; Huang S.; McDonald D.; Jiang L.; Knight R.","Xu, Zhenjiang Zech (57026543300); Amir, Amnon (56545237700); Sanders, Jon (23390171900); Zhu, Qiyun (57200983709); Morton, James T. (56949838700); Bletz, Molly C. (55084827500); Tripathi, Anupriya (57195133839); Huang, Shi (57302255400); McDonald, Daniel (23667804700); Jiang, Lingjing (57194194691); Knight, Rob (57211119310)","57026543300; 56545237700; 23390171900; 57200983709; 56949838700; 55084827500; 57195133839; 57302255400; 23667804700; 57194194691; 57211119310","Calour: an Interactive, Microbe-Centric Analysis Tool","2019","mSystems","10.1128/MSYSTEMS.00269-18","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064177730&doi=10.1128%2fMSYSTEMS.00269-18&partnerID=40&md5=2e02bd83b4b4990708a210d434b4792f","Microbiome analyses can be challenging because microbial strains are numerous, and often, confounding factors in the data set are also numerous. Many tools reduce, summarize, and visualize these high-dimensional data to provide insight at the community level. However, they lose the detailed information about each taxon and can be misleading (for example, the well-known horseshoe effect in ordination plots). Thus, multiple methods at different levels of resolution are required to capture the full range of microbial patterns. Here we present Calour, a user-friendly data exploration tool for microbiome analyses. Calour provides a study-centric data model to store and manipulate sample-by-feature tables (with features typically being operational taxonomic units) and their associated metadata. It generates an interactive heatmap, allowing visualization of microbial patterns and exploration using microbial knowledge databases. We demonstrate the use of Calour by exploring publicly available data sets, including the gut and skin microbiota of habitat-switched fire salamander larvae, gut microbiota of Trichuris muris-infected mice, skin microbiota of different human body sites, gut microbiota of various ant species, and a metabolome study of mice exposed to intermittent hypoxia and hypercapnia. In these cases, Calour reveals novel patterns and potential contaminants of subgroups of microbes that are otherwise hard to find. Calour is open source under the Berkeley Software Distribution (BSD) license and available from https://github.com/biocore/ calour. Copyright © 2019 Xu et al.","Analysis; Contamination; Heatmap; Microbiome; Visualization","Article","Scopus"
"Dahlquist K.D.; Dionisio J.D.N.; Fitzpatrick B.G.; Anguiano N.A.; Varshneya A.; Southwick B.J.; Samdarshi M.","Dahlquist, Kam D. (6507754105); Dionisio, John David N. (7003520243); Fitzpatrick, Ben G. (7005080920); Anguiano, Nicole A. (57195616237); Varshneya, Anindita (57195616249); Southwick, Britain J. (57195616246); Samdarshi, Mihir (57195616252)","6507754105; 7003520243; 7005080920; 57195616237; 57195616249; 57195616246; 57195616252","GRNsight: A web application and service for visualizing models of small-to medium-scale gene regulatory networks","2016","PeerJ Computer Science","10.7717/peerj-cs.85","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029245364&doi=10.7717%2fpeerj-cs.85&partnerID=40&md5=2b415b436f8889cf8ad9040e68eb696f","GRNsight is a web application and service for visualizing models of gene regulatory networks (GRNs). A gene regulatory network (GRN) consists of genes, transcription factors, and the regulatory connections between them which govern the level of expression of mRNA and protein from genes. The original motivation came from our efforts to perform parameter estimation and forward simulation of the dynamics of a differential equations model of a small GRN with 21 nodes and 31 edges. We wanted a quick and easy way to visualize the weight parameters from the model which represent the direction and magnitude of the influence of a transcription factor on its target gene, so we created GRNsight. GRNsight automatically lays out either an unweighted or weighted network graph based on an Excel spreadsheet containing an adjacency matrix where regulators are named in the columns and target genes in the rows, a Simple Interaction Format (SIF) text file, or a GraphML XML file. When a user uploads an input file specifying an unweighted network, GRNsight automatically lays out the graph using black lines and pointed arrowheads. For a weighted network, GRNsight uses pointed and blunt arrowheads, and colors the edges and adjusts their thicknesses based on the sign (positive for activation or negative for repression) and magnitude of the weight parameter. GRNsight is written in JavaScript, with diagrams facilitated by D3.js, a data visualization library. Node.js and the Express framework handle server-side functions. GRNsight's diagrams are based on D3.js's force graph layout algorithm, which was then extensively customized to support the specific needs of GRNs. Nodes are rectangular and support gene labels of up to 12 characters. The edges are arcs, which become straight lines when the nodes are close together. Self-regulatory edges are indicated by a loop.When a user mouses over an edge, the numerical value of the weight parameter is displayed. Visualizations can be modified by sliders that adjust the force graph layout parameters and through manual node dragging. GRNsight is best-suited for visualizing networks of fewer than 35 nodes and 70 edges, although it accepts networks of up to 75 nodes or 150 edges. GRNsight has general applicability for displaying any small, unweighted or weighted network with directed edges for systems biology or other application domains. GRNsight serves as an example of following and teaching best practices for scientific computing and complying with FAIR principles, using an open and test-driven development model with rigorous documentation of requirements and issues on GitHub. An exhaustive unit testing framework using Mocha and the Chai assertion library consists of around 160 automated unit tests that examine nearly 530 test files to ensure that the program is running as expected. The GRNsight application (http://dondi.github.io/ GRNsight/) and code (https://github.com/dondi/GRNsight) are available under the open source BSD license. © 2016 Dahlquist et al.","Automatic graph layout; Best practices for scientific computing; FAIR principles; Gene regulatory networks; Open development; Open source; Visualization; Web application; Web service","Article","Scopus"
"Mallona I.; Weiss J.; Marcos E.-C.","Mallona, Izaskun (35847766100); Weiss, Julia (7402740533); Marcos, Egea-Cortines (6505585790)","35847766100; 7402740533; 6505585790","PcrEfficiency: A Web tool for PCR amplification efficiency prediction","2011","BMC Bioinformatics","10.1186/1471-2105-12-404","51","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80054716265&doi=10.1186%2f1471-2105-12-404&partnerID=40&md5=743bd362f36187bb8d6df4067f1a2b34","Background: Relative calculation of differential gene expression in quantitative PCR reactions requires comparison between amplification experiments that include reference genes and genes under study. Ignoring the differences between their efficiencies may lead to miscalculation of gene expression even with the same starting amount of template. Although there are several tools performing PCR primer design, there is no tool available that predicts PCR efficiency for a given amplicon and primer pair.Results: We have used a statistical approach based on 90 primer pair combinations amplifying templates from bacteria, yeast, plants and humans, ranging in size between 74 and 907 bp to identify the parameters that affect PCR efficiency. We developed a generalized additive model fitting the data and constructed an open source Web interface that allows the obtention of oligonucleotides optimized for PCR with predicted amplification efficiencies starting from a given sequence.Conclusions: pcrEfficiency provides an easy-to-use web interface allowing the prediction of PCR efficiencies prior to web lab experiments thus easing quantitative real-time PCR set-up. A web-based service as well the source code are provided freely at http://srvgen.upct.es/efficiency.html under the GPL v2 license. © 2011 Mallona et al; licensee BioMed Central Ltd.","","Article","Scopus"
"Evans S.; Alden K.; Cucurull-Sanchez L.; Larminie C.; Coles M.C.; Kullberg M.C.; Timmis J.","Evans, Stephanie (57197833533); Alden, Kieran (36162419700); Cucurull-Sanchez, Lourdes (6602894103); Larminie, Christopher (6603220120); Coles, Mark C. (26643204500); Kullberg, Marika C. (7004311799); Timmis, Jon (8987417100)","57197833533; 36162419700; 6602894103; 6603220120; 26643204500; 7004311799; 8987417100","ASPASIA: A toolkit for evaluating the effects of biological interventions on SBML model behaviour","2017","PLoS Computational Biology","10.1371/journal.pcbi.1005351","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014223710&doi=10.1371%2fjournal.pcbi.1005351&partnerID=40&md5=c167b579607051429cdcdd113900a7b3","A calibrated computational model reflects behaviours that are expected or observed in a complex system, providing a baseline upon which sensitivity analysis techniques can be used to analyse pathways that may impact model responses. However, calibration of a model where a behaviour depends on an intervention introduced after a defined time point is difficult, as model responses may be dependent on the conditions at the time the intervention is applied. We present ASPASIA (Automated Simulation Parameter Alteration and SensItivity Analysis), a cross-platform, open-source Java toolkit that addresses a key deficiency in software tools for understanding the impact an intervention has on system behaviour for models specified in Systems Biology Markup Language (SBML). ASPASIA can generate and modify models using SBML solver output as an initial parameter set, allowing interventions to be applied once a steady state has been reached. Additionally, multiple SBML models can be generated where a subset of parameter values are perturbed using local and global sensitivity analysis techniques, revealing the model’s sensitivity to the intervention. To illustrate the capabilities of ASPASIA, we demonstrate how this tool has generated novel hypotheses regarding the mechanisms by which Th17-cell plasticity may be controlled in vivo. By using ASPASIA in conjunction with an SBML model of Th17-cell polarisation, we predict that promotion of the Th1-associated transcription factor T-bet, rather than inhibition of the Th17-associated transcription factor RORγt, is sufficient to drive switching of Th17 cells towards an IFN-γ-producing phenotype. Our approach can be applied to all SBML-encoded models to predict the effect that intervention strategies have on system behaviour. ASPASIA, released under the Artistic License (2.0), can be downloaded from http://www.york.ac.uk/ycil/software. © 2017 Evans et al.","","Article","Scopus"
"Moll A.; Hildebrandt A.; Lenhof H.-P.; Kohlbacher O.","Moll, Andreas (57196813849); Hildebrandt, Andreas (12238853600); Lenhof, Hans-Peter (6602931980); Kohlbacher, Oliver (6602349901)","57196813849; 12238853600; 6602931980; 6602349901","BALLView: An object-oriented molecular visualization and modeling framework","2005","Journal of Computer-Aided Molecular Design","10.1007/s10822-005-9027-x","39","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33644520261&doi=10.1007%2fs10822-005-9027-x&partnerID=40&md5=5ea6ef3f37ef875decf56739c7e47164","We present BALLView, an extensible tool for visualizing and modeling bio-molecular structures. It provides a variety of different models for bio-molecular visualization, e.g. ball-and-stick models, molecular surfaces, or ribbon models. In contrast to most existing visualization tools, BALLView also offers rich functionality for molecular modeling and simulation, including molecular mechanics methods (AMBER and CHARMM force fields), continuum electrostatics methods employing a Finite-Difference Poisson Boltzmann solver, and secondary structure calculation. Results of these computations can be exported as publication quality images or as movies. Even unexperienced users have direct access to this functionality through an intuitive graphical user interface, which makes BALLView particularly useful for teaching. For more advanced users, BALLView is extensible in different ways. Owing to its framework design, extension on the level of C++ code is very convenient. In addition, an interface to the scripting language Python allows the interactive rapid prototyping of new methods. BALLView is portable and runs on all major platforms (Windows, MacOS X, Linux, most Unix flavors). It is available free of charge under the GNU Public License (GPL) from our website http://www.ballview.org. © Springer 2006.","Molecular dynamics; Molecular mechanics; Molecular modeling; Molecular visualization; Rapid prototyping","Article","Scopus"
"Ferreira I.C.; Aragão M.V.C.; Oliveira E.M.; Kuehne B.T.; Moreira E.M.; Carpinteiro O.A.S.","Ferreira, Isaac C. (57302123100); Aragão, Marcelo V. C. (57190585422); Oliveira, Edvard M. (56516159100); Kuehne, Bruno T. (27067840700); Moreira, Edmilson M. (11939758400); Carpinteiro, Otávio A. S. (6603455175)","57302123100; 57190585422; 56516159100; 27067840700; 11939758400; 6603455175","The Development of the Open Machine-Learning-Based Anti-Spam (Open-MaLBAS)","2021","IEEE Access","10.1109/ACCESS.2021.3118901","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117470392&doi=10.1109%2fACCESS.2021.3118901&partnerID=40&md5=b8e77488a3076be7b6949b7a652d6707","Spam e-mails are unsolicited e-mails received by users of the e-mail service. Spam e-mails cause serious harm to organizations, for they waste, among other things, their computational and networking resources. To reduce the damage caused by them, organizations use anti-spams. Anti-spams are software systems that classify e-mails in order to separate legitimate from spam e-mails. The best current commercial and open-source anti-spams, and in particular the well-known commercial anti-spam CanIt-PRO, make use of various techniques, such as blacklists and/or SMTP extensions, to classify e-mails. Unfortunately, both blacklists and SMTP extensions have serious drawbacks, such as low scalability and high computational and network costs. This paper introduces the Open Machine-Learning-Based Anti-Spam (Open-MaLBAS). Unlike the best current anti-spams, Open-MaLBAS does not make use of blacklists and SMTP extensions, but only of machine learning models for e-mail classification. Open-MaLBAS was compared to CanIt-PRO in a series of experiments on a database composed of 862,227 real e-mails, collected over three months at the Federal University of Itajubá, Brazil. The e-mails were previously classified by CanIt-PRO. From the experiments, it was observed that Open-MaLBAS was able to correctly classify 81.48% and 98.13% of the e-mails in the database, using, respectively, the two models-Multi-Layer Perceptron and Random Forest-evaluated. In addition, it managed to obtain times of up to 88% shorter than those of CanIt-PRO to classify all e-mails in the database. Open-MaLBAS is implemented in Java language, under free software license, for free use. It is available on GitHub.  © 2013 IEEE.","Electronic mail (e-mail); internet; machine learning; network security; open source software; simple mail transfer protocol (SMTP); software engineering; unsolicited electronic mail (spam)","Article","Scopus"
"Hansen T.M.; Cordua K.S.; Looms M.C.; Mosegaard K.","Hansen, Thomas Mejer (35402645500); Cordua, Knud Skou (23972583700); Looms, Majken Caroline (23972861700); Mosegaard, Klaus (55879596700)","35402645500; 23972583700; 23972861700; 55879596700","SIPPI: A Matlab toolbox for sampling the solution to inverse problems with complex prior information: Part 2-Application to crosshole GPR tomography","2013","Computers and Geosciences","10.1016/j.cageo.2012.10.001","32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872819222&doi=10.1016%2fj.cageo.2012.10.001&partnerID=40&md5=d13bbfc8a1048996093a9f9147448e1a","We present an application of the SIPPI Matlab toolbox, to obtain a sample from the a posteriori probability density function for the classical tomographic inversion problem. We consider a number of different forward models, linear and non-linear, such as ray based forward models that rely on the high frequency approximation of the wave-equation and 'fat' ray based forward models relying on finite frequency theory. In order to sample the a posteriori probability density function we make use of both least squares based inversion, for linear Gaussian inverse problems, and the extended Metropolis sampler, for non-linear non-Gaussian inverse problems. To illustrate the applicability of the SIPPI toolbox to a tomographic field data set we use a cross-borehole traveltime data set from Arrenæs, Denmark. Both the computer code and the data are released in the public domain using open source and open data licenses. The code has been developed to facilitate inversion of 2D and 3D travel time tomographic data using a wide range of possible a priori models and choices of forward models. © 2012 Elsevier Ltd.","A posteriori; A priori; Inversion; Non-linear; Sampling; Tomography","Article","Scopus"
"Kawama K.; Fukushima Y.; Ikeguchi M.; Ohta M.; Yoshidome T.","Kawama, Kosuke (57711348200); Fukushima, Yusaku (57711348300); Ikeguchi, Mitsunori (7103349462); Ohta, Masateru (57710584000); Yoshidome, Takashi (13608916400)","57711348200; 57711348300; 7103349462; 57710584000; 13608916400","Gr Predictor: A Deep Learning Model for Predicting the Hydration Structures around Proteins","2022","Journal of Chemical Information and Modeling","10.1021/acs.jcim.2c00987","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137926984&doi=10.1021%2facs.jcim.2c00987&partnerID=40&md5=d88d786623d4a0823d9015f3b179b962","Among the factors affecting biological processes such as protein folding and ligand binding, hydration, which is represented by a three-dimensional water site distribution function around the protein, is crucial. The typical methods for computing the distribution functions, including molecular dynamics simulations and the three-dimensional reference interaction site model (3D-RISM) theory, require a long computation time ranging from hours to tens of hours. Here, we propose a deep learning (DL) model that rapidly estimates the distribution functions around proteins obtained using the 3D-RISM theory from the protein 3D structure. The distribution functions predicted using our DL model are in good agreement with those obtained using the 3D-RISM theory. Particularly, the coefficient of determination between the distribution function obtained by the DL model and that obtained using the 3D-RISM theory is approximately 0.98. Furthermore, using a graphics processing unit, the prediction by the DL model is completed in less than 1 min, more than 2 orders of magnitude faster than the calculation time of the 3D-RISM theory. The position of water molecules around the protein was estimated based on the distribution function obtained by our DL model, and the position of waters estimated by our DL model was in good agreement with that of water molecules estimated using the 3D-RISM theory and of crystallographic waters. Therefore, our DL model provides a practical and efficient way to calculate the three-dimensional water site distribution functions and to estimate the position of water molecules around the protein. The program called ""gr Predictor"" is available under the GNU General Public License from https://github.com/YoshidomeGroup-Hydration/gr-predictor. © 2022 American Chemical Society. All rights reserved.","","Article","Scopus"
"Chalk S.J.","Chalk, Stuart J. (6603873609)","6603873609","The Open Spectral Database: An open platform for sharing and searching spectral data","2016","Journal of Cheminformatics","10.1186/s13321-016-0170-2","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992315699&doi=10.1186%2fs13321-016-0170-2&partnerID=40&md5=69281c55bb6af565f563bdcbdea8cfb1","Background: A number of websites make available spectral data for download (typically as JCAMP-DX text files) and one (ChemSpider) that also allows users to contribute spectral files. As a result, searching and retrieving such spectral data can be time consuming, and difficult to reuse if the data is compressed in the JCAMP-DX file. What is needed is a single resource that allows submission of JCAMP-DX files, export of the raw data in multiple formats, searching based on multiple chemical identifiers, and is open in terms of license and access. To address these issues a new online resource called the Open Spectral Database (OSDB) http://osdb.info/ has been developed and is now available. Built using open source tools, using open code (hosted on GitHub), providing open data, and open to community input about design and functionality, the OSDB is available for anyone to submit spectral data, making it searchable and available to the scientific community. This paper details the concept and coding, internal architecture, export formats, Representational State Transfer (REST) Application Programming Interface and options for submission of data. Results: The OSDB website went live in November 2015. Concurrently, the GitHub repository was made available at https://github.com/stuchalk/OSDB/, and is open for collaborators to join the project, submit issues, and contribute code. Conclusion: The combination of a scripting environment (PHPStorm), a PHP Framework (CakePHP), a relational database (MySQL) and a code repository (GitHub) provides all the capabilities to easily develop REST based websites for ingestion, curation and exposure of open chemical data to the community at all levels. It is hoped this software stack (or equivalent ones in other scripting languages) will be leveraged to make more chemical data available for both humans and computers. © 2016 The Author(s).","JCAMP-DX; Open data; Open science; REST API; Scientific data model; Spectral data; XML","Article","Scopus"
"Yang P.; Oldfield A.; Kim T.; Yang A.; Yang J.Y.H.; Ho J.W.K.","Yang, Pengyi (55479219200); Oldfield, Andrew (16064501500); Kim, Taiyun (57212571936); Yang, Andrian (56508878700); Yang, Jean Yee Hwa (7409391345); Ho, Joshua W. K. (14527168600)","55479219200; 16064501500; 57212571936; 56508878700; 7409391345; 14527168600","Integrative analysis identifies co-dependent gene expression regulation of BRG1 and CHD7 at distal regulatory sites in embryonic stem cells","2017","Bioinformatics","10.1093/bioinformatics/btx092","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021828588&doi=10.1093%2fbioinformatics%2fbtx092&partnerID=40&md5=c8dce3c611b3938ef7bce3be6321736c","Motivation: DNA binding proteins such as chromatin remodellers, transcription factors (TFs), histone modifiers and co-factors often bind cooperatively to activate or repress their target genes in a cell type-specific manner. Nonetheless, the precise role of cooperative binding in defining cell-type identity is still largely uncharacterized. Results: Here, we collected and analyzed 214 public datasets representing chromatin immunoprecipitation followed by sequencing (ChIP-Seq) of 104 DNA binding proteins in embryonic stem cell (ESC) lines. We classified their binding sites into those proximal to gene promoters and those in distal regions, and developed a web resource called Proximal And Distal (PAD) clustering to identify their co-localization at these respective regions. Using this extensive dataset, we discovered an extensive co-localization of BRG1 and CHD7 at distal but not proximal regions. The comparison of co-localization sites to those bound by either BRG1 or CHD7 alone showed an enrichment of ESC master TFs binding and active chromatin architecture at co-localization sites. Most notably, our analysis reveals the co-dependency of BRG1 and CHD7 at distal regions on regulating expression of their common target genes in ESC. This work sheds light on cooperative binding of TF binding proteins in regulating gene expression in ESC, and demonstrates the utility of integrative analysis of a manually curated compendium of genome-wide protein binding profiles in our online resource PAD. Availability and Implementation: PAD is freely available at http://pad.victorchang.edu.au/and its source code is available via an open source GPL 3.0 license at https://github.com/VCCRI/PAD. © 2017 The Author.","","Article","Scopus"
